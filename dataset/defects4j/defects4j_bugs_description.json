{
  "Chart_1": {
    "description": "#983 Potential NPE in AbstractCategoryItemRender.getLegendItems()\nSetting up a working copy of the current JFreeChart trunk in Eclipse I got a warning about a null pointer access in this bit of code from AbstractCategoryItemRender.java:\npublic LegendItemCollection getLegendItems() {\nLegendItemCollection result = new LegendItemCollection();\nif (this.plot == null) {\nreturn result;\n}\nint index = this.plot.getIndexOf(this);\nCategoryDataset dataset = this.plot.getDataset(index);\nif (dataset != null) {\nreturn result;\n}\nint seriesCount = dataset.getRowCount();\n...\n}\nThe warning is in the last code line where seriesCount is assigned. The variable dataset is guaranteed to be null in this location, I suppose that the check before that should actually read \"if (dataset == null)\", not \"if (dataset != null)\".\nThis is trunk as of 2010-02-08.",
    "desc_source": "sourceforge"
  },
  "Chart_2": {
    "description": "#959 Bugs in DatasetUtilities.iterateRangeBounds() methods\nAll explained in this forum post:\nhttp://www.jfree.org/phpBB2/viewtopic.php?f=3&t=29171",
    "desc_source": "sourceforge"
  },
  "Chart_3": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_4": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_5": {
    "description": "#862 XYSeries.addOrUpdate() should add if duplicates are allowed\nCopied from this post (by Ted Schwartz) in the forum:\nhttp://www.jfree.org/phpBB2/viewtopic.php?t=24523\nI've found a bug in jfreechart-1.0.9 code for org.jfree.data.xy.XYSeries. There was a change some time ago which introduced the notion of allowing duplicate X values in XYSeries data. The method addOrUpdate(Number x, Number y) was never modified to support this, and therefore duplicate data were overwriting existing data. This is the fix I've made, but I don't know how to submit a patch...\n$ diff original/jfreechart-1.0.9/source/org/jfree/data/xy/XYSeries.java fixed/org/jfree/data/xy/XYSeries.java\n537c537\n< if (index >= 0) {\n---\n> if (index >= 0 && !allowDuplicateXValues) {\n545a546,559\n> } else if (index >= 0){\n> XYDataItem item = new XYDataItem(x, y);\n> // need to make sure we are adding *after* any duplicates\n> int size = this.data.size();\n> while (index < size\n> && item.compareTo(this.data.get(index)) == 0) {\n> index++;\n> }\n> if (index < this.data.size()) {\n> this.data.add(index, item);\n> }\n> else {\n> this.data.add(item);\n> }\n558,561d571\n< // check if this addition will exceed the maximum item count...\n< if (getItemCount() > this.maximumItemCount) {\n< this.data.remove(0);\n< }\n562a573,576\n> // check if this addition will exceed the maximum item count...\n> if (getItemCount() > this.maximumItemCount) {\n> this.data.remove(0);\n> }",
    "desc_source": "sourceforge"
  },
  "Chart_6": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_7": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_8": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_9": {
    "description": "#818 Error on TimeSeries createCopy() method\nThe test case at the end fails with :\njava.lang.IllegalArgumentException: Requires start <= end.\nThe problem is in that the int start and end indexes corresponding to given timePeriod are computed incorectly. Here I would expect an empty serie to be returned, not an exception. This is with jfreechart 1.0.7\npublic class foo {\nstatic public void main(String args[]) {\n        TimeSeries foo = new TimeSeries(\"foo\",Day.class);\n        foo.add(new Day(19,4,2005),1);\n        foo.add(new Day(25,5,2005),1);\n        foo.add(new Day(28,5,2005),1);\n        foo.add(new Day(30,5,2005),1);\n        foo.add(new Day(1,6,2005),1);\n        foo.add(new Day(3,6,2005),1);\n        foo.add(new Day(19,8,2005),1);\n        foo.add(new Day(31,1,2006),1);\n    try \\{\n        TimeSeries bar = foo.createCopy\\(new Day\\(1,12,2005\\),new Day\\(18,1,2006\\)\\);\n    \\} catch \\(CloneNotSupportedException e\\) \\{\n\n        e.printStackTrace\\(\\);\n\n}\n}",
    "desc_source": "sourceforge"
  },
  "Chart_10": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_11": {
    "description": "#868 JCommon 1.0.12 ShapeUtilities.equal(path1,path2)\nThe comparison of two GeneralPath objects uses the same PathIterator for both objects. equal(GeneralPath path1, GeneralPath path2) will thus return true for any pair of non-null GeneralPath instances having the same windingRule.",
    "desc_source": "sourceforge"
  },
  "Chart_12": {
    "description": "#213 Fix for MultiplePiePlot\nWhen dataset is passed into constructor for MultiplePiePlot, the dataset is not wired to a listener, as it would be if setDataset is called.",
    "desc_source": "sourceforge"
  },
  "Chart_13": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_14": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_15": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_16": {
    "description": "#834 Bug propgated from v1.0.5 on to present\nThe method getRowCount() in class org.jfree.data.category.DefaultIntervalCategoryDataset says that it \"Returns the number of series in the dataset (possibly zero).\"  \nThe implementation from v1.0.5 on no longer checks for a null condition (which would then return a zero) on the seriesKeys as it did in v1.0.4 and previous.  This now throws a Null Pointer if seriesKeys never got initialized and the getRowCount() method is called.",
    "desc_source": "sourceforge"
  },
  "Chart_17": {
    "description": "#803 cloning of TimeSeries\nIt's just a minor bug!\nWhen I clone a TimeSeries which has no items, I get an IllegalArgumentException (\"Requires start <= end\").\nBut I don't think the user should be responsible for checking whether the TimeSeries has any items or not.",
    "desc_source": "sourceforge"
  },
  "Chart_18": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_19": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_20": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_21": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_22": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_23": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_24": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_25": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Chart_26": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Math_1": {
    "description": "Fraction specified with maxDenominator and a value very close to a simple fraction should not throw an overflow exception\nAn overflow exception is thrown when a Fraction is initialized with a maxDenominator from a double that is very close to a simple\nfraction.  For example:\n\ndouble d = 0.5000000001;\nFraction f = new Fraction(d, 10);\n\nPatch with unit test on way.",
    "desc_source": "jira"
  },
  "Math_2": {
    "description": "HypergeometricDistribution.sample suffers from integer overflow\nHi, I have an application which broke when ported from commons math 2.2 to 3.2. It looks like the HypergeometricDistribution.sample() method doesn't work as well as it used to with large integer values -- the example code below should return a sample between 0 and 50, but usually returns -50.\n\n{code}\nimport org.apache.commons.math3.distribution.HypergeometricDistribution;\n\npublic class Foo {\n  public static void main(String[] args) {\n    HypergeometricDistribution a = new HypergeometricDistribution(\n        43130568, 42976365, 50);\n    System.out.printf(\"%d %d%n\", a.getSupportLowerBound(), a.getSupportUpperBound()); // Prints \"0 50\"\n    System.out.printf(\"%d%n\",a.sample());                                             // Prints \"-50\"\n  }\n}\n{code}\n\nIn the debugger, I traced it as far as an integer overflow in HypergeometricDistribution.getNumericalMean() -- instead of doing\n{code}\nreturn (double) (getSampleSize() * getNumberOfSuccesses()) / (double) getPopulationSize();\n{code}\nit could do:\n{code}\nreturn getSampleSize() * ((double) getNumberOfSuccesses() / (double) getPopulationSize());\n{code}\nThis seemed to fix it, based on a quick test.",
    "desc_source": "jira"
  },
  "Math_3": {
    "description": "ArrayIndexOutOfBoundsException in MathArrays.linearCombination\nWhen MathArrays.linearCombination is passed arguments with length 1, it throws an ArrayOutOfBoundsException. This is caused by this line:\n\ndouble prodHighNext = prodHigh[1];\n\nlinearCombination should check the length of the arguments and fall back to simple multiplication if length == 1.",
    "desc_source": "jira"
  },
  "Math_4": {
    "description": "NPE when calling SubLine.intersection() with non-intersecting lines\nWhen calling SubLine.intersection() with two lines that not intersect, then a NullPointerException is thrown in Line.toSubSpace(). This bug is in the twod and threed implementations.\n\nThe attached patch fixes both implementations and adds the required test cases.\n\n",
    "desc_source": "jira"
  },
  "Math_5": {
    "description": "Complex.ZERO.reciprocal() returns NaN but should return INF.\nComplex.ZERO.reciprocal() returns NaN but should return INF.\n\nClass: org.apache.commons.math3.complex.Complex;\nMethod: reciprocal()\n@version $Id: Complex.java 1416643 2012-12-03 19:37:14Z tn $\n",
    "desc_source": "jira"
  },
  "Math_6": {
    "description": "LevenbergMarquardtOptimizer reports 0 iterations\nThe method LevenbergMarquardtOptimizer.getIterations() does not report the correct number of iterations; It always returns 0. A quick look at the code shows that only SimplexOptimizer calls BaseOptimizer.incrementEvaluationsCount()\n\nI've put a test case below. Notice how the evaluations count is correctly incremented, but the iterations count is not.\n\n{noformat}\n    @Test\n    public void testGetIterations() {\n        // setup\n        LevenbergMarquardtOptimizer otim = new LevenbergMarquardtOptimizer();\n\n        // action\n        otim.optimize(new MaxEval(100), new Target(new double[] { 1 }),\n                new Weight(new double[] { 1 }), new InitialGuess(\n                        new double[] { 3 }), new ModelFunction(\n                        new MultivariateVectorFunction() {\n                            @Override\n                            public double[] value(double[] point)\n                                    throws IllegalArgumentException {\n                                return new double[] { FastMath.pow(point[0], 4) };\n                            }\n                        }), new ModelFunctionJacobian(\n                        new MultivariateMatrixFunction() {\n                            @Override\n                            public double[][] value(double[] point)\n                                    throws IllegalArgumentException {\n                                return new double[][] { { 0.25 * FastMath.pow(\n                                        point[0], 3) } };\n                            }\n                        }));\n\n        // verify\n        assertThat(otim.getEvaluations(), greaterThan(1));\n        assertThat(otim.getIterations(), greaterThan(1));\n    }\n\n{noformat}",
    "desc_source": "jira"
  },
  "Math_7": {
    "description": "event state not updated if an unrelated event triggers a RESET_STATE during ODE integration\nWhen an ODE solver manages several different event types, there are some unwanted side effects.\n\nIf one event handler asks for a RESET_STATE (for integration state) when its eventOccurred method is called, the other event handlers that did not trigger an event in the same step are not updated correctly, due to an early return.\n\nAs a result, when the next step is processed with a reset integration state, the forgotten event still refer to the start date of the previous state. This implies that when these event handlers will be checked for In some cases, the function defining an event g(double t, double[] y) is called with state parameters y that are completely wrong. In one case when the y array should have contained values between -1 and +1, one function call got values up to 1.0e20.\n\nThe attached file reproduces the problem.\n",
    "desc_source": "jira"
  },
  "Math_8": {
    "description": "DiscreteDistribution.sample(int) may throw an exception if first element of singletons of sub-class type\nCreating an array with {{Array.newInstance(singletons.get(0).getClass(), sampleSize)}} in DiscreteDistribution.sample(int) is risky. An exception will be thrown if:\n* {{singleons.get(0)}} is of type T1, an sub-class of T, and\n* {{DiscreteDistribution.sample()}} returns an object which is of type T, but not of type T1.\n\nTo reproduce:\n{code}\nList<Pair<Object,Double>> list = new ArrayList<Pair<Object, Double>>();\nlist.add(new Pair<Object, Double>(new Object() {}, new Double(0)));\nlist.add(new Pair<Object, Double>(new Object() {}, new Double(1)));\nnew DiscreteDistribution<Object>(list).sample(1);\n{code}\n\nAttaching a patch.",
    "desc_source": "jira"
  },
  "Math_9": {
    "description": "Line.revert() is imprecise\nLine.revert() only maintains ~10 digits for the direction. This becomes an issue when the line's position is evaluated far from the origin. A simple fix would be to use Vector3D.negate() for the direction.\n\nAlso, is there a reason why Line is not immutable? It is just comprised of two vectors.",
    "desc_source": "jira"
  },
  "Math_10": {
    "description": "DerivativeStructure.atan2(y,x) does not handle special cases properly\nThe four special cases +/-0 for both x and y should give the same values as Math.atan2 and FastMath.atan2. However, they give NaN for the value in all cases.",
    "desc_source": "jira"
  },
  "Math_11": {
    "description": "MultivariateNormalDistribution.density(double[]) returns wrong value when the dimension is odd\nTo reproduce:\n{code}\nAssert.assertEquals(0.398942280401433, new MultivariateNormalDistribution(new double[]{0}, new double[][]{{1}}).density(new double[]{0}), 1e-15);\n{code}",
    "desc_source": "jira"
  },
  "Math_12": {
    "description": "GammaDistribution cloning broken\nSerializing a GammaDistribution and deserializing it, does not result in a cloned distribution that produces the same samples.\n\nCause: GammaDistribution inherits from AbstractRealDistribution, which implements Serializable. AbstractRealDistribution has random, in which we have a Well19937c instance, which inherits from AbstractWell. AbstractWell implements Serializable. AbstractWell inherits from BitsStreamGenerator, which is not Serializable, but does have a private field 'nextGaussian'.\n\nSolution: Make BitStreamGenerator implement Serializable as well.\n\nThis probably affects other distributions as well.",
    "desc_source": "jira"
  },
  "Math_13": {
    "description": "new multivariate vector optimizers cannot be used with large number of weights\nWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers, an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large.\n\nThis happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points, which created a matrix with 1.7 billion elements.",
    "desc_source": "jira"
  },
  "Math_14": {
    "description": "new multivariate vector optimizers cannot be used with large number of weights\nWhen using the Weigth class to pass a large number of weights to multivariate vector optimizers, an nxn full matrix is created (and copied) when a n elements vector is used. This exhausts memory when n is large.\n\nThis happens for example when using curve fitters (even simple curve fitters like polynomial ones for low degree) with large number of points. I encountered this with curve fitting on 41200 points, which created a matrix with 1.7 billion elements.",
    "desc_source": "jira"
  },
  "Math_15": {
    "description": "FastMath.pow deviates from Math.pow for negative, finite base values with an exponent 2^52 < y < 2^53 \nAs reported by Jeff Hain:\n\npow(double,double):\nMath.pow(-1.0,5.000000000000001E15) = -1.0\nFastMath.pow(-1.0,5.000000000000001E15) = 1.0\n===> This is due to considering that power is an even\ninteger if it is >= 2^52, while you need to test\nthat it is >= 2^53 for it.\n===> replace\n\"if (y >= TWO_POWER_52 || y <= -TWO_POWER_52)\"\nwith\n\"if (y >= 2*TWO_POWER_52 || y <= -2*TWO_POWER_52)\"\nand that solves it.",
    "desc_source": "jira"
  },
  "Math_16": {
    "description": "FastMath.[cosh, sinh] do not support the same range of values as the Math counterparts\nAs reported by Jeff Hain:\n\ncosh(double) and sinh(double):\nMath.cosh(709.783) = 8.991046692770538E307\nFastMath.cosh(709.783) = Infinity\nMath.sinh(709.783) = 8.991046692770538E307\nFastMath.sinh(709.783) = Infinity\n===> This is due to using exp( x )/2 for values of |x|\nabove 20: the result sometimes should not overflow,\nbut exp( x ) does, so we end up with some infinity.\n===> for values of |x| >= StrictMath.log(Double.MAX_VALUE),\nexp will overflow, so you need to use that instead:\nfor x positive:\ndouble t = exp(x*0.5);\nreturn (0.5*t)*t;\nfor x negative:\ndouble t = exp(-x*0.5);\nreturn (-0.5*t)*t;",
    "desc_source": "jira"
  },
  "Math_17": {
    "description": "Dfp Dfp.multiply(int x) does not comply with the general contract FieldElement.multiply(int n)\nIn class {{org.apache.commons.math3.Dfp}},  the method {{multiply(int n)}} is limited to {{0 <= n <= 9999}}. This is not consistent with the general contract of {{FieldElement.multiply(int n)}}, where there should be no limitation on the values of {{n}}.",
    "desc_source": "jira"
  },
  "Math_18": {
    "description": "CMAESOptimizer with bounds fits finely near lower bound and coarsely near upper bound. \nWhen fitting with bounds, the CMAESOptimizer fits finely near the lower bound and coarsely near the upper bound.  This is because it internally maps the fitted parameter range into the interval [0,1].  The unit of least precision (ulp) between floating point numbers is much smaller near zero than near one.  Thus, fits have much better resolution near the lower bound (which is mapped to zero) than the upper bound (which is mapped to one).  I will attach a example program to demonstrate.",
    "desc_source": "jira"
  },
  "Math_19": {
    "description": "Wide bounds to CMAESOptimizer result in NaN parameters passed to fitness function\nIf you give large values as lower/upper bounds (for example -Double.MAX_VALUE as a lower bound), the optimizer can call the fitness function with parameters set to NaN.  My guess is this is due to FitnessFunction.encode/decode generating NaN when normalizing/denormalizing parameters.  For example, if the difference between the lower and upper bound is greater than Double.MAX_VALUE, encode could divide infinity by infinity.",
    "desc_source": "jira"
  },
  "Math_20": {
    "description": "CMAESOptimizer does not enforce bounds\nThe CMAESOptimizer can exceed the bounds passed to optimize.  Looking at the generationLoop in doOptimize(), it does a bounds check by calling isFeasible() but if checkFeasableCount is zero (the default) then isFeasible() is never even called.  Also, even with non-zero checkFeasableCount it may give up before finding an in-bounds offspring and go forward with an out-of-bounds offspring.  This is against svn revision 1387637.  I can provide an example program where the optimizer ends up with a fit outside the prescribed bounds if that would help.",
    "desc_source": "jira"
  },
  "Math_21": {
    "description": "Correlated random vector generator fails (silently) when faced with zero rows in covariance matrix\nThe following three matrices (which are basically permutations of each other) produce different results when sampling a multi-variate Gaussian with the help of CorrelatedRandomVectorGenerator (sample covariances calculated in R, based on 10,000 samples):\n\nArray2DRowRealMatrix{\n{0.0,0.0,0.0,0.0,0.0},\n{0.0,0.013445532,0.01039469,0.009881156,0.010499559},\n{0.0,0.01039469,0.023006616,0.008196856,0.010732709},\n{0.0,0.009881156,0.008196856,0.019023866,0.009210099},\n{0.0,0.010499559,0.010732709,0.009210099,0.019107243}}\n\n> cov(data1)\n   V1 V2 V3 V4 V5\nV1 0 0.000000000 0.00000000 0.000000000 0.000000000\nV2 0 0.013383931 0.01034401 0.009913271 0.010506733\nV3 0 0.010344006 0.02309479 0.008374730 0.010759306\nV4 0 0.009913271 0.00837473 0.019005488 0.009187287\nV5 0 0.010506733 0.01075931 0.009187287 0.019021483\n\nArray2DRowRealMatrix{\n{0.013445532,0.01039469,0.0,0.009881156,0.010499559},\n{0.01039469,0.023006616,0.0,0.008196856,0.010732709},\n{0.0,0.0,0.0,0.0,0.0},\n{0.009881156,0.008196856,0.0,0.019023866,0.009210099},\n{0.010499559,0.010732709,0.0,0.009210099,0.019107243}}\n\n> cov(data2)\n            V1 V2 V3 V4 V5\nV1 0.006922905 0.010507692 0 0.005817399 0.010330529\nV2 0.010507692 0.023428918 0 0.008273152 0.010735568\nV3 0.000000000 0.000000000 0 0.000000000 0.000000000\nV4 0.005817399 0.008273152 0 0.004929843 0.009048759\nV5 0.010330529 0.010735568 0 0.009048759 0.018683544 \n\nArray2DRowRealMatrix{\n{0.013445532,0.01039469,0.009881156,0.010499559},\n{0.01039469,0.023006616,0.008196856,0.010732709},\n{0.009881156,0.008196856,0.019023866,0.009210099},\n{0.010499559,0.010732709,0.009210099,0.019107243}}\n\n> cov(data3)\n            V1          V2          V3          V4\nV1 0.013445047 0.010478862 0.009955904 0.010529542\nV2 0.010478862 0.022910522 0.008610113 0.011046353\nV3 0.009955904 0.008610113 0.019250975 0.009464442\nV4 0.010529542 0.011046353 0.009464442 0.019260317\n\n\nI've traced this back to the RectangularCholeskyDecomposition, which does not seem to handle the second matrix very well (decompositions in the same order as the matrices above):\n\nCorrelatedRandomVectorGenerator.getRootMatrix() = \nArray2DRowRealMatrix{{0.0,0.0,0.0,0.0,0.0},{0.0759577418122063,0.0876125188474239,0.0,0.0,0.0},{0.07764443622513505,0.05132821221460752,0.11976381821791235,0.0,0.0},{0.06662930527909404,0.05501661744114585,0.0016662506519307997,0.10749324207653632,0.0},{0.13822895138139477,0.0,0.0,0.0,0.0}}\nCorrelatedRandomVectorGenerator.getRank() = 5\n\nCorrelatedRandomVectorGenerator.getRootMatrix() = \nArray2DRowRealMatrix{{0.0759577418122063,0.034512751379448724,0.0},{0.07764443622513505,0.13029949164628746,0.0},{0.0,0.0,0.0},{0.06662930527909404,0.023203936694855674,0.0},{0.13822895138139477,0.0,0.0}}\nCorrelatedRandomVectorGenerator.getRank() = 3\n\nCorrelatedRandomVectorGenerator.getRootMatrix() = \nArray2DRowRealMatrix{{0.0759577418122063,0.034512751379448724,0.033913748226348225,0.07303890149947785},{0.07764443622513505,0.13029949164628746,0.0,0.0},{0.06662930527909404,0.023203936694855674,0.11851573313229945,0.0},{0.13822895138139477,0.0,0.0,0.0}}\nCorrelatedRandomVectorGenerator.getRank() = 4\n\nClearly, the rank of each of these matrices should be 4. The first matrix does not lead to incorrect results, but the second one does. Unfortunately, I don't know enough about the Cholesky decomposition to find the flaw in the implementation, and I could not find documentation for the \"rectangular\" variant (also not at the links provided in the javadoc).",
    "desc_source": "jira"
  },
  "Math_22": {
    "description": "Fix and then deprecate isSupportXxxInclusive in RealDistribution interface\nThe conclusion from [1] was never implemented. We should deprecate these\nproperties from the RealDistribution interface, but since removal\nwill have to wait until 4.0, we should agree on a precise\ndefinition and fix the code to match it in the mean time.\n\nThe definition that I propose is that isSupportXxxInclusive means\nthat when the density function is applied to the upper or lower\nbound of support returned by getSupportXxxBound, a finite (i.e. not\ninfinite), not NaN value is returned.\n\n[1] http://markmail.org/message/dxuxh7eybl7xejde\n",
    "desc_source": "jira"
  },
  "Math_23": {
    "description": "\"BrentOptimizer\" not always reporting the best point\n{{BrentOptimizer}} (package \"o.a.c.m.optimization.univariate\") does not check that the point it is going to return is indeed the best one it has encountered. Indeed, the last evaluated point might be slightly worse than the one before last.",
    "desc_source": "jira"
  },
  "Math_24": {
    "description": "\"BrentOptimizer\" not always reporting the best point\n{{BrentOptimizer}} (package \"o.a.c.m.optimization.univariate\") does not check that the point it is going to return is indeed the best one it has encountered. Indeed, the last evaluated point might be slightly worse than the one before last.",
    "desc_source": "jira"
  },
  "Math_25": {
    "description": "\"HarmonicFitter.ParameterGuesser\" sometimes fails to return sensible values\nThe inner class \"ParameterGuesser\" in \"HarmonicFitter\" (package \"o.a.c.m.optimization.fitting\") fails to compute a usable guess for the \"amplitude\" parameter.\n",
    "desc_source": "jira"
  },
  "Math_26": {
    "description": "Fraction(double, int) constructor strange behaviour\nThe Fraction constructor Fraction(double, int) takes a double value and a int maximal denominator, and approximates a fraction. When the double value is a large, negative number with many digits in the fractional part, and the maximal denominator is a big, positive integer (in the 100'000s), two distinct bugs can manifest:\n\n1: the constructor returns a positive Fraction. Calling Fraction(-33655.1677817278, 371880) returns the fraction 410517235/243036, which both has the wrong sign, and is far away from the absolute value of the given value\n\n2: the constructor does not manage to reduce the Fraction properly. Calling Fraction(-43979.60679604749, 366081) returns the fraction -1651878166/256677, which should have* been reduced to -24654898/3831.\n\nI have, as of yet, not found a solution. The constructor looks like this:\n\npublic Fraction(double value, int maxDenominator)\n        throws FractionConversionException\n    {\n       this(value, 0, maxDenominator, 100);\n    }\n\nIncreasing the 100 value (max iterations) does not fix the problem for all cases. Changing the 0-value (the epsilon, maximum allowed error) to something small does not work either, as this breaks the tests in FractionTest. \n\nThe problem is not neccissarily that the algorithm is unable to approximate a fraction correctly. A solution where a FractionConversionException had been thrown in each of these examples would probably be the best solution if an improvement on the approximation algorithm turns out to be hard to find.\n\nThis bug has been found when trying to explore the idea of axiom-based testing (http://bldl.ii.uib.no/testing.html). Attached is a java test class FractionTestByAxiom (junit, goes into org.apache.commons.math3.fraction) which shows these bugs through a simplified approach to this kind of testing, and a text file describing some of the value/maxDenominator combinations which causes one of these failures.\n\n* It is never specified in the documentation that the Fraction class guarantees that completely reduced rational numbers are constructed, but a comment inside the equals method claims that \"since fractions are always in lowest terms, numerators and can be compared directly for equality\", so it seems like this is the intention. ",
    "desc_source": "jira"
  },
  "Math_27": {
    "description": "Fraction percentageValue rare overflow\nThe percentageValue() method of the Fraction class works by first multiplying the Fraction by 100, then converting the Fraction to a double. This causes overflows when the numerator is greater than Integer.MAX_VALUE/100, even when the value of the fraction is far below this value.\n\nThe patch changes the method to first convert to a double value, and then multiply this value by 100 - the result should be the same, but with less overflows. An addition to the test for the method that covers this bug is also included.",
    "desc_source": "jira"
  },
  "Math_28": {
    "description": "Not expected UnboundedSolutionException\nSimplexSolver throws UnboundedSolutionException when trying to solve minimization linear programming problem. The number of exception thrown depends on the number of variables.\n\nIn order to see that behavior of SimplexSolver first try to run JUnit test setting a final variable ENTITIES_COUNT = 2 and that will give almost good result and then set it to 15 and you'll get a massive of unbounded exceptions.\nFirst iteration is runned with predefined set of input data with which the Solver gives back an appropriate result.\n\nThe problem itself is well tested by it's authors (mathematicians who I believe know what they developed) using Matlab 10 with no unbounded solutions on the same rules of creatnig random variables values.\n\nWhat is strange to me is the dependence of the number of UnboundedSolutionException exceptions on the number of variables in the problem.\n\nThe problem is formulated as\nmin(1*t + 0*L) (for every r-th subject)\ns.t.\n-q(r) + QL >= 0\nx(r)t - XL >= 0\nL >= 0\nwhere \nr = 1..R, \nL = {l(1), l(2), ..., l(R)} (vector of R rows and 1 column),\nQ - coefficients matrix MxR\nX - coefficients matrix NxR ",
    "desc_source": "jira"
  },
  "Math_29": {
    "description": "Bugs in RealVector.ebeMultiply(RealVector) and ebeDivide(RealVector)\n{{OpenMapRealVector.ebeMultiply(RealVector)}} and {{OpenMapRealVector.ebeDivide(RealVector)}} return wrong values when one entry of the specified {{RealVector}} is nan or infinity. The bug is easy to understand. Here is the current implementation of {{ebeMultiply}}\n\n{code:java}\n    public OpenMapRealVector ebeMultiply(RealVector v) {\n        checkVectorDimensions(v.getDimension());\n        OpenMapRealVector res = new OpenMapRealVector(this);\n        Iterator iter = entries.iterator();\n        while (iter.hasNext()) {\n            iter.advance();\n            res.setEntry(iter.key(), iter.value() * v.getEntry(iter.key()));\n        }\n        return res;\n    }\n{code}\n\nThe assumption is that for any double {{x}}, {{x * 0d == 0d}} holds, which is not true. The bug is easy enough to identify, but more complex to solve. The only solution I can come up with is to loop through *all* entries of v (instead of those entries which correspond to non-zero entries of this). I'm afraid about performance losses.\n\n",
    "desc_source": "jira"
  },
  "Math_30": {
    "description": "Mann-Whitney U Test Suffers From Integer Overflow With Large Data Sets\nWhen performing a Mann-Whitney U Test on large data sets (the attached test uses two 1500 element sets), intermediate integer values used in calculateAsymptoticPValue can overflow, leading to invalid results, such as p-values of NaN, or incorrect calculations.\n\nAttached is a patch, including a test, and a fix, which modifies the affected code to use doubles",
    "desc_source": "jira"
  },
  "Math_31": {
    "description": "inverseCumulativeProbability of BinomialDistribution returns wrong value for large trials.\nThe inverseCumulativeProbability method of the BinomialDistributionImpl class returns wrong value for large trials.  Following code will be reproduce the problem.\n\n{{System.out.println(new BinomialDistributionImpl(1000000, 0.5).inverseCumulativeProbability(0.5));}}\n\nThis returns 499525, though it should be 499999.\n\nI'm not sure how it should be fixed, but the cause is that the cumulativeProbability method returns Infinity, not NaN.  As the result the checkedCumulativeProbability method doesn't work as expected.",
    "desc_source": "jira"
  },
  "Math_32": {
    "description": "BSPTree class and recovery of a Euclidean 3D BRep\nNew to the work here. Thanks for your efforts on this code.\n\nI create a BSPTree from a BoundaryRep (Brep) my test Brep is a cube as represented by a float array containing 8 3D points in(x,y,z) order and an array of indices (12 triplets for the 12 faces of the cube). I construct a BSPMesh() as shown in the code below. I can construct the PolyhedronsSet() but have problems extracting the faces from the BSPTree to reconstruct the BRep. The attached code (BSPMesh2.java) shows that a small change to 1 of the vertex positions causes/corrects the problem.\n\nAny ideas?\n",
    "desc_source": "jira"
  },
  "Math_33": {
    "description": "SimplexSolver gives bad results\nMethode SimplexSolver.optimeze(...) gives bad results with commons-math3-3.0\nin a simple test problem. It works well in commons-math-2.2. ",
    "desc_source": "jira"
  },
  "Math_34": {
    "description": "ListPopulation Iterator allows you to remove chromosomes from the population.\nCalling the iterator method of ListPopulation returns an iterator of the protected modifiable list. Before returning the iterator we should wrap it in an unmodifiable list.",
    "desc_source": "jira"
  },
  "Math_35": {
    "description": "Need range checks for elitismRate in ElitisticListPopulation constructors.\nThere is a range check for setting the elitismRate via ElitisticListPopulation's setElitismRate method, but not via the constructors.",
    "desc_source": "jira"
  },
  "Math_36": {
    "description": "BigFraction.doubleValue() returns Double.NaN for large numerators or denominators\nThe current implementation of doubleValue() divides numerator.doubleValue() / denominator.doubleValue().  BigInteger.doubleValue() fails for any number greater than Double.MAX_VALUE.  So if the user has 308-digit numerator or denominator, the resulting quotient fails, even in cases where the result would be well inside Double's range.\n\nI have a patch to fix it, if I can figure out how to attach it here I will.",
    "desc_source": "jira"
  },
  "Math_37": {
    "description": "[math] Complex Tanh for \"big\" numbers\nHi,\n\nIn Complex.java the tanh is computed with the following formula:\n\ntanh(a + bi) = sinh(2a)/(cosh(2a)+cos(2b)) + [sin(2b)/(cosh(2a)+cos(2b))]i\n\nThe problem that I'm finding is that as soon as \"a\" is a \"big\" number,\nboth sinh(2a) and cosh(2a) are infinity and then the method tanh returns in\nthe real part NaN (infinity/infinity) when it should return 1.0.\n\nWouldn't it be appropiate to add something as in the FastMath library??:\n\nif (real>20.0){\n      return createComplex(1.0, 0.0);\n}\nif (real<-20.0){\n      return createComplex(-1.0, 0.0);\n}\n\n\nBest regards,\n\nJBB\n",
    "desc_source": "jira"
  },
  "Math_38": {
    "description": "Errors in BOBYQAOptimizer when numberOfInterpolationPoints is greater than 2*dim+1\nI've been having trouble getting BOBYQA to minimize a function (actually a non-linear least squares fit) so as one change I increased the number of interpolation points.  It seems that anything larger than 2*dim+1 causes an error (typically at\n\nline 1662\n                   interpolationPoints.setEntry(nfm, ipt, interpolationPoints.getEntry(ipt, ipt));\n\nI'm guessing there is an off by one error in the translation from FORTRAN.  Changing the BOBYQAOptimizerTest as follows (increasing number of interpolation points by one) will cause failures.\n\nBruce\n\n\n\nIndex: src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java\n===================================================================\n--- src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java\t(revision 1221065)\n+++ src/test/java/org/apache/commons/math/optimization/direct/BOBYQAOptimizerTest.java\t(working copy)\n@@ -258,7 +258,7 @@\n //        RealPointValuePair result = optim.optimize(100000, func, goal, startPoint);\n         final double[] lB = boundaries == null ? null : boundaries[0];\n         final double[] uB = boundaries == null ? null : boundaries[1];\n-        BOBYQAOptimizer optim = new BOBYQAOptimizer(2 * dim + 1);\n+        BOBYQAOptimizer optim = new BOBYQAOptimizer(2 * dim + 2);\n         RealPointValuePair result = optim.optimize(maxEvaluations, func, goal, startPoint, lB, uB);\n //        System.out.println(func.getClass().getName() + \" = \" \n //              + optim.getEvaluations() + \" f(\");\n",
    "desc_source": "jira"
  },
  "Math_39": {
    "description": "too large first step with embedded Runge-Kutta integrators (Dormand-Prince 8(5,3) ...)\nAdaptive step size integrators compute the first step size by themselves if it is not provided.\nFor embedded Runge-Kutta type, this step size is not checked against the integration range, so if the integration range is extremely short, this step size may evaluate the function out of the range (and in fact it tries afterward to go back, and fails to stop). Gragg-Bulirsch-Stoer integrators do not have this problem, the step size is checked and truncated if needed.",
    "desc_source": "jira"
  },
  "Math_40": {
    "description": "BracketingNthOrderBrentSolver exceeds maxIterationCount while updating always the same boundary\nIn some cases, the aging feature in BracketingNthOrderBrentSolver fails.\nIt attempts to balance the bracketing points by targeting a non-zero value instead of the real root. However, the chosen target is too close too zero, and the inverse polynomial approximation is always on the same side, thus always updates the same bracket.\nIn the real used case for a large program, I had a bracket point xA = 12500.0, yA = 3.7e-16, agingA = 0, which is the (really good) estimate of the zero on one side of the root and xB = 12500.03, yB = -7.0e-5, agingB = 97. This shows that the bracketing interval is completely unbalanced, and we never succeed to rebalance it as we always updates (xA, yA) and never updates (xB, yB).",
    "desc_source": "jira"
  },
  "Math_41": {
    "description": "One of Variance.evaluate() methods does not work correctly\nThe method org.apache.commons.math.stat.descriptive.moment.Variance.evaluate(double[] values, double[] weights, double mean, int begin, int length) does not work properly. Looks loke it ignores the length parameter and grabs the whole dataset.\nSimilar method in Mean class seems to work.\nI did not check other methods taking the part of the array; they may have the same problem.\n\nWorkaround: I had to shrink my arrays and use the method without the length.",
    "desc_source": "jira"
  },
  "Math_42": {
    "description": "Negative value with restrictNonNegative\nProblem: commons-math-2.2 SimplexSolver.\n\nA variable with 0 coefficient may be assigned a negative value nevertheless restrictToNonnegative flag in call:\nSimplexSolver.optimize(function, constraints, GoalType.MINIMIZE, true);\n\nFunction\n1 * x + 1 * y + 0\n\nConstraints:\n1 * x + 0 * y = 1\n\nResult:\nx = 1; y = -1;\n\nProbably variables with 0 coefficients are omitted at some point of computation and because of that the restrictions do not affect their values.",
    "desc_source": "jira"
  },
  "Math_43": {
    "description": "Statistics.setVarianceImpl makes getStandardDeviation produce NaN\nInvoking SummaryStatistics.setVarianceImpl(new Variance(true/false) makes getStandardDeviation produce NaN. The code to reproduce it:\n\n{code:java}\nint[] scores = {1, 2, 3, 4};\nSummaryStatistics stats = new SummaryStatistics();\nstats.setVarianceImpl(new Variance(false)); //use \"population variance\"\nfor(int i : scores) {\n  stats.addValue(i);\n}\ndouble sd = stats.getStandardDeviation();\nSystem.out.println(sd);\n{code}\n\nA workaround suggested by Mikkel is:\n{code:java}\n  double sd = FastMath.sqrt(stats.getSecondMoment() / stats.getN());\n{code}",
    "desc_source": "jira"
  },
  "Math_44": {
    "description": "Incomplete reinitialization with some events handling\nI get a bug with event handling: I track 2 events that occur in the same step, when the first one is accepted, it resets the state but the reinitialization is not complete and the second one becomes unable to find its way.\nI can't give my context, which is rather large, but I tried a patch that works for me, unfortunately it breaks the unit tests.",
    "desc_source": "jira"
  },
  "Math_45": {
    "description": "Integer overflow in OpenMapRealMatrix\ncomputeKey() has an integer overflow. Since it is a sparse matrix, this is quite easily encountered long before heap space is exhausted. The attached code demonstrates the problem, which could potentially be a security vulnerability (for example, if one was to use this matrix to store access control information).\n\nWorkaround: never create an OpenMapRealMatrix with more cells than are addressable with an int.",
    "desc_source": "jira"
  },
  "Math_46": {
    "description": "Division by zero\nIn class {{Complex}}, division by zero always returns NaN. I think that it should return NaN only when the numerator is also {{ZERO}}, otherwise the result should be {{INF}}. See [here|http://en.wikipedia.org/wiki/Riemann_sphere#Arithmetic_operations].\n",
    "desc_source": "jira"
  },
  "Math_47": {
    "description": "Division by zero\nIn class {{Complex}}, division by zero always returns NaN. I think that it should return NaN only when the numerator is also {{ZERO}}, otherwise the result should be {{INF}}. See [here|http://en.wikipedia.org/wiki/Riemann_sphere#Arithmetic_operations].\n",
    "desc_source": "jira"
  },
  "Math_48": {
    "description": "\"RegulaFalsiSolver\" failure\nThe following unit test:\n{code}\n@Test\npublic void testBug() {\n    final UnivariateRealFunction f = new UnivariateRealFunction() {\n            @Override\n            public double value(double x) {\n                return Math.exp(x) - Math.pow(Math.PI, 3.0);\n            }\n        };\n\n    UnivariateRealSolver solver = new RegulaFalsiSolver();\n    double root = solver.solve(100, f, 1, 10);\n}\n{code}\nfails with\n{noformat}\nillegal state: maximal count (100) exceeded: evaluations\n{noformat}\n\nUsing \"PegasusSolver\", the answer is found after 17 evaluations.\n",
    "desc_source": "jira"
  },
  "Math_49": {
    "description": "MathRuntimeException with simple ebeMultiply on OpenMapRealVector\nThe following piece of code\n{code:java}\nimport org.apache.commons.math.linear.OpenMapRealVector;\nimport org.apache.commons.math.linear.RealVector;\n\npublic class DemoBugOpenMapRealVector {\n    public static void main(String[] args) {\n        final RealVector u = new OpenMapRealVector(3, 1E-6);\n        u.setEntry(0, 1.);\n        u.setEntry(1, 0.);\n        u.setEntry(2, 2.);\n        final RealVector v = new OpenMapRealVector(3, 1E-6);\n        v.setEntry(0, 0.);\n        v.setEntry(1, 3.);\n        v.setEntry(2, 0.);\n        System.out.println(u);\n        System.out.println(v);\n        System.out.println(u.ebeMultiply(v));\n    }\n}\n{code}\nraises an exception\n{noformat}\norg.apache.commons.math.linear.OpenMapRealVector@7170a9b6\nException in thread \"main\" org.apache.commons.math.MathRuntimeException$6: map has been modified while iterating\n\tat org.apache.commons.math.MathRuntimeException.createConcurrentModificationException(MathRuntimeException.java:373)\n\tat org.apache.commons.math.util.OpenIntToDoubleHashMap$Iterator.advance(OpenIntToDoubleHashMap.java:564)\n\tat org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:372)\n\tat org.apache.commons.math.linear.OpenMapRealVector.ebeMultiply(OpenMapRealVector.java:1)\n\tat DemoBugOpenMapRealVector.main(DemoBugOpenMapRealVector.java:17)\n{noformat}\n",
    "desc_source": "jira"
  },
  "Math_50": {
    "description": "\"RegulaFalsiSolver\" failure\nThe following unit test:\n{code}\n@Test\npublic void testBug() {\n    final UnivariateRealFunction f = new UnivariateRealFunction() {\n            @Override\n            public double value(double x) {\n                return Math.exp(x) - Math.pow(Math.PI, 3.0);\n            }\n        };\n\n    UnivariateRealSolver solver = new RegulaFalsiSolver();\n    double root = solver.solve(100, f, 1, 10);\n}\n{code}\nfails with\n{noformat}\nillegal state: maximal count (100) exceeded: evaluations\n{noformat}\n\nUsing \"PegasusSolver\", the answer is found after 17 evaluations.\n",
    "desc_source": "jira"
  },
  "Math_51": {
    "description": "\"RegulaFalsiSolver\" failure\nThe following unit test:\n{code}\n@Test\npublic void testBug() {\n    final UnivariateRealFunction f = new UnivariateRealFunction() {\n            @Override\n            public double value(double x) {\n                return Math.exp(x) - Math.pow(Math.PI, 3.0);\n            }\n        };\n\n    UnivariateRealSolver solver = new RegulaFalsiSolver();\n    double root = solver.solve(100, f, 1, 10);\n}\n{code}\nfails with\n{noformat}\nillegal state: maximal count (100) exceeded: evaluations\n{noformat}\n\nUsing \"PegasusSolver\", the answer is found after 17 evaluations.\n",
    "desc_source": "jira"
  },
  "Math_52": {
    "description": "numerical problems in rotation creation\nbuilding a rotation from the following vector pairs leads to NaN:\nu1 = -4921140.837095533, -2.1512094250440013E7, -890093.279426377\nu2 = -2.7238580938724895E9, -2.169664921341876E9, 6.749688708885301E10\nv1 = 1, 0, 0\nv2 = 0, 0, 1\n\nThe constructor first changes the (v1, v2) pair into (v1', v2') ensuring the following scalar products hold:\n <v1'|v1'> == <u1|u1>\n <v2'|v2'> == <u2|u2>\n <u1 |u2>  == <v1'|v2'>\n\nOnce the (v1', v2') pair has been computed, we compute the cross product:\n  k = (v1' - u1)^(v2' - u2)\n\nand the scalar product:\n  c = <k | (u1^u2)>\n\nBy construction, c is positive or null and the quaternion axis we want to build is q = k/[2*sqrt(c)].\nc should be null only if some of the vectors are aligned, and this is dealt with later in the algorithm.\n\nHowever, there are numerical problems with the vector above with the way these computations are done, as shown\nby the following comparisons, showing the result we get from our Java code and the result we get from manual\ncomputation with the same formulas but with enhanced precision:\n\ncommons math:   k = 38514476.5,            -84.,                           -1168590144\nhigh precision: k = 38514410.36093388...,  -0.374075245201180409222711..., -1168590152.10599715208...\n\nand it becomes worse when computing c because the vectors are almost orthogonal to each other, hence inducing additional cancellations. We get:\ncommons math    c = -1.2397173627587605E20\nhigh precision: c =  558382746168463196.7079627...\n\nWe have lost ALL significant digits in cancellations, and even the sign is wrong!\n",
    "desc_source": "jira"
  },
  "Math_53": {
    "description": "Complex Add and Subtract handle NaN arguments differently, but javadoc contracts are the same\nFor both Complex add and subtract, the javadoc states that\n\n{code}\n     * If either this or <code>rhs</code> has a NaN value in either part,\n     * {@link #NaN} is returned; otherwise Inifinite and NaN values are\n     * returned in the parts of the result according to the rules for\n     * {@link java.lang.Double} arithmetic\n{code}\n\nSubtract includes an isNaN test and returns Complex.NaN if either complex argument isNaN; but add omits this test.  The test should be added to the add implementation (actually restored, since this looks like a code merge problem going back to 1.1).\n",
    "desc_source": "jira"
  },
  "Math_54": {
    "description": "class Dfp toDouble method return -inf whan Dfp value is 0 \"zero\"\nI found a bug in the toDouble() method of the Dfp class.\nIf the Dfp's value is 0 \"zero\", the toDouble() method returns a  negative infini.\n\nThis is because the double value returned has an exposant equal to 0xFFF \nand a significand is equal to 0.\nIn the IEEE754 this is a -inf.\n\nTo be equal to zero, the exposant and the significand must be equal to zero.\n\nA simple test case is :\n----------------------------------------------\nimport org.apache.commons.math.dfp.DfpField;\n\n\npublic class test {\n\n\t/**\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\tDfpField field = new DfpField(100);\n\t\tSystem.out.println(\"toDouble value of getZero() =\"+field.getZero().toDouble()+\n\t\t\t\t\"\\ntoDouble value of newDfp(0.0) =\"+\n\t\t\t\tfield.newDfp(0.0).toDouble());\n\t}\n}\n\nMay be the simplest way to fix it is to test the zero equality at the begin of the toDouble() method, to be able to return the correctly signed zero ?\n",
    "desc_source": "jira"
  },
  "Math_55": {
    "description": "Vector3D.crossProduct is sensitive to numerical cancellation\nCross product implementation uses the naive formulas (y1 z2 - y2 z1, ...). These formulas fail when vectors are almost colinear, like in the following example:\n{code}\nVector3D v1 = new Vector3D(9070467121.0, 4535233560.0, 1);\nVector3D v2 = new Vector3D(9070467123.0, 4535233561.0, 1);\nSystem.out.println(Vector3D.crossProduct(v1, v2));\n{code}\n\nThe previous code displays { -1, 2, 0 } instead of the correct answer { -1, 2, 1 }",
    "desc_source": "jira"
  },
  "Math_56": {
    "description": "MultidimensionalCounter.getCounts(int) returns wrong array of indices\nMultidimensionalCounter counter = new MultidimensionalCounter(2, 4);\nfor (Integer i : counter) {\n    int[] x = counter.getCounts(i);\n    System.out.println(i + \" \" + Arrays.toString(x));\n}\n\nOutput is:\n0 [0, 0]\n1 [0, 1]\n2 [0, 2]\n3 [0, 2]   <=== should be [0, 3]\n4 [1, 0]\n5 [1, 1]\n6 [1, 2]\n7 [1, 2]   <=== should be [1, 3]",
    "desc_source": "jira"
  },
  "Math_57": {
    "description": "Truncation issue in KMeansPlusPlusClusterer\nThe for loop inside KMeansPlusPlusClusterer.chooseInitialClusters defines a variable\n  int sum = 0;\nThis variable should have type double, rather than int.  Using an int causes the method to truncate the distances between points to (square roots of) integers.  It's especially bad when the distances between points are typically less than 1.\n\nAs an aside, in version 2.2, this bug manifested itself by making the clusterer return empty clusters.  I wonder if the EmptyClusterStrategy would still be necessary if this bug were fixed.",
    "desc_source": "jira"
  },
  "Math_58": {
    "description": "GaussianFitter Unexpectedly Throws NotStrictlyPositiveException\nRunning the following:\n\n    \tdouble[] observations = \n    \t{ \n    \t\t\t1.1143831578403364E-29, \n    \t\t\t 4.95281403484594E-28, \n    \t\t\t 1.1171347211930288E-26, \n    \t\t\t 1.7044813962636277E-25, \n    \t\t\t 1.9784716574832164E-24, \n    \t\t\t 1.8630236407866774E-23, \n    \t\t\t 1.4820532905097742E-22, \n    \t\t\t 1.0241963854632831E-21, \n    \t\t\t 6.275077366673128E-21, \n    \t\t\t 3.461808994532493E-20, \n    \t\t\t 1.7407124684715706E-19, \n    \t\t\t 8.056687953553974E-19, \n    \t\t\t 3.460193945992071E-18, \n    \t\t\t 1.3883326374011525E-17, \n    \t\t\t 5.233894983671116E-17, \n    \t\t\t 1.8630791465263745E-16, \n    \t\t\t 6.288759227922111E-16, \n    \t\t\t 2.0204433920597856E-15, \n    \t\t\t 6.198768938576155E-15, \n    \t\t\t 1.821419346860626E-14, \n    \t\t\t 5.139176445538471E-14, \n    \t\t\t 1.3956427429045787E-13, \n    \t\t\t 3.655705706448139E-13, \n    \t\t\t 9.253753324779779E-13, \n    \t\t\t 2.267636001476696E-12, \n    \t\t\t 5.3880460095836855E-12, \n    \t\t\t 1.2431632654852931E-11 \n    \t};\n  \n    \tGaussianFitter g = \n    \t\tnew GaussianFitter(new LevenbergMarquardtOptimizer());\n    \t\n    \tfor (int index = 0; index < 27; index++)\n    \t{\n    \t\tg.addObservedPoint(index, observations[index]);\n    \t}\n       \tg.fit();\n\nResults in:\n\norg.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than, or equal to, the minimum (0)\n\tat org.apache.commons.math.analysis.function.Gaussian$Parametric.validateParameters(Gaussian.java:184)\n\tat org.apache.commons.math.analysis.function.Gaussian$Parametric.value(Gaussian.java:129)\n\n\nI'm guessing the initial guess for sigma is off.  ",
    "desc_source": "jira"
  },
  "Math_59": {
    "description": "FastMath.max(50.0f, -50.0f) => -50.0f; should be +50.0f\nFastMath.max(50.0f, -50.0f) => -50.0f; should be +50.0f.\n\nThis is because the wrong variable is returned.\n\nThe bug was not detected by the test case \"testMinMaxFloat()\" because that has a bug too - it tests doubles, not floats.",
    "desc_source": "jira"
  },
  "Math_60": {
    "description": "ConvergenceException in NormalDistributionImpl.cumulativeProbability()\nI get a ConvergenceException in  NormalDistributionImpl.cumulativeProbability() for very large/small parameters including Infinity, -Infinity.\nFor instance in the following code:\n\n\t@Test\n\tpublic void testCumulative() {\n\t\tfinal NormalDistribution nd = new NormalDistributionImpl();\n\t\tfor (int i = 0; i < 500; i++) {\n\t\t\tfinal double val = Math.exp(i);\n\t\t\ttry {\n\t\t\t\tSystem.out.println(\"val = \" + val + \" cumulative = \" + nd.cumulativeProbability(val));\n\t\t\t} catch (MathException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t\tfail();\n\t\t\t}\n\t\t}\n\t}\n\nIn version 2.0, I get no exception. \n\nMy suggestion is to change in the implementation of cumulativeProbability(double) to catch all ConvergenceException (and return for very large and very small values), not just MaxIterationsExceededException.\n",
    "desc_source": "jira"
  },
  "Math_61": {
    "description": "Dangerous code in \"PoissonDistributionImpl\"\nIn the following excerpt from class \"PoissonDistributionImpl\":\n\n{code:title=PoissonDistributionImpl.java|borderStyle=solid}\n    public PoissonDistributionImpl(double p, NormalDistribution z) {\n        super();\n        setNormal(z);\n        setMean(p);\n    }\n{code}\n\n(1) Overridable methods are called within the constructor.\n(2) The reference \"z\" is stored and modified within the class.\n\nI've encountered problem (1) in several classes while working on issue 348. In those cases, in order to remove potential problems, I copied/pasted the body of the \"setter\" methods inside the constructor but I think that a more elegant solution would be to remove the \"setters\" altogether (i.e. make the classes immutable).\nProblem (2) can also create unexpected behaviour. Is it really necessary to pass the \"NormalDistribution\" object; can't it be always created within the class?\n",
    "desc_source": "jira"
  },
  "Math_62": {
    "description": "Miscellaneous issues concerning the \"optimization\" package\nRevision 990792 contains changes triggered the following issues:\n* [MATH-394|https://issues.apache.org/jira/browse/MATH-394]\n* [MATH-397|https://issues.apache.org/jira/browse/MATH-397]\n* [MATH-404|https://issues.apache.org/jira/browse/MATH-404]\n\nThis issue collects the currently still unsatisfactory code (not necessarily sorted in order of annoyance):\n# \"BrentOptimizer\": a specific convergence checker must be used. \"LevenbergMarquardtOptimizer\" also has specific convergence checks.\n# Trying to make convergence checking independent of the optimization algorithm creates problems (conceptual and practical):\n ** See \"BrentOptimizer\" and \"LevenbergMarquardtOptimizer\", the algorithm passes \"points\" to the convergence checker, but the actual meaning of the points can very well be different in the caller (optimization algorithm) and the callee (convergence checker).\n ** In \"PowellOptimizer\" the line search (\"BrentOptimizer\") tolerances depend on the tolerances within the main algorithm. Since tolerances come with \"ConvergenceChecker\" and so can be changed at any time, it is awkward to adapt the values within the line search optimizer without exposing its internals (\"BrentOptimizer\" field) to the enclosing class (\"PowellOptimizer\").\n# Given the numerous changes, some Javadoc comments might be out-of-sync, although I did try to update them all.\n# Class \"DirectSearchOptimizer\" (in package \"optimization.direct\") inherits from class \"AbstractScalarOptimizer\" (in package \"optimization.general\").\n# Some interfaces are defined in package \"optimization\" but their base implementations (abstract class that contain the boiler-plate code) are in package \"optimization.general\" (e.g. \"DifferentiableMultivariateVectorialOptimizer\" and \"BaseAbstractVectorialOptimizer\").\n# No check is performed to ensure the the convergence checker has been set (see e.g. \"BrentOptimizer\" and \"PowellOptimizer\"); if it hasn't there will be a NPE. The alternative is to initialize a default checker that will never be used in case the user had intended to explicitly sets the checker.\n# \"NonLinearConjugateGradientOptimizer\": Ugly workaround for the checked \"ConvergenceException\".\n# Everywhere, we trail the checked \"FunctionEvaluationException\" although it is never used.\n# There remains some duplicate code (such as the \"multi-start loop\" in the various \"MultiStart...\" implementations).\n# The \"ConvergenceChecker\" interface is very general (the \"converged\" method can take any number of \"...PointValuePair\"). However there remains a \"semantic\" problem: One cannot be sure that the list of points means the same thing for the caller of \"converged\" and within the implementation of the \"ConvergenceChecker\" that was independently set.\n# It is not clear whether it is wise to aggregate the counter of gradient evaluations to the function evaluation counter. In \"LevenbergMarquartdOptimizer\" for example, it would be unfair to do so. Currently I had to remove all tests referring to gradient and Jacobian evaluations.\n# In \"AbstractLeastSquaresOptimizer\" and \"LevenbergMarquardtOptimizer\", occurences of \"OptimizationException\" were replaced by the unchecked \"ConvergenceException\" but in some cases it might not be the most appropriate one.\n# \"MultiStartUnivariateRealOptimizer\": in the other classes (\"MultiStartMultivariate...\") similar to this one, the randomization is on the firts-guess value while in this class, it is on the search interval. I think that here also we should randomly choose the start value (within the user-selected interval).\n# The Javadoc utility raises warnings (see output of \"mvn site\") which I couldn't figure out how to correct.\n# Some previously existing classes and interfaces have become no more than a specialisation of new \"generics\" classes; it might be interesting to remove them in order to reduce the number of classes and thus limit the potential for confusion.\n",
    "desc_source": "jira"
  },
  "Math_63": {
    "description": "NaN in \"equals\" methods\nIn \"MathUtils\", some \"equals\" methods will return true if both argument are NaN.\nUnless I'm mistaken, this contradicts the IEEE standard.\n\nIf nobody objects, I'm going to make the changes.\n",
    "desc_source": "jira"
  },
  "Math_64": {
    "description": "Inconsistent result from Levenberg-Marquardt\nLevenberg-Marquardt (its method doOptimize) returns a VectorialPointValuePair.  However, the class holds the optimum point, the vector of the objective function, the cost and residuals.  The value returns by doOptimize does not always corresponds to the point which leads to the residuals and cost",
    "desc_source": "jira"
  },
  "Math_65": {
    "description": "weight versus sigma in AbstractLeastSquares\nIn AbstractLeastSquares, residualsWeights contains the WEIGHTS assigned to each observation.  In the method getRMS(), these weights are multiplicative as they should. unlike in getChiSquare() where it appears at the denominator!   If the weight is really the weight of the observation, it should multiply the square of the residual even in the computation of the chi2.\n\n Once corrected, getRMS() can even reduce\n\n public double getRMS() {return Math.sqrt(getChiSquare()/rows);}",
    "desc_source": "jira"
  },
  "Math_66": {
    "description": "Bugs in \"BrentOptimizer\"\nI apologize for having provided a buggy implementation of Brent's optimization algorithm (class \"BrentOptimizer\" in package \"optimization.univariate\").\nThe unit tests didn't show that there was something wrong, although (from the \"changes.xml\" file) I discovered that, at the time, Luc had noticed something weird in the implementation's behaviour.\nComparing with an implementation in Python, I could figure out the fixes. I'll modify \"BrentOptimizer\" and add a test. I also propose to change the name of the unit test class from \"BrentMinimizerTest\" to \"BrentOptimizerTest\".\n",
    "desc_source": "jira"
  },
  "Math_67": {
    "description": "Method \"getResult()\" in \"MultiStartUnivariateRealOptimizer\"\nIn \"MultiStartUnivariateRealOptimizer\" (package \"optimization\"), the method \"getResult\" returns the result of the last run of the \"underlying\" optimizer; this last result might not be the best one, in which case it will not correspond to the value returned by the \"optimize\" method. This is confusing and does not seem very useful. I think that \"getResult\" should be defined as\n{code} \npublic double getResult() {\n    return optima[0];\n}\n{code}\nand similarly\n{code}\npublic double getFunctionValue() {\n    return optimaValues[0];\n}\n{code}\n",
    "desc_source": "jira"
  },
  "Math_68": {
    "description": "LevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it\nLevenbergMarquardtOptimizer ignores the VectorialConvergenceChecker parameter passed to it. This makes it hard to specify custom stopping criteria for the optimizer.",
    "desc_source": "jira"
  },
  "Math_69": {
    "description": "PearsonsCorrelation.getCorrelationPValues() precision limited by machine epsilon\nSimilar to the issue described in MATH-201, using PearsonsCorrelation.getCorrelationPValues() with many treatments results in p-values that are continuous down to 2.2e-16 but that drop to 0 after that.\n\nIn MATH-201, the problem was described as such:\n> So in essence, the p-value returned by TTestImpl.tTest() is:\n> \n> 1.0 - (cumulativeProbability(t) - cumulativeProbabily(-t))\n> \n> For large-ish t-statistics, cumulativeProbabilty(-t) can get quite small, and cumulativeProbabilty(t) can get very close to 1.0. When \n> cumulativeProbability(-t) is less than the machine epsilon, we get p-values equal to zero because:\n> \n> 1.0 - 1.0 + 0.0 = 0.0\n\nThe solution in MATH-201 was to modify the p-value calculation to this:\n> p = 2.0 * cumulativeProbability(-t)\n\nHere, the problem is similar.  From PearsonsCorrelation.getCorrelationPValues():\n  p = 2 * (1 - tDistribution.cumulativeProbability(t));\n\nDirectly calculating the p-value using identical code as PearsonsCorrelation.getCorrelationPValues(), but with the following change seems to solve the problem:\n  p = 2 * (tDistribution.cumulativeProbability(-t));\n\n\n\n\n",
    "desc_source": "jira"
  },
  "Math_70": {
    "description": "BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial) throws NullPointerException\nMethod \n\n    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max, double initial)  \n\ninvokes \n\n    BisectionSolver.solve(double min, double max) \n\nwhich throws NullPointerException, as member variable\n\n    UnivariateRealSolverImpl.f \n\nis null.\n\nInstead the method:\n\n    BisectionSolver.solve(final UnivariateRealFunction f, double min, double max)\n\nshould be called.\n\nSteps to reproduce:\n\ninvoke:\n\n     new BisectionSolver().solve(someUnivariateFunctionImpl, 0.0, 1.0, 0.5);\n\nNullPointerException will be thrown.\n\n\n",
    "desc_source": "jira"
  },
  "Math_71": {
    "description": "ODE integrator goes past specified end of integration range\nEnd of integration range in ODE solving is handled as an event.\nIn some cases, numerical accuracy in events detection leads to error in events location.\nThe following test case shows the end event is not handled properly and an integration that should cover a 60s range in fact covers a 160s range, more than twice the specified range.\n{code}\n  public void testMissedEvent() throws IntegratorException, DerivativeException {\n          final double t0 = 1878250320.0000029;\n          final double t =  1878250379.9999986;\n          FirstOrderDifferentialEquations ode = new FirstOrderDifferentialEquations() {\n            \n            public int getDimension() {\n                return 1;\n            }\n            \n            public void computeDerivatives(double t, double[] y, double[] yDot)\n                throws DerivativeException {\n                yDot[0] = y[0] * 1.0e-6;\n            }\n        };\n\n        DormandPrince853Integrator integrator = new DormandPrince853Integrator(0.0, 100.0,\n                                                                               1.0e-10, 1.0e-10);\n\n        double[] y = { 1.0 };\n        integrator.setInitialStepSize(60.0);\n        double finalT = integrator.integrate(ode, t0, y, t, y);\n        Assert.assertEquals(t, finalT, 1.0e-6);\n    }\n\n{code}",
    "desc_source": "jira"
  },
  "Math_72": {
    "description": "Brent solver returns the wrong value if either bracket endpoint is root\nThe solve(final UnivariateRealFunction f, final double min, final double max, final double initial) function returns yMin or yMax if min or max are deemed to be roots, respectively, instead of min or max.",
    "desc_source": "jira"
  },
  "Math_73": {
    "description": "Brent solver doesn't throw IllegalArgumentException when initial guess has the wrong sign\nJavadoc for \"public double solve(final UnivariateRealFunction f, final double min, final double max, final double initial)\" claims that \"if the values of the function at the three points have the same sign\" an IllegalArgumentException is thrown. This case isn't even checked.",
    "desc_source": "jira"
  },
  "Math_74": {
    "description": "Wrong parameter for first step size guess for Embedded Runge Kutta methods\nIn a space application using DOP853 i detected what seems to be a bad parameter in the call to the method  initializeStep of class AdaptiveStepsizeIntegrator.\n\nHere, DormandPrince853Integrator is a subclass for EmbeddedRungeKuttaIntegrator which perform the call to initializeStep at the beginning of its method integrate(...)\n\nThe problem comes from the array \"scale\" that is used as a parameter in the call off initializeStep(..)\n\nFollowing the theory described by Hairer in his book \"Solving Ordinary Differential Equations 1 : Nonstiff Problems\", the scaling should be :\n\nsci = Atol i + |y0i| * Rtoli\n\nWhereas EmbeddedRungeKuttaIntegrator uses :  sci = Atoli\n\nNote that the Gragg-Bulirsch-Stoer integrator uses the good implementation \"sci = Atol i + |y0i| * Rtoli  \" when he performs the call to the same method initializeStep(..)\n\nIn the method initializeStep, the error leads to a wrong step size h used to perform an  Euler step. Most of the time it is unvisible for the user.\nBut in my space application the Euler step with this wrong step size h (much bigger than it should be)  makes an exception occur (my satellite hits the ground...)\n\n\nTo fix the bug, one should use the same algorithm as in the rescale method in GraggBulirschStoerIntegrator\nFor exemple :\n\n final double[] scale= new double[y0.length];;\n          \n          if (vecAbsoluteTolerance == null) {\n              for (int i = 0; i < scale.length; ++i) {\n                final double yi = Math.max(Math.abs(y0[i]), Math.abs(y0[i]));\n                scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * yi;\n              }\n            } else {\n              for (int i = 0; i < scale.length; ++i) {\n                final double yi = Math.max(Math.abs(y0[i]), Math.abs(y0[i]));\n                scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * yi;\n              }\n            }\n          \n          hNew = initializeStep(equations, forward, getOrder(), scale,\n                           stepStart, y, yDotK[0], yTmp, yDotK[1]);\n\n\n\nSorry for the length of this message, looking forward to hearing from you soon\n\nVincent Morand\n\n\n\n\n",
    "desc_source": "jira"
  },
  "Math_75": {
    "description": "In stat.Frequency, getPct(Object) uses getCumPct(Comparable) instead of getPct(Comparable) \nDrop in Replacement of 1.2 with 2.0 not possible because all getPct calls will be cummulative without code change\n\nFrequency.java\n\n   /**\n      * Returns the percentage of values that are equal to v\n     * @deprecated replaced by {@link #getPct(Comparable)} as of 2.0\n     */\n    @Deprecated\n    public double getPct(Object v) {\n        return getCumPct((Comparable<?>) v);\n    }",
    "desc_source": "jira"
  },
  "Math_76": {
    "description": "NaN singular value from SVD\nThe following jython code\nStart code\n\nfrom org.apache.commons.math.linear import *\n \nAlist = [[1.0, 2.0, 3.0],[2.0,3.0,4.0],[3.0,5.0,7.0]]\n \nA = Array2DRowRealMatrix(Alist)\n \ndecomp = SingularValueDecompositionImpl(A)\n \nprint decomp.getSingularValues()\n\nEnd code\n\nprints\narray('d', [11.218599757513008, 0.3781791648535976, nan])\nThe last singular value should be something very close to 0 since the matrix\nis rank deficient.  When i use the result from getSolver() to solve a system, i end \nup with a bunch of NaNs in the solution.  I assumed i would get back a least squares solution.\n\nDoes this SVD implementation require that the matrix be full rank?  If so, then i would expect\nan exception to be thrown from the constructor or one of the methods.\n\n\n",
    "desc_source": "jira"
  },
  "Math_77": {
    "description": "getLInfNorm() uses wrong formula in both ArrayRealVector and OpenMapRealVector (in different ways)\nthe L_infinity norm of a finite dimensional vector is just the max of the absolute value of its entries.\n\nThe current implementation in ArrayRealVector has a typo:\n\n{code}\n    public double getLInfNorm() {\n        double max = 0;\n        for (double a : data) {\n            max += Math.max(max, Math.abs(a));\n        }\n        return max;\n    }\n{code}\n\nthe += should just be an =.\n\nThere is sadly a unit test assuring us that this is the correct behavior (effectively a regression-only test, not a test for correctness).\n\nWorse, the implementation in OpenMapRealVector is not even positive semi-definite:\n\n{code}   \n    public double getLInfNorm() {\n        double max = 0;\n        Iterator iter = entries.iterator();\n        while (iter.hasNext()) {\n            iter.advance();\n            max += iter.value();\n        }\n        return max;\n    }\n{code}\n\nI would suggest that this method be moved up to the AbstractRealVector superclass and implemented using the sparseIterator():\n\n{code}\n  public double getLInfNorm() {\n    double norm = 0;\n    Iterator<Entry> it = sparseIterator();\n    Entry e;\n    while(it.hasNext() && (e = it.next()) != null) {\n      norm = Math.max(norm, Math.abs(e.getValue()));\n    }\n    return norm;\n  }\n{code}\n\nUnit tests with negative valued vectors would be helpful to check for this kind of thing in the future.",
    "desc_source": "jira"
  },
  "Math_78": {
    "description": "during ODE integration, the last event in a pair of very close event may not be detected\nWhen an events follows a previous one very closely, it may be ignored. The occurrence of the bug depends on the side of the bracketing interval that was selected. For example consider a switching function that is increasing around first event around t = 90, reaches its maximum and is decreasing around the second event around t = 135. If an integration step spans from 67.5 and 112.5, the switching function values at start and end of step will  have opposite signs, so the first event will be detected. The solver will find the event really occurs at 90.0 and will therefore truncate the step at 90.0. The next step will start from where the first step ends, i.e. it will start at 90.0. Let's say this step spans from 90.0 to 153.0. The switching function switches once again in this step.\n\nIf the solver for the first event converged to a value slightly before 90.0 (say 89.9999999), then the switch will not be detected because g(89.9999999) and g(153.0) are both negative.\n\nThis bug was introduced as of r781157 (2009-06-02) when special handling of events very close to step start was added.",
    "desc_source": "jira"
  },
  "Math_79": {
    "description": "NPE in  KMeansPlusPlusClusterer unittest\nWhen running this unittest, I am facing this NPE:\njava.lang.NullPointerException\n\tat org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer.assignPointsToClusters(KMeansPlusPlusClusterer.java:91)\n\nThis is the unittest:\n\n\npackage org.fao.fisheries.chronicles.calcuation.cluster;\n\nimport static org.junit.Assert.assertEquals;\nimport static org.junit.Assert.assertTrue;\n\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Random;\n\nimport org.apache.commons.math.stat.clustering.Cluster;\nimport org.apache.commons.math.stat.clustering.EuclideanIntegerPoint;\nimport org.apache.commons.math.stat.clustering.KMeansPlusPlusClusterer;\nimport org.fao.fisheries.chronicles.input.CsvImportProcess;\nimport org.fao.fisheries.chronicles.input.Top200Csv;\nimport org.junit.Test;\n\npublic class ClusterAnalysisTest {\n\n\n\t@Test\n\tpublic void testPerformClusterAnalysis2() {\n\t\tKMeansPlusPlusClusterer<EuclideanIntegerPoint> transformer = new KMeansPlusPlusClusterer<EuclideanIntegerPoint>(\n\t\t\t\tnew Random(1746432956321l));\n\t\tEuclideanIntegerPoint[] points = new EuclideanIntegerPoint[] {\n\t\t\t\tnew EuclideanIntegerPoint(new int[] { 1959, 325100 }),\n\t\t\t\tnew EuclideanIntegerPoint(new int[] { 1960, 373200 }), };\n\t\tList<Cluster<EuclideanIntegerPoint>> clusters = transformer.cluster(Arrays.asList(points), 1, 1);\n\t\tassertEquals(1, clusters.size());\n\n\t}\n\n}\n",
    "desc_source": "jira"
  },
  "Math_80": {
    "description": "wrong result in eigen decomposition\nSome results computed by EigenDecompositionImpl are wrong. The following case computed by Fortran Lapack fails with version 2.0\n{code}\n    public void testMathpbx02() {\n\n        double[] mainTridiagonal = {\n        \t  7484.860960227216, 18405.28129035345, 13855.225609560746,\n        \t 10016.708722343366, 559.8117399576674, 6750.190788301587, \n        \t    71.21428769782159\n        };\n        double[] secondaryTridiagonal = {\n        \t -4175.088570476366,1975.7955858241994,5193.178422374075, \n        \t  1995.286659169179,75.34535882933804,-234.0808002076056\n        };\n\n        // the reference values have been computed using routine DSTEMR\n        // from the fortran library LAPACK version 3.2.1\n        double[] refEigenValues = {\n        \t\t20654.744890306974412,16828.208208485466457,\n        \t\t6893.155912634994820,6757.083016675340332,\n        \t\t5887.799885688558788,64.309089923240379,\n        \t\t57.992628792736340\n        };\n        RealVector[] refEigenVectors = {\n        \t\tnew ArrayRealVector(new double[] {-0.270356342026904, 0.852811091326997, 0.399639490702077, 0.198794657813990, 0.019739323307666, 0.000106983022327, -0.000001216636321}),\n        \t\tnew ArrayRealVector(new double[] {0.179995273578326,-0.402807848153042,0.701870993525734,0.555058211014888,0.068079148898236,0.000509139115227,-0.000007112235617}),\n        \t\tnew ArrayRealVector(new double[] {-0.399582721284727,-0.056629954519333,-0.514406488522827,0.711168164518580,0.225548081276367,0.125943999652923,-0.004321507456014}),\n        \t\tnew ArrayRealVector(new double[] {0.058515721572821,0.010200130057739,0.063516274916536,-0.090696087449378,-0.017148420432597,0.991318870265707,-0.034707338554096}),\n        \t\tnew ArrayRealVector(new double[] {0.855205995537564,0.327134656629775,-0.265382397060548,0.282690729026706,0.105736068025572,-0.009138126622039,0.000367751821196}),\n        \t\tnew ArrayRealVector(new double[] {-0.002913069901144,-0.005177515777101,0.041906334478672,-0.109315918416258,0.436192305456741,0.026307315639535,0.891797507436344}),\n        \t\tnew ArrayRealVector(new double[] {-0.005738311176435,-0.010207611670378,0.082662420517928,-0.215733886094368,0.861606487840411,-0.025478530652759,-0.451080697503958})\n        };\n\n        // the following line triggers the exception\n        EigenDecomposition decomposition =\n            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);\n\n        double[] eigenValues = decomposition.getRealEigenvalues();\n        for (int i = 0; i < refEigenValues.length; ++i) {\n            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-3);\n            if (refEigenVectors[i].dotProduct(decomposition.getEigenvector(i)) < 0) {\n                assertEquals(0, refEigenVectors[i].add(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);\n            } else {\n                assertEquals(0, refEigenVectors[i].subtract(decomposition.getEigenvector(i)).getNorm(), 1.0e-5);\n            }\n        }\n\n    }\n{code}",
    "desc_source": "jira"
  },
  "Math_81": {
    "description": "ArrayIndexOutOfBoundException in EigenDecompositionImpl\nThe following test triggers an ArrayIndexOutOfBoundException:\n\n{code:java}\n    public void testMath308() {\n\n        double[] mainTridiagonal = {\n            22.330154644539597, 46.65485522478641, 17.393672330044705, 54.46687435351116, 80.17800767709437\n        };\n        double[] secondaryTridiagonal = {\n            13.04450406501361, -5.977590941539671, 2.9040909856707517, 7.1570352792841225\n        };\n\n        // the reference values have been computed using routine DSTEMR\n        // from the fortran library LAPACK version 3.2.1\n        double[] refEigenValues = {\n            14.138204224043099, 18.847969733754262, 52.536278520113882, 53.456697699894512, 82.044413207204002\n        };\n        RealVector[] refEigenVectors = {\n            new ArrayRealVector(new double[] {  0.584677060845929, -0.367177264979103, -0.721453187784497,  0.052971054621812, -0.005740715188257 }),\n            new ArrayRealVector(new double[] {  0.713933751051495, -0.190582113553930,  0.671410443368332, -0.056056055955050,  0.006541576993581 }),\n            new ArrayRealVector(new double[] {  0.222368839324646,  0.514921891363332, -0.021377019336614,  0.801196801016305, -0.207446991247740 }),\n            new ArrayRealVector(new double[] {  0.314647769490148,  0.750806415553905, -0.167700312025760, -0.537092972407375,  0.143854968127780 }),\n            new ArrayRealVector(new double[] { -0.000462690386766, -0.002118073109055,  0.011530080757413,  0.252322434584915,  0.967572088232592 })\n        };\n\n        // the following line triggers the exception\n        EigenDecomposition decomposition =\n            new EigenDecompositionImpl(mainTridiagonal, secondaryTridiagonal, MathUtils.SAFE_MIN);\n\n        double[] eigenValues = decomposition.getRealEigenvalues();\n        for (int i = 0; i < refEigenValues.length; ++i) {\n            assertEquals(refEigenValues[i], eigenValues[i], 1.0e-6);\n            if (refEigenVectors[i].dotProduct(decomposition.getEigenvector(i)) < 0) {\n                assertEquals(0, refEigenVectors[i].add(decomposition.getEigenvector(i)).getNorm(), 1.0e-6);\n            } else {\n                assertEquals(0, refEigenVectors[i].subtract(decomposition.getEigenvector(i)).getNorm(), 1.0e-6);\n            }\n        }\n\n    }\n{code}\n\nRunning the previous method as a Junit test triggers the exception when the EigenDecompositionImpl instance is built. The first few lines of the stack trace are:\n\n{noformat}\njava.lang.ArrayIndexOutOfBoundsException: -1\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.computeShiftIncrement(EigenDecompositionImpl.java:1545)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.goodStep(EigenDecompositionImpl.java:1072)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.processGeneralBlock(EigenDecompositionImpl.java:894)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.findEigenvalues(EigenDecompositionImpl.java:658)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.decompose(EigenDecompositionImpl.java:246)\n\tat org.apache.commons.math.linear.EigenDecompositionImpl.<init>(EigenDecompositionImpl.java:205)\n\tat org.apache.commons.math.linear.EigenDecompositionImplTest.testMath308(EigenDecompositionImplTest.java:136)\n{noformat}\n\nI'm currently investigating this bug. It is not a simple index translation error between the original fortran (Lapack) and commons-math implementation.",
    "desc_source": "jira"
  },
  "Math_82": {
    "description": "SimplexSolver not working as expected 2\nSimplexSolver didn't find the optimal solution.\n\nProgram for Lpsolve:\n=====================\n/* Objective function */\nmax: 7 a 3 b;\n\n/* Constraints */\nR1: +3 a -5 c <= 0;\nR2: +2 a -5 d <= 0;\nR3: +2 b -5 c <= 0;\nR4: +3 b -5 d <= 0;\nR5: +3 a +2 b <= 5;\nR6: +2 a +3 b <= 5;\n\n/* Variable bounds */\na <= 1;\nb <= 1;\n=====================\nResults(correct): a = 1, b = 1, value = 10\n\n\nProgram for SimplexSolve:\n=====================\nLinearObjectiveFunction kritFcia = new LinearObjectiveFunction(new double[]{7, 3, 0, 0}, 0);\nCollection<LinearConstraint> podmienky = new ArrayList<LinearConstraint>();\npodmienky.add(new LinearConstraint(new double[]{1, 0, 0, 0}, Relationship.LEQ, 1));\npodmienky.add(new LinearConstraint(new double[]{0, 1, 0, 0}, Relationship.LEQ, 1));\npodmienky.add(new LinearConstraint(new double[]{3, 0, -5, 0}, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]{2, 0, 0, -5}, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]{0, 2, -5, 0}, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]{0, 3, 0, -5}, Relationship.LEQ, 0));\npodmienky.add(new LinearConstraint(new double[]{3, 2, 0, 0}, Relationship.LEQ, 5));\npodmienky.add(new LinearConstraint(new double[]{2, 3, 0, 0}, Relationship.LEQ, 5));\nSimplexSolver solver = new SimplexSolver();\nRealPointValuePair result = solver.optimize(kritFcia, podmienky, GoalType.MAXIMIZE, true);\n=====================\nResults(incorrect): a = 1, b = 0.5, value = 8.5\n\nP.S. I used the latest software from the repository (including MATH-286 fix).",
    "desc_source": "jira"
  },
  "Math_83": {
    "description": "SimplexSolver not working as expected?\nI guess (but I could be wrong) that SimplexSolver does not always return the optimal solution, nor satisfies all the constraints...\n\nConsider this LP:\n\nmax: 0.8 x0 + 0.2 x1 + 0.7 x2 + 0.3 x3 + 0.6 x4 + 0.4 x5;\nr1: x0 + x2 + x4 = 23.0;\nr2: x1 + x3 + x5 = 23.0;\nr3: x0 >= 10.0;\nr4: x2 >= 8.0;\nr5: x4 >= 5.0;\n\nLPSolve returns 25.8, with x0 = 10.0, x1 = 0.0, x2 = 8.0, x3 = 0.0, x4 = 5.0, x5 = 23.0;\n\nThe same LP expressed in Apache commons math is:\n\nLinearObjectiveFunction f = new LinearObjectiveFunction(new double[] { 0.8, 0.2, 0.7, 0.3, 0.6, 0.4 }, 0 );\nCollection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();\nconstraints.add(new LinearConstraint(new double[] { 1, 0, 1, 0, 1, 0 }, Relationship.EQ, 23.0));\nconstraints.add(new LinearConstraint(new double[] { 0, 1, 0, 1, 0, 1 }, Relationship.EQ, 23.0));\nconstraints.add(new LinearConstraint(new double[] { 1, 0, 0, 0, 0, 0 }, Relationship.GEQ, 10.0));\nconstraints.add(new LinearConstraint(new double[] { 0, 0, 1, 0, 0, 0 }, Relationship.GEQ, 8.0));\nconstraints.add(new LinearConstraint(new double[] { 0, 0, 0, 0, 1, 0 }, Relationship.GEQ, 5.0));\n\nRealPointValuePair solution = new SimplexSolver().optimize(f, constraints, GoalType.MAXIMIZE, true);\n\nthat returns 22.20, with x0 = 15.0, x1 = 23.0, x2 = 8.0, x3 = 0.0, x4 = 0.0, x5 = 0.0;\n\nIs it possible SimplexSolver is buggy that way? The returned value is 22.20 instead of 25.8, and the last constraint (x4 >= 5.0) is not satisfied...\n\nAm I using the interface wrongly?",
    "desc_source": "jira"
  },
  "Math_84": {
    "description": "MultiDirectional optimzation loops forver if started at the correct solution\nMultiDirectional.iterateSimplex loops forever if the starting point is the correct solution.\n\nsee the attached test case (testMultiDirectionalCorrectStart) as an example.",
    "desc_source": "jira"
  },
  "Math_85": {
    "description": "bug in inverseCumulativeProbability() for Normal Distribution\n\n * @version $Revision: 617953 $ $Date: 2008-02-02 22:54:00 -0700 (Sat, 02 Feb 2008) $\n */\npublic class NormalDistributionImpl extends AbstractContinuousDistribution \n\n\n * @version $Revision: 506600 $ $Date: 2007-02-12 12:35:59 -0700 (Mon, 12 Feb 2007) $\n */\npublic abstract class AbstractContinuousDistribution\n\n\nThis code:\n\n        \tDistributionFactory factory = app.getDistributionFactory();\n        \tNormalDistribution normal = factory.createNormalDistribution(0,1);\n        \tdouble result = normal.inverseCumulativeProbability(0.9772498680518209);\n\ngives the exception below. It should return (approx) 2.0000...\n\nnormal.inverseCumulativeProbability(0.977249868051820); works fine\n\nThese also give errors:\n0.9986501019683698 (should return 3.0000...)\n0.9999683287581673 (should return 4.0000...)\n\norg.apache.commons.math.MathException: Number of iterations=1, maximum iterations=2,147,483,647, initial=1, lower bound=0, upper bound=179,769,313,486,231,570,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000, final a value=0, final b value=2, f(a)=-0.477, f(b)=0\n\tat org.apache.commons.math.distribution.AbstractContinuousDistribution.inverseCumulativeProbability(AbstractContinuousDistribution.java:103)\n\tat org.apache.commons.math.distribution.NormalDistributionImpl.inverseCumulativeProbability(NormalDistributionImpl.java:145)\n\n\n",
    "desc_source": "jira"
  },
  "Math_86": {
    "description": "testing for symmetric positive definite matrix in CholeskyDecomposition\nI used this matrix:\n\n        double[][] cv = {\n            {0.40434286, 0.09376327, 0.30328980, 0.04909388},\n            {0.09376327, 0.10400408, 0.07137959, 0.04762857},\n            {0.30328980, 0.07137959, 0.30458776, 0.04882449},\n            {0.04909388, 0.04762857, 0.04882449, 0.07543265}\n        };\n\nAnd it works fine, because it is symmetric positive definite\n\nI tried this matrix:\n\n        double[][] cv = {\n            {0.40434286, -0.09376327, 0.30328980, 0.04909388},\n            {-0.09376327, 0.10400408, 0.07137959, 0.04762857},\n            {0.30328980, 0.07137959, 0.30458776, 0.04882449},\n            {0.04909388, 0.04762857, 0.04882449, 0.07543265}\n        };\n\nAnd it should throw an exception but it does not.  I tested the matrix in R and R's cholesky decomposition method returns that the matrix is not symmetric positive definite.\n\nObviously your code is not catching this appropriately.\n\nBy the way (in my opinion) the use of exceptions to check these conditions is not the best design or use for exceptions.  If you are going to force the use to try and catch these exceptions at least provide methods  to test the conditions prior to the possibility of the exception.  \n\n",
    "desc_source": "jira"
  },
  "Math_87": {
    "description": "Basic variable is not found correctly in simplex tableau\nThe last patch to SimplexTableau caused an automated test suite I'm running at work to go down a new code path and uncover what is hopefully the last bug remaining in the Simplex code.\nSimplexTableau was assuming an entry in the tableau had to be nonzero to indicate a basic variable, which is incorrect - the entry should have a value equal to 1.",
    "desc_source": "jira"
  },
  "Math_88": {
    "description": "Simplex Solver arrives at incorrect solution\nI have reduced the problem reported to me down to a minimal test case which I will attach.",
    "desc_source": "jira"
  },
  "Math_89": {
    "description": "Bugs in Frequency API\nI think the existing Frequency API has some bugs in it.\n\nThe addValue(Object v) method allows one to add a plain Object, but one cannot add anything further to the instance, as the second add fails with IllegalArgumentException.\nIn fact, the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects.\nThis could be fixed by checking that the object is Comparable.\n\nSimilar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable.\n\nThe getCount(Object) and getPct(Object) methods don't fail when given a non-Comparable object (because the class cast exception is caught), however they just return 0 as if the object was not present:\n\n{code}\n        final Object OBJ = new Object();\n        f.addValue(OBJ); // This ought to fail, but doesn't, causing the unexpected behaviour below\n        System.out.println(f.getCount(OBJ)); // 0\n        System.out.println(f.getPct(OBJ)); // 0.0\n{code}\n\nRather than adding extra checks for Comparable, it seems to me that the API would be much improved by using Comparable instead of Object.\nAlso, it should make it easier to implement generics.\n\nHowever, this would cause compilation failures for some programs that pass Object rather than Comparable to the class.\nThese would need recoding, but I think they would continue to run OK against the new API.\n\nIt would also affect the run-time behaviour slightly, as the first attempt to add a non-Comparable object would fail, rather than the second add of a possibly valid object.\nBut is that a viable program? It can only add one object, and any attempt to get statistics will either return 0 or an Exception, and applying the instanceof fix would also cause it to fail.",
    "desc_source": "jira"
  },
  "Math_90": {
    "description": "Bugs in Frequency API\nI think the existing Frequency API has some bugs in it.\n\nThe addValue(Object v) method allows one to add a plain Object, but one cannot add anything further to the instance, as the second add fails with IllegalArgumentException.\nIn fact, the problem is with the first call to addValue(Object) which should not allow a plain Object to be added - it should only allow Comparable objects.\nThis could be fixed by checking that the object is Comparable.\n\nSimilar considerations apply to the getCumFreq(Object) and getCumPct(Object) methods - they will only work with objects that implement Comparable.\n\nThe getCount(Object) and getPct(Object) methods don't fail when given a non-Comparable object (because the class cast exception is caught), however they just return 0 as if the object was not present:\n\n{code}\n        final Object OBJ = new Object();\n        f.addValue(OBJ); // This ought to fail, but doesn't, causing the unexpected behaviour below\n        System.out.println(f.getCount(OBJ)); // 0\n        System.out.println(f.getPct(OBJ)); // 0.0\n{code}\n\nRather than adding extra checks for Comparable, it seems to me that the API would be much improved by using Comparable instead of Object.\nAlso, it should make it easier to implement generics.\n\nHowever, this would cause compilation failures for some programs that pass Object rather than Comparable to the class.\nThese would need recoding, but I think they would continue to run OK against the new API.\n\nIt would also affect the run-time behaviour slightly, as the first attempt to add a non-Comparable object would fail, rather than the second add of a possibly valid object.\nBut is that a viable program? It can only add one object, and any attempt to get statistics will either return 0 or an Exception, and applying the instanceof fix would also cause it to fail.",
    "desc_source": "jira"
  },
  "Math_91": {
    "description": "Fraction.comparTo returns 0 for some differente fractions\nIf two different fractions evaluate to the same double due to limited precision,\nthe compareTo methode returns 0 as if they were identical.\n\n{code}\n// value is roughly PI - 3.07e-18\nFraction pi1 = new Fraction(1068966896, 340262731);\n\n// value is roughly PI + 1.936e-17\nFraction pi2 = new Fraction( 411557987, 131002976);\n\nSystem.out.println(pi1.doubleValue() - pi2.doubleValue()); // exactly 0.0 due to limited IEEE754 precision\nSystem.out.println(pi1.compareTo(pi2)); // display 0 instead of a negative value\n{code}",
    "desc_source": "jira"
  },
  "Math_92": {
    "description": "MathUtils.binomialCoefficient(n,k) fails for large results\nProbably due to rounding errors, MathUtils.binomialCoefficient(n,k) fails for results near Long.MAX_VALUE.\n\nThe existence of failures can be demonstrated by testing the recursive property:\n\n{noformat}\n         assertEquals(MathUtils.binomialCoefficient(65,32) + MathUtils.binomialCoefficient(65,33),\n                 MathUtils.binomialCoefficient(66,33));\n{noformat}\n\nOr by directly using the (externally calculated and hopefully correct) expected value:\n\n{noformat}\n         assertEquals(7219428434016265740L, MathUtils.binomialCoefficient(66,33));\n{noformat}\n\nI suggest a nonrecursive test implementation along the lines of\n\n{code:title=MathUtilsTest.java|borderStyle=solid}\n    /**\n     * Exact implementation using BigInteger and the explicit formula\n     * (n, k) == ((k-1)*...*n) / (1*...*(n-k))\n     */\n\tpublic static long binomialCoefficient(int n, int k) {\n\t\tif (k == 0 || k == n)\n\t\t\treturn 1;\n\t\tBigInteger result = BigInteger.ONE;\n\t\tfor (int i = k + 1; i <= n; i++) {\n\t\t\tresult = result.multiply(BigInteger.valueOf(i));\n\t\t}\n\t\tfor (int i = 1; i <= n - k; i++) {\n\t\t\tresult = result.divide(BigInteger.valueOf(i));\n\t\t}\n\t\tif (result.compareTo(BigInteger.valueOf(Long.MAX_VALUE)) > 0) {\n\t\t\tthrow new ArithmeticException(\n                                \"Binomial coefficient overflow: \" + n + \", \" + k);\n\t\t}\n\t\treturn result.longValue();\n\t}\n{code} \n\nWhich would allow you to test the expected values directly:\n\n{noformat}\n         assertEquals(binomialCoefficient(66,33), MathUtils.binomialCoefficient(66,33));\n{noformat}\n",
    "desc_source": "jira"
  },
  "Math_93": {
    "description": "MathUtils.factorial(n) fails for n >= 17\nThe result of MathUtils.factorial( n ) for n = 17, 18, 19 is wrong, probably because of rounding errors in the double calculations.\n\nReplace the first line of MathUtilsTest.testFactorial() by\n\n        for (int i = 1; i <= 20; i++) {\n\nto check all valid arguments for the long result and see the failure.\n\nI suggest implementing a simple loop to multiply the long result - or even using a precomputed long[] - instead of adding logarithms.",
    "desc_source": "jira"
  },
  "Math_94": {
    "description": "MathUtils.gcd(u, v) fails when u and v both contain a high power of 2\nThe test at the beginning of MathUtils.gcd(u, v) for arguments equal to zero fails when u and v contain high enough powers of 2 so that their product overflows to zero.\n\n        assertEquals(3 * (1<<15), MathUtils.gcd(3 * (1<<20), 9 * (1<<15)));\n\nFix: Replace the test at the start of MathUtils.gcd()\n\n        if (u * v == 0) {\n\nby\n\n        if (u == 0 || v == 0) {\n",
    "desc_source": "jira"
  },
  "Math_95": {
    "description": "denominatorDegreeOfFreedom in FDistribution leads to IllegalArgumentsException in UnivariateRealSolverUtils.bracket\nWe are using the FDistributionImpl from the commons.math project to do\nsome statistical calculations, namely receiving the upper and lower\nboundaries of a confidence interval. Everything is working fine and the\nresults are matching our reference calculations.\n\nHowever, the FDistribution behaves strange if a\ndenominatorDegreeOfFreedom of 2 is used, with an alpha-value of 0.95.\nThis results in an IllegalArgumentsException, stating:\n        \nInvalid endpoint parameters:  lowerBound=0.0 initial=Infinity\nupperBound=1.7976931348623157E308\n        \ncoming from\norg.apache.commons.math.analysis.UnivariateRealSolverUtils.bracket\n        \nThe problem is the 'initial' parameter to that function, wich is\nPOSITIVE_INFINITY and therefore not within the boundaries. I already\npinned down the problem to the FDistributions getInitialDomain()-method,\nwich goes like:\n\n        return getDenominatorDegreesOfFreedom() /\n                    (getDenominatorDegreesOfFreedom() - 2.0);\n        \nObviously, in case of denominatorDegreesOfFreedom == 2, this must lead\nto a division-by-zero, resulting in POSTIVE_INFINITY. The result of this\noperation is then directly passed into the\nUnivariateRealSolverUtils.bracket() - method as second argument.",
    "desc_source": "jira"
  },
  "Math_96": {
    "description": "Result of multiplying and equals for complex numbers is wrong\nHi.\n\nThe bug relates on complex numbers.\nThe methods \"multiply\" and \"equals\" of the class Complex are involved.\n\nmathematic background:  (0,i) * (-1,0i) = (0,-i).\n\nlittle java program + output that shows the bug:\n-----------------------------------------------------------------------\n{code}\nimport org.apache.commons.math.complex.*;\npublic class TestProg {\n        public static void main(String[] args) {\n\n                ComplexFormat f = new ComplexFormat();\n                Complex c1 = new Complex(0,1);\n                Complex c2 = new Complex(-1,0);\n\n                Complex res = c1.multiply(c2);\n                Complex comp = new Complex(0,-1);\n\n                System.out.println(\"res:  \"+f.format(res));\n                System.out.println(\"comp: \"+f.format(comp));\n\n                System.out.println(\"res=comp: \"+res.equals(comp));\n        }\n}\n{code}\n-----------------------------------------------------------------------\n\nres:  -0 - 1i\ncomp: 0 - 1i\nres=comp: false\n\n-----------------------------------------------------------------------\n\nI think the \"equals\" should return \"true\".\nThe problem could either be the \"multiply\" method that gives (-0,-1i) instead of (0,-1i),\nor if you think thats right, the equals method has to be modified.\n\nGood Luck\nDieter",
    "desc_source": "jira"
  },
  "Math_97": {
    "description": "BrentSolver throws IllegalArgumentException \nI am getting this exception:\n\njava.lang.IllegalArgumentException: Function values at endpoints do not have different signs.  Endpoints: [-100000.0,1.7976931348623157E308]  Values: [0.0,-101945.04630982173]\nat org.apache.commons.math.analysis.BrentSolver.solve(BrentSolver.java:99)\nat org.apache.commons.math.analysis.BrentSolver.solve(BrentSolver.java:62)\n\nThe exception should not be thrown with values  [0.0,-101945.04630982173] because 0.0 is positive.\nAccording to Brent Worden, the algorithm should stop and return 0 as the root instead of throwing an exception.\n\nThe problem comes from this method:\n    public double solve(double min, double max) throws MaxIterationsExceededException, \n        FunctionEvaluationException {\n        \n        clearResult();\n        verifyInterval(min, max);\n        \n        double yMin = f.value(min);\n        double yMax = f.value(max);\n        \n        // Verify bracketing\n        if (yMin * yMax >= 0) {\n            throw new IllegalArgumentException\n            (\"Function values at endpoints do not have different signs.\" +\n                    \"  Endpoints: [\" + min + \",\" + max + \"]\" + \n                    \"  Values: [\" + yMin + \",\" + yMax + \"]\");       \n        }\n\n        // solve using only the first endpoint as initial guess\n        return solve(min, yMin, max, yMax, min, yMin);\n\n    }\n\nOne way to fix it would be to add this code after the assignment of yMin and yMax:\n        if (yMin ==0 || yMax == 0) {\n        \treturn 0;\n       \t}\n",
    "desc_source": "jira"
  },
  "Math_98": {
    "description": "RealMatrixImpl#operate gets result vector dimensions wrong\n{{org.apache.commons.math.linear.RealMatrixImpl#operate}} tries to create a result vector that always has the same length as the input vector. This can result in runtime exceptions if the matrix is non-square and it always yields incorrect results if the matrix is non-square. The correct behaviour would of course be to create a vector with the same length as the row dimension of the matrix.\n\nThus line 640 in RealMatrixImpl.java should read\n  {{double[] out = new double[nRows];}}\ninstead of\n  {{double[] out = new double[v.length];}}\n",
    "desc_source": "jira"
  },
  "Math_99": {
    "description": "MathUtils.gcd(Integer.MIN_VALUE, 0) should throw an Exception instead of returning Integer.MIN_VALUE\nThe gcd method should throw an Exception for gcd(Integer.MIN_VALUE, 0), like for gcd(Integer.MIN_VALUE, Integer.MIN_VALUE). The method should only return nonnegative results.",
    "desc_source": "jira"
  },
  "Math_100": {
    "description": "AbstractEstimator: getCovariances() and guessParametersErrors() crash when having bound parameters\nthe two methods getCovariances() and guessParametersErrors() from org.apache.commons.math.estimation.AbstractEstimator crash with ArrayOutOfBounds exception when some of the parameters are bound. The reason is that the Jacobian is calculated only for the unbound parameters. in the code you loop through all parameters.\n\nline #166: final int cols = problem.*getAllParameters()*.length;\nshould be replaced by:  final int cols = problem.*getUnboundParameters()*.length;\n(similar changes could be done in guessParametersErrors())\n\nthe dissadvantage of the above bug fix is that what is returned to the user is an array with smaller size than the number of all parameters. Alternatively, you can have some logic in the code which writes zeros for the elements of the covariance matrix corresponding to the bound parameters",
    "desc_source": "jira"
  },
  "Math_101": {
    "description": "java.lang.StringIndexOutOfBoundsException in ComplexFormat.parse(String source, ParsePosition pos)\nThe parse(String source, ParsePosition pos) method in the ComplexFormat class does not check whether the imaginary character is set or not which produces StringIndexOutOfBoundsException in the substring method :\n\n(line 375 of ComplexFormat)\n...\n        // parse imaginary character\n        int n = getImaginaryCharacter().length();\n        \n        startIndex = pos.getIndex();\n        int endIndex = startIndex + n;\n        if (source.substring(startIndex, endIndex).compareTo(\n            getImaginaryCharacter()) != 0) {\n...\nI encoutered this exception typing in a JTextFied with ComplexFormat set to look up an AbstractFormatter.\nIf only the user types the imaginary part of the complex number first, he gets this exception.\n\nSolution: Before setting to n length of the imaginary character, check if the source contains it. My proposal:\n...\n        int n = 0;\n        if (source.contains(getImaginaryCharacter()))\n        n = getImaginaryCharacter().length();\n...\t\t \n\nF.S.",
    "desc_source": "jira"
  },
  "Math_102": {
    "description": "chiSquare(double[] expected, long[] observed) is returning incorrect test statistic\nChiSquareTestImpl is returning incorrect chi-squared value. An implicit assumption of public double chiSquare(double[] expected, long[] observed) is that the sum of expected and observed are equal. That is, in the code:\nfor (int i = 0; i < observed.length; i++) {\n            dev = ((double) observed[i] - expected[i]);\n            sumSq += dev * dev / expected[i];\n        }\nthis calculation is only correct if sum(observed)==sum(expected). When they are not equal then one must rescale the expected value by sum(observed) / sum(expected) so that they are.\nIronically, it is an example in the unit test ChiSquareTestTest that highlights the error:\n\nlong[] observed1 = { 500, 623, 72, 70, 31 };\n        double[] expected1 = { 485, 541, 82, 61, 37 };\n        assertEquals( \"chi-square test statistic\", 16.4131070362, testStatistic.chiSquare(expected1, observed1), 1E-10);\n        assertEquals(\"chi-square p-value\", 0.002512096, testStatistic.chiSquareTest(expected1, observed1), 1E-9);\n\n16.413 is not correct because the expected values do not make sense, they should be: 521.19403 581.37313  88.11940  65.55224  39.76119 so that the sum of expected equals 1296 which is the sum of observed.\n\nHere is some R code (r-project.org) which proves it:\n> o1\n[1] 500 623  72  70  31\n> e1\n[1] 485 541  82  61  37\n> chisq.test(o1,p=e1,rescale.p=TRUE)\n\n        Chi-squared test for given probabilities\n\ndata:  o1 \nX-squared = 9.0233, df = 4, p-value = 0.06052\n\n> chisq.test(o1,p=e1,rescale.p=TRUE)$observed\n[1] 500 623  72  70  31\n> chisq.test(o1,p=e1,rescale.p=TRUE)$expected\n[1] 521.19403 581.37313  88.11940  65.55224  39.76119\n\n\n\n\n\n ",
    "desc_source": "jira"
  },
  "Math_103": {
    "description": "ConvergenceException in normal CDF\nNormalDistributionImpl::cumulativeProbability(double x) throws ConvergenceException\nif x deviates too much from the mean. For example, when x=+/-100, mean=0, sd=1.\nOf course the value of the CDF is hard to evaluate in these cases,\nbut effectively it should be either zero or one.",
    "desc_source": "jira"
  },
  "Math_104": {
    "description": "Special functions not very accurate\nThe Gamma and Beta functions return values in double precision but the default epsilon is set to 10e-9. I think that the default should be set to the highest possible accuracy, as this is what I'd expect to be returned by a double precision routine. Note that the erf function already uses a call to Gamma.regularizedGammaP with an epsilon of 1.0e-15.",
    "desc_source": "jira"
  },
  "Math_105": {
    "description": "[math]  SimpleRegression getSumSquaredErrors\ngetSumSquaredErrors returns -ve value. See test below:\n\npublic void testSimpleRegression() {\n\t\tdouble[] y = {  8915.102, 8919.302, 8923.502};\n\t\tdouble[] x = { 1.107178495, 1.107264895, 1.107351295};\n\t\tdouble[] x2 = { 1.107178495E2, 1.107264895E2, 1.107351295E2};\n\t\tSimpleRegression reg = new SimpleRegression();\n\t\tfor (int i = 0; i < x.length; i++) {\n\t\t\treg.addData(x[i],y[i]);\n\t\t}\n\t\tassertTrue(reg.getSumSquaredErrors() >= 0.0); // OK\n\t\treg.clear();\n\t\tfor (int i = 0; i < x.length; i++) {\n\t\t\treg.addData(x2[i],y[i]);\n\t\t}\n\t\tassertTrue(reg.getSumSquaredErrors() >= 0.0); // FAIL\n\t\t\n\t}",
    "desc_source": "jira"
  },
  "Math_106": {
    "description": "[math] Function math.fraction.ProperFractionFormat.parse(String, ParsePosition) return illogical result\nHello,\n\nI find illogical returned result from function \"Fraction parse(String source, \nParsePostion pos)\" (in class ProperFractionFormat of the Fraction Package) of \nthe Commons Math library. Please see the following code segment for more \ndetails:\n\n\"\nProperFractionFormat properFormat = new ProperFractionFormat();\nresult = null;\nString source = \"1 -1 / 2\";\nParsePosition pos = new ParsePosition(0);\n\n//Test 1 : fail \npublic void testParseNegative(){\n \n   String source = \"-1 -2 / 3\";\n   ParsePosition pos = new ParsePosition(0);\n\n   Fraction actual = properFormat.parse(source, pos);\n   assertNull(actual);\n}\n\n// Test2: success\npublic void testParseNegative(){\n \n   String source = \"-1 -2 / 3\";\n   ParsePosition pos = new ParsePosition(0);\n\n   Fraction actual = properFormat.parse(source, pos);  // return Fraction 1/3\n   assertEquals(1, source.getNumerator());\n   assertEquals(3, source.getDenominator());\n}\n\n\"\n\nNote: Similarly, when I passed in the following inputs: \n  input 2: (source = \u00931 2 / -3\u0094, pos = 0)\n  input 3: ( source = \u0094 -1 -2 / 3\u0094, pos = 0)\n\nFunction \"Fraction parse(String, ParsePosition)\" returned Fraction 1/3 (means \nthe result Fraction had numerator = 1 and  denominator = 3)for all 3 inputs \nabove.\n \nI think the function does not handle parsing the numberator/ denominator \nproperly incase input string provide invalid numerator/denominator. \n\nThank you!",
    "desc_source": "jira"
  },
  "Time_1": {
    "description": "Partial.with fails with NPE\nWith the latest master:\n\n``` java\nnew Partial(yearOfCentury(),  1).with(weekyear(), 1);\n// NullPointerException\n// org.joda.time.Partial.with (Partial.java:447)\n```\n\nFails with yearOfCentury, year and yearOfEra. Probably because weekyear has a null range duration type.\n\n",
    "desc_source": "github_issue"
  },
  "Time_2": {
    "description": "Partial.with fails with NPE\nWith the latest master:\n\n``` java\nnew Partial(yearOfCentury(),  1).with(weekyear(), 1);\n// NullPointerException\n// org.joda.time.Partial.with (Partial.java:447)\n```\n\nFails with yearOfCentury, year and yearOfEra. Probably because weekyear has a null range duration type.\n\n",
    "desc_source": "github_issue"
  },
  "Time_3": {
    "description": "addDays(0) changes value of MutableDateTime\nUpon DST transition from summer to winter time zone, adding the amount of zero days to a mutable date time object changes the value of the object.\n\nThe code\n\n``` java\nfinal MutableDateTime mdt = new MutableDateTime(2011, 10, 30, 3, 0, 0, 0, DateTimeZone.forID(\"Europe/Berlin\"));\nSystem.out.println(\"Start date:   \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\nmdt.addHours(-1);\nSystem.out.println(\"addHours(-1): \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\nmdt.addHours(0);\nSystem.out.println(\"addHours(0):  \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\nmdt.addDays(0);\nSystem.out.println(\"addDays(0):   \" + mdt + \" (\" + mdt.toInstant().getMillis() + \")\");\n```\n\nprints\n\n```\nStart date:   2011-10-30T03:00:00.000+01:00 (1319940000000)    //OK\naddHours(-1): 2011-10-30T02:00:00.000+01:00 (1319936400000)    //OK\naddHours(0):  2011-10-30T02:00:00.000+01:00 (1319936400000)    //OK, no change in time\naddDays(0):   2011-10-30T02:00:00.000+02:00 (1319932800000)    //error, time has changed by 1 hour\n```\n\nThe methods addMonths and addYears show the same problem; addSeconds, addMinutes and addHours are ok.\n\nI have tested with version 2.3. However, if I repeat the test with Joda 1.5.2, the invocation of addDays(0) does not change the date's value.\n\n",
    "desc_source": "github_issue"
  },
  "Time_4": {
    "description": "Constructing invalid Partials\nPartials can be constructed by invoking a constructor `Partial(DateTimeFieldType[], int[])` or by merging together a set of partials using `with`, each constructed by calling `Partial(DateTimeFieldType, int)`, e.g.:\n\n``` java\nPartial a = new Partial(new DateTimeFieldType[] { year(), hourOfDay() }, new int[] { 1, 1});\nPartial b = new Partial(year(), 1).with(hourOfDay(), 1);\nassert(a == b);\n```\n\nHowever, the above doesn't work in all cases:\n\n``` java\nnew Partial(new DateTimeFieldType[] { clockhourOfDay(), hourOfDay() }, new int[] { 1, 1}); // throws Types array must not contain duplicate\nnew Partial(clockhourOfDay(), 1).with(hourOfDay(), 1); // #<Partial [clockhourOfDay=1, hourOfDay=1]>\n```\n\nI suppose the Partials should not allow to be constructed in either case. Is that right?\n\nThere's also a related issue (probably stems from the fact that the Partial is invalid):\n\n``` java\nnew Partial(clockhourOfDay(), 1).with(hourOfDay(), 1).isEqual(new Partial(hourOfDay() ,1).with(clockhourOfDay(), 1)) // throws objects must have matching field types\n```\n\n",
    "desc_source": "github_issue"
  },
  "Time_5": {
    "description": "none standard PeriodType without year throws exception\nHi.\n\nI tried to get a Period only for months and weeks with following code:\n\n``` Java\nPeriod p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()})).normalizedStandard(PeriodType.forFields(new DurationFieldType[]{DurationFieldType.months(), DurationFieldType.weeks()}));\nreturn p.getMonths();\n```\n\nThis throws following exception:\n\n```\n 10-17 14:35:50.999: E/AndroidRuntime(1350): java.lang.UnsupportedOperationException: Field is not supported\n 10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.PeriodType.setIndexedField(PeriodType.java:690)\n 10-17 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.withYears(Period.java:896) 10-17\n 14:35:50.999: E/AndroidRuntime(1350): at org.joda.time.Period.normalizedStandard(Period.java:1630)\n```\n\nEven removing the year component with .withYearsRemoved() throws the same exception:\n\nthis works:\n\n``` Java\nPeriod p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard()).normalizedStandard(PeriodType.standard());\nreturn p.getMonths();\n```\n\nthis fails:\n\n``` Java\nPeriod p = new Period(new DateTime(startDate.getTime()), new DateTime(endDate.getTime()), PeriodType.standard().withYearsRemoved()).normalizedStandard(PeriodType.standard().withYearsRemoved());\nreturn p.getMonths();\n```\n\n",
    "desc_source": "github_issue"
  },
  "Time_6": {
    "description": "Questionable behaviour of GJChronology when dates pass 1BC\nI expect the following test to pass:\n\n```\nChronology chronology = GJChronology.getInstance();\n\nLocalDate start = new LocalDate(2013, 5, 31, chronology);\nLocalDate expectedEnd = new LocalDate(-1, 5, 31, chronology); // 1 BC\nassertThat(start.minusYears(2013), is(equalTo(expectedEnd)));\nassertThat(start.plus(Period.years(-2013)), is(equalTo(expectedEnd)));\n```\n\nThe error it gives is:\n\n```\norg.joda.time.IllegalFieldValueException: Value 0 for year is not supported\n```\n\nHowever, I never provided \"0\" for the year myself. I thought it was the job of the framework to skip over non-existent year 0 for me to return 1 BC?\n\n",
    "desc_source": "github_issue"
  },
  "Time_7": {
    "description": "DateTimeFormat.parseInto sometimes miscalculates year (2.2)\nThere appears to be a bug in the fix to http://sourceforge.net/p/joda-time/bugs/148 (which I also reported).\n\nThe following code (which can be added to org.joda.time.format.TestDateTimeFormatter) breaks, because the input mutable date time's millis appear to be mishandled and the year for the parse is changed to 1999:\n\n``` java\n    public void testParseInto_monthDay_feb29_startOfYear() {\n        DateTimeFormatter f = DateTimeFormat.forPattern(\"M d\").withLocale(Locale.UK);\n        MutableDateTime result = new MutableDateTime(2000, 1, 1, 0, 0, 0, 0, NEWYORK);\n        assertEquals(4, f.parseInto(result, \"2 29\", 0));\n        assertEquals(new MutableDateTime(2000, 2, 29, 0, 0, 0, 0, NEWYORK), result);\n    }\n```\n\n",
    "desc_source": "github_issue"
  },
  "Time_8": {
    "description": "DateTimeZone.forOffsetHoursMinutes cannot handle negative offset < 1 hour\n`DateTimeZone.forOffsetHoursMinutes(h,m)` cannot handle negative offset < 1 hour like `-0:30` due to argument range checking. I used `forOffsetMillis()` instead.\n\nThis should probably be mentioned in the documentation or negative minutes be accepted.\n\n",
    "desc_source": "github_issue"
  },
  "Time_9": {
    "description": "Ensure there is a max/min valid offset\n`DateTimeZone` does not apply a max/min value for an offset. However the parse method is limited to 23:59. Make 23:59:59.999 the maximum.\n\n",
    "desc_source": "github_issue"
  },
  "Time_10": {
    "description": "Days#daysBetween throw exception for MonthDay with 29 February\nfinal LocalDate january12012 = new LocalDate(2012, 1,1);\nfinal LocalDate february292012 = new LocalDate(2012, 2, 29);\n// OK\nassertEquals(59, Days.daysBetween(january12012, february292012).getDays());\n\nfinal MonthDay january1 = new MonthDay(1,1);\nfinal MonthDay february29 = new MonthDay(2, 29);\n// FAIL\nassertEquals(59, Days.daysBetween(january1, february29).getDays());\n\norg.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range [1,28]\n    at org.joda.time.field.FieldUtils.verifyValueBounds(FieldUtils.java:217)\n    at org.joda.time.field.PreciseDurationDateTimeField.set(PreciseDurationDateTimeField.java:78)\n    at org.joda.time.chrono.BaseChronology.set(BaseChronology.java:240)\n    at org.joda.time.base.BaseSingleFieldPeriod.between(BaseSingleFieldPeriod.java:103)\n    at org.joda.time.Days.daysBetween(Days.java:141)\n\nIs there a way to avoid this happening? I understand fiddling around with the leap year, you're bound to get issues.\n\nThanks! \n\n",
    "desc_source": "github_issue"
  },
  "Time_11": {
    "description": "NPE in DateTimeZoneBuilder\nWhen a DateTimeZone is build with duplicate-named 'recurring saving time' in a first thread, all goes Ok: a warning message is generated and an identifier is automatically generated in PrecalculatedZone.create(). When a second thread does the same, an NPE is generated in ZoneInfoCompiler.verbose().\n\nThe cause is that the cVerbose ThreadLocal is incorrectly initialized in ZoneInfoCompiler:\n\n``` java\n   static {\n        cVerbose.set(Boolean.FALSE);\n    }\n```\n\n...will initialize cVerbose only for the first thread and not for the subsequent ones. The NPE is caused by the autoboxing in:\n\n``` java\n   public static boolean verbose() {\n        return cVerbose.get();\n    }\n```\n\nA better approach could be to remove the initialization and test for null:\n\n``` java\npublic static boolean verbose(){\n    Boolean verbose = cVerbose.get();\n    return (verbose != null) ? verbose : false;\n}\n```\n\n---\n\nHere follows a test case:\n\n``` java\n    @Test\n    public void testDateTimeZoneBuilder() throws Exception {\n        getTestDataTimeZoneBuilder().toDateTimeZone(\"TestDTZ1\", true);\n        Thread t = new Thread(new Runnable() {\n            @Override\n            public void run() {\n                getTestDataTimeZoneBuilder().toDateTimeZone(\"TestDTZ2\", true);\n            }\n        });\n        t.start();\n        t.join();\n    }\n\n    private DateTimeZoneBuilder getTestDataTimeZoneBuilder() {\n         return new DateTimeZoneBuilder()\n         .addCutover(1601, 'w', 1, 1, 1, false, 7200000)\n         .setStandardOffset(3600000)\n         .addRecurringSavings(\"\", 3600000, 1601, Integer.MAX_VALUE, 'w', 3, -1, 1, false, 7200000)\n         .addRecurringSavings(\"\", 0, 1601, Integer.MAX_VALUE, 'w', 10, -1, 1, false, 10800000);\n    }\n```\n\n",
    "desc_source": "github_issue"
  },
  "Time_12": {
    "description": "Check Calendar.ERA in LocalDate.fromCalendarFields\n\n",
    "desc_source": "github_issue"
  },
  "Time_13": {
    "description": "#160 Negative millis display incorrectly in Period.toString\nThis code:\nimport org.joda.time.Duration;\nimport org.joda.time.Period;\npublic class A {\n  public static void main(String[] args) {\n    System.out.println(\"new Duration(-1000).getMillis() = \" + new Duration(-1000).getMillis());\n    System.out.println(\"new Duration(-1000).toString()  = \" + new Duration(-1000).toString());\n    System.out.println(\"new Period(-1000).getSeconds()  = \" + new Period(-1000).getSeconds());\n    System.out.println(\"new Period(-1000).toString()    = \" + new Period(-1000).toString());\n    System.out.println(\"new Duration(-100).getMillis()  = \" + new Duration(-100).getMillis());\n    System.out.println(\"new Duration(-100).toString()   = \" + new Duration(-100).toString());\n    System.out.println(\"new Period(-100).getMillis()    = \" + new Period(-100).getMillis());\n    System.out.println(\"new Period(-100).toString()     = \" + new Period(-100).toString());\n  }\n}\nProduces output:\nnew Duration(-1000).getMillis() = -1000\nnew Duration(-1000).toString()  = PT-1S\nnew Period(-1000).getSeconds()  = -1\nnew Period(-1000).toString()    = PT-1S\nnew Duration(-100).getMillis()  = -100\nnew Duration(-100).toString()   = PT-0.100S\nnew Period(-100).getMillis()    = -100\nnew Period(-100).toString()     = PT0.100S\nThe last line should produce \"PT-0.100S\" instead of \"PT0.100S\".",
    "desc_source": "sourceforge"
  },
  "Time_14": {
    "description": "#151 Unable to add days to a MonthDay set to the ISO leap date\nIt's not possible to add days to a MonthDay set to the ISO leap date (February 29th).  This is even more bizarre given the exact error message thrown.\nSample snippet:\nfinal MonthDay isoLeap = new MonthDay(DateTimeConstants.FEBRUARY, 29, ISOChronology.getInstanceUTC());\nSystem.out.println(isoLeap);\nSystem.out.println(isoLeap.plusDays(2));\n\nWhich generates the following combined console output and stack trace:  \n--02-29\nException in thread \"main\" org.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range [1,28]\n    at org.joda.time.field.FieldUtils.verifyValueBounds(FieldUtils.java:215)\n    at org.joda.time.field.PreciseDurationDateTimeField.set(PreciseDurationDateTimeField.java:78)\n    at org.joda.time.chrono.BasicMonthOfYearDateTimeField.add(BasicMonthOfYearDateTimeField.java:212)\n    at org.joda.time.field.BaseDateTimeField.add(BaseDateTimeField.java:324)\n    at org.joda.time.MonthDay.withFieldAdded(MonthDay.java:519)\n    at org.joda.time.MonthDay.minusDays(MonthDay.java:672)\n    at ext.site.time.chrono.Main.m7(Main.java:191)\n    at ext.site.time.chrono.Main.main(Main.java:27)\nThe follwing method calls and parameters also generate the same or related error:  \nisoLeap.plusMonths(1);\nisoLeap.plusMonths(-1);\nisoLeap.minusMonths(1);\nisoLeap.minusMonths(-1);\nisoLeap.minusDays(-1);\n\nHowever, the following methods work:  \nisoLeap.minusDays(1);\nisoLeap.plusDays(-1);\n\nPerforming operations on dates around the ISO leap date react as if it exists, ie:\nSystem.out.println(isoLeap.minusDays(1).plusDays(2));\n\nPrints out '--03-01' as expected.",
    "desc_source": "sourceforge"
  },
  "Time_15": {
    "description": "#147 possibly a bug in org.joda.time.field.FieldUtils.safeMultipl\nIt seems to me that as currently written in joda-time-2.1.jar\norg.joda.time.field.FieldUtils.safeMultiply(long val1, int scalar)\ndoesn't detect the overflow if the long val1 == Long.MIN_VALUE and the int scalar == -1.\nThe attached file demonstrates what I think is the bug and suggests a patch.\nI looked at the Joda Time bugs list in SourceForge but couldn't see anything that looked relevant: my apologies if I've missed something, or if I'm making a mistake with this bug report.\nColin Bartlett",
    "desc_source": "sourceforge"
  },
  "Time_16": {
    "description": "#148 DateTimeFormatter.parseInto broken when no year in format\nIn Joda Time 2.0, the default year was set to 2000 so that Feb 29 could be parsed correctly. However, parseInto now overwrites the given instant's year with 2000 (or whatever iDefaultYear is set to). The correct behavior would seem to be to use the given instant's year instead of iDefaultYear.\nThis does mean that Feb 29 might not be parseable if the instant's year is not a leap year, but in this case the caller asked for that in a sense.",
    "desc_source": "sourceforge"
  },
  "Time_17": {
    "description": "#141 Bug on withLaterOffsetAtOverlap method\nThe method withLaterOffsetAtOverlap created to workaround the issue 3192457 seems to not be working at all.\nI won\u00b4t write many info about the problem to solve because the issue 3192457  have this info indeed.\nBut If something is unclear I can answer on the comments.\nProblem demonstration:\n    TimeZone.setDefault(TimeZone.getTimeZone(\"America/Sao_Paulo\"));\n        DateTimeZone.setDefault( DateTimeZone.forID(\"America/Sao_Paulo\") );\n    DateTime dtch;\n    {\n        dtch = new DateTime(2012,2,25,5,5,5,5).millisOfDay().withMaximumValue();\n        System.out.println( dtch ); // prints: 2012-02-25T23:59:59.999-02:00 //Were are at the first 23:** of the day.\n        //At this point dtch have the -03:00 offset\n    }\n    {\n        dtch = dtch.plus(60001);\n        System.out.println( dtch ); // prints: 2012-02-25T23:01:00.000-03:00 //Were are at the first minute of the second 23:** of the day. Ok its correct\n        //At this point dtch have the -03:00 offset\n    }\n    {\n        dtch = dtch.withEarlierOffsetAtOverlap();\n        System.out.println( dtch ); // prints: 2012-02-25T23:01:00.000-02:00 //Were are at the first minute of the first 23:** of the day. Ok its correct\n        //At this point dtch have the -02:00 offset ( because we called withEarlierOffsetAtOverlap() ) // This method is working perfectly\n    }       \n    {\n        dtch = dtch.withLaterOffsetAtOverlap();\n        System.out.println( dtch ); // prints: 2012-02-25T23:01:00.000-02:00 //Were are at the first minute of the first 23:** of the day. \n        // Here is the problem we should have a -03:00 offset here since we called withLaterOffsetAtOverlap() expecting to change to the second 23:** of the day\n    }\n\nOn the last two brackets we can see that withLaterOffsetAtOverlap is not undoing withEarlierOffsetAtOverlap as it should ( and not even working at all )",
    "desc_source": "sourceforge"
  },
  "Time_18": {
    "description": "#130 GJChronology rejects valid Julian dates\nExample:\nDateTime jdt  = new DateTime(1500, 2, 29, 0, 0, 0, 0, JulianChronology.getInstanceUTC());   // Valid.\nDateTime gjdt = new DateTime(1500, 2, 29, 0, 0, 0, 0, GJChronology.getInstanceUTC());       // Invalid.\nThe 2nd statement fails with \"org.joda.time.IllegalFieldValueException: Value 29 for dayOfMonth must be in the range [1,28]\".\nGiven that I left the cutover date at the default (October 15, 1582), isn't 1500/02/29 a valid date in the GJChronology?",
    "desc_source": "sourceforge"
  },
  "Time_19": {
    "description": "#124 Inconsistent interpretation of ambiguous time during DST\nThe inconsistency appears for timezone Europe/London.\nConsider the following code\n\u2026\n        DateTime britishDate    = new DateTime(2011, 10, 30, 1, 59, 0, 0, DateTimeZone.forID(\"Europe/London\"));\n        DateTime norwDate       = new DateTime(2011, 10, 30, 2, 59, 0, 0, DateTimeZone.forID(\"Europe/Oslo\"));\n        DateTime finnishDate    = new DateTime(2011, 10, 30, 3, 59, 0, 0, DateTimeZone.forID(\"Europe/Helsinki\"));\n    System.out.println(britishDate);\n    System.out.println(norwDate);\n    System.out.println(finnishDate);\n\n\u2026\nThese three DateTime objects should all represent the same moment in time even if they are ambiguous. And using jodatime 1.6.2 this is the case. The code produces the following output:\n2011-10-30T01:59:00.000Z\n2011-10-30T02:59:00.000+01:00\n2011-10-30T03:59:00.000+02:00\nUsing jodatime 2.0 however, the output is:\n2011-10-30T01:59:00.000Z\n2011-10-30T02:59:00.000+02:00\n2011-10-30T03:59:00.000+03:00\nwhich IMO is wrong for Europe/London. Correct output should have been \n2011-10-30T01:59:00.000+01:00\nThe release notes for 2.0 states that: \n\"Now, it always returns the earlier instant (summer time) during an overlap. \u2026\"",
    "desc_source": "sourceforge"
  },
  "Time_20": {
    "description": "#126 Errors creating/parsing dates with specific time zones.\nConsider the following test code using Joda 2.0\nimport org.joda.time.DateTime;\nimport org.joda.time.DateTimeZone;\nimport org.joda.time.format.DateTimeFormat;\nimport org.joda.time.format.DateTimeFormatter;\nimport java.util.Set;\npublic class JodaDateTimeZoneTester {\nprivate static DateTimeFormatter formatter = DateTimeFormat.forPattern(\"MM/dd/yyyy HH:mm:ss.SSS ZZZ\");\nprivate static int numTimeZonesTested = 0;\nprivate static int numTimeZonesPassed = 0;\nprivate static int numTimeZonesFailed = 0;\nprivate static int numTimeZonesException = 0;\n\nprivate static String convertDateTimeToFormattedString(DateTime dateTime) {\n    return formatter.print(dateTime);\n}\n\nprivate static DateTime parseStringToDateTime(String formattedDateTime) {\n    return formatter.parseDateTime(formattedDateTime);\n}\n\nprivate static void testDateTimeFormatter(DateTime dateTime, String timeZone) {\n    numTimeZonesTested++;\n\n    final String dateTimeZoneId = dateTime.getZone().getID();\n\n    if (!timeZone.equals(dateTimeZoneId)) {\n        numTimeZonesFailed++;\n        System.out.println(timeZone + \" failed to construct into the proper date time zone - constructed time zone = \" + dateTimeZoneId);\n        return;\n    }\n    try {\n        DateTime convertedDateTime = parseStringToDateTime(convertDateTimeToFormattedString(dateTime));\n\n        if (dateTime.equals(convertedDateTime)) {\n            numTimeZonesPassed++;\n            //System.out.println(dateTime.getZone().getID() + \" passed.\");\n        } else {\n            numTimeZonesFailed++;\n            System.out.println(\"Formatter failed for time zone ID: \" + dateTimeZoneId + \"    converted it to: \" + convertedDateTime.getZone().getID());\n        }\n    } catch (IllegalArgumentException iae) {\n        numTimeZonesException++;\n        System.out.println(\"Formatter threw exception for time zone id: \" + dateTimeZoneId);\n    }\n}\n\npublic static void main(String[] args) {\n    Set<String> timeZones = DateTimeZone.getAvailableIDs();\n\n    for (String timeZone : timeZones) {\n        testDateTimeFormatter(DateTime.now().withZone(DateTimeZone.forID(timeZone)), timeZone);\n    }\n\n    System.out.println();\n    System.out.println(\"Number of Time Zones tested: \" + numTimeZonesTested);\n    System.out.println(\"Number passed:     \" + numTimeZonesPassed);\n    System.out.println(\"Number failed:     \" + numTimeZonesFailed);\n    System.out.println(\"Number exceptions: \" + numTimeZonesException);\n    System.out.println();\n}\n\n}\nThe results are out of 572 time zones 130 fail and 30 throw exceptions. \nThe failures are the most interesting.  When I query DateTimeZone to get its time zone ids I will get a time zone like America/Atka.  When I take that id and create a date time with it its time zone id is America/Adak.  It is like there are multiple list of time zones in Joda time and they are out of sync. \nSource code is attached.",
    "desc_source": "sourceforge"
  },
  "Time_22": {
    "description": "#113 Duration.toPeriod with fixed time zones.\nI have a question concerning the conversion of a Duration to Period.  I'm not sure if this is a bug, or if there is a different way to do this.\nThe basis of the problem, is that using Duration.toPeriod() uses the chronology of the default time zone to do the conversion.  This can cause different results from a timezone with DST and one without.  This can be reproduced easily with this test.\n//set default time zone with this argument -Duser.timezone=\"GMT\"\npublic void testForJodaForum()\n{\n    System.out.println(\"Timezone: \" + DateTimeZone.getDefault());\n\n    //Duration of more than 24 hours\n    Duration aDuration = new Duration(DateTimeConstants.MILLIS_PER_HOUR * 30 + DateTimeConstants.MILLIS_PER_MINUTE * 50\n        + DateTimeConstants.MILLIS_PER_SECOND * 14);\n\n    System.out.println(\"Duration before: \" + aDuration);\n    Period period = aDuration.toPeriod();\n    System.out.println(\"Period after: \" + period);        \n}\n\nA fixed time zone produces this output\nTimezone: Etc/GMT\nDuration before: PT111014S\nPeriod after: P1DT6H50M14S\nA DST time zone produces this output\nTimezone: America/Chicago\nDuration before: PT111014S\nPeriod after: PT30H50M14S\nIn the joda code, Duration.toPeriod() uses a period constructor that takes the chronology, but null is passed in, so the chronology of the default time zone is used, which leads to this behavior.\nThe javadoc of toPeriod() states that only precise fields of hours, minutes, seconds, and millis will be converted.  But for a fixed timezone, days and weeks are also precise, which is stated in the javadoc for toPeriod(Chronology chrono).  In our app, we need consistent behavior regardless of the default time zone, which is to have all the extra hours put into the hours bucket.  Since Duration is supposed to be a 'time zone independent' length of time, I don't think we should have to do any chronology manipulation to get this to work.\nAny help is appreciated.\nThanks,\nCameron",
    "desc_source": "sourceforge"
  },
  "Time_23": {
    "description": "#112 Incorrect mapping of the MET time zone\nThis timezone is mapped to Asia/Tehran in DateTimeZone. It should be middle europena time.\nI know that this bug has been raised before (Incorrect mapping of the MET time zone - ID: 2012274), and there is a comment stating that you won't break backward compatibility to fix this bug.\n\nI disagree that this is a backward compatibility argument\nNo matter how you look at it, it is a bug.\n\nYou could very well state that ALL bugs won't be fixed, because of backward compatibility.\nI request again that this bug be fixed.",
    "desc_source": "sourceforge"
  },
  "Time_24": {
    "description": "#107 Incorrect date parsed when week and month used together\nI have following code snippet :\n    DateTimeFormatter dtf = DateTimeFormat.forPattern(\"xxxxMM'w'ww\");\nDateTime dt = dtf.parseDateTime(\"201101w01\");       \nSystem.out.println(dt);\n\nIt should print 2011-01-03 but it is printing 2010-01-04. \nPlease let me know if I am doing something wrong here.",
    "desc_source": "sourceforge"
  },
  "Time_25": {
    "description": "#90 DateTimeZone.getOffsetFromLocal error during DST transition\nThis may be a failure of my understanding, but the comments in DateTimeZone.getOffsetFromLocal lead me to believe that if an ambiguous local time is given, the offset corresponding to the later of the two possible UTC instants will be returned - i.e. the greater offset.\nThis doesn't appear to tally with my experience. In fall 2009, America/Los_Angeles changed from -7 to -8 at 2am wall time on November 11. Thus 2am became 1am - so 1:30am is ambiguous. I would therefore expect that constructing a DateTime for November 11th, 1:30am would give an instant corresponding with the later value (i.e. 9:30am UTC). This appears not to be the case:\nimport org.joda.time.DateTime;\nimport org.joda.time.DateTimeZone;\npublic class TzTest {\n    public static void main(String[] args) throws Exception {\n        DateTimeZone zone = DateTimeZone.forID(\"America/Los_Angeles\");\n        DateTime when1 = new DateTime(2009, 11, 1, 0, 30, 0, 0, zone);\n        DateTime when2 = new DateTime(2009, 11, 1, 1, 30, 0, 0, zone);\n        DateTime when3 = new DateTime(2009, 11, 1, 2, 30, 0, 0, zone);\n        System.out.println(when1);\n        System.out.println(when2);\n        System.out.println(when3);\n    }\n}\nResults:\n2009-11-01T00:30:00.000-07:00 // Correct\n2009-11-01T01:30:00.000-07:00 // Should be -08:00\n2009-11-01T02:30:00.000-08:00 // Correct",
    "desc_source": "sourceforge"
  },
  "Time_26": {
    "description": "#60 .withHourOfDay() sets hour inconsistantly on DST transition.\nWhen the hour of day is set to the ambiguous hour on the daylight to\nstandard time transition in a given time zone the result is inconsistent for different time zones. Shoul the hour be set to the\ndaylight hour or the standard hour for all time zones? I can't find anything\nthat documents this behavior.\nMy test code below returns different results for different time zones.\n/*\n* Verify Joda converts the hour of day the same for regions north and\nsouth of the equator on the DST\n* daylight to standard time transition.\n/\n@Test\npublic void jodaTest ()\n{\nChronology chronUTC =\nGregorianChronology.getInstance(DateTimeZone.UTC);\nDateTime usCentralStandardInUTC = new DateTime(2008, 11, 2, 7, 0, 0,\n0, chronUTC);\nDateTime usCentralDaylightInUTC = new DateTime(2008, 11, 2, 6, 0, 0,\n0, chronUTC);\nChronology chronUSCentral =\nGregorianChronology.getInstance(DateTimeZone.forID(\"US/Central\"));\nAssert.assertTrue(\"Should be standard time\",\nchronUSCentral.getZone().isStandardOffset(\nusCentralStandardInUTC.getMillis()));\nAssert.assertFalse(\"Should be daylight time\",\nchronUSCentral.getZone().isStandardOffset(\nusCentralDaylightInUTC.getMillis()));\nDateTime usCentralStandardInUSCentral =\nusCentralStandardInUTC.toDateTime(chronUSCentral);\nDateTime usCentralDaylightInUSCentral =\nusCentralDaylightInUTC.toDateTime(chronUSCentral);\nassertEquals(1, usCentralStandardInUSCentral.getHourOfDay());\nassertEquals(usCentralStandardInUSCentral.getHourOfDay(),\nusCentralDaylightInUSCentral.getHourOfDay());\nAssert.assertTrue(usCentralStandardInUSCentral.getMillis() !=\nusCentralDaylightInUSCentral.getMillis());\nDateTime australiaNSWStandardInUTC = new DateTime(2008, 4, 5, 16, 0,\n0, 0, chronUTC);\nDateTime australiaNSWDaylightInUTC = new DateTime(2008, 4, 5, 15, 0,\n0, 0, chronUTC);\nChronology chronAusNSW =\nGregorianChronology.getInstance(DateTimeZone.forID(\"Australia/NSW\"));\nAssert.assertTrue(\"Should be standard time\",\nchronAusNSW.getZone().isStandardOffset(\naustraliaNSWStandardInUTC.getMillis()));\nAssert.assertFalse(\"Should be daylight time\",\nchronAusNSW.getZone().isStandardOffset(\naustraliaNSWDaylightInUTC.getMillis()));\nDateTime australiaNSWStandardInAustraliaNSW =\naustraliaNSWStandardInUTC.toDateTime(chronAusNSW);\nDateTime australiaNSWDaylightInAusraliaNSW =\naustraliaNSWDaylightInUTC.toDateTime(chronAusNSW);\nassertEquals(2, australiaNSWStandardInAustraliaNSW.getHourOfDay());\nassertEquals(australiaNSWStandardInAustraliaNSW.getHourOfDay(),\naustraliaNSWDaylightInAusraliaNSW.getHourOfDay());\nAssert.assertTrue(australiaNSWStandardInAustraliaNSW.getMillis() !=\naustraliaNSWDaylightInAusraliaNSW.getMillis());\n// Verify that setting the hour of day on the DST boundary results\nin a daylight time for\n// both time zones.\nassertEquals(usCentralDaylightInUSCentral,\nusCentralStandardInUSCentral.withHourOfDay(1));\nassertEquals(australiaNSWDaylightInAusraliaNSW,\naustraliaNSWStandardInAustraliaNSW.withHourOfDay(2));\n}\nThe very last assertion fails on the Australia time zone cutover.\njava.lang.AssertionError: expected:<2008-04-06T02:00:00.000+11:00> but\nwas:<2008-04-06T02:00:00.000+10:00>",
    "desc_source": "sourceforge"
  },
  "Time_27": {
    "description": "#64 Different behaviour of PeriodFormatter\nPeriodFormatter pfmt2 = pfmtbuilder2.append(ISOPeriodFormat.standard() ).toFormatter(); is not the same as \nPeriodFormatterBuilder pfmtbuilder1 = new PeriodFormatterBuilder()\n        .appendLiteral(\"P\")\n        .appendYears()\n        .appendSuffix(\"Y\")\n        .appendMonths()\n        .appendSuffix(\"M\")\n        .appendWeeks()\n        .appendSuffix(\"W\")\n        .appendDays()\n        .appendSuffix(\"D\")\n        .appendSeparatorIfFieldsAfter(\"T\")\n        .appendHours()\n        .appendSuffix(\"H\")\n        .appendMinutes()\n        .appendSuffix(\"M\")\n        .appendSecondsWithOptionalMillis()\n        .appendSuffix(\"S\");\nwhich is copied from ISOPeriodFormat.standard() method",
    "desc_source": "sourceforge"
  },
  "Gson_1": {
    "description": "Fails to serialize/deserialize a class where a super-class has a type parameter\n```\nUnfortunately, shortly after the Gson 1.2 release, I found a bug in the\nTypeVariable support.  Basically, the following class can not be serialized\nor deserialized using Gson:\n\npublic class Foo<T> {\n  private final T someField;\n\n  public Foo(T value) {\n    this.someField = value;\n  }\n\n  public boolean equals(Object o) {\n    if (!(o instanceof Foo)) {\n      return false;\n    } else {\n        return someField.equals(((Foo)o).someField);\n    }\n  }\n}\n\npublic class Bar extends Foo<Integer> {\n  public Bar(Integer i) {\n    super(i);\n  }\n}\n\nGson gson = new Gson();\nBar bar1 = new Bar(1);\nString json = gson.toJson(bar1);   // Fails\nBar bar2 = gson.fromJson(\"{\\\"someField\\\":1\", Bar.class);    // Fails\n\nassertEquals(bar1, bar2);\n\n```\n\nOriginal issue reported on code.google.com by `joel.leitch@gmail.com` on 29 Aug 2008 at 11:53\n- Merged into: #168\n\n",
    "desc_source": "github_issue"
  },
  "Gson_2": {
    "description": "Fix type hierarchy adapters to do a runtime check.\nOtherwise if we have a type hierarchy adapter for Vehicle, and we\nattempt to decode a JSON string as a Car, we get the right exception\nif the JSON string is actually decoded as a Truck.\n\n",
    "desc_source": "github_issue"
  },
  "Gson_3": {
    "description": "Error desirialization of ConcurrentNavigableMap \n```\nWhat steps will reproduce the problem?\n1. Create POJO with filled ConcurrentNavigableMap field\n2. Sirialize to json string\n3. Desirialize from json string\n\nWhat is the expected output? What do you see instead?\nOriginal state is expected. IllegalArgumentException is thrown\n\nWhat version of the product are you using? On what operating system?\nGson 2.3.1, java 8, windows 7\n\nPlease provide any additional information below.\nGson works only with class type field such as ConcurrentSkipListMap.\nGood programming style is using interface type such as ConcurrentNavigableMap. \nSee attach for log and unit-test\n\n```\n\nOriginal issue reported on code.google.com by `dkhomya...@gmail.com` on 29 Jan 2015 at 8:34\n\nAttachments:\n- [gsonErrLog.TXT](https://storage.googleapis.com/google-code-attachments/google-gson/issue-624/comment-0/gsonErrLog.TXT)\n- [JsonUtilsTest.java](https://storage.googleapis.com/google-code-attachments/google-gson/issue-624/comment-0/JsonUtilsTest.java)\n\n",
    "desc_source": "github_issue"
  },
  "Gson_4": {
    "description": "Update reader and writer for RFC 7159.\nThis allows for top-level value types without the requirement of leniency.\n\n",
    "desc_source": "github_issue"
  },
  "Gson_5": {
    "description": "ISO8601 is not fully implemented\nHi guys,\n\nI'm working on a project where I have to parse `2016-01-11T11:06:14.000-02` to java.util.Date which is a valid date according to [RFC3339](https://www.ietf.org/rfc/rfc3339.txt) on page 12.\n\nBut I got an Exception trying to archive it\n\n```\nCaused by: com.google.gson.JsonSyntaxException: 2016-01-11T11:06:14.000-02\n        at com.google.gson.DefaultDateTypeAdapter.deserializeToDate(DefaultDateTypeAdapter.java:107)\n        at com.google.gson.DefaultDateTypeAdapter.deserialize(DefaultDateTypeAdapter.java:84)\n        at com.google.gson.DefaultDateTypeAdapter.deserialize(DefaultDateTypeAdapter.java:38)\n        at com.google.gson.TreeTypeAdapter.read(TreeTypeAdapter.java:58)\n        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:117)\n        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:217)\n        at com.google.gson.internal.bind.TypeAdapterRuntimeTypeWrapper.read(TypeAdapterRuntimeTypeWrapper.java:40)\n        at com.google.gson.internal.bind.CollectionTypeAdapterFactory$Adapter.read(CollectionTypeAdapterFactory.java:82)\n        at com.google.gson.internal.bind.CollectionTypeAdapterFactory$Adapter.read(CollectionTypeAdapterFactory.java:61)\n        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:117)\n        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:217)\n        at com.google.gson.Gson.fromJson(Gson.java:861)\n        at com.google.gson.Gson.fromJson(Gson.java:926)\n        at com.google.gson.Gson.fromJson(Gson.java:899)\n        at ...\nCaused by: java.text.ParseException: Failed to parse date [\"2016-01-11T11:06:14.000-02']: Mismatching time zone indicator: GMT-02 given, resolves to GMT-02:00\n        at com.google.gson.internal.bind.util.ISO8601Utils.parse(ISO8601Utils.java:270)\n        at com.google.gson.DefaultDateTypeAdapter.deserializeToDate(DefaultDateTypeAdapter.java:105)\n        ... 31 more\nCaused by: java.lang.IndexOutOfBoundsException: Mismatching time zone indicator: GMT-02 given, resolves to GMT-02:00\n        at com.google.gson.internal.bind.util.ISO8601Utils.parse(ISO8601Utils.java:236)\n        ... 32 more\n```\n\nI'm able to fix this if it sounds reasonable.\n\n",
    "desc_source": "github_issue"
  },
  "Gson_6": {
    "description": "Fixed a regression in Gson 2.6 where Gson caused NPE if the TypeAdapt\u2026\n\u2026erFactory.create() returned null.\n\n",
    "desc_source": "github_issue"
  },
  "Gson_7": {
    "description": "JsonReader.nextInt() doesent work if p == PEEKED_UNQUOTED\n```\nWhat steps will reproduce the problem?\nThis unit test describes the problem:\n\n    @Test public void test() {\n        Map<Integer, Integer> expected = new HashMap<Integer, Integer>() {{ put(0, 1); }};\n        Map<Integer, Integer> actual = new Gson().fromJson(\"{0:1}\", new TypeToken<Map<Integer, Integer>>() {}.getType());\n        assertEquals(expected, actual);\n    }\n\n\nWhat version of the product are you using? On what operating system?\n2.3 (version 2.1 works OK)\n```\n\nOriginal issue reported on code.google.com by `feathoro...@gmail.com` on 28 Oct 2014 at 4:32\n\n",
    "desc_source": "github_issue"
  },
  "Gson_8": {
    "description": "JNI Error in Android\nI am getting a 'JNI DETECTED AN ERROR IN APPLICATION\" while using gson 2.5.jar in Android. Can anyone tell me how to solve this? Appreciate it.\nI am using a sub-class of Parse Object using Parse SDK.\nHere is the stack trace: \n\n```\n03-28 14:01:15.445: E/art(28683): JNI DETECTED ERROR IN APPLICATION: can't make objects of type java.util.concurrent.locks.Lock: 0x70dd7858\n03-28 14:01:15.445: E/art(28683):     in call to AllocObject\n03-28 14:01:15.445: E/art(28683):     from java.lang.Object sun.misc.Unsafe.allocateInstance(java.lang.Class)\n03-28 14:01:15.445: E/art(28683): \"main\" prio=5 tid=1 Runnable\n03-28 14:01:15.445: E/art(28683):   | group=\"main\" sCount=0 dsCount=0 obj=0x7617aef8 self=0x7fa917c400\n03-28 14:01:15.445: E/art(28683):   | sysTid=28683 nice=0 cgrp=default sched=0/0 handle=0x7face5d2c0\n03-28 14:01:15.445: E/art(28683):   | state=R schedstat=( 657346072 17671229 611 ) utm=52 stm=13 core=1 HZ=100\n03-28 14:01:15.445: E/art(28683):   | stack=0x7fe28ac000-0x7fe28ae000 stackSize=8MB\n03-28 14:01:15.445: E/art(28683):   | held mutexes= \"mutator lock\"(shared held)\n03-28 14:01:15.445: E/art(28683):   at sun.misc.Unsafe.allocateInstance(Native method)\n03-28 14:01:15.445: E/art(28683):   at java.lang.reflect.Method.invoke!(Native method)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.internal.UnsafeAllocator$1.newInstance(UnsafeAllocator.java:48)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.internal.ConstructorConstructor$14.construct(ConstructorConstructor.java:223)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:207)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:117)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:217)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$1.read(ReflectiveTypeAdapterFactory.java:117)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:217)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.Gson.fromJson(Gson.java:861)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.Gson.fromJson(Gson.java:826)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.Gson.fromJson(Gson.java:775)\n03-28 14:01:15.445: E/art(28683):   at com.google.gson.Gson.fromJson(Gson.java:747)\n03-28 14:01:15.445: E/art(28683):   at b5.project.medibro.FeedItemDetails.onCreate(FeedItemDetails.java:47)\n03-28 14:01:15.445: E/art(28683):   at android.app.Activity.performCreate(Activity.java:6583)\n03-28 14:01:15.445: E/art(28683):   at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1114)\n03-28 14:01:15.445: E/art(28683):   at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2531)\n03-28 14:01:15.445: E/art(28683):   at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2666)\n03-28 14:01:15.445: E/art(28683):   at android.app.ActivityThread.-wrap11(ActivityThread.java:-1)\n03-28 14:01:15.445: E/art(28683):   at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1493)\n03-28 14:01:15.445: E/art(28683):   at android.os.Handler.dispatchMessage(Handler.java:111)\n03-28 14:01:15.445: E/art(28683):   at android.os.Looper.loop(Looper.java:207)\n03-28 14:01:15.445: E/art(28683):   at android.app.ActivityThread.main(ActivityThread.java:5769)\n03-28 14:01:15.445: E/art(28683):   at java.lang.reflect.Method.invoke!(Native method)\n03-28 14:01:15.445: E/art(28683):   at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:789)\n03-28 14:01:15.445: E/art(28683):   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:679)\n```\n\nThe error is occurring at the last line of this code:\n\n```\n        gson=new Gson();\n        String jsonObj=getIntent().getStringExtra(\"feedItem\");\n        item = gson.fromJson(jsonObj, FeedItem.class);\n```\n\nI have logged the json string which I am getting. The formatted json string is \n\n```\n{\n   \"feedItemChannel\":\"mdldsrgXN1\",\n   \"estimatedData\":{\n      \"feedTopic\":\"Testing\",\n      \"feedComments\":2,\n      \"createdBy\":\"KXTQtpfBSW\",\n      \"feedQuestion\":\"Test Question \",\n      \"feedDesc\":\"Test \"\n   },\n   \"hashedObjects\":{\n\n   },\n   \"isDeleted\":false,\n   \"isDeletingEventually\":0,\n   \"mutex\":{\n\n   },\n   \"operationSetQueue\":[\n      {\n\n      }\n   ],\n   \"saveEvent\":{\n      \"callbacks\":[\n\n      ]\n   },\n   \"state\":{\n      \"className\":\"FeedItem\",\n      \"createdAt\":1458798818385,\n      \"isComplete\":true,\n      \"objectId\":\"mdldsrgXN1\",\n      \"serverData\":{\n         \"feedTopic\":\"TestTopic\",\n         \"createdBy\":\"KXTQtpfBSW\",\n         \"feedComments\":2,\n         \"feedQuestion\":\"Test Question \",\n         \"feedDesc\":\"Test \"\n      },\n      \"updatedAt\":1458803553636\n   },\n   \"taskQueue\":{\n      \"lock\":{\n         \"sync\":{\n            \"state\":0\n         }\n      }\n   }\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "Gson_9": {
    "description": "Add boxed boolean value() overload.\nWhen calling value() with a Boolean, overload resolution would choose value(boolean) which would throw an NPE on null. The other boxed types are all numbers which would resolve to value(Number) and behave correctly.\n\nProof this happens: https://github.com/bugsnag/bugsnag-android/pull/42\n\n",
    "desc_source": "github_issue"
  },
  "Gson_10": {
    "description": "JsonAdapter annotation ignored for primitive fields\n`ReflectiveTypeAdapterFactory` correctly detects the `@JsonAdapter` annotation and registers the custom adapter ([source](https://github.com/google/gson/blob/6f6af8050799bec5321d2c06cd3230daadbb6535/gson/src/main/java/com/google/gson/internal/bind/ReflectiveTypeAdapterFactory.java#L133)), but its `write` method wraps that type adapter in a `TypeAdapterRuntimeTypeWrapper` ([source](https://github.com/google/gson/blob/6f6af8050799bec5321d2c06cd3230daadbb6535/gson/src/main/java/com/google/gson/internal/bind/ReflectiveTypeAdapterFactory.java#L111)), which overrides the adapter with the default Gson adapter ([source](https://github.com/google/gson/blob/6f6af8050799bec5321d2c06cd3230daadbb6535/gson/src/main/java/com/google/gson/internal/bind/TypeAdapterRuntimeTypeWrapper.java#L65)).\n\nHere's a test that demonstrates the behavior:\n\n``` diff\ndiff --git a/gson/src/test/java/com/google/gson/functional/JsonAdapterAnnotationOnFieldsTest.java b/gson/src/test/java/com/google/gson/functional/JsonAdapterAnnotationOnFieldsTest\nindex 4c745ec..8cae980 100644\n--- a/gson/src/test/java/com/google/gson/functional/JsonAdapterAnnotationOnFieldsTest.java\n+++ b/gson/src/test/java/com/google/gson/functional/JsonAdapterAnnotationOnFieldsTest.java\n@@ -220,4 +220,43 @@ public final class JsonAdapterAnnotationOnFieldsTest extends TestCase {\n       this.part = part;\n     }\n   }\n+\n+  public void testPrimitiveFieldAnnotationTakesPrecedenceOverDefault() {\n+    Gson gson = new Gson();\n+    String json = gson.toJson(new GadgetWithPrimitivePart(42));\n+    assertEquals(\"{\\\"part\\\":\\\"42\\\"}\", json);\n+    GadgetWithPrimitivePart gadget = gson.fromJson(json, GadgetWithPrimitivePart.class);\n+    assertEquals(42, gadget.part);\n+  }\n+\n+  private static final class GadgetWithPrimitivePart {\n+    @JsonAdapter(LongToStringTypeAdapterFactory.class)\n+    final long part;\n+\n+    private GadgetWithPrimitivePart(long part) {\n+      this.part = part;\n+    }\n+  }\n+\n+  private static final class LongToStringTypeAdapterFactory implements TypeAdapterFactory {\n+    static final TypeAdapter<Long> ADAPTER = new TypeAdapter<Long>() {\n+      @Override public void write(JsonWriter out, Long value) throws IOException {\n+        out.value(value.toString());\n+      }\n+      @SuppressWarnings(\"unchecked\")\n+      @Override public Long read(JsonReader in) throws IOException {\n+        return in.nextLong();\n+      }\n+    };\n+    @Override public <T> TypeAdapter<T> create(Gson gson, final TypeToken<T> type) {\n+      Class<?> cls = type.getRawType();\n+      if (Long.class.isAssignableFrom(cls)) {\n+        return (TypeAdapter<T>) ADAPTER;\n+      } else if (long.class.isAssignableFrom(cls)) {\n+        return (TypeAdapter<T>) ADAPTER;\n+      }\n+      throw new IllegalStateException(\"Non-long field of type \" + type\n+          + \" annotated with @JsonAdapter(LongToStringTypeAdapterFactory.class)\");\n+    }\n+  }\n }\n```\n\nAnd here's the result of running it:\n\n```\n[snip]\nRunning com.google.gson.functional.JsonAdapterAnnotationOnFieldsTest\nTests run: 8, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.016 sec <<< FAILURE!\n[snip]\nResults :\n\nFailed tests:   testPrimitiveFieldAnnotationTakesPrecedenceOverDefault(com.google.gson.functional.JsonAdapterAnnotationOnFieldsTest): expected:<{\"part\":[\"42\"]}> but was:<{\"part\":[42]}>\n\nTests run: 990, Failures: 1, Errors: 0, Skipped: 0\n```\n\nIs this the intended behavior? If so, `JsonAdapter`'s documentation is a bit misleading.\n\nIf it's not, I unfortunately do not have a suggested fix. I was actually a bit surprised to see that a new `TypeAdapterRuntimeTypeWrapper` object is constructed for each field that is serialized, on every serialization.\n\nIn case you would like to incorporate my test into Gson, I hereby assign copyright of that test to Google.\n\nThanks!\n\n",
    "desc_source": "github_issue"
  },
  "Gson_11": {
    "description": "Allow deserialization of a Number represented as a String\nThis works:\r\n```\r\ngson.fromJson(\"\\\"15\\\"\", int.class)\r\n```\r\n\r\nThis doesn't:\r\n```\r\ngson.fromJson(\"\\\"15\\\"\", Number.class)\r\n```\r\n\r\nThis PR makes it so the second case works too.\n",
    "desc_source": "github_issue"
  },
  "Gson_12": {
    "description": "Bug when skipping a value while using the JsonTreeReader\nWhen using a `JsonReader` to read a JSON object, `skipValue()` skips the structure successfully.\r\n```Java\r\n@Test\r\npublic void testSkipValue_JsonReader() throws IOException {\r\n  try (JsonReader in = new JsonReader(new StringReader(\"{}\"))) {\r\n    in.skipValue();\r\n  }\r\n}\r\n```\r\nBut when using a `JsonTreeReader` to read a JSON object, `skipValue()` throws a `ArrayIndexOutOfBoundsException`.\r\n```Java\r\n@Test\r\npublic void testSkipValue_JsonTreeReader() throws IOException {\r\n  try (JsonTreeReader in = new JsonTreeReader(new JsonObject())) {\r\n    in.skipValue();\r\n  }\r\n}\r\n```\r\nStacktrace\r\n```\r\njava.lang.ArrayIndexOutOfBoundsException: -1\r\n\tat com.google.gson.internal.bind.JsonTreeReader.skipValue(JsonTreeReader.java:262)\r\n```\r\nThe method `popStack()` is being called on line 261 with a `stackSize` of `1` and afterwards the `stackSize` is `0` and the call on line 262 must result in an `ArrayIndexOutOfBoundsException`.\n",
    "desc_source": "github_issue"
  },
  "Gson_13": {
    "description": "Negative zero\nHi,\r\n\r\nI have been cross testing various json parsers looking for those that expose the lexical of json numbers and not only their bound java.lang.Number. Because of the lazy parsing done by gson with `LazilyParsedNumber`,  that keeps the lexical, all my roundtrip tests pass apart one: the lexical  `-0` that is treated as it were `0`\r\n\r\nI read some threads about negative zero: \r\nhttps://www.ietf.org/mail-archive/web/json/current/msg03668.html\r\nhttps://www.ietf.org/mail-archive/web/json/current/msg01520.html\r\nhttps://www.ietf.org/mail-archive/web/json/current/msg01523.html\r\nhttps://www.ietf.org/mail-archive/web/json/current/msg01525.html\r\n\r\nI created this issue thinking that `-0` is a float, the same as `-0.0`, since a signed zero makes sense only in floating point numbers and also because in Java only Double/Float preserve sign of zero.  This would have the implication that `-0` could not be validated by jsonschema `type` `integer` , and that a jsonschema implementation would have the need to know if a `-0` is present in json data, but probably this is not the case.\r\n\r\nAfter I started to (re)consider that `-0` could be an integer, only that seems that in no programming language there is an integer that preserves sign for zero.\r\n\r\nIn any case, differentiating between `0` and `-0`  at lexical level would allow a client of gson to be able to refuse the value `-0`.\r\n\r\nGson could easily support differentiating between `0` and `-0`: in code `-0` is [treated as an integer (PEEKED_LONG) in JsonReader](https://github.com/google/gson/blob/master/gson/src/main/java/com/google/gson/stream/JsonReader.java#L731) so its value is stored in a Java `long` that cannot represent negative zero. I noted that `-0.0` roundtrips correctly because is treated as a PEEKED_NUMBER that is kept as a Java String. So the case of `-0` could be trapped and treated as `-0.0`, as a PEEKED_NUMBER, in this way the `toString()` method of `LazilyParsedNumber` will return `-0` and gson will be able to roundtrip any valid number value found in source, only clients using `Number.toString()` will notice any difference.\r\n\r\nMy proposal is to change [this code](https://github.com/google/gson/blob/master/gson/src/main/java/com/google/gson/stream/JsonReader.java#L731)  from\r\n\r\n          if (last == NUMBER_CHAR_DIGIT && fitsInLong && (value != Long.MIN_VALUE || negative)) {\r\n    \r\nto \r\n\r\n          if (last == NUMBER_CHAR_DIGIT && fitsInLong && (value!=0 || false==negative) && (value != Long.MIN_VALUE || negative)) {\r\n    \r\n\r\nThanks,\r\nMichele\r\n\n",
    "desc_source": "github_issue"
  },
  "Gson_14": {
    "description": "$Gson$Types.resolve() shall collapse chains of super/extends type bounds to avoid StackOverflowError\nWhile resolving recursive generic types, $Gson$Types.resolve() sometimes starts to generate chains of type bounds like  \"super ? extends ? .... ? extends A\" , causing infinite recursion and thus StackOverflowError's like \r\n`java.lang.StackOverflowError\r\n\tat com.google.gson.internal.$Gson$Types.resolveTypeVariable($Gson$Types.java:407)\r\n\tat com.google.gson.internal.$Gson$Types.resolve($Gson$Types.java:330)\r\n\tat com.google.gson.internal.$Gson$Types.resolve($Gson$Types.java:384)\r\n\tat com.google.gson.internal.$Gson$Types.resolve($Gson$Types.java:379)\r\n\tat com.google.gson.internal.$Gson$Types.resolve($Gson$Types.java:384)\r\n\tat com.google.gson.internal.$Gson$Types.resolve($Gson$Types.java:379)\r\n\tat com.google.gson.internal.$Gson$Types.resolve($Gson$Types.java:384)\r\n...\r\n`\r\nThis can be reproduced on the following simple ccde:\r\n```java\r\n  private static class Foo1<A> {\r\n    Foo2<? extends A> foo2;\r\n  }\r\n  private static class Foo2<B> {\r\n    Foo1<? super B> foo1;\r\n  }\r\n  public void testRecursiveResolveSimple() {\r\n    new Gson().getAdapter(Foo1.class);\r\n  }\r\n```\r\n\r\nThis is the root cause of StackOverflowError's described in Issue #440 and Issue #603.\r\n\r\nIn order to fix them, such chains need to be collapsed using the following rules:\r\n- supertypeOf(supertypeOf(X)) == supertypeOf(X)\r\n- subtypeOf(subtypeOf(X)) == subtypeOf(X)\r\n- supertypeOf(subtypeOf(X)) == subtypeOf(Object.class)\r\n- subtypeOf(supertypeOf(X)) == subtypeOf(Object.class)\n",
    "desc_source": "github_issue"
  },
  "Gson_15": {
    "description": "JsonWriter#value(java.lang.Number) can be lenient, but JsonWriter#value(double) can't,\nIn lenient mode, JsonWriter#value(java.lang.Number) can write pseudo-numeric values like `NaN`, `Infinity`, `-Infinity`:\r\n```java\r\n    if (!lenient\r\n        && (string.equals(\"-Infinity\") || string.equals(\"Infinity\") || string.equals(\"NaN\"))) {\r\n      throw new IllegalArgumentException(\"Numeric values must be finite, but was \" + value);\r\n    }\r\n```\r\n\r\nBut JsonWriter#value(double) behaves in different way: \r\n```java\r\n    if (Double.isNaN(value) || Double.isInfinite(value)) {\r\n      throw new IllegalArgumentException(\"Numeric values must be finite, but was \" + value);\r\n    }\r\n```\r\n\r\nSo, while working with streaming, it's impossible to write semi-numeric value without boxing a double (e. g. `out.value((Number) Double.valueOf(Double.NaN))`).\r\n\r\nI think, this should be possible, because boxing gives worse performance.\n",
    "desc_source": "github_issue"
  },
  "Gson_16": {
    "description": "Fix StackOverflowError on resolving types with TypeVariable recursion\nSample failing code:\r\n  private static class TestType<X> {\r\n    TestType<? super X> superType;\r\n  }\r\n  ...\r\n  new Gson().getAdapter(TestType.class);\n",
    "desc_source": "github_issue"
  },
  "Gson_17": {
    "description": "Fixed DefaultDateTypeAdapter nullability issue and JSON primitives contract\nRegression in:\r\n\r\n* b8f616c939c652b8540c95fa2b377b8c628ef3ff - Migrate DefaultDateTypeAdapter to streaming adapter (#1070)\r\n\r\nBug reports:\r\n\r\n* #1096 - 2.8.1 can't serialize and deserialize date null (2.8.0 works fine)\r\n* #1098 - Gson 2.8.1 DefaultDateTypeAdapter is not null safe.\r\n* #1095 - serialize date sometimes TreeTypeAdapter, sometimes DefaultDateTypeAdapter?\n",
    "desc_source": "github_issue"
  },
  "Gson_18": {
    "description": "Gson deserializes wildcards to LinkedHashMap\nThis issue is a successor to #1101.\r\n\r\nModels:\r\n```java\r\n// ? extends causes the issue\r\nclass BigClass { Map<String, ? extends List<SmallClass>> inBig; }\r\n\r\nclass SmallClass { String inSmall; }\r\n```\r\n\r\nJson:\r\n```json\r\n{\r\n  \"inBig\": {\r\n    \"key\": [\r\n      { \"inSmall\": \"hello\" }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nGson call:\r\n```java\r\nSmallClass small = new Gson().fromJson(json, BigClass.class).inBig.get(\"inSmall\").get(0);\r\n```\r\n\r\nThis call will fail with a `ClassCastException` exception \u2013\r\n `com.google.gson.internal.LinkedTreeMap cannot be cast to Entry`. If we remove `? extends` then everything works fine.\n",
    "desc_source": "github_issue"
  },
  "Mockito_1": {
    "description": "ArgumentCaptor no longer working for varargs\nI ran into the issue described here: http://stackoverflow.com/questions/27303562/why-does-upgrading-mockito-from-1-9-5-to-1-10-8-break-this-captor\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_2": {
    "description": "Mockito.after() method accepts negative timeperiods and subsequent verifications always pass\ne.g.\n\n```\nRunnable runnable = Mockito.mock(Runnable.class);\nMockito.verify(runnable, Mockito.never()).run(); // passes as expected\nMockito.verify(runnable, Mockito.after(1000).never()).run(); // passes as expected\nMockito.verify(runnable, Mockito.after(-1000).atLeastOnce()).run(); // passes incorrectly\n```\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_3": {
    "description": "ArgumentCaptor no longer working for varargs\nI ran into the issue described here: http://stackoverflow.com/questions/27303562/why-does-upgrading-mockito-from-1-9-5-to-1-10-8-break-this-captor\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_4": {
    "description": "java.lang.ClassCastException: java.lang.Class cannot be cast to java.lang.String\nException throws on verifyZeroInteractions when using mock with default answer.\nchecked on versions 1.10.5-2.0.5\nall ok on 1.9.5\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_5": {
    "description": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError, NoClassDefFoundError)\nIf JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit, then the JVM may fail with a `VerifyError` or a `NoClassDefFoundError`.\n\nThis issue has been reported on the [mailing list](https://groups.google.com/forum/#!topic/mockito/A6D7myKiD5k) and on [StackOverflow](http://stackoverflow.com/questions/27721621/java-lang-verifyerror-with-mockito-1-10-17)\n\nA simple test like that with **TestNG** (and no JUnit in the class path of course) exposes the issue:\n\n```\nimport org.testng.annotations.Test;\nimport java.util.Observable;\nimport static org.mockito.Mockito.*;\n\npublic class VerifyErrorOnVerificationWithTimeoutTest {\n    @Test public void should_not_throw_VerifyError() {\n        verify(mock(Observable.class), timeout(500)).countObservers();\n    }\n}\n```\n\nWith TestNG 5.13.1, the stack trace is :\n\n```\njava.lang.VerifyError: (class: org/mockito/internal/verification/VerificationOverTimeImpl, method: verify signature: (Lorg/mockito/internal/verification/api/VerificationData;)V) Incompatible argument to function\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\n```\n\nTestNG includes a dependency on JUnit 3.8.1, which has the `junit.framework.ComparisonFailure`, but the JVM cannot perform the linking at runtime (`VerifyError` extends `LinkageError`), probably because for the JVM there's some incompatible changes in this class between version 3.x and 4.x.\nNote that Mockito is compiled against JUnit 4.x. This also reveal that Mockito is not anymore compatible with JUnit 3.x.\n\nWith TestNG 6.8.13, the stack trace is :\n\n```\njava.lang.NoClassDefFoundError: junit/framework/ComparisonFailure\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClassCond(ClassLoader.java:637)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:621)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)\n    at java.net.URLClassLoader.access$000(URLClassLoader.java:58)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:197)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\nCaused by: java.lang.ClassNotFoundException: junit.framework.ComparisonFailure\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:202)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    ... 49 more\n```\n\nIndeed JUnit is not anymore a dependency of TestNG.\n\nIn this specific case the issue is that the `Timeout` class wraps a `VerficationOverTimeImpl` that uses in try/catch block the exception `org.mockito.exceptions.verification.junit.ArgumentsAreDifferent` which extends `junit.framework.ComparisonFailure`.\n\nAt this time it seems to be the only place where JUnit is needed, this affect the following public API : \n\n``` java\nMockito.timeout(...)\nMockito.after(...)\n```\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_6": {
    "description": "Argument matcher anyXxx() (i.e. anyString(), anyList()) should not match nulls\nThis is a bug I'm seeing in 1.10.8 version (older version has the same issue - tested with 1.9.0).\n\nGiven:\n\n``` java\nFunction<Object, Integer> function = Mockito.mock(Function.class);\nwhen(function.apply(Mockito.anyString())).thenReturn(1);\nInteger result = function.apply(2);\n```\n\nExpected behavior:\n\n``` java\nresult == null;\n```\n\nActual behavior:\n\n``` java\nresult == 1;\n```\n\nNote that the function is called with an integer (not a string), and still the mocked function return the value which it should return only when a string is passed. The same works when using anyBoolean() or any other methof from any\\* family.\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_7": {
    "description": "Deep stubbing with generic responses in the call chain is not working\nDeep stubbing will throw an Exception if multiple generics occur in the call chain. For instance, consider having a mock `myMock1` that provides a function that returns a generic `T`. If `T` also has a function that returns a generic, an Exception with the message \"Raw extraction not supported for : 'null'\" will be thrown.\n\nAs an example the following test will throw an Exception:\n\n``` Java\npublic class MockitoGenericsDeepStubTest {\n\n    @Test\n    public void discoverDeepMockingOfGenerics() {\n        MyClass1 myMock1 = mock(MyClass1.class, RETURNS_DEEP_STUBS);\n\n        when(myMock1.getNested().getNested().returnSomething()).thenReturn(\"Hello World.\");\n    }\n\n    public static interface MyClass1 <MC2 extends MyClass2> {\n        public MC2 getNested();\n    }\n\n    public static interface MyClass2<MC3 extends MyClass3> {\n        public MC3 getNested();\n    }\n\n    public static interface MyClass3 {\n        public String returnSomething();\n    }\n}\n```\n\nYou can make this test run if you step into the class `ReturnsDeepStubs` and change the method `withSettingsUsing` to return `MockSettings` with `ReturnsDeepStubs` instead of `ReturnsDeepStubsSerializationFallback` as default answer:\n\n``` Java\nprivate MockSettings withSettingsUsing(GenericMetadataSupport returnTypeGenericMetadata, MockCreationSettings parentMockSettings) {\n    MockSettings mockSettings = returnTypeGenericMetadata.hasRawExtraInterfaces() ?\n            withSettings().extraInterfaces(returnTypeGenericMetadata.rawExtraInterfaces())\n            : withSettings();\n\n    return propagateSerializationSettings(mockSettings, parentMockSettings)\n            .defaultAnswer(this);\n}\n```\n\nHowever, this breaks other tests and features.\n\nI think, the issue is that further generics are not possible to be mocked by `ReturnsDeepStubsSerializationFallback` since the `GenericMetadataSupport` is \"closed\" at this point.\n\nThanks and kind regards\nTobias\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_8": {
    "description": "1.10 regression (StackOverflowError) with interface where generic type has itself as upper bound\nAdd this to `GenericMetadataSupportTest`:\n\n``` java\n    interface GenericsSelfReference<T extends GenericsSelfReference<T>> {\n        T self();\n    }\n\n    @Test\n    public void typeVariable_of_self_type() {\n        GenericMetadataSupport genericMetadata = inferFrom(GenericsSelfReference.class).resolveGenericReturnType(firstNamedMethod(\"self\", GenericsSelfReference.class));\n\n        assertThat(genericMetadata.rawType()).isEqualTo(GenericsSelfReference.class);\n    }\n```\n\nIt fails on master and 1.10.8 with this:\n\n```\njava.lang.StackOverflowError\n    at sun.reflect.generics.reflectiveObjects.TypeVariableImpl.hashCode(TypeVariableImpl.java:201)\n    at java.util.HashMap.hash(HashMap.java:338)\n    at java.util.HashMap.get(HashMap.java:556)\n    at org.mockito.internal.util.reflection.GenericMetadataSupport.getActualTypeArgumentFor(GenericMetadataSupport.java:193)\n    at org.mockito.internal.util.reflection.GenericMetadataSupport.getActualTypeArgumentFor(GenericMetadataSupport.java:196)\n    at org.mockito.internal.util.reflection.GenericMetadataSupport.getActualTypeArgumentFor(GenericMetadataSupport.java:196)\n```\n\nIt worked on 1.9.5. May be caused by the changes in ab9e9f3 (cc @bric3).\n\n(Also note that while the above interface looks strange, it is commonly used for builder hierarchies, where base class methods want to return this with a more specific type.)\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_9": {
    "description": "Problem spying on abstract classes\nThere's a problem with spying on abstract classes when the real implementation calls out to the abstract method. More details: #121 \n\n",
    "desc_source": "github_issue"
  },
  "Mockito_10": {
    "description": "RETURNS_DEEP_STUBS automatically tries to create serializable mocks\nI am just migrating from mockito 1.9.5 to 1.10.5\n\nThe following code runs fine with version 1.9.5. but breaks now:\n\n``` java\n\n  @Test\n  public void test() {\n    ToBeMocked mock = mock(ToBeMocked.class, RETURNS_DEEP_STUBS);\n    assertThat(mock.getSomething()).isNotNull();\n  }\n\n  public static class ToBeMocked {\n\n    NotSerializableReturnValue field1;\n\n    public ToBeMocked(NotSerializableReturnValue field1) {\n      this.field1 = field1;\n    }\n\n    public NotSerializableReturnValue getSomething() {\n      return field1;\n    }\n  }\n\n  public static class NotSerializableReturnValue {\n\n    String field1 = \"\";\n\n    public NotSerializableReturnValue(String field1) {\n      this.field1 = field1;\n    }\n\n    public String getSomething2() {\n      return field1;\n    }\n  }\n```\n\norg.mockito.exceptions.base.MockitoException: \nYou are using the setting 'withSettings().serializable()' however the type you are trying to mock 'NotSerializableReturnValue'\ndo not implement Serializable AND do not have a no-arg constructor.\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_11": {
    "description": "Fixed DelegatingMethod.equals() so that it's easier to extend Mockito by custom verification modes\nCurrently if you create a DelegatingMethod and compare it to itself using .equals() it will show as not equal because the .equals() method expects a java.lang.reflect.Method (without explicitly stating such).  This has a knock on effect on the evaluation of InvocationImpl.equals() which at runtime may be using a DelegatingMethod in its .equals().\n\nI have changed .equals() and .hashCode() in DelegatingMethod to a more appropriate implementation, which can handle both the case where the input object is a DelegatingMethod and where it is a java.lang.reflect.Method.\n\nI ran up against this issue when creating a custom VerificationMode which used InvocationImpl.equals() to check that the appropriate invocation was made.  My comparison failed even though I was comparing two references to the same InvocationImpl instance.\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_12": {
    "description": "ArgumentCaptor no longer working for varargs\nI ran into the issue described here: http://stackoverflow.com/questions/27303562/why-does-upgrading-mockito-from-1-9-5-to-1-10-8-break-this-captor\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_13": {
    "description": "fix proposal for #114\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_14": {
    "description": "fix proposal for #114\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_15": {
    "description": "ArgumentCaptor no longer working for varargs\nFixes #188 . These commits should fix issue with capturing varargs.\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_16": {
    "description": "Investigate why #125 did not trigger release\nInvestigate why #125 did not trigger release\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_17": {
    "description": "Mockito 1.10.x timeout verification needs JUnit classes (VerifyError, NoClassDefFoundError)\nIf JUnit is not on the classpath and mockito is version 1.10.x (as of now 1.10.1 up to 1.10.19) and the code is using the timeout verification which is not supposed to be related to JUnit, then the JVM may fail with a `VerifyError` or a `NoClassDefFoundError`.\n\nThis issue has been reported on the [mailing list](https://groups.google.com/forum/#!topic/mockito/A6D7myKiD5k) and on [StackOverflow](http://stackoverflow.com/questions/27721621/java-lang-verifyerror-with-mockito-1-10-17)\n\nA simple test like that with **TestNG** (and no JUnit in the class path of course) exposes the issue:\n\n```\nimport org.testng.annotations.Test;\nimport java.util.Observable;\nimport static org.mockito.Mockito.*;\n\npublic class VerifyErrorOnVerificationWithTimeoutTest {\n    @Test public void should_not_throw_VerifyError() {\n        verify(mock(Observable.class), timeout(500)).countObservers();\n    }\n}\n```\n\nWith TestNG 5.13.1, the stack trace is :\n\n```\njava.lang.VerifyError: (class: org/mockito/internal/verification/VerificationOverTimeImpl, method: verify signature: (Lorg/mockito/internal/verification/api/VerificationData;)V) Incompatible argument to function\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\n```\n\nTestNG includes a dependency on JUnit 3.8.1, which has the `junit.framework.ComparisonFailure`, but the JVM cannot perform the linking at runtime (`VerifyError` extends `LinkageError`), probably because for the JVM there's some incompatible changes in this class between version 3.x and 4.x.\nNote that Mockito is compiled against JUnit 4.x. This also reveal that Mockito is not anymore compatible with JUnit 3.x.\n\nWith TestNG 6.8.13, the stack trace is :\n\n```\njava.lang.NoClassDefFoundError: junit/framework/ComparisonFailure\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClassCond(ClassLoader.java:637)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:621)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)\n    at java.net.URLClassLoader.access$000(URLClassLoader.java:58)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:197)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:32)\n    at org.mockito.verification.Timeout.<init>(Timeout.java:25)\n    at org.mockito.Mockito.timeout(Mockito.java:2103)\n    at com.example.UserServiceImplTest.test(UserServiceImplTest.java:26)\nCaused by: java.lang.ClassNotFoundException: junit.framework.ComparisonFailure\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:202)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\n    ... 49 more\n```\n\nIndeed JUnit is not anymore a dependency of TestNG.\n\nIn this specific case the issue is that the `Timeout` class wraps a `VerficationOverTimeImpl` that uses in try/catch block the exception `org.mockito.exceptions.verification.junit.ArgumentsAreDifferent` which extends `junit.framework.ComparisonFailure`.\n\nAt this time it seems to be the only place where JUnit is needed, this affect the following public API : \n\n``` java\nMockito.timeout(...)\nMockito.after(...)\n```\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_18": {
    "description": "Return empty value for Iterables\nhttp://code.google.com/p/mockito/issues/detail?id=175\n\nI expect an Iterable to be mocked by default with an empty Iterable. I understand from the initial issue this behavior would be introduced in Mockito 2, but beta-8 still returns null.\n\nCould we return null for Iterables ?\n\nShould we have the same behavior for Iterator ?\n\nThanks\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_19": {
    "description": "InjectMocks injects mock into wrong field\nUsing `1.10.19`.\n\nWhen using `@InjectMocks` on some Android `TextView`s, the mock is injected into the wrong field.\n\nWe have two fields, `txtGateView` & `txtNextStep` in a class, and our test mocks out `txtNextStep`, then tried to inject. This field is injected wrong, see screenshot.\n\n![image](https://cloud.githubusercontent.com/assets/1404810/7410003/4f200580-ef2b-11e4-9c39-7a699dc4fefa.png)\n\nFrom our quick testing, the name `txtNextView` doesn't matter, that can be changed. But both `txtGateView` and `txtGateLabel` messed things up. If we mock out both fields, it works correctly.\n\nTestproject: https://github.com/SimenB/emptyandroid\n\nI don't know if it's because it's Android, but it was easiest for me to create a minimal test from existing code.\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_20": {
    "description": "Allow convenient spying on abstract classes\nI posted this in GoogleCode and was asked to submit in github.\n\nMockito is easy to use when the test needs to provide canned values for a certain method.\n\nBut it gets harder when a canned value isn't sufficient.\n##### Example 1: Fake with trivial Logic\n\n```\ninterface UserAccount {\n  List<String> getEmails();\n  void addEmail(String email);\n  // 12 other methods ...\n}\n```\n\nWhen mocking such domain entity object, it's tedious to manually program getEmails()/addEmail() with when().thenReturn() and to make sure the two methods are logically consistent, that is, getEmails() returns all emails added.\n##### Example 2: callback-style API\n\n```\ninterface AccountService {\n  void getAccount(String id, AsyncCallback<UserAccount> callback);\n}\n```\n\nStubbing AccountService isn't easy. It'd require use of Answer, and the Answer API isn't statically type safe:\n\n```\nwhen(service.getAccount(eq(id), any(AsyncCallback.class)).thenAnswer(new Answer<Void>() {\n  AsyncCallback<UserAccount> callback = (AsyncCallback<UserAccount>) getArguments()[1];\n  ...\n});\n```\n##### Example 3: Uninteresting parameters\n\n```\ninterface AccountRpcService {\n  FutureAccount getAccount(RpcContext context, String id);\n}\n```\n\nNone of the tests care about the context object. It's an uninteresting parameter imposed by the framework.\n\nIf AccountRpcService were directly mocked, all tests would have to use isA() to repetitively mention this uninteresting parameter, like this:\n\n`when(service.getAccount(isA(RpcContext.class), eq(\"id\")).thenReturn(...);`\n\nAnd all other parameters are required to be wrapped in eq().\n#### Proposal\n\nI propose adding support for abstract classes to mockito to make it easier to deal with tests like above:\n##### For example 1\n\n```\nabstract class FakeUserAccount implements UserAccount {\n  private final List<String> emails = new ArrayList<>();\n\n  @Override public void addEmail(String email) {\n    emails.add(email);\n  }\n  @Override List<String> getEmails() {\n    return ImmutableList.copyOf(emails);\n  }\n}\n\n@Fake private FakeUserAccount userAccount; // Mockito instantiates abstract class.\n```\n##### For example 2\n\n```\nabstract class MockAccountService implements AccountService {\n  @Override public void getAccount(String id, AsyncCallback<UserAccount> callback) {\n    callback.onSuccess(getAccount(id));\n  }\n  abstract UserAccount getAccount(String id);\n}\n\n@Fake private MockAccountService service;\n\n...\n\nwhen(service.getAccount(\"id\")).thenReturn(account);\n```\n##### For example 3\n\n```\nabstract class MockAccountRpcService implements AccountRpcService {\n  @Override Future<Account> getAccount(RpcContext context, String id) {\n    checkNotNull(context);  // Common sanity test. Don't have to repeat it in tests.\n    return getAccount(id);\n  }\n\n  abstract Future<Account> getAccount(String id);\n}\n\n@Fake private MockAccountRpcService service;\n\nwhen(service.getAccount(\"id\")).thenReturn(...);\n```\n\nMy work place internally implemented a default Answer to support abstract classes. We found that the support of abstract classes helps us to avoid overusing mocks when we should be using fakes. And in situations like above we get cleaner test code.\n\nBut because it's not integrated in the core Mockito, there are gotchas with our implementation (like, you can't have private/final methods in your fake).\n\nIf the idea sounds okay to give a try, I'll volunteer to submit a patch.\n\nThanks!\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_21": {
    "description": "Allow convenient spying on abstract classes\nI posted this in GoogleCode and was asked to submit in github.\n\nMockito is easy to use when the test needs to provide canned values for a certain method.\n\nBut it gets harder when a canned value isn't sufficient.\n##### Example 1: Fake with trivial Logic\n\n```\ninterface UserAccount {\n  List<String> getEmails();\n  void addEmail(String email);\n  // 12 other methods ...\n}\n```\n\nWhen mocking such domain entity object, it's tedious to manually program getEmails()/addEmail() with when().thenReturn() and to make sure the two methods are logically consistent, that is, getEmails() returns all emails added.\n##### Example 2: callback-style API\n\n```\ninterface AccountService {\n  void getAccount(String id, AsyncCallback<UserAccount> callback);\n}\n```\n\nStubbing AccountService isn't easy. It'd require use of Answer, and the Answer API isn't statically type safe:\n\n```\nwhen(service.getAccount(eq(id), any(AsyncCallback.class)).thenAnswer(new Answer<Void>() {\n  AsyncCallback<UserAccount> callback = (AsyncCallback<UserAccount>) getArguments()[1];\n  ...\n});\n```\n##### Example 3: Uninteresting parameters\n\n```\ninterface AccountRpcService {\n  FutureAccount getAccount(RpcContext context, String id);\n}\n```\n\nNone of the tests care about the context object. It's an uninteresting parameter imposed by the framework.\n\nIf AccountRpcService were directly mocked, all tests would have to use isA() to repetitively mention this uninteresting parameter, like this:\n\n`when(service.getAccount(isA(RpcContext.class), eq(\"id\")).thenReturn(...);`\n\nAnd all other parameters are required to be wrapped in eq().\n#### Proposal\n\nI propose adding support for abstract classes to mockito to make it easier to deal with tests like above:\n##### For example 1\n\n```\nabstract class FakeUserAccount implements UserAccount {\n  private final List<String> emails = new ArrayList<>();\n\n  @Override public void addEmail(String email) {\n    emails.add(email);\n  }\n  @Override List<String> getEmails() {\n    return ImmutableList.copyOf(emails);\n  }\n}\n\n@Fake private FakeUserAccount userAccount; // Mockito instantiates abstract class.\n```\n##### For example 2\n\n```\nabstract class MockAccountService implements AccountService {\n  @Override public void getAccount(String id, AsyncCallback<UserAccount> callback) {\n    callback.onSuccess(getAccount(id));\n  }\n  abstract UserAccount getAccount(String id);\n}\n\n@Fake private MockAccountService service;\n\n...\n\nwhen(service.getAccount(\"id\")).thenReturn(account);\n```\n##### For example 3\n\n```\nabstract class MockAccountRpcService implements AccountRpcService {\n  @Override Future<Account> getAccount(RpcContext context, String id) {\n    checkNotNull(context);  // Common sanity test. Don't have to repeat it in tests.\n    return getAccount(id);\n  }\n\n  abstract Future<Account> getAccount(String id);\n}\n\n@Fake private MockAccountRpcService service;\n\nwhen(service.getAccount(\"id\")).thenReturn(...);\n```\n\nMy work place internally implemented a default Answer to support abstract classes. We found that the support of abstract classes helps us to avoid overusing mocks when we should be using fakes. And in situations like above we get cleaner test code.\n\nBut because it's not integrated in the core Mockito, there are gotchas with our implementation (like, you can't have private/final methods in your fake).\n\nIf the idea sounds okay to give a try, I'll volunteer to submit a patch.\n\nThanks!\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_22": {
    "description": "Can not Return deep stubs from generic method that returns generic type\nHey,\n\nif I try to mock a generic method which a generic returntype, where the returntype is derived from the generic type of the method using deep stubs I get a `ClassCastException` when calling `when` on it.\n\n```\ninterface I {\n    <T> Supplier<T> m(Class<T> type);\n}\n@Test\npublic void test() throws Exception {\n    I i = mock(I.class, RETURNS_DEEP_STUBS);\n    when(i.m(Boolean.class).get()); // <- ClassCastException\n}\n```\n\nWhen you don't use deep stubs and a raw `Supplier` mock to pass around it works:\n\n```\nI i = mock(I.class);\nSupplier s = mock(Supplier.class);\nwhen(i.m(Boolean.class)).thenReturn(s);\nwhen(i.m(Boolean.class).get());\n```\n\nThe `ClassCastException`:\n\n```\njava.lang.ClassCastException: org.mockito.internal.creation.cglib.ClassImposterizer$ClassWithSuperclassToWorkAroundCglibBug$$EnhancerByMockitoWithCGLIB$$cdb13154 cannot be cast to java.lang.String\n  at MockitoGenerics.test(MockitoGenerics.java:21)\n  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:483)\n  at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n  at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n  at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n  at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n  at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\n  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\n  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\n  at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\n  at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\n  at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\n  at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\n  at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\n  at org.junit.runners.ParentRunner.run(ParentRunner.java:309)\n  at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n  at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n  at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n```\n\nTested using mockito 1.10.19, jdk 1.8.0_20 and no Powermock\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_23": {
    "description": "WrongTypeOfReturnValue when abstract class have two abstract method\nHey\nI found a strange problem, when i create a abstract class:\n\n``` java\nabstract class AbstractClass {\n    abstract protected Long lol();\n    abstract protected String wow();\n    public String give() {\n        wow();\n        lol();\n        return \"give\";\n    }\n}\n```\n\nand i have another class extends abstract Class:\n\n``` java\npublic class ClassExtendsAbstractClass extends AbstractClass {\n@Override\n protected Long lol() {\n        return 2L;\n    }\n    @Override\n    protected String wow() {\n        return \"WOW\";\n    }\n}\n```\n\nand I have class:\n\n``` java\npublic class A {\n  private ClassExtendsAbstractClass classExtendsAbstractClass;\n  public A(ClassExtendsAbstractClass classExtendsAbstractClass) {\n    this.classExtendsAbstractClass = classExtendsAbstractClass;\n  }\n  public String doSomeThing(){\n    return classExtendsAbstractClass.wow();\n  }\n}\n```\n\nand when i try mock method doSomeThing() from A class in test:\n\n``` java\n  @Mock\n  private ClassExtendsAbstractClass classExtendsAbstractClass;\n  private A a;\n\n  @Before\n  public void before(){\n    Mockito.when(classExtendsAbstractClass.give()).thenReturn(\"aaa\");\n  }\n  @Test\n  public void test() {\n    a = new A(classExtendsAbstractClass);\n  }\n```\n\nI get the error:\n\n> org.mockito.exceptions.misusing.WrongTypeOfReturnValue: \n> String cannot be returned by lol()\n> lol() should return Long\n\nThis is strange behavior, because the method `lol()` should not be called, but when I delete one abstract method everything is good.\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_24": {
    "description": "fix some rawtype warnings in tests\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_25": {
    "description": "Null Pointer when invoking Whitebox.invokeMethod() with null one of the params null \nGetting below exceptions when trying to invoke Whitebox.invokeMethod(erxProviderManager, \"setCommand\", Provider, null,retait, mail);\n\nVersion used 1.6.2\n\nFAILED: testSetEnrollmentCommandWithUnEnrollmentWithNull\njava.lang.NullPointerException\n    at java.lang.Class.isAssignableFrom(Native Method)\n    at org.powermock.reflect.internal.WhiteboxImpl.checkIfParameterTypesAreSame(WhiteboxImpl.java:2257)\n    at org.powermock.reflect.internal.WhiteboxImpl.getMethods(WhiteboxImpl.java:1800)\n    at org.powermock.reflect.internal.WhiteboxImpl.getBestMethodCandidate(WhiteboxImpl.java:955)\n    at org.powermock.reflect.internal.WhiteboxImpl.findMethodOrThrowException(WhiteboxImpl.java:832)\n    at org.powermock.reflect.internal.WhiteboxImpl.doInvokeMethod(WhiteboxImpl.java:770)\n    at org.powermock.reflect.internal.WhiteboxImpl.invokeMethod(WhiteboxImpl.java:638)\n    at org.powermock.reflect.Whitebox.invokeMethod(Whitebox.java:401)\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_26": {
    "description": "use @InjectMocks for final fields\nI'm trying to upgrade the mockito version that we're using (1.8.5) to a newer version but there is a problem with @InjectMocks which since 1.9.0 doesn't inject into final field anymore.\n\nWere there any reasons for that feature to be removed?\nIs there another way to achieve this without polutting our class with useless (outside testing context) constructors / accessors? \n\nIs there a possibility to get that feature back?\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_27": {
    "description": "Exception when stubbing more than once with when...thenThrow\nIf I create a mock and stub a method so it throws an exception and do that twice the first exception will be thrown upon invoking the second stub instruction.\n\nExample:\n\n```\n@Test\npublic void testThrowException() {\n    Object o = Mockito.mock(Object.class);\n    // test behavior with Runtimeexception\n    Mockito.when(o.toString()).thenThrow(RuntimeException.class);\n    // ...\n    // test behavior with another exception\n    // this throws a RuntimeException\n    Mockito.when(o.toString()).thenThrow(IllegalArgumentException.class);\n    // ...\n}\n```\n\nI can work around this if I do it the other way around with doThrow...when. But I lose type safety then. Can you fix this?\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_28": {
    "description": "nicer textual printing of typed parameters\nWhen matchers fail but yield the same toString(), Mockito prints extra type information. However, the type information is awkwardly printed for Strings. I've encountered this issue while working on removing hard dependency to hamcrest.\n\n```\n//current:\nsomeMethod(1, (Integer) 2);\nsomeOther(1, \"(String) 2\");\n//desired:\nsomeOther(1, (String) \"2\");\n```\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_29": {
    "description": "Fixes #228: fixed a verify() call example in @Captor javadoc\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_30": {
    "description": "Failing tests on Windows machine\nI just posted on the Google Forums, but someway somehow my post immediately disappeared in the void. So I am reposting it again here.\n\nI have 3 failing tests on my Windows 8.1 machine.\n1. DefaultMockingDetailsTest.should_get_extra_interfaces\n2. NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy\n3. ClassLoadersTest.excluding_class_loader_cannot_load_classes_when_no_correct_source_url_set\n\nFor the first test, I was able to let it pass by changing line https://github.com/mockito/mockito/blob/master/test/org/mockito/internal/util/DefaultMockingDetailsTest.java#L56 to\n\n``` java\nBar bar = mock(Bar.class, withSettings().extraInterfaces(List.class, Observer.class));\n```\n\nI am not sure if this is indeed the correct test, so please let me know.\n\nFor the 2nd test, I first get the stack trace\n\n```\njava.lang.AssertionError: 'org\\mockito\\configuration\\MockitoConfiguration' has some dependency to JUnit\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:40)\n    at org.mockitointegration.NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy(NoJUnitDependenciesTest.java:32)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\nCaused by: java.lang.NoClassDefFoundError: org\\mockito\\configuration\\MockitoConfiguration (wrong name: org/mockito/configuration/MockitoConfiguration)\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:348)\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:38)\n    ... 24 more\n\n\n```\n\nWhen I change line https://github.com/mockito/mockito/blob/master/test/org/mockitoutil/ClassLoaders.java#L361 to\n\n``` java\nString temp = file.getAbsolutePath().substring(root.getAbsolutePath().length() + 1).replace('/', '.').replace('\\\\', '.');\n```\n\nI get the following stack trace:\n\n```\njava.lang.AssertionError: 'org.mockito.internal.progress.TimesTest' has some dependency to JUnit\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:40)\n    at org.mockitointegration.NoJUnitDependenciesTest.pure_mockito_should_not_depend_JUnit___ByteBuddy(NoJUnitDependenciesTest.java:32)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\nCaused by: java.lang.NoClassDefFoundError: junit/framework/Assert\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:760)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:467)\n    at java.net.URLClassLoader.access$100(URLClassLoader.java:73)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:368)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:362)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:361)\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:156)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    at java.lang.Class.forName0(Native Method)\n    at java.lang.Class.forName(Class.java:348)\n    at org.mockitointegration.NoJUnitDependenciesTest.checkDependency(NoJUnitDependenciesTest.java:38)\n    ... 24 more\nCaused by: java.lang.ClassNotFoundException: classes with prefix : [junit, org.junit] are excluded\n    at org.mockitoutil.ClassLoaders$LocalExcludingURLClassLoader.findClass(ClassLoaders.java:155)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 51 more\n```\n\nThe reason I changed that line is because the temp result does not contain dots on windows machines, due to the fact that absolutepath does not return a path seperated by `/` but by `\\\\`.\nHowever then the test fails because the `TimesTest` in `test/` does indeed depend on junit. Shouldn't it only load classes that are under `src/`?\n\nThe 3rd test I sadly have no clue why it is succeeding and not throwing an exception.\n\nLooking forward to your responses =]\n\n",
    "desc_source": "github_issue"
  },
  "Mockito_31": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Mockito_32": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Mockito_33": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Mockito_34": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Mockito_35": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Mockito_36": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Mockito_37": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Mockito_38": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_1": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_2": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_3": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_4": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_5": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_6": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_7": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_8": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_9": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_10": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_11": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_12": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_13": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_14": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_15": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_16": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_17": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_18": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_19": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_20": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_21": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_22": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_23": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_24": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_25": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_26": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_27": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_28": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_29": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_30": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_31": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_32": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_33": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_34": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_35": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_36": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_37": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_38": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_39": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_40": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_41": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_42": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_43": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_44": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_45": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_46": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_47": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_48": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_49": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_50": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_51": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_52": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_53": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_54": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_55": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_56": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_57": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_58": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_59": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_60": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_61": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_62": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_63": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_64": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_65": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_66": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_67": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_68": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_69": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_70": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_71": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_72": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_73": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_74": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_75": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_76": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_77": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_78": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_79": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_80": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_81": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_82": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_83": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_84": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_85": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_86": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_87": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_88": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_89": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_90": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_91": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_92": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_93": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Cli_1": {
    "description": "[cli] CommandLine.getOptionValue() behaves contrary to docs\nHi\n\nIf I have:\n\nfinal String debugOpt = \"debug\";\n\tOption debug = OptionBuilder\n\t    .withArgName(debugOpt)\n\t    .withDescription(\"turn on debugging\")\n\t    .withLongOpt(debugOpt)\n\t    .create('d');\n\nand then later I do:\n\nString dbg = commandLine.getOptionValue(debugOpt);\n\nthen dbg will be null. Instead, I have to use getOptionValue('d'). This seems\ncontrary to the docs (see bottom of\nhttp://jakarta.apache.org/commons/cli/usage.html), which implies that I should\nbe able to query the commandLine object using a full string, rather than just\nthe string's first character.\n\nCan I suggest that the API of OptionBuilder be made clearer so that it is\nobvious that you can have long and short option names---perhaps make the\ncreate() method take no arguments (thus forcing long and short arg names to be\nset explicitly). (Also, there seems to be some confusion between the terms\n'argument' and 'option' in the API, but perhaps that is just me).\n\nAlso, I would hop to be able to query commandLine by either a single char or an\nentire string, as suggested by the docs.\n\nThanks,\n\nChris",
    "desc_source": "jira"
  },
  "Cli_2": {
    "description": "[cli] Parameter value \"-something\" misinterpreted as a parameter\nIf a parameter value is passed that contains a hyphen as the (delimited) first \ncharacter, CLI parses this a parameter. For example using the call\njava myclass -t \"-something\"\nResults in the parser creating the invalid parameter -o (noting that it is \nskipping the 's')\n\nMy code is using the Posix parser as follows\nOptions options = buildCommandLineOptions();\nCommandLineParser parser = new PosixParser();\nCommandLine commandLine = null;\ntry {\n\t\t\t\n\tcommandLine = parser.parse(options, args);\n}\ncatch (ParseException e) {\n\t\t\t\n\tSystem.out.println(\"Invalid parameters. \" + e.getMessage() + NEW_LINE);\n\tSystem.exit(EXIT_CODE_ERROR);\n}\n\nThis has been tested against the nightly build dated 20050503.",
    "desc_source": "jira"
  },
  "Cli_3": {
    "description": "PosixParser interupts \"-target opt\" as \"-t arget opt\"\nThis was posted on the Commons-Developer list and confirmed as a bug.\n\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try {\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       } catch (ParseException pe) {\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) {\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself ;).  To support *special* \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \n\nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non *special* options. I'll have a look into this and let you know.\n\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\n\nThanks,\n-John K",
    "desc_source": "jira"
  },
  "Cli_4": {
    "description": "PosixParser interupts \"-target opt\" as \"-t arget opt\"\nThis was posted on the Commons-Developer list and confirmed as a bug.\n\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try {\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       } catch (ParseException pe) {\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) {\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself ;).  To support *special* \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \n\nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non *special* options. I'll have a look into this and let you know.\n\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\n\nThanks,\n-John K",
    "desc_source": "jira"
  },
  "Cli_5": {
    "description": "NullPointerException in Util.stripLeadingHyphens when passed a null argument\nIf you try to do a hasOption(null), you get a NPE:\n\njava.lang.NullPointerException\n\tat org.apache.commons.cli.Util.stripLeadingHyphens(Util.java:39)\n\tat org.apache.commons.cli.CommandLine.resolveOption(CommandLine.java:166)\n\tat org.apache.commons.cli.CommandLine.hasOption(CommandLine.java:68)\n\nEither hasOption should reject the null argument, or the function should simply return false.  I think the latter makes more since, as this is how Java collections generally work.",
    "desc_source": "jira"
  },
  "Cli_7": {
    "description": "Tests fail under 1.6 + error at end that may or may not be related\nTestsuite: org.apache.commons.cli2.bug.Bug27575Test\nTests run: 1, Failures: 1, Errors: 0, Time elapsed: 0.058 sec\n\nTestcase: testRequiredOptions(org.apache.commons.cli2.bug.Bug27575Test):        FAILED\nexpected:<[-h]> but was:<-c <arg>>\njunit.framework.ComparisonFailure: expected:<[-h]> but was:<-c <arg>>\n        at org.apache.commons.cli2.bug.Bug27575Test.testRequiredOptions(Bug27575Test.java:36)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\n\nand error at end of:\n\nException in thread \"Thread-1\" javax.xml.transform.TransformerFactoryConfigurationError: Provider for javax.xml.transform.TransformerFactory cannot be found\n        at javax.xml.transform.TransformerFactory.newInstance(Unknown Source)\n        at java.util.prefs.XmlSupport.writeDoc(XmlSupport.java:246)\n        at java.util.prefs.XmlSupport.exportMap(XmlSupport.java:333)\n        at java.util.prefs.FileSystemPreferences$8.run(FileSystemPreferences.java:607)",
    "desc_source": "jira"
  },
  "Cli_8": {
    "description": "HelpFormatter wraps incorrectly on every line beyond the first\nThe method findWrapPos(...) in the HelpFormatter is a couple of bugs in the way that it deals with the \"startPos\" variable.  This causes it to format every line beyond the first line by \"startPos\" to many characters, beyond the specified width.  \n\nTo see this, create an option with a long description, and then use the help formatter to print it.  The first line will be the correct length.  The 2nd, 3rd, etc lines will all be too long.\n\nI don't have a patch (sorry) - but here is a corrected version of the method.\n\nI fixed it in two places - both were using \"width + startPos\" when they should have been using width.\n\n{code}\n protected int findWrapPos(String text, int width, int startPos)\n    {\n        int pos = -1;\n\n        // the line ends before the max wrap pos or a new line char found\n        if (((pos = text.indexOf('\\n', startPos)) != -1 && pos <= width)\n            || ((pos = text.indexOf('\\t', startPos)) != -1 && pos <= width))\n        {\n            return pos+1;\n        }\n        else if ((width) >= text.length())\n        {\n            return -1;\n        }\n\n\n        // look for the last whitespace character before startPos+width\n        pos = width;\n\n        char c;\n\n        while ((pos >= startPos) && ((c = text.charAt(pos)) != ' ')\n               && (c != '\\n') && (c != '\\r'))\n        {\n            --pos;\n        }\n\n        // if we found it - just return\n        if (pos > startPos)\n        {\n            return pos;\n        }\n        \n        // must look for the first whitespace chearacter after startPos \n        // + width\n        pos = startPos + width;\n\n        while ((pos <= text.length()) && ((c = text.charAt(pos)) != ' ')\n               && (c != '\\n') && (c != '\\r'))\n        {\n            ++pos;\n        }\n\n        return (pos == text.length())        ? (-1) : pos;\n    }\n{code}",
    "desc_source": "jira"
  },
  "Cli_9": {
    "description": "MissingOptionException.getMessage() changed from CLI 1.0 > 1.1\nThe MissingOptionException.getMessage() string changed from CLI 1.0 > 1.1. \n\nCLI 1.0 was poorly formatted but readable:\nMissing required options: -format-source-properties\n\nCLI 1.1 is almost unreadable:\nMissing required options: formatsourceproperties\n\nIn CLI 1.0 Options.addOption(Option) prefixed the stored options with a \"-\" and in CLI 1.1 it doesn't.\n\nI would suggest changing Parser.checkRequiredOptions() to add the options to the error message with a prefix of \" -\":\n\nOLD: \n            // loop through the required options\n            while (iter.hasNext())\n            {\n                buff.append(iter.next());\n            }\n\nNEW: \n            // loop through the required options\n            while (iter.hasNext())\n            {\n                buff.append(\" -\" + iter.next());\n            }\n\nResulting in:\nMissing required options: -format -source -properties\n",
    "desc_source": "jira"
  },
  "Cli_10": {
    "description": "Missing required options not throwing MissingOptionException\nWhen an Options object is used to parse a second set of command arguments it won't throw a MissingOptionException.\n\n{code:java}\nimport org.apache.commons.cli.CommandLine;\nimport org.apache.commons.cli.GnuParser;\nimport org.apache.commons.cli.OptionBuilder;\nimport org.apache.commons.cli.Options;\nimport org.apache.commons.cli.ParseException;\n\npublic class Example\n{\n\tpublic static void main(String[] args) throws ParseException\n\t{\n\t\tbrokenExample();\n\t\tworkingExample();\n\t}\n\n\t// throws exception as expected\n\tprivate static void workingExample() throws ParseException\n\t{\n\t\tString[] args = {};\n\n\t\tOptions opts = new Options();\n\t\topts.addOption(OptionBuilder.isRequired().create('v'));\n\n\t\tGnuParser parser = new GnuParser();\n\t\tCommandLine secondCL = parser.parse(opts, args);\n\n\t\tSystem.out.println(\"Done workingExample\");\n\t}\n\n\t// fails to throw exception on second invocation of parse\n\tprivate static void brokenExample() throws ParseException\n\t{\n\t\tString[] firstArgs = { \"-v\" };\n\t\tString[] secondArgs = {};\n\n\t\tOptions opts = new Options();\n\t\topts.addOption(OptionBuilder.isRequired().create('v'));\n\n\t\tGnuParser parser = new GnuParser();\n\t\tCommandLine firstCL = parser.parse(opts, firstArgs);\n\t\tCommandLine secondCL = parser.parse(opts, secondArgs);\n\n\t\tSystem.out.println(\"Done brokenExample\");\n\t}\n}\n{code}\n\nThis is a result of the Options object returning the reference to its own list and the parsers modifying that list. The first call is removing the required options as they are found and subsequent calls get back an empty list.",
    "desc_source": "jira"
  },
  "Cli_11": {
    "description": "PosixParser interupts \"-target opt\" as \"-t arget opt\"\nThis was posted on the Commons-Developer list and confirmed as a bug.\n\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try {\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       } catch (ParseException pe) {\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) {\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself ;).  To support *special* \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \n\nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non *special* options. I'll have a look into this and let you know.\n\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\n\nThanks,\n-John K",
    "desc_source": "jira"
  },
  "Cli_12": {
    "description": "PosixParser interupts \"-target opt\" as \"-t arget opt\"\nThis was posted on the Commons-Developer list and confirmed as a bug.\n\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try {\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       } catch (ParseException pe) {\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) {\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself ;).  To support *special* \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \n\nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non *special* options. I'll have a look into this and let you know.\n\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\n\nThanks,\n-John K",
    "desc_source": "jira"
  },
  "Cli_13": {
    "description": "[cli] argument defaults prevent commandline usage.\nI have found a bug in the following scenario:\n\nYou have an option which can take a single argument which in turn has a default\nvalue. You supply a value on the command line which is intended to override\nthis default however as the CommandLine already has a value for this Option,\nthis second value is not allowed and the command line cannot be parsed.\n\nI have created a patch which adds a method to WritableCommandLine and its Impl\nwhich allows you to retrieve the undefaulted values for an Option. I have then\nchanged ArgumentImpl to use this method to determine the argument count",
    "desc_source": "jira"
  },
  "Cli_14": {
    "description": "adding a FileValidator results in ClassCastException in parser.parseAndHelp(args)\nWhen I add a FileValidator.getExistingFileInstance() to an Argument, I get a ClassCastException when I parse args.\n\nBelow is a testcase invoke with\n\n   java org.apache.commons.cli2.issues.CLI2Sample -classpath commons-cli-2.0-SNAPSHOT.jar --file-name path-to-an-existing-file\n\nRun it and you get:\n\nException in thread \"main\" java.lang.ClassCastException: java.io.File cannot be cast to java.lang.String\n\tat org.apache.commons.cli2.validation.FileValidator.validate(FileValidator.java:122)\n\tat org.apache.commons.cli2.option.ArgumentImpl.validate(ArgumentImpl.java:250)\n\tat org.apache.commons.cli2.option.ParentImpl.validate(ParentImpl.java:123)\n\tat org.apache.commons.cli2.option.DefaultOption.validate(DefaultOption.java:175)\n\tat org.apache.commons.cli2.option.GroupImpl.validate(GroupImpl.java:264)\n\tat org.apache.commons.cli2.commandline.Parser.parse(Parser.java:105)\n\tat org.apache.commons.cli2.commandline.Parser.parseAndHelp(Parser.java:125)\n\tat org.apache.commons.cli2.issues.CLI2Sample.main(CLI2Sample.java:38)\n\nComment out the withValidator call and it runs with no exception. \n\nI also get a similar ClassCastException if I add a \n\n  .withValidator(NumberValidator.getIntegerInstance())\n\nto another option/argument.\n\nHere is the source\n\n\npackage org.apache.commons.cli2.issues;\n\nimport java.io.File;\nimport org.apache.commons.cli2.CommandLine;\nimport org.apache.commons.cli2.Group;\nimport org.apache.commons.cli2.builder.ArgumentBuilder;\nimport org.apache.commons.cli2.builder.DefaultOptionBuilder;\nimport org.apache.commons.cli2.builder.GroupBuilder;\nimport org.apache.commons.cli2.commandline.Parser;\nimport org.apache.commons.cli2.option.DefaultOption;\nimport org.apache.commons.cli2.validation.FileValidator;\n\npublic class CLI2Sample\n{\n   public static void main(String[] args)\n   {\n      final DefaultOptionBuilder obuilder = new DefaultOptionBuilder();\n      final ArgumentBuilder abuilder = new ArgumentBuilder();\n      final GroupBuilder gbuilder = new GroupBuilder();\n      DefaultOption fileNameOption = obuilder\n            .withShortName(\"f\")\n            .withLongName(\"file-name\")\n            .withRequired(true)\n            .withDescription(\"name of an existing file\")\n            .withArgument(abuilder\n                  .withName(\"file-name\")\n                  .withValidator(FileValidator.getExistingFileInstance())\n                  .create())\n            .create();\n      Group options = gbuilder\n            .withName(\"options\")\n            .withOption(fileNameOption)\n            .create();\n      Parser parser = new Parser();\n      parser.setHelpTrigger(\"--help\");\n      parser.setGroup(options);\n      CommandLine cl = parser.parseAndHelp(args);\n     }\n}\n",
    "desc_source": "jira"
  },
  "Cli_15": {
    "description": "deafult arguments only works if no arguments are submitted\nWhen using multple arguments and defaults, the behaviour is counter-intuitive and will only pick up a default if no args are passed in.\n\nFor instance in the code below I have set up so 0, 1, or 2 args may bve accepted, with defaults 100 and 1000.\n\nI expect it to behave as follows.\n1. for 2 args, 1 and 2 the values should be 1 and 2. This works as expected.\n2. for 0 args passed in the values should be 100 and 1000, picking up both of the defaults. This works as expected\n\n\n3. for 1 arg passed in the values should be 1 and 1000, so the second argument picks up the second default value. The valuse become just 1, which is not as expected..\n\n\nCurrently, in the second case will only return 1 and ignore the defaults.\n\n\n\n    public void testSingleOptionSingleArgument() throws Exception {\n        String defaulValue1 = \"100\";\n        String defaultValue2 = \"1000\";\n        final DefaultOptionBuilder obuilder = new DefaultOptionBuilder();\n        final ArgumentBuilder abuilder = new ArgumentBuilder();\n        final GroupBuilder gbuilder = new GroupBuilder();\n\n        DefaultOption bOption = obuilder.withShortName(\"b\")\n                .withLongName(\"b\")\n                .withArgument(abuilder.withName(\"b\")\n                        .withMinimum(0)\n                        .withMaximum(2)\n                        .withDefault(defaulValue1)\n                        .withDefault(defaultValue2)\n                        .create())\n                .create();\n\n        Group options = gbuilder\n                .withName(\"options\")\n                .withOption(bOption)\n                .create();\n\n        Parser parser = new Parser();\n        parser.setHelpTrigger(\"--help\");\n        parser.setGroup(options);\n        String enteredValue1 = \"1\";\n        String[] args = new String[]{\"-b\", enteredValue1};\n        CommandLine cl = parser.parse(args);\n        CommandLine cmd = cl;\n        assertNotNull(cmd);\n        List b = cmd.getValues(\"-b\");\n        assertEquals(\"[\" + enteredValue1 + \"]\", b + \"\");\n    }\n\n",
    "desc_source": "jira"
  },
  "Cli_16": {
    "description": "the minimum and maximum constraints on a group do not take other groups into account\nIf you have a Group A as a child of Group B and you set a minimum or maximum on Group B, the presence or not of Group A will not affect GroupB. This is because Groups are never added to a CommandLine so .hasOption(A) returns false and so it isn't counted. WriteableCommandLine#addOption(Option) should be used to indicate that a Group is present if any of a Groups children is present.",
    "desc_source": "jira"
  },
  "Cli_17": {
    "description": "PosixParser keeps bursting tokens even if a non option character is found\nPosixParser doesn't stop the bursting process of a token if stopAtNonOption is enabled and a non option character is encountered.\n\nFor example if the options a and b are defined, with stopAtNonOption=true the following command line:\n\n{code}-azb{code}\n\nis turned into:\n\n{code}-a zb -b{code}\n\nthe right output should be:\n\n{code}-a zb{code}\n",
    "desc_source": "jira"
  },
  "Cli_18": {
    "description": "PosixParser ignores unrecognized tokens starting with '-'\nPosixParser doesn't handle properly unrecognized tokens starting with '-' when stopAtNonOption is enabled, the token is simply ignored.\n\nFor example, if the option 'a' is defined, the following command line:\n\n{code}-z -a foo{code}\n\nis interpreted as:\n\n{code}-a foo{code}",
    "desc_source": "jira"
  },
  "Cli_19": {
    "description": "PosixParser ignores unrecognized tokens starting with '-'\nPosixParser doesn't handle properly unrecognized tokens starting with '-' when stopAtNonOption is enabled, the token is simply ignored.\n\nFor example, if the option 'a' is defined, the following command line:\n\n{code}-z -a foo{code}\n\nis interpreted as:\n\n{code}-a foo{code}",
    "desc_source": "jira"
  },
  "Cli_20": {
    "description": "PosixParser keeps processing tokens after a non unrecognized long option\nPosixParser keeps processing tokens after a non unrecognized long option when stopAtNonOption is enabled. The tokens after the unrecognized long option are burst, split around '=', etc.. instead of being kept as is.\n\nFor example, with the options 'a' and 'b' defined, 'b' having an argument, the following command line:\n\n{code}--zop -abfoo{code}\n\nis interpreted as:\n\n{code}--zop -a -b foo{code}\n\nbut the last token should remain unchanged.",
    "desc_source": "jira"
  },
  "Cli_21": {
    "description": "Negative numbers mistaken for options\nIf an option has a negative numerical argument, the parser mistakes it for another option and throws an error. For example, consider:\n\n{{Argument numArg = aBuilder.withValidator(NumberValidator.getNumberInstance()).withMinimum(1).withMaximum(1).create();}}\n{{Option numOpt = oBuilder.withLongName(\"num\").withArgument(numArg).create();}}\n{{Group options = gBuilder.withOption(numOpt).create();}}\n\nThen parsing {{--num -0.1}} results in:\n\n{{Unexpected -0.1 while processing --num}}\n\n\n\n",
    "desc_source": "jira"
  },
  "Cli_22": {
    "description": "PosixParser interupts \"-target opt\" as \"-t arget opt\"\nThis was posted on the Commons-Developer list and confirmed as a bug.\n\n> Is this a bug?  Or am I using this incorrectly?\n> I have an option with short and long values.  Given code that is \n> essentially what is below, with a PosixParser I see results as \n> follows:\n> \n> A command line with just \"-t\" prints out the results of the catch \n> block\n> (OK)\n> A command line with just \"-target\" prints out the results of the catch\n> block (OK)\n> A command line with just \"-t foobar.com\" prints out \"processing selected\n> target: foobar.com\" (OK)\n> A command line with just \"-target foobar.com\" prints out \"processing\n> selected target: arget\" (ERROR?)\n> \n> ======================================================================\n> ==\n> =======================\n>   private static final String OPTION_TARGET = \"t\";\n>   private static final String OPTION_TARGET_LONG = \"target\";\n>   // ...\n>   Option generateTarget = new Option(OPTION_TARGET, \n>                                      OPTION_TARGET_LONG, \n>                                      true, \n>                                      \"Generate files for the specified\n> target machine\");\n>   // ...\n>   try {\n>         parsedLine = parser.parse(cmdLineOpts, args);\n>       } catch (ParseException pe) {\n>         System.out.println(\"Invalid command: \" + pe.getMessage() +\n> \"\\n\");\n>         HelpFormatter hf = new HelpFormatter();\n>         hf.printHelp(USAGE, cmdLineOpts);\n>         System.exit(-1);\n>       }\n> \n>   if (parsedLine.hasOption(OPTION_TARGET)) {\n>     System.out.println(\"processing selected target: \" +\n> parsedLine.getOptionValue(OPTION_TARGET));        \n>   }\n\nIt is a bug but it is due to well defined behaviour (so that makes me feel a\nlittle better about myself ;).  To support *special* \n(well I call them special anyway) like -Dsystem.property=value we need to be\nable to examine the first character of an option.  If the first character is\nitself defined as an Option then the remainder of the token is used as the\nvalue, e.g. 'D' is the token, it is an option so 'system.property=value' is the\nargument value for that option.  This is the behaviour that we are seeing for\nyour example.  \n't' is the token, it is an options so 'arget' is the argument value.  \n\nI suppose a solution to this could be to have a way to specify properties for\nparsers.  In this case 'posix.special.option == true' for turning \non *special* options. I'll have a look into this and let you know.\n\nJust to keep track of this and to get you used to how we operate, can you log a\nbug in bugzilla for this.\n\nThanks,\n-John K",
    "desc_source": "jira"
  },
  "Cli_23": {
    "description": "infinite loop in the wrapping code of HelpFormatter\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\n\nTest case:\n\n{code}\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n{code}\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.",
    "desc_source": "jira"
  },
  "Cli_24": {
    "description": "infinite loop in the wrapping code of HelpFormatter\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\n\nTest case:\n\n{code}\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n{code}\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.",
    "desc_source": "jira"
  },
  "Cli_25": {
    "description": "infinite loop in the wrapping code of HelpFormatter\nIf there is not enough space to display a word on a single line, HelpFormatter goes into a infinite loops until the JVM crashes with an OutOfMemoryError.\n\nTest case:\n\n{code}\nOptions options = new Options();\noptions.addOption(\"h\", \"help\", false, \"This is a looooong description\");\n\nHelpFormatter formatter = new HelpFormatter();\nformatter.setWidth(20);\nformatter.printHelp(\"app\", options); // hang & crash\n{code}\n\nAn helpful exception indicating the insufficient width would be more appropriate than an OutOfMemoryError.",
    "desc_source": "jira"
  },
  "Cli_26": {
    "description": "OptionBuilder is not reseted in case of an IAE at create\nIf the call to OptionBuilder.create() fails with an IllegalArgumentException, the OptionBuilder is not resetted and its next usage may contain unwanted settings. Actually this let the CLI-1.2 RCs fail on IBM JDK 6 running on Maven 2.0.10.",
    "desc_source": "jira"
  },
  "Cli_27": {
    "description": "Unable to select a pure long option in a group\nOptionGroup doesn't play nice with options with a long name and no short name. If the selected option hasn't a short name, group.setSelected(option) has no effect.\n",
    "desc_source": "jira"
  },
  "Cli_28": {
    "description": "Default options may be partially processed\nThe Properties instance passed to the Parser.parse() method to initialize the default options may be partially processed. This happens when the properties contains an option that doesn't accept arguments and has a default value that isn't evaluated to \"true\". When this case occurs the processing of the properties is stopped and the remaining options are never handled.\n\nThis is caused by the break statement in Parser.processProperties(Properties), a continue statement should have been used instead.\n\nThe related test in ValueTest is also wrong, there are two assertions that need to be changed:\n\n{code}\nOptions opts = new Options();\nopts.addOption(\"a\", false, \"toggle -a\");\nopts.addOption(\"c\", \"c\", false, \"toggle -c\");\nopts.addOption(OptionBuilder.hasOptionalArg().create('e'));\n\nproperties = new Properties();\nproperties.setProperty( \"a\", \"false\" );\nproperties.setProperty( \"c\", \"no\" );\nproperties.setProperty( \"e\", \"0\" );\n\ncmd = parser.parse(opts, null, properties);\nassertTrue( !cmd.hasOption(\"a\") );\nassertTrue( !cmd.hasOption(\"c\") );\nassertTrue( !cmd.hasOption(\"e\") ); // Wrong, this option accepts an argument and should receive the value \"0\"\n{code}\n\n and the second one:\n\n{code}\nproperties = new Properties();\nproperties.setProperty( \"a\", \"just a string\" );\nproperties.setProperty( \"e\", \"\" );\n\ncmd = parser.parse(opts, null, properties);\nassertTrue( !cmd.hasOption(\"a\") );\nassertTrue( !cmd.hasOption(\"c\") );\nassertTrue( !cmd.hasOption(\"e\") ); // Wrong, this option accepts an argument and should receive an empty string as value\n{code}\n",
    "desc_source": "jira"
  },
  "Cli_29": {
    "description": "Commons CLI incorrectly stripping leading and trailing quotes\norg.apache.commons.cli.Parser.processArgs() calls Util.stripLeadingAndTrailingQuotes() for all argument values. IMHO this is incorrect and totally broken.\n\nIt is trivial to create a simple test for this. Output:\n\n    $ java -cp target/clitest.jar Clitest --balloo \"this is a \\\"test\\\"\"\n    Value of argument balloo is 'this is a \"test'.\n\nThe argument 'balloo' should indeed keep its trailing double quote. It is what the shell gives it, so don't try to do something clever to it.\n\nThe offending code was committed here:\n    http://svn.apache.org/viewvc?view=rev&revision=129874\nand has been there for more than 6 years (!). Why was this committed in the first place?\n\nThe fix is trivial, just get rid of Util.stripLeadingAndTrailingQuotes(), and consequently avoid calling it from Parser.processArgs().",
    "desc_source": "jira"
  },
  "Cli_30": {
    "description": "The state of the option groups is not updated by the default options\nThe state of the option groups is neither checked nor updated when the default options passed as a Properties instance to the parse method are processed. For example if 'a' and 'b' are two mutually exclusive options, the command line argument could specify 'a' and the default options could contain 'b', the parser will not complain and the resulting CommandLine will contain 'a' and 'b'.\n",
    "desc_source": "jira"
  },
  "Cli_31": {
    "description": "HelpFormatter.setArgName() has no effect\nThe default argument name set on the HelpFormatter has no effect because the Option and the OptionBuilder bring automatically a default value 'arg'.",
    "desc_source": "jira"
  },
  "Cli_32": {
    "description": "StringIndexOutOfBoundsException in HelpFormatter.findWrapPos\nIn the last while loop in HelpFormatter.findWrapPos, it can pass text.length() to text.charAt(int), which throws a StringIndexOutOfBoundsException. The first expression in that while loop condition should use a <, not a <=.\n\nThis is on line 908 in r779646:\n  http://svn.apache.org/viewvc/commons/proper/cli/trunk/src/java/org/apache/commons/cli/HelpFormatter.java?revision=779646&view=markup",
    "desc_source": "jira"
  },
  "Cli_33": {
    "description": "HelpFormatter strips leading whitespaces in the footer\nI discovered a bug in Commons CLI while using it through Groovy's CliBuilder. See the following issue:\n\nhttp://jira.codehaus.org/browse/GROOVY-4313?page=com.atlassian.jira.plugin.system.issuetabpanels:all-tabpanel\n\nCopied:\nThe following code:\n\ndef cli = new CliBuilder(footer: \"line1:\\n line2:\\n\")\ncli.usage()\n\nProduces the following output:\n\nline1\nline2\n\nNote that there are no whitespaces before \"line2\". Replacing them with \"\\t\" doesn't solve the problem either.",
    "desc_source": "jira"
  },
  "Cli_34": {
    "description": "String as default Option type\ngetParsedOptionValue returns null unless Option.type gets explicitly set. The user expects it to be String unless set to any other type.\nThis coult be either fixed in the Option constructor or in CommandLine.getParsedOptionValue. Mentioning this behaviour in Javadoc would be advisable.\n\n",
    "desc_source": "jira"
  },
  "Cli_35": {
    "description": "LongOpt falsely detected as ambiguous\nOptions options = new Options();\noptions.addOption(Option.builder().longOpt(\"importToOpen\").hasArg().argName(\"FILE\").build());\noptions.addOption(Option.builder(\"i\").longOpt(\"import\").hasArg().argName(\"FILE\").build());\n\nParsing \"--import=FILE\" is not possible since 1.3 as it throws a AmbiguousOptionException stating that it cannot decide whether import is import or importToOpen. In 1.2 this is not an issue. \n\nThe root lies in the new DefaultParser which does a startsWith check internally. \n",
    "desc_source": "jira"
  },
  "Cli_36": {
    "description": "HelpFormatter#setOptionComparator(null) doesn't display the values in inserted order\n{code:java}\nOptionGroup group = new OptionGroup();\nOption h = Option.builder(\"h\").build();\nOption s = Option.builder(\"s\").build();\nOption b = Option.builder(\"b\").build();\nOption t = Option.builder(\"t\").build();\ngroup.addOption(h)\n    .addOption(s)\n    .addOption(b)\n    .addOption(t);\nOptions options = new Options();\noptions.addOptionGroup(group);\noptions.addOption(Option.builder(\"o\").build());\nHelpFormatter formatter = new HelpFormatter();\nformatter.setOptionComparator(null);\nformatter.printHelp(\"cmd\", \"\", options, null);\n{code}\n\nThis code does print the options(1. Group, 2. Option \"o\") in the order of insertion but the groups order of display is messed up.\n\nThe OptionGroup internally uses a HashMap. If that could be replaced with a *LinkedHashMap* this issue can be solved.",
    "desc_source": "jira"
  },
  "Cli_37": {
    "description": "Optional argument picking up next regular option as its argument\nNone",
    "desc_source": "jira"
  },
  "Cli_38": {
    "description": "Optional argument picking up next regular option as its argument\nNone",
    "desc_source": "jira"
  },
  "Cli_39": {
    "description": "Option parser type EXISTING_FILE_VALUE not check file existing\nWhen the user pass option type FileInputStream.class, I think the expected behavior for the return value is the same type, which the user passed.\n\nOptions options = new Options();\noptions.addOption(Option.builder(\"f\").hasArg().type(FileInputStream.class).build());\nCommandLine cline = new DefaultParser().parse(options, args);\nFileInputStream file = (FileInputStream) cline.getParsedOptionValue(\"f\"); // it returns \"File\" object, without check File exist.\n\n\nI attach a solution for it:\nhttps://github.com/schaumb/commons-cli/commit/abfcc8211f529ab75f3b3edd4a827e484109eb0b\n\n",
    "desc_source": "jira"
  },
  "Cli_40": {
    "description": "TypeHandler should throw ParseException for an unsupported class\nJavaDoc for TypeHandler states that createValue will\r\n{noformat}\r\n* @throws ParseException if the value creation for the given object type failedtype{noformat}\r\n\u00a0However createValue(String str, Class<?> clazz) will return null if the clazz is unknown.",
    "desc_source": "jira"
  },
  "JacksonDatabind_1": {
    "description": "NULL values are duplicated when serializing as array [via @JsonFormat(shape = JsonFormat.Shape.ARRAY)]\nExample:\n\n``` java\npublic class TestOuter {\n\n    @JsonFormat(shape = JsonFormat.Shape.ARRAY)\n    public ArrayList<TestInner> array;\n\n    public TestOuter() {\n        this.array = new ArrayList<TestInner>();\n        this.array.add(new TestInner(1, \"one\"));\n        this.array.add(new TestInner(0, null));\n    }\n\n    private class TestInner {\n        public int i;\n        public String mayBeNull;\n\n        public TestInner(int i, String s) {\n            this.i = i;\n            this.mayBeNull = s;\n        }\n    }\n}\n```\n\nSerializing an instance of TestOuter will produce the following incorrect result (as of Jackson 2.2.1):\n\n``` json\n\"array\": [[1, \"one\"], [0, null, null]]\n```\n\nwhere the null value is duplicated. The expected result would be:\n\n``` json\n\"array\": [[1, \"one\"], [0, null]]\n```\n\nI tracked the issue down to:\n\n``` java\npackage com.fasterxml.jackson.databind.ser;\n// ...\npublic class BeanPropertyWriter {\n// ...\n    public void serializeAsColumn(Object bean, JsonGenerator jgen, SerializerProvider prov)\n        throws Exception\n    {\n        Object value = get(bean);\n        if (value == null) { // nulls need specialized handling\n            if (_nullSerializer != null) {\n                _nullSerializer.serialize(null, jgen, prov);\n            } else { // can NOT suppress entries in tabular output\n                jgen.writeNull();\n            }\n        }\n        // otherwise find serializer to use\n        JsonSerializer<Object> ser = _serializer;\n    // ... ...\n```\n\nwhere I suspect there is a missing \"return\", to exit the function once handling of the null value in the dedicated branch is done.\nAs it is now, a null value is first serialized in the dedicated branch (jgen.writeNull()), and then execution continues on the \"normal\" (non-null) path and eventually the value is serialized once again.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_2": {
    "description": "Unwanted POJO's embedded in tree via serialization to tree\nI have a class, more or less:\n\n```\n   class X<T> {\n       String s;\n       List<T> items;\n  };\n```\n\nIt has a custom serializer.\n\nWhen I serialize to a tree, the entire list ends up as a\nVALUE_EMBEDDED_OBJECT: the ArrayList itself.\n\nHere's the serializer class, note the use of writeObjectField.\n\n```\npublic class ListAttributeSerializer extends JsonSerializer<ListAttribute> {\n    @Override\n    public void serialize(ListAttribute value, JsonGenerator jgen,\nSerializerProvider provider) throws IOException {\n        jgen.writeStartObject();\n        jgen.writeStringField(\"itemType\", value.getItemJsonKey());\n        jgen.writeObjectField(\"items\", value.getItems());\n        jgen.writeEndObject();\n    }\n\n    @Override\n    public void serializeWithType(ListAttribute value, JsonGenerator\njgen, SerializerProvider provider, TypeSerializer typeSer) throws\nIOException {\n        typeSer.writeTypePrefixForObject(value, jgen);\n        jgen.writeStringField(\"itemType\", value.getItemJsonKey());\n        jgen.writeObjectField(\"items\", value.getItems());\n        typeSer.writeTypeSuffixForObject(value, jgen);\n}\n}\n```\n\nAnd Tatu wrote me:\n\nOk. valueToTree() uses TokenBuffer as target, so it probably then simply retains Object passed as-is, to defer conversion/serialization, for common use case of buffering. But in your case you would rather get actual serialization into JsonNodes.\n\nYou will probably want to write conversion out then, something like:\n\nbyte[] json = mapper.writeValueAsBytes(referenceText);\nJsonNode tree = mapper.readTree(json);\n\nThis is just the work-around on short term.\nBut this is one thing where configurability might be needed; or possibly different methods. One that forces full serialization into JSON with no POJONodes, other that leaves things as is.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_3": {
    "description": "Regression updating from 2.3.3 to 2.4.0: `null` won't deserialize in `String[]`\nSteps to reproduce\n1. Clone the repository at https://github.com/huxi/sulky\n2. Execute the contained `./gradlew` or `gradlew.bat`\n3. Clone the repository at https://github.com/huxi/lilith/\n4. Change jackson-version [in the project.ext.versions map of dependencyDefinitions.gradle](https://github.com/huxi/lilith/blob/master/dependencyDefinitions.gradle#L6) from `'2.3.3'` to `'2.4.0'`.\n5. Execute the contained `./gradlew` or `gradlew.bat`\n\nThere will be six test-failures with 2.4.0 that won't happen with 2.3.3.\n\nThere are actually only 2 test-methods that fail 3 times each.\n\nThose methods reside at [full()](https://github.com/huxi/lilith/blob/master/lilith-data/logging-io-test/src/main/java/de/huxhorn/lilith/data/logging/test/LoggingEventIOTestBase.java#L230) and [nullArgument()](https://github.com/huxi/lilith/blob/master/lilith-data/logging-io-test/src/main/java/de/huxhorn/lilith/data/logging/test/LoggingEventIOTestBase.java#L120).\n\nI first suspected that `AfterburnerModule` might be the culprit but removing it from `LoggingJsonDecoder`/`LoggingJsonEncoder` didn't fix the problem.\n\nSorry for not narrowing down the problem further. I'll give this another look tomorrow but you may already be able to find the issue in the meantime.\n\nThe interesting thing is that several other test cases are working as intended...\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_4": {
    "description": "Index is never set for Collection and Array in InvalidFormatException.Reference\nWhen a InvalidFormatException is created, index values is always '-1'.\nIndeed, in StringCollectionDeserializer, and CollectionDeserializer the exception is not caught.\nThe JsonMappingException shoud be caught and the index should be added and based on the \"result\" size.\nWithout this information, there is no way to get the index of the item involved in the mapping error.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_5": {
    "description": "Mixin annotations lost when using a mixin class hierarchy with non-mixin interfaces\nIn summary, mixin annotations are lost when Jackson scans a parent mixin class with Json annotations followed by an interface implemented by the parent mixin class that does not have the same Json annotations.\nJackson version: 2.4.0\n\nDetail:\nI have the following class structure\n\n``` java\npublic interface Contact {\n    String getCity();\n}\n\npublic class ContactImpl implements Contact {\n    public String getCity() { ... }\n}\n\npublic class ContactMixin implements Contact {\n    @JsonProperty\n    public String getCity() { return null; }\n}\n\npublic interface Person extends Contact {}\n\npublic class PersonImpl extends ContactImpl implements Person {}\n\npublic class PersonMixin extends ContactMixin implements Person {}\n```\n\nand I configure a module as\n\n``` java\n// There are other getters/properties in the Impl class that do not need to be serialized and so\n// I am using the Mixin to match the interface and explicitly annotate all the inherited methods\nmodule.disable(MapperFeature.ALLOW_FINAL_FIELDS_AS_MUTATORS)\n    .disable(MapperFeature.AUTO_DETECT_FIELDS)\n    .disable(MapperFeature.AUTO_DETECT_GETTERS)\n    .disable(MapperFeature.AUTO_DETECT_IS_GETTERS)\n    .disable(MapperFeature.INFER_PROPERTY_MUTATORS);\nmodule.setMixInAnnotation(Person.class, PersonMixin.class);\n```\n\nWhen a `PersonImpl` instance is serialized, `city` is not included.\n\nI debugged the code and this is what happens:\nIn `AnnotatedClass.resolveMemberMethods()` the supertypes of `PersonImpl` are `[Person.class, Contact.class, ContactImpl.class]` in that order.\n\nIt starts with `Person` for which it finds `PersonMixin` and proceeds to `AnnotatedClass._addMethodMixIns()`. Here the `parents` list has `[PersonMixin, ContactMixin, Contact]`. When it processes `ContactMixin` it adds `getCity()` with the `JsonProperty` annotation. Then it processes `Contact`, doesn't find `getCity()` in `methods` map and so creates a new `AnnotatedMethod` for `getCity()` with the one from the interface which has no annotation which replaces the one from `ContactMixin`\n\nThe workaround for this issue is to explicitly add any parent mixins to the module i.e.\n\n``` java\nmodule.setMixInAnnotation(Contact.class, ContactMixin.class);\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_6": {
    "description": "Add Support for Parsing All Compliant ISO-8601 Date Formats\nSome providers create JSON date stamps in ISO-8601 formats that cannot be parsed by the jackson-databind library. Here is a sampling of some valid formats that do not parse correctly:\n\n2014-10-03T18:00:00.6-05:00\n2014-10-03T18:00:00.61-05:00\n1997-07-16T19:20+01:00\n1997-07-16T19:20:30.45+01:00\n\nThe last two actually come from the ISO-8601 notes on http://www.w3.org/TR/NOTE-datetime.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_7": {
    "description": "Possibly wrong `TokenBuffer` delegate deserialization using `@JsonCreator`\n``` java\nclass Value {\n@JsonCreator\npublic static Value from(TokenBuffer buffer) {\n...\n}\n```\n\nGiven JSON string is  `{ \"a\":1, \"b\":null }`, it is expected that while deserializing using delegate buffer,\ncurrent token will be start object `{`, and rest of the tokens will be available in buffer:\n\n```\n[START_OBJECT, FIELD_NAME, VALUE_NUMBER_INT, FIELD_NAME, VALUE_NULL, END_OBJECT]\n```\n\nBut, buffers ends up being started with field name and then contains single attribute value\n\n```\n[FIELD_NAME, VALUE_NUMBER_INT]\n```\n\nIt's due to how `TokenBuffer#copyCurrentStructure` works when we have current token as a `FIELD_NAME`, rather than `START_OBJECT`, because it's forced to move to next token [BeanDeserializer.java:120](https://github.com/FasterXML/jackson-databind/blob/2.4/src/main/java/com/fasterxml/jackson/databind/deser/BeanDeserializer.java#L120)\n\nHope this helps to nail it down. Is it an intended behavior, or it's regression/bug? \n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_8": {
    "description": "Problem with bogus conflict between single-arg-String vs `CharSequence` constructor\nAlthough it is good idea to allow recognizing `CharSequence` as almost like an alias for `String`, this can cause problems for classes like `StringBuilder` that have separate constructors for both.\nThis actually throws a bogus exception for 2.5.0, due to introduction of ability to recognize `CharSequence`.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_9": {
    "description": "Deserializing Map<Class<? extends Object>, String>\nI am having problems deserializing my `Map<Class<? extends Object>, String>`. Simple test case demonstrates it:\n\n``` java\n@Test\npublic void testMapWithClassAsKey() throws Exception {\n    Map<Class<? extends Object>, String> map = new HashMap<>();\n    map.put(ArrayList.class, \"ArrayList\");\n    map.put(HashMap.class, \"HashMap\");\n\n    ObjectMapper mapper = new ObjectMapper();\n\n    String json = mapper.writerWithDefaultPrettyPrinter().writeValueAsString(map);\n    System.out.println(json);\n    mapper.readValue(json, new TypeReference<Map<Class<? extends Object>, String>>(){});\n}\n```\n\nThis test serializes the map as:\n\n``` json\n{\n    \"class java.util.ArrayList\" : \"ArrayList\",\n    \"class java.util.HashMap\" : \"HashMap\"\n}\n```\n\n`mapper.readValue(json, new TypeReference<Map<Class<? extends Object>, String>>(){});` then throws a `Exception`:\n\n```\ncom.fasterxml.jackson.databind.exc.InvalidFormatException: Can not construct     Map key of type java.lang.Class from String \"class java.util.ArrayList\": not a valid representation: Can not construct Map key of type java.lang.Class from String \"class java.util.ArrayList\": unable to parse key as Class\n at [Source: ...\n```\n\nAs i understood from #630 the KeyDeserializer for Class should be part of Jackson. Am I missing something?\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_10": {
    "description": "JsonAnyGetter doesn't work with JsonSerialize (except with keyUsing)\n(This is happening with 2.5.0. Haven't tried 2.5.1 but I couldn't see any related issue anyway)\n\nJackson ignores JsonSerialize annotation when there is JsonAnyGetter annotation.\n\n``` java\n  @JsonSerialize(using = MySerializer.class)\n  // or\n  @JsonSerialize(converter = MyConverter.class)\n  @JsonAnyGetter\n  public Map<String, String> getParameters(){\n    return parameters;\n  }\n```\n\nexcept \n\n``` Java\n@JsonSerialize(keyUsing = MyKeySerializer.class)\n```\n\n(haven't tried each setting. Only tried keyUsing because I've seen a different issue (#661) with it)\nThen it works. But I need the converter, so..\n\nFor the time being I will use\n\n``` Java\n  @JsonAnyGetter\n  public Map<String, JsonNode> getParameters(){\n    return new MyConverter().convert(parameters);\n  }\n```\n\nbut I'd prefer to stick to annotations.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_11": {
    "description": "Problem resolving locally declared generic type\n(reported by Hal H)\n\nCase like:\n\n``` java\nclass Something {\n    public <T extends Ruleform> T getEntity()\n    public <T extends Ruleform> void setEntity(T entity) \n}\n```\n\nappears to fail on deserialization.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_12": {
    "description": "@JsonDeserialize on Map with contentUsing custom deserializer overwrites default behavior\nI recently updated from version 2.3.3 to 2.5.1 and encountered a new issue with our custom deserializers. They either seemed to stop working or were active on the wrong fields.\nI could narrow it down to some change in version 2.4.4 (2.4.3 is still working for me)\n\nI wrote a test to show this behavior. It seems to appear when there a two maps with the same key and value types in a bean, and only one of them has a custom deserializer. The deserializer is then falsely used either for both or none of the maps.\n\nThis test works for me in version 2.4.3 and fails with higher versions.\n\n``` java\nimport static org.junit.Assert.assertEquals;\n\nimport java.io.IOException;\nimport java.util.Map;\n\nimport org.junit.Test;\n\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonParser;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.annotation.JsonDeserialize;\nimport com.fasterxml.jackson.databind.deser.std.StdDeserializer;\n\npublic class DeserializeTest {\n\n    @Test\n    public void testIt() throws Exception {\n        ObjectMapper om = new ObjectMapper();\n        String json = \"{\\\"map1\\\":{\\\"a\\\":1},\\\"map2\\\":{\\\"a\\\":1}}\";\n        TestBean bean = om.readValue(json.getBytes(), TestBean.class);\n\n        assertEquals(100, bean.getMap1().get(\"a\").intValue());\n        assertEquals(1, bean.getMap2().get(\"a\").intValue());\n    }\n\n    public static class TestBean {\n\n        @JsonProperty(\"map1\")\n        @JsonDeserialize(contentUsing = CustomDeserializer.class)\n        Map<String, Integer> map1;\n\n        @JsonProperty(\"map2\")\n        Map<String, Integer> map2;\n\n        public Map<String, Integer> getMap1() {\n            return map1;\n        }\n\n        public void setMap1(Map<String, Integer> map1) {\n            this.map1 = map1;\n        }\n\n        public Map<String, Integer> getMap2() {\n            return map2;\n        }\n\n        public void setMap2(Map<String, Integer> map2) {\n            this.map2 = map2;\n        }\n    }\n\n    public static class CustomDeserializer extends StdDeserializer<Integer> {\n\n        public CustomDeserializer() {\n            super(Integer.class);\n        }\n\n        @Override\n        public Integer deserialize(JsonParser p, DeserializationContext ctxt) throws IOException, JsonProcessingException {\n            Integer value = p.readValueAs(Integer.class);\n            return value * 100;\n        }\n    }\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_13": {
    "description": "Allow deserialization of `null` Object Id\n(note: related to https://github.com/FasterXML/jackson-annotations/issues/56)\n\nFor some use cases (one known case being use from ORM like Hibernate) it makes sense to allow use of `null` (or missing) Object Id, in cases where actual Id will be generated by something other than Jackson. It may also make sense to add matching `DeserializationFeature` which allows such a condition to either be acceptable (default), or not (throw an exception), to allow for strict checks in cases where null/missing Object Id is not a legal use case.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_14": {
    "description": "Custom deserializer with parent object update\nHi, I have custom deserializer for `DataA`. An instance of `DataA` is contained in `DataB`, when updating an existing instance of `DataB` (as opposed to creating a new one) I get an exception when deserializing via a `JsonNode` object (deserializing via a `String` object works). \n\n``` java\nimport java.io.IOException;\n\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport com.fasterxml.jackson.core.JsonParser;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.JsonToken;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.deser.std.StdDeserializer;\nimport com.fasterxml.jackson.databind.module.SimpleModule;\n\npublic class TestDeserTest {\n    static class DataA {\n        public int i = 1;\n        public int j = 2;\n\n    }\n\n    static class DataB {\n        public DataA da = new DataA();\n        public int k = 3;\n    }\n\n    static class DataADeserializer extends StdDeserializer<DataA> {\n        private static final long serialVersionUID = 1L;\n\n        DataADeserializer() {\n            super(DataA.class);\n        }\n\n        public DataA deserialize(JsonParser jp, DeserializationContext ctxt)\n                throws JsonProcessingException, IOException {\n            assert (jp.getCurrentToken() == JsonToken.START_OBJECT);\n            JsonNode node = jp.getCodec().readTree(jp);\n\n            DataA da = new DataA();\n            da.i = 5;\n            return da;\n        }\n    }\n\n    @Test\n    public void test() throws IOException {\n        ObjectMapper mapper = new ObjectMapper();\n        SimpleModule module = new SimpleModule();\n        module.addDeserializer(DataA.class, new DataADeserializer());\n        mapper.registerModule(module);\n\n        DataB db = new DataB();\n        db.da.i = 11;\n        db.k = 13;\n        String jsonBString = mapper.writeValueAsString(db);\n        JsonNode jsonBNode = mapper.valueToTree(db);\n\n        // create parent\n        DataB dbNewViaString = mapper.readValue(jsonBString, DataB.class);\n        Assert.assertEquals(5, dbNewViaString.da.i);\n        Assert.assertEquals(13, dbNewViaString.k);\n\n        DataB dbNewViaNode = mapper.treeToValue(jsonBNode, DataB.class);\n        Assert.assertEquals(5, dbNewViaNode.da.i);\n        Assert.assertEquals(13, dbNewViaNode.k);\n\n        // update parent\n        DataB dbUpdViaString = new DataB();\n        DataB dbUpdViaNode = new DataB();\n\n        Assert.assertEquals(1, dbUpdViaString.da.i);\n        Assert.assertEquals(3, dbUpdViaString.k);\n        mapper.readerForUpdating(dbUpdViaString).readValue(jsonBString);\n        Assert.assertEquals(5, dbUpdViaString.da.i);\n        Assert.assertEquals(13, dbUpdViaString.k);\n\n        Assert.assertEquals(1, dbUpdViaNode.da.i);\n        Assert.assertEquals(3, dbUpdViaNode.k);\n        // FAILS HERE:\n        mapper.readerForUpdating(dbUpdViaNode).readValue(jsonBNode);\n        Assert.assertEquals(5, dbUpdViaNode.da.i);\n        Assert.assertEquals(13, dbUpdViaNode.k);\n    }\n}\n```\n\nThe trace:\n\n``` java\ncom.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field \"i\" (class myorg.TestDeserTest$DataB), not marked as ignorable (2 known properties: \"da\", \"k\"])\n at [Source: N/A; line: -1, column: -1] (through reference chain: myorg.DataB[\"da\"]->myorg.DataB[\"i\"])\n    at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:51)\n    at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:817)\n    at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:954)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1324)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1302)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:249)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:136)\n    at com.fasterxml.jackson.databind.ObjectReader._bindAsTree(ObjectReader.java:1478)\n    at com.fasterxml.jackson.databind.ObjectReader.readTree(ObjectReader.java:1020)\n    at myorg.TestDeserTest$DataADeserializer.deserialize(TestDeserTest.java:39)\n    at myorg.TestDeserTest$DataADeserializer.deserialize(TestDeserTest.java:1)\n    at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:523)\n    at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101)\n    at com.fasterxml.jackson.databind.deser.impl.BeanPropertyMap.findDeserializeAndSet(BeanPropertyMap.java:285)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:220)\n    at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1443)\n    at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1154)\n    at myorg.TestDeserTest.test(TestDeserTest.java:81)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)\n    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:459)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:675)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:382)\n    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:192)\n\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_15": {
    "description": "XmlAdapter result marshaling error in case of ValueType=Object \nHi,\n\nI have an error \"com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.lang.String and no properties discovered to create BeanSerializer\" in case of using custom XmlAdapter with such declaration:\n\n``` java\npublic static class IntegerListXmlAdapter extends XmlAdapter<Object, List<Integer>> {\n        ...\n        @Override\n        public Object marshal(List<Integer> list) throws Exception {\n            return Joiner.on(\",\").join(list);\n        }\n}\n```\n\nIf change declaration of this class to \"extends XmlAdapter<String, List<Integer>>\" it works good.\n\nFull example:\n\n``` java\npublic class IntegerListXmlAdapterTest {\n    @Test\n    public void testBasic() throws JsonProcessingException {\n        ObjectMapper mapper = (new ObjectMapper()).setAnnotationIntrospector(new JaxbAnnotationIntrospector());\n        SomeIntListHolder listHolder = new SomeIntListHolder();\n        listHolder.setListOne(asList(1, 2, 3));\n        System.out.println(mapper.writeValueAsString(listHolder));\n    }\n\n    public static class IntegerListXmlAdapter extends XmlAdapter<Object, List<Integer>> {\n        @Override\n        public List<Integer> unmarshal(Object value) throws Exception {return null;}\n\n        @Override\n        public Object marshal(List<Integer> list) throws Exception {\n            return Joiner.on(\",\").join(list);\n        }\n    }\n\n    public static class IntegerListToStringXmlAdapter extends XmlAdapter<String, List<Integer>> {\n        public List<Integer> unmarshal(String value) throws Exception {return null;}\n\n        public String marshal(List<Integer> list) throws Exception {\n            return Joiner.on(\",\").join(list);\n        }\n    }\n\n    @XmlRootElement\n    @XmlAccessorType(XmlAccessType.NONE)\n    public static class SomeIntListHolder {\n\n        @XmlAttribute\n        @XmlJavaTypeAdapter(IntegerListXmlAdapter.class)\n        private List<Integer> listOne;\n\n        public List<Integer> getListOne() {\n            return listOne;\n        }\n\n        public void setListOne(List<Integer> listOne) {\n            this.listOne = listOne;\n        }\n    }\n}\n```\n\nIn this state with last Jackson version we will get an error\n\n```\ncom.fasterxml.jackson.databind.JsonMappingException: No serializer found for class java.lang.String and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: SomeIntListHolder[\"listOne\"])\n    at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:59)\n    at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:26)\n    at com.fasterxml.jackson.databind.ser.std.StdDelegatingSerializer.serialize(StdDelegatingSerializer.java:157)\n    at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:575)\n    at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:663)\n    at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:156)\n    at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:129)\n    at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:3385)\n    at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2779)\n```\n\nBut if we change XmlJavaTypeAdapter to IntegerListToStringXmlAdapter error will be fixed and code will work fine.\nThis error exists only in Jackson 2, we have this code with Object generic on Jackson 1 and get an issue only during migration to new major version.\n\nThis concrete error can be fixed by hack in com.fasterxml.jackson.databind.ser.std.StdDelegatingSerializer:\n\n``` java\n    @Override\n    public void serialize(Object value, JsonGenerator gen, SerializerProvider provider) throws IOException\n    {\n        Object delegateValue = convertValue(value);\n        // should we accept nulls?\n        if (delegateValue == null) {\n            provider.defaultSerializeNull(gen);\n            return;\n        }\n\n        //original code:\n        //_delegateSerializer.serialize(delegateValue, gen, provider);\n\n        JsonSerializer<Object> delegateSerializer;\n        if (_delegateSerializer instanceof UnknownSerializer) {\n            delegateSerializer =  provider.findValueSerializer(delegateValue.getClass());\n        } else {\n            delegateSerializer = _delegateSerializer;\n        }\n\n        delegateSerializer.serialize(delegateValue, gen, provider);\n    }\n```\n\nYou can find test class here: https://github.com/Spikhalskiy/jackson_xmladapter__bug/blob/master/src/test/java/IntegerListXmlAdapterTest.java\n\nand hacked serializer code here: https://github.com/Spikhalskiy/jackson_xmladapter__bug/blob/master/src/main/java/com/fasterxml/jackson/databind/ser/std/StdDelegatingSerializer.java\n\nNow test passing in this repo because of fake StdDelegatingSerializer in classpath - try to delete it to get an issue.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_16": {
    "description": "Annotation bundles ignored when added to Mixin\nWhen updating from v 2.4.4 to 2.5.\\* it appears as though annotation bundles created with `@JacksonAnnotationsInside` are ignored when placed on a mixin.  Moving the annotation bundel to the actual class seems to resolve the issue.  Below is a simple test that attempts to rename a property.  I have more complicated test cases that are also failing but this should provide some context.\n\n``` java\npublic class Fun {\n\n    @Test\n    public void test() throws JsonProcessingException {\n        ObjectMapper mapper = new ObjectMapper().addMixIn(Foo.class, FooMixin.class);\n        String result = mapper.writeValueAsString(new Foo(\"result\"));\n        Assert.assertEquals(\"{\\\"bar\\\":\\\"result\\\"}\", result);\n    }\n\n    @Target(value={ ElementType.CONSTRUCTOR, ElementType.FIELD, ElementType.METHOD })\n    @Retention(value=RetentionPolicy.RUNTIME)\n    @JacksonAnnotationsInside\n    @JsonProperty(\"bar\")\n    public @interface ExposeStuff {\n\n    }\n\n    public abstract class FooMixin {\n        @ExposeStuff\n        public abstract String getStuff();\n    }\n\n    public class Foo {\n\n        private String stuff;\n\n        Foo(String stuff) {\n            this.stuff = stuff;\n        }\n\n        public String getStuff() {\n            return stuff;\n        }\n    }\n}\n```\n\nI'm expecting the \"stuff\" property to be serialized as \"bar\".\n\nI apologize I haven't been able to identify the culprit (and perhaps it's in my usage).  Let me know your thoughts. I'm always happy to provide more details!\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_17": {
    "description": "readTree does not work with defaultTyping enabled but no type info provided\nI have enabled `defaultTyping`, and serialized `Foo` entity with no type info. I'm trying to read json as a tree with `mapper.readTree(json)`, and it throws an exception \n\n``` java\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: \nUnexpected token (START_OBJECT), expected START_ARRAY: need JSON Array to contain As.WRAPPER_ARRAY \ntype information for class com.fasterxml.jackson.databind.JsonNode\n at [Source: {\n  \"bar\" : \"bar\"\n}; line: 1, column: 1]\n    at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)\n    at com.fasterxml.jackson.databind.DeserializationContext.wrongTokenException(DeserializationContext.java:927)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._locateTypeId(AsArrayTypeDeserializer.java:127)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer._deserialize(AsArrayTypeDeserializer.java:93)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsArrayTypeDeserializer.deserializeTypedFromAny(AsArrayTypeDeserializer.java:68)\n    at com.fasterxml.jackson.databind.deser.std.BaseNodeDeserializer.deserializeWithType(JsonNodeDeserializer.java:144)\n    at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer.deserializeWithType(JsonNodeDeserializer.java:14)\n    at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:42)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3562)\n    at com.fasterxml.jackson.databind.ObjectMapper.readTree(ObjectMapper.java:2136)\n    at test.App.main(App.java:23)\n```\n\nHowever, if I disable `defaultTyping`, the same code works fine. So, `readTree(json)` does not actually need type info for the root element, because it works when `defaultTyping` is disabled (i.e. `{\"bar\" : \"bar\"}`), but it throws the exception when `defaultTyping` is enabled, that's why it looks like a bug. The same thing happens for `valueToTree(foo)`. \nJackson version is `2.5.3`\nFull code is provided.\n\n``` java\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.MapperFeature;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport java.io.IOException;\n\npublic class App {\n    public static void main(String[] args) throws IOException {\n        ObjectMapper mapper = new ObjectMapper()\n                .enableDefaultTyping() // works fine with disableDefaultTyping()\n                .enable(MapperFeature.AUTO_DETECT_GETTERS)\n                .enable(MapperFeature.REQUIRE_SETTERS_FOR_GETTERS)\n                .disable(MapperFeature.USE_GETTERS_AS_SETTERS)\n                .disable(MapperFeature.CAN_OVERRIDE_ACCESS_MODIFIERS)\n                .enable(SerializationFeature.INDENT_OUTPUT)\n                .disable(SerializationFeature.FAIL_ON_EMPTY_BEANS);\n\n        Foo foo = new Foo(\"bar\");\n        String serialized = mapper.writeValueAsString(foo); // {\"bar\" : \"bar\"}\n\n        JsonNode jsonNode = mapper.readTree(serialized); // exception here\n        JsonNode node = mapper.valueToTree(foo); // and here\n    }\n\n    public static class Foo {\n        private String bar;\n\n        public Foo() {\n        }\n\n        public Foo(String bar) {\n            this.bar = bar;\n        }\n\n        public String getBar() {\n            return bar;\n        }\n\n        public void setBar(String bar) {\n            this.bar = bar;\n        }\n    }\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_18": {
    "description": "Add basic error-recovery for `ObjectReader.readValues()`\n(follow up for #733)\n\nIn case of `JsonProcessingException`, `MappingIterator` will currently be left pointing right after whatever token was last tokenized (or character following tokenization error). While this is better than indeterminate state, ideally it should try to do some error recover. And although it may not be possible to recover successfully from all kinds of issues, it should be possible to do best effort given that iterator has some knowledge of state when it was opened; that is, it can try to heuristically match closing `END_OBJECT`, depending on nesting level it was created at.\n\nIn addition it may make sense to add a switch to prevent using of any automated heuristics, for those users who want full control over recovery.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_19": {
    "description": "Force value coercion for `java.util.Properties`, so that values are `String`s\nCurrently there is no custom handling for `java.util.Properties`, and although it is possible to use it (since it really is a `Map` under the hood), results are only good if values are already `String`s.\nThe problem here is that `Properties` is actually declared as `Map<String,Object>`, probably due to backwards-compatibility constraints.\n\nBut Jackson should know better: perhaps by `TypeFactory` tweaking parameterizations a bit?\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_20": {
    "description": "Presence of PropertyNamingStrategy Makes Deserialization Fail\nI originally came across this issue using Dropwizard - https://github.com/dropwizard/dropwizard/issues/1095.  But it looks like this is a Jackson issue.  Here's the rerproducer:\n\n``` java\npublic class TestPropertyNamingStrategyIssue {\n  public static class ClassWithObjectNodeField {\n    public String id;\n    public ObjectNode json;\n  }\n\n  @Test\n  public void reproducer() throws Exception {\n    ObjectMapper mapper = new ObjectMapper();\n    mapper.setPropertyNamingStrategy(PropertyNamingStrategy.LOWER_CASE);\n    ClassWithObjectNodeField deserialized =\n        mapper.readValue(\n            \"{ \\\"id\\\": \\\"1\\\", \\\"json\\\": { \\\"foo\\\": \\\"bar\\\", \\\"baz\\\": \\\"bing\\\" } }\",\n            ClassWithObjectNodeField.class);\n  }\n}\n```\n\nLooks like the presence of any PropertyNamingStrategy make deserialization to ObjectNode fail.  This works fine if I remove the property naming strategy.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_21": {
    "description": "Specifying `Enum` value serialization using `@JsonProperty`\nCurrently, if I want to deserialize an enum with a value that isn't its `Enum.name()`, I can do either\n\n``` java\npublic enum TestEnum {\n    VALUE_ONE(\"value1\");\n\n    private String valueInJson;\n\n    private TestEnum(String valueInJson) {\n        this.valueInJson = valueInJson;\n    }\n\n    @JsonCreator\n    public static TestEnum getEnumFromValue(String value) {\n        for (TestEnum testEnum : values()) {\n            if (testEnum.valueInJson.equals(value)) {\n                return testEnum;\n            }\n        }\n        throw new IllegalArgumentException();\n    }\n}\n```\n\nor, using `DeserializationFeature.READ_ENUMS_USING_TO_STRING`,\n\n``` java\npublic enum TestEnum {\n    VALUE_ONE(\"value1\");\n\n    private String valueInJson;\n\n    private TestEnum(String valueInJson) {\n        this.valueInJson = valueInJson;\n    }\n\n    @Override\n    public String toString() {\n        return valueInJson;\n    }\n}\n```\n\nThis seems like a lot of boilerplate - is there a simpler way to do this, similar to how `Gson` handles it?\n\n``` java\npublic enum TestEnum {\n    @SerializedName(\"value1\")\n    VALUE_ONE\n}\n```\n\nIt's both more concise and handles both serialization and deserialization.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_22": {
    "description": "Custom serializer not used if POJO has `@JsonValue`\nLooks like serializers constructed for `@JsonValue` have higher precedence than custom serializers; that is, registered custom serializer is not found if POJO type has `@JsonValue` annotation.\nThis is wrong.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_23": {
    "description": "Possible problem with `NON_EMPTY` exclusion, `int`s, `Strings`\n(from https://github.com/FasterXML/jackson-module-afterburner/issues/55)\n\nIt appears like default handling might not work as expected with 2.5.4, whereas Afterburner does seem to handle things better. Need to investigate, and also see if 2.6.0-rc3 works better.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_24": {
    "description": "Configuring an ObjectMapper's DateFormat changes time zone when serialising Joda DateTime\nThe serialisation of Joda `DateTime` instances behaves differently in 2.6.0 vs 2.5.4 when the `ObjectMapper`'s had its `DateFormat` configured. The behaviour change is illustrated by the following code:\n\n``` java\npublic static void main(String[] args) throws JsonProcessingException {\n    System.out.println(createObjectMapper()\n            .writeValueAsString(new DateTime(1988, 6, 25, 20, 30, DateTimeZone.UTC)));\n}\n\nprivate static ObjectMapper createObjectMapper() {\n    ObjectMapper mapper = new ObjectMapper();\n    mapper.registerModule(createJodaModule());\n    mapper.configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false);\n    System.out.println(mapper.getSerializationConfig().getTimeZone());\n    mapper.setDateFormat(new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"));\n    System.out.println(mapper.getSerializationConfig().getTimeZone());\n    return mapper;\n}\n\nprivate static SimpleModule createJodaModule() {\n    SimpleModule module = new SimpleModule();\n    module.addSerializer(DateTime.class, new DateTimeSerializer(\n            new JacksonJodaDateFormat(DateTimeFormat.forPattern(\"yyyy-MM-dd HH:mm:ss\")\n                    .withZoneUTC())));\n        return module;\n    }\n```\n\nWhen run with Jackson 2.5.4 the output is:\n\n```\nsun.util.calendar.ZoneInfo[id=\"GMT\",offset=0,dstSavings=0,useDaylight=false,transitions=0,lastRule=null]\nsun.util.calendar.ZoneInfo[id=\"GMT\",offset=0,dstSavings=0,useDaylight=false,transitions=0,lastRule=null]\n\"1988-06-25 20:30:00\"\n```\n\nWhen run with Jackson 2.6.0 the output is:\n\n```\nsun.util.calendar.ZoneInfo[id=\"GMT\",offset=0,dstSavings=0,useDaylight=false,transitions=0,lastRule=null]\nsun.util.calendar.ZoneInfo[id=\"Europe/London\",offset=0,dstSavings=3600000,useDaylight=true,transitions=242,lastRule=java.util.SimpleTimeZone[id=Europe/London,offset=0,dstSavings=3600000,useDaylight=true,startYear=0,startMode=2,startMonth=2,startDay=-1,startDayOfWeek=1,startTime=3600000,startTimeMode=2,endMode=2,endMonth=9,endDay=-1,endDayOfWeek=1,endTime=3600000,endTimeMode=2]]\n\"1988-06-25 21:30:00\"\n```\n\nIt looks like the fix for #824 is the cause. In 2.6, the call to `mapper.setDateFormat` causes the `ObjectMapper`'s time zone to be set to the JVM's default time zone. In 2.5.x, calling `mapper.setDateFormat` has no effect on its time zone.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_25": {
    "description": "Exception deserializing a byte[] when the target type comes from an annotation\nWhen trying to deserialize a `byte[]` from a `Map` when the deserialization type comes from an annotation, I'm seeing the following exception:\n\n```\njava.lang.IllegalArgumentException: Can not deserialize Class [B (of type array) as a Bean\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.isPotentialBeanType(BeanDeserializerFactory.java:808)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:138)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer2(DeserializerCache.java:403)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createDeserializer(DeserializerCache.java:352)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:264)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\n        at com.fasterxml.jackson.databind.DeserializationContext.findContextualValueDeserializer(DeserializationContext.java:428)\n        at com.fasterxml.jackson.databind.deser.std.StdDeserializer.findDeserializer(StdDeserializer.java:947)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.resolve(BeanDeserializerBase.java:439)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCache2(DeserializerCache.java:296)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache._createAndCacheValueDeserializer(DeserializerCache.java:244)\n        at com.fasterxml.jackson.databind.deser.DeserializerCache.findValueDeserializer(DeserializerCache.java:142)\n        at com.fasterxml.jackson.databind.DeserializationContext.findRootValueDeserializer(DeserializationContext.java:461)\n        at com.fasterxml.jackson.databind.ObjectMapper._findRootDeserializer(ObjectMapper.java:3804)\n        at com.fasterxml.jackson.databind.ObjectMapper._convert(ObjectMapper.java:3418)\n        at com.fasterxml.jackson.databind.ObjectMapper.convertValue(ObjectMapper.java:3351)\n```\n\nThe below is a repro.\n\n``` java\npublic class JacksonTest {\n\n    static class Foo {\n        @JsonProperty\n        @JsonDeserialize(as=byte[].class)\n        Object someBytes;\n    }\n\n    public void testFooFromMap() {\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"someBytes\", \"HelloWorld\".getBytes());\n\n        ObjectMapper m = new ObjectMapper();\n        m.convertValue(map, Foo.class);\n    }\n}\n```\n\nI discovered this on 2.5.1, but I tried 2.6.0 and it's exhibiting the same behavior.\n\nThanks!\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_26": {
    "description": "Problem serializing `ObjectReader` (and possibly `ObjectMapper`) in 2.6\nLooks like serializability is missing for one of new (2.6) helper classes, `CompactStringObjectMap`, leading to problems with systems like Apache Spark that may need to serialize handlers like `ObjectReader` and/or `ObjectWriter`.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_27": {
    "description": "Problem deserializing External Type Id if type id comes before POJO\n(note: seems to be similar or related to https://github.com/FasterXML/jackson-module-afterburner/issues/58)\n\nWith 2.6, looks like handling of External Type Id is broken in some rare (?) cases; existing unit tests did not catch this. At this point I am speculating this is due to some refactoring, or change to use more efficient 'nextFieldName()' method.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_28": {
    "description": "Deserialization from \"{}\" to ObjectNode field causes \"out of END_OBJECT token\" error\nI found that deserializing from an empty object (`{}`) to ObjectNode field in a class field fails.\n\nHere is the minimum code to reproduce:\n\n``` java\npublic class Main\n{\n    public static class MyValue\n    {\n        private final ObjectNode object;\n\n        @JsonCreator\n        public MyValue(ObjectNode object) { this.object = object; }\n\n        @JsonValue\n        public ObjectNode getObject() { return object; }\n    }\n\n    public static void main(String[] args)\n            throws Exception\n    {\n        ObjectMapper om = new ObjectMapper();\n\n        ObjectNode object = new ObjectNode(JsonNodeFactory.instance);\n\n        String json = om.writeValueAsString(object);\n        System.out.println(\"json: \"+json);\n\n        ObjectNode de1 = om.readValue(json, ObjectNode.class);  // this works\n        System.out.println(\"Deserialized to ObjectNode: \"+de1);\n\n        MyValue de2 = om.readValue(json, MyValue.class);  // but this throws exception\n        System.out.println(\"Deserialized to MyValue: \"+de2);\n    }\n}\n```\n\nResult is:\n\n```\njson: {}\nDeserialized to ObjectNode: {}\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of com.fasterxml.jackson.databind.node.ObjectNode out of END_OBJECT token\n at [Source: {}; line: 1, column: 2]\n        at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)\n        at com.fasterxml.jackson.databind.DeserializationContext.mappingException(DeserializationContext.java:854)\n        at com.fasterxml.jackson.databind.DeserializationContext.mappingException(DeserializationContext.java:850)\n        at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer$ObjectDeserializer.deserialize(JsonNodeDeserializer.java:104)\n        at com.fasterxml.jackson.databind.deser.std.JsonNodeDeserializer$ObjectDeserializer.deserialize(JsonNodeDeserializer.java:83)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1095)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:294)\n        at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:131)\n        at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3731)\n        at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2724)\n        at Main.main(Main.java:35)\n```\n\nIf the object is not empty (e.g. `{\"k\":\"v\"}`), it works:\n\n``` java\n        ...\n        ObjectNode object = new ObjectNode(JsonNodeFactory.instance);\n        object.put(\"k\", \"v\");  // added\n        ...\n```\n\n```\njson: {\"k\":\"v\"}\nDeserialized to ObjectNode: {\"k\":\"v\"}\nDeserialized to MyValue: io.digdag.cli.Main$MyValue@17550481\n```\n\nEnvironment:\n- jackson-core 2.6.2\n- jackson-databind 2.6.2\n- Java 8 (`Java(TM) SE Runtime Environment (build 1.8.0_20-b26)`)\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_29": {
    "description": "Handle null type id for polymorphic values that use external type id\nRemove exceptions thrown when polymorphic value is null.\nIf there is a need to force non-null value, this could be provided as an extra property in @JsonTypeInfo, or perhaps use an existing property such as JsonProperty.required.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_30": {
    "description": "BigDecimal values via @JsonTypeInfo/@JsonSubTypes get rounded\nWhen using an `ObjectMapper` to serialize/deserialize a class with an `Object` field annotated with a `@JsonSubTypes.Type` that indicate `BigDecimal`, it looks like the value is getting rounded to a double.\n\nI tried configuring `DeserializationFeature.USE_BIG_DECIMAL_FOR_FLOATS`, but that didn't seem to help.\n\nWhat I think is a valid repro is below, but let me know if I'm actually doing something wrong here.\n\nThanks!\n\n``` java\nimport org.junit.Test;\nimport org.junit.Assert;\n\nimport java.math.BigDecimal;\n\nimport com.fasterxml.jackson.annotation.*;\nimport com.fasterxml.jackson.databind.DeserializationFeature;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class JacksonTest {\n\n    enum Type { BIG_DECIMAL }\n\n    static class Wrapper {\n\n        @JsonIgnore\n        Type typeEnum;\n\n        @JsonIgnore\n        Object value;\n\n        Wrapper() { }\n\n        @JsonGetter(value = \"type\")\n        String getTypeString() {\n            return typeEnum.name();\n        }\n\n        @JsonSetter(value = \"type\")\n        void setTypeString(String type) {\n            this.typeEnum = Type.valueOf(type);\n        }\n\n        @JsonGetter(value = \"objectValue\") \n        Object getValue() {\n            return value;\n        }\n\n        @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.EXTERNAL_PROPERTY, property = \"type\")\n        @JsonSubTypes({ @JsonSubTypes.Type(name = \"BIG_DECIMAL\", value = BigDecimal.class) })\n        @JsonSetter(value = \"objectValue\") \n        private void setValue(Object value) {\n            this.value = value;\n        }\n    }\n\n    @Test\n    public void test() throws Exception {\n\n        ObjectMapper m = new ObjectMapper();\n        m.configure(DeserializationFeature.USE_BIG_DECIMAL_FOR_FLOATS, true);\n\n        Wrapper w = new Wrapper();\n        w.typeEnum = Type.BIG_DECIMAL;\n        w.value = new BigDecimal(\"-10000000000.0000000001\");\n\n        String json = m.writeValueAsString(w);\n        Wrapper w2 = m.readValue(json, Wrapper.class);\n\n        Assert.assertEquals(w.typeEnum, w2.typeEnum);\n        Assert.assertTrue(String.format(\"Expected %s = %s; got back %s = %s\",\n            w.value.getClass().getSimpleName(), w.value.toString(), w2.value.getClass().getSimpleName(), w2.value.toString()),\n            w.value.equals(w2.value));\n    }\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_31": {
    "description": "JsonStreamContexts are not build the same way for write.. and convert methods\nHI\nI got an issue reported in my jackson-antpathfilter project that the filtering is not working correctly when it is used together with Jackson's convert feature: https://github.com/Antibrumm/jackson-antpathfilter/issues/2\n\nDuring the investigation i found out that the cause is that the writeContext is created differently and I am wondering if this is the desired behavior or if that's a bug for you.\n\nIn this comment (https://github.com/Antibrumm/jackson-antpathfilter/issues/2#issuecomment-145211847) I print out what is found in the writeContext and I have created a TestCase to reproduce the error. \n\nPlease let me know what you think.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_32": {
    "description": "Deserialization from \"{}\" to java.lang.Object causes \"out of END_OBJECT token\" error\nHi, I've faced with a problem that is too similar this one #941. I expect that \"{}\" will be parsed correctly to empty Map when I'm using `@JsonCreator`\n\nI've found that this case is invalid https://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.6.3/src/main/java/com/fasterxml/jackson/databind/deser/std/UntypedObjectDeserializer.java#L272, but why?\n\nHere is the minimum code to reproduce:\n\n```\nimport java.io.IOException;\nimport com.fasterxml.jackson.annotation.JsonCreator;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class Main {\n    public static void main(String[] args) throws IOException {\n        ObjectMapper mapper = new ObjectMapper();\n        mapper.readValue(\"[]\", SomeObjectThatCanBeAggregated.class);\n        mapper.readValue(\"[{}]\", SomeObjectThatCanBeAggregated.class);\n        mapper.readValue(\"{\\\"key\\\":null}\", SomeObjectThatCanBeAggregated.class);\n        mapper.readValue(\"{}\", SomeObjectThatCanBeAggregated.class);\n    }\n}\nclass SomeObjectThatCanBeAggregated {\n\n    @JsonCreator\n    public SomeObjectThatCanBeAggregated(Object obj) {\n        System.out.println(obj + \" //\" + obj.getClass());\n    }\n}\n```\n\nOutput: \n\n```\n[] //class java.util.ArrayList\n[{}] //class java.util.ArrayList\n{key=null} //class java.util.LinkedHashMap\nException in thread \"main\" com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.lang.Object out of END_OBJECT token\n at [Source: {}; line: 1, column: 2]\n...\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_33": {
    "description": "@JsonUnwrapped is not treated as assuming @JsonProperty(\"\")\nSee discussion [here](https://groups.google.com/forum/#!topic/jackson-user/QLpWb8YzIoE) but basically `@JsonUnwrapped` on a private field by itself does not cause that field to be serialized, currently,  You need to add an explicit `@JsonProperty`.  You shouldn't have to do that.  (Following test fails currently, should pass, though you can make it pass by commenting out the line with `@JsonProperty`.  Uses TestNG and AssertJ.)\n\n``` java\npackage com.bakins_bits;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\nimport org.testng.annotations.Test;\n\nimport com.fasterxml.jackson.annotation.JsonUnwrapped;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class TestJsonUnwrappedShouldMakePrivateFieldsSerializable\n{\n    public static class Inner\n    {\n        public String animal;\n    }\n\n    public static class Outer\n    {\n        // @JsonProperty\n        @JsonUnwrapped\n        private Inner inner;\n    }\n\n    @Test\n    public void jsonUnwrapped_should_make_private_fields_serializable() throws JsonProcessingException {\n        // ARRANGE\n        Inner inner = new Inner();\n        inner.animal = \"Zebra\";\n\n        Outer outer = new Outer();\n        outer.inner = inner;\n\n        ObjectMapper sut = new ObjectMapper();\n\n        // ACT\n        String actual = sut.writeValueAsString(outer);\n\n        // ASSERT\n        assertThat(actual).contains(\"animal\");\n        assertThat(actual).contains(\"Zebra\");\n        assertThat(actual).doesNotContain(\"inner\");\n    }\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_34": {
    "description": "Regression in 2.7.0-rc2, for schema/introspection for `BigDecimal`\n(found via Avro module, but surprisingly json schema module has not test to catch it)\n\nLooks like schema type for `BigDecimal` is not correctly produced, due to an error in refactoring (made to simplify introspection for simple serializers): it is seen as `BigInteger` (and for Avro, for example, results in `long` getting written).\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_35": {
    "description": "Problem with Object Id and Type Id as Wrapper Object (regression in 2.5.1)\n(note: originally from https://github.com/FasterXML/jackson-module-jaxb-annotations/issues/51)\n\nLooks like fix for #669 caused a regression for the special use case of combining type and object ids, with wrapper-object type id inclusion. The problem started with 2.5.1.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_36": {
    "description": "Allow use\tof `StdDateFormat.setLenient()`\nObjectMapper uses the StdDateFormat for date serialization. Jackson date parsing is lenient by default, so 2015-01-32 gets parsed as 2015-02-01.  Jackson\u2019s StdDateParser is matching default behavior of DateParser.  \n\nStdDateParser wasn\u2019t really designed for extension to just enable strict date parsing.  If it were, we could just call objectMapper.setDateFormat(new StdDateFormat().setLenient(false)). But StdDateFomrat doesn't support setting lenient to false. And i.e. the reason date like 2015-01-32 gets parsed as 2015-02-01 ad Jackson date parsing is lenient by defualt.\n\nCan StdDateFormat can be enhanced to support to non lenient date parsing?\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_37": {
    "description": "Field in base class is not recognized, when using `@JsonType.defaultImpl`\nWhen deserializing JSON to Java POJOS, a field inherited from a base class is not recognized. Here is the stack:\n\n```\ncom.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field \"name\" (class org.apache.calcite.model.JsonMapSchema), not marked as ignorable (2 known properties: \"functions\", \"tables\"])\n at [Source: {\n  version: '1.0',\n   schemas: [\n     {\n       name: 'FoodMart',\n       tables: [\n         {\n           name: 'time_by_day',\n           columns: [\n             {\n               name: 'time_id'\n             }\n           ]\n         },\n         {\n           name: 'sales_fact_1997',\n           columns: [\n             {\n               name: 'time_id'\n             }\n           ]\n         }\n       ]\n     }\n   ]\n}; line: 24, column: 7] (through reference chain: org.apache.calcite.model.JsonRoot[\"schemas\"]->java.util.ArrayList[0]->org.apache.calcite.model.JsonMapSchema[\"name\"])\n\n    at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:62)\n    at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:855)\n    at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:1083)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1389)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1367)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:266)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:163)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:135)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedUsingDefaultImpl(AsPropertyTypeDeserializer.java:136)\n    at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:99)\n    at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:142)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:279)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:249)\n    at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:26)\n    at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:490)\n    at com.fasterxml.jackson.databind.deser.impl.FieldProperty.deserializeAndSet(FieldProperty.java:101)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:260)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:125)\n    at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:3788)\n    at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2779)\n    at org.apache.calcite.test.ModelTest.testRead(ModelTest.java:58)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n    at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)\n    at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234)\n    at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\n```\n\nMy `JsonMapSchema` class has a base class `JsonSchema` and it has a public field `name`. See https://github.com/apache/calcite/blob/master/core/src/test/java/org/apache/calcite/test/ModelTest.java.\n\nI have an application that worked in 2.6.3, fails in 2.7.0, so I suspect this is a regression. \n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_38": {
    "description": "(2.7-regress) Handling of deprecated `SimpleType.construct()` too minimalistic\n(note: spun from https://github.com/FasterXML/jackson/issues/48)\n\nDue to changes in type resolution, most direct construction methods in `JavaType` sub-classes can not be fully supported. Failure modes are typically with complex cases (and expected to be rare), with one exception: use of `SimpleType.construct(Class)`, because:\n1. This is mostly used for complex types, and not just \"well-known\" interfaces like `List`, `Map`; so actual access to at least immediate fields is necessary (and similarly lack of super-type info is problematic), and\n2. Its usage is likely to be wide-spread, despite existence of preferable methods (`TypeFactory`)\n3. Since refactoring of type resolution was not anticipated early enough in advance, deprecation of methods we want to move users away from could not be done in 2.6, as it should have been (in perfect case)\n\nExact reasoning behind problems is quite complicated: but the fundamental reason is that `TypeFactory` has all the logic to do the generic resolution; `JavaType` has (and should have) very little if any. Since no reference to the factory is passed via constructors/factory methods, they can not properly delegate resolution tasks. This is why direct calls should only be made with all necessary, pre-resolved information; passing `JavaType`s for elements, not `Class`.\nInability to resolve things means that super-types can not be properly resolved, for example. Handling of fields, methods will also be inexact wrt generic types.\n\nThe first immediate problem is something that should be addressable: introspection by POJO deserializer builder does not find any fields or methods. It should be possible to at least find them, even if type resolution for generic types will not work well. This should be acceptable for the common (and reported) case of constructing element types for `Collection`s and `Map`s: generic parameterization will not be accessible anyway.\n\nThere are other potential issues to address as best we can, but first things first.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_39": {
    "description": "Jackson not continue to parse after DeserializationFeature.FAIL_ON_INVALID_SUBTYPE error\nAfter FAIL_ON_INVALID_SUBTYPE error, jackson should continue to parse, but seems jackson doesn't.\n\nThe output:\n\n```\nCallRecord [version=0.0, application=123, ] // doesn't read item2 which is valid\nCallRecord [version=0.0, application=123, ]\nCallRecord [version=0.0, ] // doesn't read application after invalid item.\n```\n\n``` jaca\n@JsonInclude(Include.NON_NULL)\npublic class CallRecord {\n    public float version;\n    public String application;\n    public Item item;\n    public Item item2;\n    public CallRecord() {}\n\n    public static void main(final String[] args) throws IOException {\n        final ObjectMapper objectMapper = new ObjectMapper().disable(DeserializationFeature.FAIL_ON_INVALID_SUBTYPE,\n                DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, DeserializationFeature.FAIL_ON_IGNORED_PROPERTIES);\n        final CallRecord call = new CallRecord();\n\n        final Event event = new Event();\n        event.location = \"location1\";\n        call.item = event;\n        call.item2 = event;\n        call.application = \"123\";\n        // System.out.println(objectMapper.writeValueAsString(call));\n        String json =\n                \"{\\\"version\\\":0.0,\\\"application\\\":\\\"123\\\",\\\"item\\\":{\\\"type\\\":\\\"xevent\\\",\\\"location\\\":\\\"location1\\\"},\\\"item2\\\":{\\\"type\\\":\\\"event\\\",\\\"location\\\":\\\"location1\\\"}}\";\n        // can't read item2 - which is valid\n        System.out.println(objectMapper.readValue(json, CallRecord.class));\n\n        json = \"{\\\"version\\\":0.0,\\\"application\\\":\\\"123\\\"},{\\\"item\\\":{\\\"type\\\":\\\"xevent\\\",\\\"location\\\":\\\"location1\\\"}\";\n        System.out.println(objectMapper.readValue(json, CallRecord.class));\n\n        json = \"{\\\"item\\\":{\\\"type\\\":\\\"xevent\\\",\\\"location\\\":\\\"location1\\\"}, \\\"version\\\":0.0,\\\"application\\\":\\\"123\\\"}\";\n        // order matters: move item to the fornt, now it can't read application property\n        System.out.println(objectMapper.readValue(json, CallRecord.class));\n    }\n    @Override\n    public String toString() {\n        final StringBuilder builder = new StringBuilder();\n        builder.append(\"CallRecord [version=\").append(version).append(\", \");\n        if (application != null) {\n            builder.append(\"application=\").append(application).append(\", \");\n        }\n        if (item != null) {\n            builder.append(\"item=\").append(item);\n        }\n        builder.append(\"]\");\n        return builder.toString();\n    }\n}\n\n@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = \"type\", visible = true)\n@JsonSubTypes({@Type(value = Event.class, name = Event.TYPE)})\npublic interface Item {\n}\n\npublic final class Event implements Item {\n    public String location;\n    public static final String TYPE = \"event\";\n    public Event() {}\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_40": {
    "description": "Prevent coercion of `int` from empty String to `null` if `DeserializationFeature .FAIL_ON_NULL_FOR_PRIMITIVES` is `true`\nI got 0 from the code below.\n\n``` java\nint i = mapper.readValue(\"\\\"\\\"\", int.class);\nSystem.out.println(i);\n```\n\nIt seems that Json Number type cannot start with \".\nCould I make the code throw some Exceptions?\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_41": {
    "description": "Problems with deprecated `TypeFactory.constructType(type, ctxt)` methods if `ctxt` is `null`\n(note: continuation of #1079)\n\nLooks like earlier fix was incomplete, and there is one more edge case to handle: if passed-in context is `null`, attempt to resolve that will fail. This should not occur since previously passing of `null` would simply have used \"empty\" bindings. Code needs to take care to handle this as version 2.6 did.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_42": {
    "description": "Serializing and Deserializing Locale.ROOT\nSerializing and Deserializing Locale objects seems to work just fine, until you try on the Root Locale.\nIt writes it out as an empty string and when it reads it in, the value is null\n\n```\n@Test\n    public void testLocaleDeserialization() throws IOException {\n        ObjectMapper objectMapper = new ObjectMapper();\n        Locale root = Locale.ROOT;\n        String json = objectMapper.writeValueAsString(root);\n        System.out.printf(\"Root Locale: '%s'\", json);\n        Locale actual = objectMapper.readValue(json, Locale.class);\n        Assert.assertEquals(root, actual);\n    }\n```\n\nHere is the output:\nRoot Locale: '\"\"'\njava.lang.AssertionError: \nExpected :\nActual   :null\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_43": {
    "description": "Problem with Object id handling, explicit `null` token\nAccording to #742, it shouldn't throw an exception if the value of the property is null\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_44": {
    "description": "Problem with polymorphic types, losing properties from base type(s)\n(background, see: https://github.com/dropwizard/dropwizard/pull/1449)\n\nLooks like sub-type resolution may be broken for one particular case: that of using `defaultImpl`. If so, appears like properties from super-types are not properly resolved; guessing this could be follow-up item for #1083 (even sooner than I thought...).\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_45": {
    "description": "Fix for #1154\nFix for #1154. Partially rolls back to pre-#1111 behavior.\nWe just make sure that the STRING shape is chosen when Shape.ANY (the default) is set on the annotation, but some other annotation attribute was also set (pattern, locale or timezone).\nThis way of fixing the issue has the added benefit of respecting the user config regarding the default serialization of ~~strings~~ dates when @JsonFormat(shape = Shape.ANY) is set on a property.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_46": {
    "description": "Incorrect signature for generic type via `JavaType.getGenericSignature\n(see https://github.com/FasterXML/jackson-modules-base/issues/8 for background)\n\nIt looks like generic signature generation is missing one closing `>` character to produce:\n\n```\n()Ljava/util/concurrent/atomic/AtomicReference<Ljava/lang/String;;\n```\n\ninstead of expected\n\n```\n()Ljava/util/concurrent/atomic/AtomicReference<Ljava/lang/String;>;\n```\n\nthat is, closing '>' is missing.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_47": {
    "description": "`@JsonSerialize(as=superType)` behavior disallowed in 2.7.4\n#1178 fixed the problem with collections, but I'm seeing a problem with individual objects.\n\nI'm getting:\n\n```\ncom.fasterxml.jackson.databind.JsonMappingException: Failed to widen type [simple type, class org.pharmgkb.model.AccessionIdentifier] with annotation (value org.pharmgkb.model.BaseAccessionIdentifier), from 'getReference': Class org.pharmgkb.model.BaseAccessionIdentifier not a super-type of [simple type, class org.pharmgkb.model.AccessionIdentifier]\n\n    at com.fasterxml.jackson.databind.AnnotationIntrospector.refineSerializationType(AnnotationIntrospector.java:821)\n    at com.fasterxml.jackson.databind.introspect.AnnotationIntrospectorPair.refineSerializationType(AnnotationIntrospectorPair.java:488)\n    at com.fasterxml.jackson.databind.ser.PropertyBuilder.findSerializationType(PropertyBuilder.java:194)\n    at com.fasterxml.jackson.databind.ser.PropertyBuilder.buildWriter(PropertyBuilder.java:73)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory._constructWriter(BeanSerializerFactory.java:805)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.findBeanProperties(BeanSerializerFactory.java:608)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.constructBeanSerializer(BeanSerializerFactory.java:388)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.findBeanSerializer(BeanSerializerFactory.java:271)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory._createSerializer2(BeanSerializerFactory.java:223)\n    at com.fasterxml.jackson.databind.ser.BeanSerializerFactory.createSerializer(BeanSerializerFactory.java:157)\n    at com.fasterxml.jackson.databind.SerializerProvider._createUntypedSerializer(SerializerProvider.java:1215)\n    at com.fasterxml.jackson.databind.SerializerProvider._createAndCacheUntypedSerializer(SerializerProvider.java:1167)\n    at com.fasterxml.jackson.databind.SerializerProvider.findValueSerializer(SerializerProvider.java:490)\n    at com.fasterxml.jackson.databind.SerializerProvider.findTypedValueSerializer(SerializerProvider.java:688)\n    at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:107)\n    at com.fasterxml.jackson.databind.ObjectWriter$Prefetch.serialize(ObjectWriter.java:1428)\n    at com.fasterxml.jackson.databind.ObjectWriter._configAndWriteValue(ObjectWriter.java:1129)\n    at com.fasterxml.jackson.databind.ObjectWriter.writeValueAsString(ObjectWriter.java:1001)\n    at org.pharmgkb.jackson.JacksonTest.testModelObjects(JacksonTest.java:48)\n```\n\nOn something like:\n\n```\npublic class Foo {\n  @JsonSerialize(as = BaseAccessionIdentifier.class)\n  @JsonDeserialize(as = BaseAccessionIdentifier.class)\n  public AccessionIdentifier getReference() {\n  }\n}\n```\n\n```\npublic interface AccessionIdentifier {\n}\n```\n\n```\npublic class BaseAccessionIdentifier implements AccessionIdentifier {\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_48": {
    "description": "`BasicClassIntrospector.forSerialization(...).findProperties` should respect MapperFeature.AUTO_DETECT_GETTERS/SETTERS\nWhen I set the ObjectMapper MapperConfig to not AutoDetect and use the BasicClassIntrospector to get the properties, I seem to still be getting the Methods.  I am currently using version 2.7.3.\n\nThe following code produces this output:\n        Found property count 2, there should only be one??\n        Found property: name=name, internalName=name\n        Found property: name=groupname, internalName=groupname\n\nI think it should produce only this output:\n        Found property: name=groupname, internalName=groupname\n\n```\npublic static void main(String [] args) {\n    class TCls {\n        @JsonProperty(\"groupname\")\n        private String groupname;\n\n        public void setName(String str) {\n            this.groupname = str;\n        }\n        public String getName() {\n            return groupname;\n        }\n    }\n\n    ObjectMapper om = new ObjectMapper();\n    // Only use explicitly specified values to be serialized/deserialized (i.e., JSONProperty).\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_FIELDS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_GETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_SETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.AUTO_DETECT_IS_GETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.USE_GETTERS_AS_SETTERS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.CAN_OVERRIDE_ACCESS_MODIFIERS, true);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.INFER_PROPERTY_MUTATORS, false);\n    om.configure(com.fasterxml.jackson.databind.MapperFeature.USE_ANNOTATIONS, true);\n\n    JavaType javaType = om.getTypeFactory().constructType(TCls.class);\n\n    BasicClassIntrospector introspector = new BasicClassIntrospector();\n    BasicBeanDescription bdesc = introspector.forSerialization(om.getSerializationConfig(), javaType, null);\n    List<BeanPropertyDefinition> bprops = bdesc.findProperties();\n\n    if (1 != bprops.size()) {\n        System.out.println(\"Found property count \" + bprops.size() + \", there should only be one??\");\n    }\n    bprops.forEach(prop -> {\n        System.out.println(\"Found property: name=\" + prop.getName() + \", internalName=\" + prop.getInternalName());\n    });\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_49": {
    "description": "JsonIdentityInfo incorrectly serializing forward references\nI wrote this small test program to demonstrate the issue:\n\n``` java\nimport com.fasterxml.jackson.annotation.JsonIdentityInfo;\nimport com.fasterxml.jackson.annotation.JsonIdentityReference;\nimport com.fasterxml.jackson.annotation.ObjectIdGenerators;\nimport com.fasterxml.jackson.databind.ObjectMapper;\n\npublic class ObjectIdTest {\n\n    public static class Foo {\n\n        @JsonIdentityReference(alwaysAsId = true)\n        public Bar bar1;\n\n        @JsonIdentityReference()\n        public Bar bar2;\n    }\n\n    @JsonIdentityInfo(generator = ObjectIdGenerators.IntSequenceGenerator.class)\n    public static class Bar {\n\n    }\n\n    public static void main(String[] args) throws Exception {\n        ObjectMapper mapper = new ObjectMapper();\n\n        // create structure to serialize\n        Foo mo = new Foo();\n        mo.bar1 = new Bar();\n        mo.bar2 = mo.bar1;\n\n        // serialize it\n        System.out.println(mapper.writeValueAsString(mo));\n    }\n\n}\n```\n\nWhen executing this test program in the latest version (2.7.4), the output will be `{\"bar1\":1,\"bar2\":{\"@id\":2}}` - the second field will be written with a new id even though both fields reference the same object. Because of this, writing forward references is essentially impossible.\n\nThe issue seems to be the fact that BeanSerializerBase will always call WritableObjectId.generateId if the referenced object has not been written in plain format yet (https://github.com/FasterXML/jackson-databind/blob/master/src/main/java/com/fasterxml/jackson/databind/ser/std/BeanSerializerBase.java#L600). This will also happen if an id has been generated before.\nIt might also be smarter to only generate a new id in WritableObjectId.generateId if that hasn't happened before; as that method doesn't have a javadoc I can't tell how it is supposed to work.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_50": {
    "description": "`@JsonIdentityInfo` deserialization fails with combination of forward references, `@JsonCreator`\nAs a follow-up to bug #1255, the patch I provided exposes related deserialization problems.\nI have attached a small project ('jackson-test.zip') to demonstrate these issues. When run with both patches from #1255, the output is provided in the attached 'both.txt'. When run with just the first patch from #1255, the output is provided in the attached 'first.txt'.\nImportant points:\n1. When the object expressed as an id is contained within a collection or map (List in this example), deserialization works correctly. When it is a field of an object, deserialization is broken.\n2. This particular example doesn't have forward references, but it does have cycles. Nevertheless, I have seen situations where non-cyclical forward-references also do not deserialize properly, with the same caveat as in 1.\n[jackson-test.zip](https://github.com/FasterXML/jackson-databind/files/301884/jackson-test.zip)\n[both.txt](https://github.com/FasterXML/jackson-databind/files/301885/both.txt)\n[first.txt](https://github.com/FasterXML/jackson-databind/files/301886/first.txt)\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_51": {
    "description": "Generic type returned from type id resolver seems to be ignored\nhttps://github.com/benson-basis/jackson-custom-mess-tc\n\nHere's the situation, with Jackson 2.7.4.\n\nI have a TypeIdResolver that returns a JavaType for a generic type. However, something seems to be forgetting/erasing the generic, as it is failing to use the generic type param to understand the type of a field in the class.\n\nAll the information is in the test case, so I'm not putting any code to read here in the issue.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_52": {
    "description": "External property is not deserialized\nI think it's easier to show the code than explain the issue, so i prepared a test project:\nhttps://github.com/crew4ok/jackson-databind-test\n\nSo basically the issue is that the external property, by which another's property type is deduced, after deserialization is null.\nSee the failing test:\nhttps://github.com/crew4ok/jackson-databind-test/blob/master/src/test/java/jackson/ExternalIdDeserTest.java\n\nAm i missing something?\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_53": {
    "description": "Problem with type specialization for Maps with `@JsonDeserialize(as=subtype)`\nIf I have json that looks like\n\n```\n{\n  \"something\": [\n        {\n           \"id\": \"a uuid\",\n           \"property\": \"value\"\n         }\n  ]\n}\n```\n\nAnd I have a java pojo with an annotation like this:\n\n```\n    @JsonDeserialize(as = MyHashMap.class)\n    private void setSomething(Map<UUID, Foo> incomingValue) {\n```\n\nWhere MyHashMap.java has some custom logic using generics that allow us to map the array json above into a Map where \"id\" is the key and everything else serializes into the value.  We use generics on MyHashMap to enforce that every value implements a certain interface that respects the contract of returning an \"id\" property.  In this example Foo.java implements this interface MyCustomIdInterface.java.\n\nWhen using 2.6.6 this worked fine, but if I switch to 2.7.x then it breaks with the error:\n\n`Can not construct instance of MyCustomIdInterface, problem: abstract types either need to be mapped to concrete types, have custom deserializer, or be instantiated with additional type information`\n\nin 2.7.x, it looks like jackson resolves to using AbstractDeserializer based on MyCustomIdInterface but in 2.6.6 it resolves to using BeanDeserializer based on Foo.java.\n\nIs this a bug or is there some default/feature flag that changed here?\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_54": {
    "description": "`Optional.empty()` not excluded if property declared with type `Object`\nJackson version is 2.6.6\n**Here is the code:**\n\n```\n        ObjectMapper mapper = new ObjectMapper();\n        mapper.setSerializationInclusion(JsonInclude.Include.NON_ABSENT);\n        mapper.registerModule(new Jdk8Module());\n\n        JsonResult result = new JsonResult();\n        result.setA(Optional.empty());\n        result.setB(Optional.empty());\n        System.out.println(mapper.writeValueAsString(result));\n```\n\n```\n@Data\npublic class JsonResult {\n    private Object a;\n    private Optional<Object> b;\n}\n```\n\n**Then I got the output: {\"a\":null}**\n\n**The real value of both is the same, why the results are different?**\n\n**How can I avoid null in such case?**\n\nBy the way, I tried 'NON_EMPTY'. It can work, but it also ignores zero and empty array. I want to keep them.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_55": {
    "description": "EnumMap keys not using enum's `@JsonProperty` values unlike Enum values\nBased on these issues:\nhttps://github.com/FasterXML/jackson-databind/issues/677\nhttps://github.com/FasterXML/jackson-databind/issues/1148\nhttps://github.com/FasterXML/jackson-annotations/issues/96\n\nI implemented @JsonProperty for my enum constants and they show up nicely when they are property values. But I also have an EnumMap which uses the enum, and it's generated JSON uses the original enum names for the keys and not the JsonProperty values.\n\nUsing 2.8.1 (in spring boot 4.3.2)\n\nThanks!\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_56": {
    "description": "Deserializing locale assumes JDK separator (underscore), does not accept RFC specified (hyphen)\nWhen deserializing a locale Jackson currently uses the underscore character as the separator rather than the dash.  Specifically, in FromStringDeserializer.java line 234:\n\n```\nint ix = value.indexOf('_');\n```\n\nMany locale implementations use dash as the separator as per https://tools.ietf.org/html/rfc5646\n\nGiven the RFC states that only the characters a-z A-Z and - are valid it should be possible to leave the current code in for backward-compatibility but it should also check for  '-' as a separator.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_57": {
    "description": "`ObjectReader.readValues()` ignores offset and length when reading an array\nObjectReader.readValues ignores offset and length when reading an array. If _dataFormatReaders it will always use the full array:\n\nhttps://github.com/FasterXML/jackson-databind/blob/2.7/src/main/java/com/fasterxml/jackson/databind/ObjectReader.java#L1435\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_58": {
    "description": "`@JsonIgnoreProperties`: ignoring the \"cause\" property of `Throwable` on GAE\nDeserializing an exception class from json on Google App Engine causes this error:\n\n```\nCaused by: java.lang.IllegalArgumentException: Can not access private java.lang.Throwable java.lang.Throwable.cause (from class java.lang.Throwable; failed to set access: java.lang.IllegalAccessException: Reflection is not allowed on private java.lang.Throwable java.lang.Throwable.cause\n    at com.fasterxml.jackson.databind.util.ClassUtil.checkAndFixAccess(ClassUtil.java:505)\n    at com.fasterxml.jackson.databind.introspect.AnnotatedMember.fixAccess(AnnotatedMember.java:123)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.constructSettableProperty(BeanDeserializerFactory.java:704)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.addBeanProps(BeanDeserializerFactory.java:501)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.buildThrowableDeserializer(BeanDeserializerFactory.java:356)\n    at com.fasterxml.jackson.databind.deser.BeanDeserializerFactory.createBeanDeserializer(BeanDeserializerFactory.java:114)\n```\n\nI tried preventing this by using `@JsonIgnoreProperties`:\n\n``` java\n@JsonIgnoreProperties(\"cause\")\npublic class MyException extends RuntimeException { ... }\n```\n\n... but the same error still occurs. What am I doing wrong? What else could I do?\n\nI've also considered setting `MapperFeature.CAN_OVERRIDE_ACCESS_MODIFIERS` to false, but I don't like this solution because I need this setting to be `true` in some other cases (in particular, I provide no-arg constructors for Jackson, but they should't be public in my API).\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_59": {
    "description": "@JsonDeserialize(keyUsing = ...) does not work correctly together with DefaultTyping.NON_FINAL\nVersion 2.8.3 seems to ignore @JsonDeserialize(keyUsing = ...) when used together with DefaultTyping.NON_FINAL setting and Map<,> argument type in constructor with concrete type (e.g. HashMap<,>) specified in JSON.\n\nIn the code below testFails() fails and testSucceeds() passes fine. The only difference is testSucceeds() has a module with deserializer registered explicitly. Both tests pass on version 2.6.\n\n``` java\npackage com.test.testjackson.testjackson;\n\nimport com.fasterxml.jackson.annotation.JsonAutoDetect;\nimport com.fasterxml.jackson.annotation.JsonCreator;\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonGenerator;\nimport com.fasterxml.jackson.core.JsonParseException;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.JsonMappingException;\nimport com.fasterxml.jackson.databind.JsonSerializer;\nimport com.fasterxml.jackson.databind.KeyDeserializer;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.ObjectMapper.DefaultTyping;\nimport com.fasterxml.jackson.databind.SerializerProvider;\nimport com.fasterxml.jackson.databind.annotation.JsonDeserialize;\nimport com.fasterxml.jackson.databind.annotation.JsonSerialize;\nimport com.fasterxml.jackson.databind.module.SimpleKeyDeserializers;\nimport com.fasterxml.jackson.databind.module.SimpleModule;\nimport java.io.IOException;\nimport java.util.Map;\nimport org.junit.Test;\n\nimport static com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility.ANY;\nimport static junit.framework.Assert.assertEquals;\n\npublic class TestJackson \n{\n    private static String TEST_INSTANCE_SERIALIZED = \"{\\\"mapProperty\\\":[\\\"java.util.HashMap\\\",{\\\"Compound|Key\\\":\\\"Value\\\"}]}\";\n\n    @Test\n    public void testFails() throws JsonParseException, JsonMappingException, IOException\n    {\n        ObjectMapper mapper = new ObjectMapper().enableDefaultTyping(DefaultTyping.NON_FINAL);\n        TestClass testInstance = mapper.readValue(TEST_INSTANCE_SERIALIZED, TestClass.class);\n        String testInstanceSerialized = mapper.writeValueAsString(testInstance);\n        assertEquals(TEST_INSTANCE_SERIALIZED, testInstanceSerialized);\n    }\n\n    @Test\n    public void testSucceeds() throws JsonParseException, JsonMappingException, IOException\n    {\n        ObjectMapper mapper = new ObjectMapper().enableDefaultTyping(DefaultTyping.NON_FINAL).registerModule(new SimpleModule() {\n            private static final long serialVersionUID = 1L;\n            @Override\n            public void setupModule(SetupContext context) {\n                context.addKeyDeserializers(new SimpleKeyDeserializers().addDeserializer(CompoundKey.class, new CompoundKeyDeserializer()));\n            }\n        });\n        TestClass testInstance = mapper.readValue(TEST_INSTANCE_SERIALIZED, TestClass.class);\n        String testInstanceSerialized = mapper.writeValueAsString(testInstance);\n        assertEquals(TEST_INSTANCE_SERIALIZED, testInstanceSerialized);\n    }\n\n    @JsonAutoDetect(fieldVisibility = ANY)\n    public static final class TestClass {\n        @JsonProperty(\"mapProperty\")\n        @JsonSerialize(keyUsing = CompoundKeySerializer.class)\n        private final Map<CompoundKey, String> mapProperty;\n\n        @JsonCreator\n        private TestClass(@JsonDeserialize(keyUsing = CompoundKeyDeserializer.class) @JsonProperty(\"mapProperty\") Map<CompoundKey, String> mapProperty) {\n            this.mapProperty = mapProperty;\n        }\n    }\n\n    public static final class CompoundKey {\n        private String part0;\n        private String part1;\n\n        public CompoundKey(String part0, String part1) {\n            this.part0 = part0;\n            this.part1 = part1;\n        }\n\n        public String getPart0() { return part0; }\n        public String getPart1() { return part1; }\n    }\n\n    public static class CompoundKeyDeserializer extends KeyDeserializer {\n        @Override\n        public Object deserializeKey(String s, DeserializationContext deserializationContext) {\n            String[] parts = s.split(\"\\\\|\");\n            return new CompoundKey(parts[0], parts[1]);\n        }\n    }\n\n    public static class CompoundKeySerializer extends JsonSerializer<CompoundKey> {\n        @Override\n        public void serialize(CompoundKey compoundKey, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {\n            jsonGenerator.writeFieldName(compoundKey.getPart0() + '|' + compoundKey.getPart1());\n        }\n    }\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_60": {
    "description": "Polymorphic type lost when using `@JsonValue`\nWhen suppressing all getters but one with @JsonIgnore and choosing to use a byte array for serialization (marking its getter with @JsonValue), the typing of the object is changed to \"[B\", which is deserialized to a byte array. I would have expected verbose typing and usage of the constructor  marked with @JsonCreator that accepts the byte array to construct the object on deserialization. The behavior is as expected when choosing more fields for serialization, which is redundant data in this case.\n\nRunning  jackson-databind 2.7.4 on Java 1.8.0_91.\n\nConfiguration of the ObjectMapper:\n\n```\nprivate final ObjectMapper mapper;\npublic JsonFilter() {\n    this.mapper = new ObjectMapper();\n    mapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);\n    mapper.enableDefaultTyping();\n}\n```\n\nSerialization: `mapper.writeValueAsString(message)`\nDeserialization: `mapper.readValue(json, RemoteCall.class)`\n\nGetter and field:\n\n```\n/** @serial */\nprivate byte[] apdu;\n\n@JsonValue\npublic byte[] getBytes() {\n    return apdu.clone();\n}\n```\n\nConstructor:\n\n```\n@JsonCreator\npublic CommandAPDU(@JsonProperty(value = \"bytes\") byte[] apdu) {\n    this.apdu = apdu.clone();\n    parse();\n    LOG.v(\"com.ubitricity.devices.common.pal.CommandAPDU creator (1)\");\n}\n```\n\nSerializes to `\"args\":[[\"[B\",\"AKQEAAnw8fLz9AAAAgA=\"],[\"net.sf.lipermi.call.RemoteInstance\",{\"instanceId\":\"b0e15098-f49e-4328-b072-fc5df42799bd\",\"className\":\"com.ubitricity.devices.common.tasks.ResponseReceiver\"}]]` where \"args\" is an Object array field of the enclosing object.\n\n",
    "desc_source": "github_issue"
  },
  "JacksonDatabind_61": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_62": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_63": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_64": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_66": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_67": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_68": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_69": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_70": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_71": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_72": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_73": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_74": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_75": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_76": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_77": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_78": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_79": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_80": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_81": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_82": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_83": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_84": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_85": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_86": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_87": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_88": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_90": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_91": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_92": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_93": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_94": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_95": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_96": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_97": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_98": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_99": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_100": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_101": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_102": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_103": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_104": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_105": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_106": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_107": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_108": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_109": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_110": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_111": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonDatabind_112": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JxPath_1": {
    "description": "Descendant or self axis does not work correctly at root node\nGiven the following XML document: <root id=\"1234\"/>\nand the XPath: //root/@id/text().\n\nJXPath returns null instead of \"1234\".\n\nJXPathContext context = JXPathContext.newContext(doc);\nassertEquals(value, context.selectSingleNode(\"//root/@id/text()\"));\n\nThe attached JUnit test highlights the problem. It seems that JXPath does not\nfind the root node if it is accessed with the axis descendant-or-self.",
    "desc_source": "jira"
  },
  "JxPath_2": {
    "description": "does not properly handle NodeSet returned by extension function\nPer the documentation, my function is returning a BasicNodeSet containing zero\nor more pointers:\n\n  public static NodeSet observations(ExpressionContext context) {\n    // the cast below shouldn't break, as this is the only pointer type that\n    // makes sense in this context\n    List<NodePointer> ptrs = extractObservations(\n                                  (NodePointer)context.getContextNodePointer(), \n                                  new ArrayList<NodePointer>());\n    BasicNodeSet result = new BasicNodeSet();\n    for (NodePointer ptr : ptrs) {\n      result.add(ptr);\n    }\n    return result;\n  }\n\nHowever, if I call JXPathContext.selectNodes(\"ems:observations()\"), I'm getting\na single node containing the BasicNodeSet. I notice that there is a testcase for\nfunctions that return NodeSets, but that it uses expressions that actually\nreturn the children of the NodeSet (\"test:nodeSet()/name\").\n\nThere appear to be two problems. First, Expression.iterate() and\nExpression.iteratePointers() do not correctly recognize a NodeSet as something\niterable. I've resolved this by reaching into the NodeSet and getting an\niterator over its pointers.\n\nSecond, Expression.PointerIterator doesn't recognize when it already has a\npointer, and instead tries to wrap it in a new pointer. This ends up treating\nthe pointer as a bean.\n\nI've made these changes, and written a testcase that uses an unadorned NodeSet\nfunction. I also found a class that used a variable named \"enum\", and changed\nthis so that it would compile under 1.5.\n\nThe patch is attached. It's relative to \"commons-jxpath-1.2\" (root of extract\ndirectory).",
    "desc_source": "jira"
  },
  "JxPath_3": {
    "description": "StackOverflow error on a call to 'JXPathContext.createPath()'\nI'm running into a StackOverflow error on a call to\n'JXPathContext.createPath()' whenever I have a path that looks like\n'a/b[1]/c'.  I took a quick look at the code and it appears JXPath, when\ntrying to create its parent pointer, simply recreates an equivalent\npointer(???).\n\nHere is code to reproduce the problem.\n\n\n    Map map = new HashMap();\n    map.put(\"a\", null);\n    \n    JXPathContext pathContext = JXPathContext.newContext(map);\n    pathContext.setFactory(new AbstractFactory() {\n      public boolean createObject(\n          JXPathContext context, Pointer pointer, Object parent, String\nname, int index) {\n\n        Map parentMap = (Map)parent;\n        System.out.println(parent + \":\" + name + \":\" + index);\n        if (index > -1) {\n          List list = (List)parentMap.get(name);\n          if (list == null) {\n            list = new ArrayList();\n          }\n          int size = list.size();\n          for (int i = size; i <= index; i++) {\n            list.add(i, null);\n          }\n          parentMap.put(name, list);\n        } else {\n          parentMap.put(name, new HashMap());\n        }\n        return true;\n      }\n      \n    });\n    pathContext.createPath(\"a/b[1]/c\");\n\n***************\n\nI have continued looking into this, and found that the problem is that, if\nthe List is created with a 'null' element, JXPath gets stuck in infinite\nrecursion.\n\nTo discover this, I changed my Factory to implement the following method:\n\n      public boolean createObject(\n          JXPathContext context, Pointer pointer, Object parent, \n          String name, int index) {\n\n        if (pointer instanceof NodePointer) {\n          index = ((NodePointer)pointer).getIndex();\n        }\n        System.out.println(parent + \":\" + name + \":\" + index);\n        Map parentMap = (Map)parent;\n        if (index > -1) {\n          List list = (List)parentMap.get(name);\n          if (list == null) {\n            list = new ArrayList();\n          }\n          int size = list.size();\n          for (int i = size; i <= index; i++) {\n            list.add(i, new HashMap());  // !!!!!!  Don't set to 'null'\n          }\n          parentMap.put(name, list);\n        } else {\n          parentMap.put(name, new HashMap());\n        }\n        return true;\n      }\n\nThen I ran the following code:\n\n    pathContext.createPath(\"a/b[1]/c\");\n    pathContext.createPath(\"a/b[2]/c\");  // STACK OVERFLOW HERE\n\nHere is the stack trace at the beginning, where\n'ValueUtils.expandCollection()' is called.  It puts 'null' into the list,\nthus causing the stack overflow as we cycle between createPath() &\ncreateChild().\n\nThread [main] (Suspended (breakpoint at line 227 in DynamicPropertyPointer))\n\tDynamicPropertyPointer.createPath(JXPathContext) line: 227\n\tDynamicPropertyPointer(PropertyPointer).createChild(JXPathContext,\nQName, int) line: 188\n\tNullElementPointer.createPath(JXPathContext) line: 82\n\tNullPointer.createPath(JXPathContext) line: 86\n\tNullPropertyPointer.createPath(JXPathContext) line: 103\n\tNullPointer.createPath(JXPathContext) line: 86\n\tNullPropertyPointer.createPath(JXPathContext) line: 103\n\tJXPathContextReferenceImpl.createPath(String, Expression) line: 447\n\tJXPathContextReferenceImpl.createPath(String) line: 427\n\tTest.test4() line: 75\n\tTest.main(String[]) line: 38",
    "desc_source": "jira"
  },
  "JxPath_4": {
    "description": "JXpath automatically trims string values\nWhen an xml contains a value with leading or trailing spaces, JXPath trims this value.\nexample: <value>     12324 56</value> is retrieved by JXPath as : '1234 56' while I expect '     1234 56'.\n",
    "desc_source": "jira"
  },
  "JxPath_5": {
    "description": "Cannot compare pointers that do not belong to the same tree\nFor XPath \"$var | /MAIN/A\" exception is thrown:\n\norg.apache.commons.jxpath.JXPathException: Cannot compare pointers that do not belong to the same tree: '$var' and ''\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareNodePointers(NodePointer.java:665)\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareNodePointers(NodePointer.java:649)\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareNodePointers(NodePointer.java:649)\n\tat org.apache.commons.jxpath.ri.model.NodePointer.compareTo(NodePointer.java:639)\n\tat java.util.Arrays.mergeSort(Arrays.java:1152)\n\tat java.util.Arrays.sort(Arrays.java:1079)\n\tat java.util.Collections.sort(Collections.java:113)\n\tat org.apache.commons.jxpath.ri.EvalContext.constructIterator(EvalContext.java:176)\n\tat org.apache.commons.jxpath.ri.EvalContext.hasNext(EvalContext.java:100)\n\tat org.apache.commons.jxpath.JXPathContext.selectNodes(JXPathContext.java:648)\n\tat org.apache.commons.jxpath.ri.model.VariablePointerTestCase.testUnionOfVariableAndNode(VariablePointerTestCase.java:76)",
    "desc_source": "jira"
  },
  "JxPath_6": {
    "description": "equality test for multi-valued variables does not conform to spec\ngiven e.g. variable d={\"a\", \"b\"}, the spec implies that \"$d = 'a'\" and that \"$d = 'b'\".  Instead of iterating the variable's components its immediate content (here, the String[]) is compared, causing the aforementioned assertions to fail.",
    "desc_source": "jira"
  },
  "JxPath_7": {
    "description": "Binary operators behaviour involving node-sets is incorrect\nAccording to XPath specification:\n\"If both objects to be compared are node-sets, then the comparison will be true if and only if there is a node in the first node-set and a node in the second node-set such that the result of performing the comparison on the string-values of the two nodes is true. If one object to be compared is a node-set and the other is a number, then the comparison will be true if and only if there is a node in the node-set such that the result of performing the comparison on the number to be compared and on the result of converting the string-value of that node to a number using the number function is true.\"\n\nBut following example illustrates, that this is not a JXPath behaviour:\n\n\n        JXPathContext pathContext = JXPathContext\n                .newContext(DocumentBuilderFactory.newInstance()\n                        .newDocumentBuilder().parse(\n                                new InputSource(new StringReader(\n                                        \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\r\\n\"\n                                                + \"<doc/>\"))));\n        Boolean result = (Boolean) pathContext.getValue(\"2.0 > child1\",\n                Boolean.class);\n        assertFalse(result.booleanValue());\n\n\"child1\" is not found - right operand node set is empty, but result is TRUE, instead of FALSE.\n\nPlease, check greaterThan(), lesserThan(), etc methods of org.apache.xpath.objects.XObject for possible solution :)",
    "desc_source": "jira"
  },
  "JxPath_8": {
    "description": "Comparing with NaN is incorrect\n'NaN' > 'NaN' is true, but should be FALSE",
    "desc_source": "jira"
  },
  "JxPath_9": {
    "description": "Comparing with NaN is incorrect\n'NaN' > 'NaN' is true, but should be FALSE",
    "desc_source": "jira"
  },
  "JxPath_10": {
    "description": "Binary operators behaviour involving node-sets is incorrect\nAccording to XPath specification:\n\"If both objects to be compared are node-sets, then the comparison will be true if and only if there is a node in the first node-set and a node in the second node-set such that the result of performing the comparison on the string-values of the two nodes is true. If one object to be compared is a node-set and the other is a number, then the comparison will be true if and only if there is a node in the node-set such that the result of performing the comparison on the number to be compared and on the result of converting the string-value of that node to a number using the number function is true.\"\n\nBut following example illustrates, that this is not a JXPath behaviour:\n\n\n        JXPathContext pathContext = JXPathContext\n                .newContext(DocumentBuilderFactory.newInstance()\n                        .newDocumentBuilder().parse(\n                                new InputSource(new StringReader(\n                                        \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\r\\n\"\n                                                + \"<doc/>\"))));\n        Boolean result = (Boolean) pathContext.getValue(\"2.0 > child1\",\n                Boolean.class);\n        assertFalse(result.booleanValue());\n\n\"child1\" is not found - right operand node set is empty, but result is TRUE, instead of FALSE.\n\nPlease, check greaterThan(), lesserThan(), etc methods of org.apache.xpath.objects.XObject for possible solution :)",
    "desc_source": "jira"
  },
  "JxPath_11": {
    "description": "Incomplete handling of undefined namespaces\nMcduffey, Joe <jdmcduf@nsa.gov>\n\nCan someone tell me how to register namespaces so that attributes with namespaces does not cause the exception\n\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: xsi\n\nFor example the following\n<ElementA  A:myAttr=\"Mytype\">\n  <B:ElementB>MY VALUE</B:ElementB>\n</ElementA>\n\nWould result in the following exception:\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: A\n\nFYI: In this example there was a namespace decaration in the file and I also manually called the\nregisterNamespace(A,\"/http...\");\nregisterNamespace(B,\"/http...\");\n\nThere was no problem encountered for elements. Only attributes. Can someone help? Thanks.",
    "desc_source": "jira"
  },
  "JxPath_12": {
    "description": "Incomplete handling of undefined namespaces\nMcduffey, Joe <jdmcduf@nsa.gov>\n\nCan someone tell me how to register namespaces so that attributes with namespaces does not cause the exception\n\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: xsi\n\nFor example the following\n<ElementA  A:myAttr=\"Mytype\">\n  <B:ElementB>MY VALUE</B:ElementB>\n</ElementA>\n\nWould result in the following exception:\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: A\n\nFYI: In this example there was a namespace decaration in the file and I also manually called the\nregisterNamespace(A,\"/http...\");\nregisterNamespace(B,\"/http...\");\n\nThere was no problem encountered for elements. Only attributes. Can someone help? Thanks.",
    "desc_source": "jira"
  },
  "JxPath_13": {
    "description": "Incomplete handling of undefined namespaces\nMcduffey, Joe <jdmcduf@nsa.gov>\n\nCan someone tell me how to register namespaces so that attributes with namespaces does not cause the exception\n\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: xsi\n\nFor example the following\n<ElementA  A:myAttr=\"Mytype\">\n  <B:ElementB>MY VALUE</B:ElementB>\n</ElementA>\n\nWould result in the following exception:\norg.apache.common.ri.model.dom.DOMNodePointer.createAttribute\nunknown namespace prefix: A\n\nFYI: In this example there was a namespace decaration in the file and I also manually called the\nregisterNamespace(A,\"/http...\");\nregisterNamespace(B,\"/http...\");\n\nThere was no problem encountered for elements. Only attributes. Can someone help? Thanks.",
    "desc_source": "jira"
  },
  "JxPath_14": {
    "description": "Core rounding functions don't handle NaN or infinite values correctly\n        assertXPathValue(context, \"floor('NaN')\", new Double(Double.NaN));\n        assertXPathValue(context, \"floor(-2 div 0)\", new Double(Double.NEGATIVE_INFINITY));\n        assertXPathValue(context, \"floor(2 div 0)\", new Double(Double.POSITIVE_INFINITY));\n\n        assertXPathValue(context, \"ceiling('NaN')\", new Double(Double.NaN));\n        assertXPathValue(context, \"ceiling(-2 div 0)\", new Double(Double.NEGATIVE_INFINITY));\n        assertXPathValue(context, \"ceiling(2 div 0)\", new Double(Double.POSITIVE_INFINITY));\n\n        assertXPathValue(context, \"round('NaN')\", new Double(Double.NaN));\n        assertXPathValue(context, \"round(-2 div 0)\", new Double(Double.NEGATIVE_INFINITY));\n        assertXPathValue(context, \"round(2 div 0)\", new Double(Double.POSITIVE_INFINITY));",
    "desc_source": "jira"
  },
  "JxPath_15": {
    "description": "Core union operation does not sort result nodes according to document order\nSource document:\n<MAIN><A>avalue</A><B>bvalue</B></MAIN>\n\nAccording to string() function defintion:\n\"A node-set is converted to a string by returning the string-value of the node in the node-set that is first in document order. If the node-set is empty, an empty string is returned.\"\n\nFollowing XPath calculated incorrectly:\n string(/MAIN/B | /MAIN/A)\n\nExpected result: \"avalue\"\nActual value: \"bvalue\"\n\nReason:\nsorting of result nodes is missing from CoreOperationUnion",
    "desc_source": "jira"
  },
  "JxPath_16": {
    "description": "node() implementation in DOM and JDOM model\nI think that the code in DOMNodePointer.java, line 120 is wrong because considers only element and document to be matched by node().\nwhile instead it matches any node that pass from there.\n\ncase Compiler.NODE_TYPE_NODE :\n                    return nodeType == Node.ELEMENT_NODE\n                            || nodeType == Node.DOCUMENT_NODE;\n\nshould be changed to \n\ncase Compiler.NODE_TYPE_NODE :\n                    return true;\n\nSame in JDOMNodePointer, line 391\n\n                  return true;//(node instanceof Element) || (node instanceof Document);\n\n",
    "desc_source": "jira"
  },
  "JxPath_17": {
    "description": "Namespaced attribute not selected with wildcard\nWith expression:\n\nxml/@*\n\nOn xml:\n\n<xml xmlns:x='foo' x:pop='a'/>\n\nselectSingleNode returns null, @x:* works fine.\n\nPossible Fix:\n\nIn DOMAttributeIterator, line 84\n\nif (equalStrings(testPrefix, nodePrefix)) {\n                return true;\n            }\n\nshould probably be changed to\n\nif (testPrefix==null || equalStrings(testPrefix, nodePrefix)) {\n                return true;\n            }\n",
    "desc_source": "jira"
  },
  "JxPath_18": {
    "description": "Issue with attribute::\nChecking test (Issue172_CountAttributeNode) I came with the following fix for the code in AttributeContext  line 72\nfrom \n-----\nif (!(nodeTest instanceof NodeNameTest)) {\n                return false;\n            }\n            QName name = ((NodeNameTest) nodeTest).getNodeName();\n            \n------\n'\nto \n--- (outside method)\nprivate static final QName WILDCARD = new QName(\"\", \"*\");\n--- (in method)\n    \nfinal QName name ;\nif (nodeTest instanceof NodeTypeTest)\n{\n\t if (((NodeTypeTest) nodeTest).getNodeType() == Compiler.NODE_TYPE_NODE)\n\t\t name = WILDCARD;\n\t else return false;\n}\nelse if (nodeTest instanceof NodeNameTest) {\n\tname = ((NodeNameTest) nodeTest).getNodeName();\n}\nelse\n{\n\treturn false;\n}\n\n\n",
    "desc_source": "jira"
  },
  "JxPath_19": {
    "description": "JXPathContext.iteratePointers() does not work with multiple prefixes for a single namespace URI\nHave a look at the following document:\n\n<a:doc xmlns:a=\"ns\">\n  <a:elem />\n  <b:elem xmlns:b=\"ns\" />\n</a:doc>\n\nWe have two elements 'elem' in the same namespace 'ns'.\nThey have a different prefix, however.\n\nWhen we use JXPathContext.iteratePointers() to iterate over them, the first element is returned two times. The second element is not returned.\n\nThis is because\nin class org.apache.commons.jxpath.ri.model.dom.DOMNodePointer\nin method getRelativePositionByName() (line 546)\nwe have:\n\nif (nm.equals(node.getNodeName()))\n\nIn the example, we have\nnm  == \"a:elem\" and node == \"b:elem\"\n\nThus, equals() returns false. But since 'a' and 'b' are just different prefixes for the same namespace URI, we should have 'true'.\n\nI attached a testcase which reproduces the bug.",
    "desc_source": "jira"
  },
  "JxPath_20": {
    "description": "relational operations do not function properly when comparing a non-Iterator LHS to an Iterator RHS\nI have a simple JXpathContext, with the following variables: var1=0, var2=0, var3=1. When I try to evaluate the following expression - \"$var1 + $var2 <= $var3\", it returns false.",
    "desc_source": "jira"
  },
  "JxPath_21": {
    "description": "null handling is inconsistent\nComparing a vaule to null using unequals (\\!=) yields false!\n{noformat}\n        Map<String, Integer> m = new HashMap<String, Integer>();\n        m.put(\"a\", 1);\n        m.put(\"b\", null);\n        m.put(\"c\", 1);\n        JXPathContext c = JXPathContext.newContext(m);\n        System.out.println(c.getValue(\"a != b\") + \" should be true\");\n        System.out.println(c.getValue(\"a != c\") + \" should be false\");\n        System.out.println(c.getValue(\"a = b\") + \" should be false\");\n        System.out.println(c.getValue(\"a = c\") + \" should be true\");\n        System.out.println(c.getValue(\"not(a = b)\") + \" should be true\");\n        System.out.println(c.getValue(\"not(a = c)\") + \" should be false\");\n{noformat} \n\nOutput using 1.3:\n{color:red} false should be true{color}\nfalse should be false\nfalse should be false\ntrue should be true\ntrue should be true\nfalse should be false\n\n\nIn 1.2 it works correctly!",
    "desc_source": "jira"
  },
  "JxPath_22": {
    "description": "Resetting the default namespace causes a serious endless loop when requesting .asPath() on a node.\nsample smaller case:\n{code}\n<...>\n <b:foo xmlns:b=\"bla\" xmlns=\"test111\">    <!--  No nodes are placed in the tree within ns \"test111\" but the attribute is still there.-->\n  <b:bar>a</b:bar>                         <!-- is in ns 'bla' -->\n  <test xmlns=\"\"></test>                   <!-- does not have a namespace -->\n </b:foo>\n</...>\n{code}\n\nwhen requesting .asPath() on the 'test' node, it loops in org.apache.commons.jxpath.ri.NamespaceResolver.getPrefix(NodePointer, String), \nand if it didn't loop it would create a wrong xpath '//b:fo/null:test' DOMNodePointer.asPath().\n\n\nSo I think that the fix should be in org.apache.commons.jxpath.ri.model.dom.DOMNodePointer.asPath()\n\n{code}\n....\n                    String ln = DOMNodePointer.getLocalName(node);\n                    String nsURI = getNamespaceURI();\n                    if (nsURI == null) {\n                        buffer.append(ln);\n                        buffer.append('[');\n                        buffer.append(getRelativePositionByName()).append(']');\n                    }\n                    else {\n                        String prefix = getNamespaceResolver().getPrefix(nsURI);\n                        if (prefix != null) {\n...\n{code}\n\nshould become\n{code}\n...\n                    String ln = DOMNodePointer.getLocalName(node);\n                    String nsURI = getNamespaceURI();\n                    if (nsURI == null || nsURI.length() == 0) { // check for empty string which means that the node doesn't have a namespace.\n                        buffer.append(ln);\n                        buffer.append('[');\n                        buffer.append(getRelativePositionByName()).append(']');\n                    }\n                    else {\n                        String prefix = getNamespaceResolver().getPrefix(nsURI);\n                        if (prefix != null) {\n...\n{code}\n",
    "desc_source": "jira"
  },
  "Lang_1": {
    "description": "NumberUtils does not handle Long Hex numbers\nNumberUtils.createLong() does not handle hex numbers, but createInteger() handles hex and octal.\nThis seems odd.\n\nNumberUtils.createNumber() assumes that hex numbers can only be Integer.\nAgain, why not handle bigger Hex numbers?\n\n==\n\nIt is trivial to fix createLong() - just use Long.decode() instead of valueOf().\nIt's not clear why this was not done originally - the decode() method was added to both Integer and Long in Java 1.2.\n\nFixing createNumber() is also fairly easy - if the hex string has more than 8 digits, use Long.\n\nShould we allow for leading zeros in an Integer? \nIf not, the length check is trivial.",
    "desc_source": "jira"
  },
  "Lang_3": {
    "description": "Method createNumber from NumberUtils doesn't work for floating point numbers other than Float\nMethod createNumber from NumberUtils is trying to parse a string with a floating point number always first as a Float, that will cause that if we send a string with a number that will need a Double or even a BigDecimal the number will be truncate to accommodate into the Float without an exception to be thrown, so in fact we will no be returning ever neither a Double nor a BigDecimal.",
    "desc_source": "jira"
  },
  "Lang_4": {
    "description": "LookupTranslator accepts CharSequence as input, but fails to work with implementations other than String\nThe core of {{org.apache.commons.lang3.text.translate}} is a {{HashMap<CharSequence, CharSequence> lookupMap}}.\n\nFrom the Javadoc of {{CharSequence}} (emphasis mine):\n{quote}\nThis interface does not refine the general contracts of the equals and hashCode methods. The result of comparing two objects that implement CharSequence is therefore, in general, undefined. Each object may be implemented by a different class, and there is no guarantee that each class will be capable of testing its instances for equality with those of the other. *It is therefore inappropriate to use arbitrary CharSequence instances as elements in a set or as keys in a map.*\n{quote}\n\nThe current implementation causes code such as the following to not work as expected:\n\n{code}\nCharSequence cs1 = \"1 < 2\";\nCharSequence cs2 = CharBuffer.wrap(\"1 < 2\".toCharArray());\n\nSystem.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs1));\nSystem.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs2));\n{code}\n\n... which gives the following results (but should be identical):\n{noformat}\n1 &lt; 2\n1 < 2\n{noformat}\n\nThe problem, at a minimum, is that {{CharBuffer.equals}} is even documented in the Javadoc that:\n{quote}\nA char buffer is not equal to any other type of object.\n{quote}\n\n... so a lookup on a CharBuffer in the Map will always fail when compared against the String implementations that it contains.\n\nAn obvious work-around is to instead use something along the lines of either of the following:\n{code}\nSystem.out.println(StringEscapeUtils.ESCAPE_HTML4.translate(cs2.toString()));\nSystem.out.println(StringEscapeUtils.escapeHtml4(cs2.toString()));\n{code}\n\n... which forces everything back to a {{String}}.  However, this is not practical when working with large sets of data, which would require significant heap allocations and garbage collection concerns.  (As such, I was actually trying to use the {{translate}} method that outputs to a {{Writer}} - but simplified the above examples to omit this.)\n\nAnother option that I'm considering is to use a custom {{CharSequence}} wrapper around a {{char[]}} that implements {{hashCode()}} and {{equals()}} to work with those implemented on {{String}}.  (However, this will be interesting due to the symmetric assumption - which is further interesting that {{String.equals}} is currently implemented using {{instanceof}} - even though {{String}} is {{final}}...)",
    "desc_source": "jira"
  },
  "Lang_5": {
    "description": "LocaleUtils.toLocale does not parse strings starting with an underscore\nHi,\n\nJavadocs of Locale.toString() states that \"If the language is missing, the string will begin with an underbar.\". This is not handled in the LocaleUtils.toLocale method if it is meant to be the inversion method of Locale.toString().\n\nThe fix for the ticket 328 does not handle well the case \"fr__P\", which I found out during fixing the first bug.\n\nI am attaching the patch for both problems.",
    "desc_source": "jira"
  },
  "Lang_6": {
    "description": "StringIndexOutOfBoundsException in CharSequenceTranslator\nI found that there is bad surrogate pair handling in the CharSequenceTranslator\n\nThis is a simple test case for this problem.\n\\uD83D\\uDE30 is a surrogate pair.\n\n{code:java}\n@Test\npublic void testEscapeSurrogatePairs() throws Exception {\n    assertEquals(\"\\uD83D\\uDE30\", StringEscapeUtils.escapeCsv(\"\\uD83D\\uDE30\"));\n}\n{code}\n\nYou'll get the exception as shown below.\n\n{code}\njava.lang.StringIndexOutOfBoundsException: String index out of range: 2\n\tat java.lang.String.charAt(String.java:658)\n\tat java.lang.Character.codePointAt(Character.java:4668)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:95)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:59)\n\tat org.apache.commons.lang3.StringEscapeUtils.escapeCsv(StringEscapeUtils.java:556)\n{code}\n\nPatch attached, the method affected:\n# public final void translate(CharSequence input, Writer out) throws IOException",
    "desc_source": "jira"
  },
  "Lang_7": {
    "description": "NumberUtils#createNumber - bad behaviour for leading \"--\"\nNumberUtils#createNumber checks for a leading \"--\" in the string, and returns null if found. This is documented as a work round for a bug in BigDecimal.\n\nReturning nulll is contrary to the Javadoc and the behaviour for other methods which would throw NumberFormatException.\n\nIt's not clear whether the BigDecimal problem still exists with recent versions of Java. However, if it does exist, then the check needs to be done for all invocations of BigDecimal, i.e. needs to be moved to createBigDecimal.",
    "desc_source": "jira"
  },
  "Lang_8": {
    "description": "FastDateFormat's \"z\" pattern does not respect timezone of Calendar instances passed to format()\nThe work on LANG-462 has introduced a time zone formatting bug in FastDateFormat in commons-lang3.\n\nThe problem can be seen by this snippet:\n{code}\n// Always prints timezone name of machine's default timezone, ignoring TZ\n// set on calendar, even though the printed time itself respects calendar's TZ.\nCalendar myCal = Calendar.getInstance(TimeZone.getTimeZone(\"US/Central\"));\nSystem.out.println(FastDateFormat.getInstance(\"h:mma z\").format(myCal));\n{code}\n\nIf you happen to be in US/Central, this will print the right thing, but just try it with US/Eastern, US/Pacific, etc.  It will print the time in the correct timezone, but the timezone name at the end (the \"z\" pattern) will always be the system default timezone.  This is a regression against commons-lang 2.x.\n\nBasically, when the \"forced time zone\" code was removed, the TimeZoneNameRule class stopped respecting the Calendar instance's timezone, and instead now always uses the mTimeZone of the FastDateFormat instance itself (which is only supposed to be used when formatting timezone-less objects such as Date or long).\n\nThe removal of the forced time zone stuff is surely the right thing to do (it was a mess).  I think the fix is to change the TimeZoneNameRule inner class to not take a TimeZone instance, but rather to use the TimeZone on the Calendar instance passed into appendTo(), just like TimeZoneNumberRule does.  Presumably then for efficiency, one would use the getTimeZoneDisplay() package-static method to quickly retrieve the required timezone's display name.",
    "desc_source": "jira"
  },
  "Lang_9": {
    "description": "FastDateParser does not handle unterminated quotes correctly\nFDP does not handled unterminated quotes the same way as SimpleDateFormat\n\nFor example:\n\nFormat: 'd'd'\nDate: d3\n\nThis should fail to parse the format and date but it actually works.\nThe format is parsed as:\n\nPattern: d(\\p{IsNd}++)",
    "desc_source": "jira"
  },
  "Lang_10": {
    "description": "FastDateParser does not handle white-space properly\nThe SimpleDateFormat Javadoc does not treat white-space specially, however FastDateParser treats a single white-space as being any number of white-space characters.\n\nThis means that FDP will parse dates that fail when parsed by SDP.",
    "desc_source": "jira"
  },
  "Lang_11": {
    "description": "RandomStringUtils throws confusing IAE when end <= start\nRandomUtils invokes Random#nextInt(n) where n = end - start.\n\nIf end <= start, then Random throws:\n\njava.lang.IllegalArgumentException: n must be positive\n\nThis is confusing, and does not identify the source of the problem.",
    "desc_source": "jira"
  },
  "Lang_12": {
    "description": "RandomStringUtils.random(count, 0, 0, false, false, universe, random) always throws java.lang.ArrayIndexOutOfBoundsException\nIn commons-lang 2.6 line 250 :\n{code}ch = chars[random.nextInt(gap) + start];{code}\n-This line of code takes a random int to fetch a char in the _chars_ array regardless of its size.-\n-(Besides _start_ is useless here)-\n\n-Fixed version would be :-\n{code}//ch = chars[random.nextInt(gap)%chars.length];{code}\n\nWhen user pass 0 as _end_ or when the array is not null but empty this line ends up with an exception",
    "desc_source": "jira"
  },
  "Lang_13": {
    "description": "SerializationUtils throws ClassNotFoundException when cloning primitive classes\nIf a serializable object contains a reference to a primitive class, e.g. int.class or int[].class, the SerializationUtils throw a ClassNotFoundException when trying to clone that object.\n\n{noformat}\nimport org.apache.commons.lang3.SerializationUtils;\nimport org.junit.Test;\n\n\npublic class SerializationUtilsTest {\n\n\t\n\t@Test\n\tpublic void primitiveTypeClassSerialization(){\n\t\tClass<?> primitiveType = int.class;\n\t\t\n\t\tClass<?> clone = SerializationUtils.clone(primitiveType);\n\t\tassertEquals(primitiveType, clone);\n\t}\n}\n{noformat} \n\nThe problem was already reported as a java bug http://bugs.sun.com/view_bug.do?bug_id=4171142 and ObjectInputStream is fixed since java version 1.4.\nThe SerializationUtils problem arises because the SerializationUtils internally use the ClassLoaderAwareObjectInputStream that overrides the ObjectInputStream's\nresoleClass method without delegating to the super method in case of a ClassNotFoundException.\n\nI understand the intention of the ClassLoaderAwareObjectInputStream, but this implementation should also implement a fallback to the original implementation.\n\nFor example:\n{noformat}\n        protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException {\n            String name = desc.getName();\n            try {\n                return Class.forName(name, false, classLoader);\n            } catch (ClassNotFoundException ex) {\n            \ttry {\n            \t     return Class.forName(name, false, Thread.currentThread().getContextClassLoader());\n            \t} catch (Exception e) {\n\t\t     return super.resolveClass(desc);\n\t\t}\n            }\n        }\n{noformat}\n\nHere is the code in ObjectInputStream that fixed the java bug.\n{noformat}\n    protected Class<?> resolveClass(ObjectStreamClass desc)\n\tthrows IOException, ClassNotFoundException\n    {\n\tString name = desc.getName();\n\ttry {\n\t    return Class.forName(name, false, latestUserDefinedLoader());\n\t} catch (ClassNotFoundException ex) {\n\t    Class cl = (Class) primClasses.get(name);\n\t    if (cl != null) {\n\t\treturn cl;\n\t    } else {\n\t\tthrow ex;\n\t    }\n\t}\n    }\n{noformat}\n",
    "desc_source": "jira"
  },
  "Lang_14": {
    "description": "StringUtils equals() relies on undefined behavior\nSince the {{java.lang.CharSequence}} class was first introduced in 1.4, the JavaDoc block has contained the following note:\n\n{quote}\nThis interface does not refine the general contracts of the equals and hashCode methods. The result of comparing two objects that implement CharSequence is therefore, in general, undefined. Each object may be implemented by a different class, and there is no guarantee that each class will be capable of testing its instances for equality with those of the other.\n{quote}\n\nWhen the signature of the StringUtils equals() method was changed from {{equals(String, String)}} to {{equals(CharSequence, CharSequence)}} in R920543, the implementation still relied on calling CharSequence#equals(Object) even though, in general, the result is undefined.\n\nOne example where {{equals(Object)}} returns {{false}} even though, as CharSequences, two objects represent equal sequences is when one object is an instance of {{javax.lang.model.element.Name}} and the other object is a String.",
    "desc_source": "jira"
  },
  "Lang_15": {
    "description": "TypeUtils.getTypeArguments() misses type arguments for partially-assigned classes\nfailing test code to add to TypeUtilsTest.testGetTypeArguments():\n{code}\ntypeVarAssigns = TypeUtils.getTypeArguments(Other.class, This.class);\nAssert.assertEquals(2, typeVarAssigns.size());\nAssert.assertEquals(String.class, typeVarAssigns.get(This.class.getTypeParameters()[0]));\nAssert.assertEquals(Other.class.getTypeParameters()[0], typeVarAssigns.get(This.class.getTypeParameters()[1]));\n{code}\n\nThese should pass based on:\n{code}\n\npublic interface This<K, V> {\n}\n\npublic class Other<T> implements This<String, T> {\n}\n{code}\n\nThis case fails because the current code ignores the Other class due to its specifying its own type variables, which is obviously incorrect.  This report is extrapolated from an offline report received by Hen.",
    "desc_source": "jira"
  },
  "Lang_16": {
    "description": "NumberUtils does not handle upper-case hex: 0X and -0X\nNumberUtils.createNumber() should work equally for 0x1234 and 0X1234; currently 0X1234 generates a NumberFormatException\n\nInteger.decode() handles both upper and lower case hex.",
    "desc_source": "jira"
  },
  "Lang_17": {
    "description": "StringEscapeUtils.escapeXml(input) outputs wrong results when an input contains characters in Supplementary Planes.\nHello.\n\nI use StringEscapeUtils.escapeXml(input) to escape special characters for XML.\nThis method outputs wrong results when input contains characters in Supplementary Planes.\n\nString str1 = \"\\uD842\\uDFB7\" + \"A\";\nString str2 = StringEscapeUtils.escapeXml(str1);\n\n// The value of str2 must be equal to the one of str1,\n// because str1 does not contain characters to be escaped.\n// However, str2 is diffrent from str1.\n\nSystem.out.println(URLEncoder.encode(str1, \"UTF-16BE\")); //%D8%42%DF%B7A\nSystem.out.println(URLEncoder.encode(str2, \"UTF-16BE\")); //%D8%42%DF%B7%FF%FD\n\nThe cause of this problem is that the loop to translate input character by character is wrong.\nIn CharSequenceTranslator.translate(CharSequence input, Writer out),\nloop counter \"i\" moves from 0 to Character.codePointCount(input, 0, input.length()),\nbut it should move from 0 to input.length().\n",
    "desc_source": "jira"
  },
  "Lang_19": {
    "description": "StringIndexOutOfBoundsException when calling unescapeHtml4(\"&#03\")\nWhen calling unescapeHtml4() on the String \"&#03\" (or any String that contains these characters) an Exception is thrown:\n\nException in thread \"main\" java.lang.StringIndexOutOfBoundsException: String index out of range: 4\n\tat java.lang.String.charAt(String.java:686)\n\tat org.apache.commons.lang3.text.translate.NumericEntityUnescaper.translate(NumericEntityUnescaper.java:49)\n\tat org.apache.commons.lang3.text.translate.AggregateTranslator.translate(AggregateTranslator.java:53)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:88)\n\tat org.apache.commons.lang3.text.translate.CharSequenceTranslator.translate(CharSequenceTranslator.java:60)\n\tat org.apache.commons.lang3.StringEscapeUtils.unescapeHtml4(StringEscapeUtils.java:351)",
    "desc_source": "jira"
  },
  "Lang_20": {
    "description": "StringUtils.join throws NPE when toString returns null for one of objects in collection\nTry\n{code} \nStringUtils.join(new Object[]{\n        new Object() {\n          @Override\n          public String toString() {\n            return null;\n          }\n        }\n    }, ',');\n{code}\n\nToString should probably never return null, but it does in javax.mail.internet.InternetAddress",
    "desc_source": "jira"
  },
  "Lang_21": {
    "description": "DateUtils.isSameLocalTime does not work correct\nHi, I think I found a bug in the DateUtils class in the method isSameLocalTime.\n\nExample: \nCalendar a = Calendar.getInstance();\na.setTimeInMillis(1297364400000L);\n\nCalendar b = Calendar.getInstance();\nb.setTimeInMillis(1297321200000L);\n\nAssert.assertFalse(DateUtils.isSameLocalTime(a, b));\n\nThis is because the method compares \ncal1.get(Calendar.HOUR) == cal2.get(Calendar.HOUR) \n\nbut I think it has to be \ncal1.get(Calendar.HOUR_OF_DAY) == cal2.get(Calendar.HOUR_OF_DAY)\n\n\n\t",
    "desc_source": "jira"
  },
  "Lang_22": {
    "description": "org.apache.commons.lang3.math.Fraction does not reduce (Integer.MIN_VALUE, 2^k)\nThe greatestCommonDivisor method in class Fraction does not find the gcd of Integer.MIN_VALUE and 2^k, and this case can be triggered by taking Integer.MIN_VALUE as the numerator. Note that the case of taking Integer.MIN_VALUE as the denominator is handled explicitly in the getReducedFraction factory method.\n\n{code:title=FractionTest.java|borderStyle=solid}\n\t// additional test cases\n\tpublic void testReducedFactory_int_int() {\n\t\t// ...\n\t\tf = Fraction.getReducedFraction(Integer.MIN_VALUE, 2);\n\t\tassertEquals(Integer.MIN_VALUE / 2, f.getNumerator());\n\t\tassertEquals(1, f.getDenominator());\n\n\tpublic void testReduce() {\n\t\t// ...\n\t\tf = Fraction.getFraction(Integer.MIN_VALUE, 2);\n\t\tresult = f.reduce();\n\t\tassertEquals(Integer.MIN_VALUE / 2, result.getNumerator());\n\t\tassertEquals(1, result.getDenominator());\n{code} \n",
    "desc_source": "jira"
  },
  "Lang_23": {
    "description": "text.ExtendedMessageFormat doesn't override java.text.MessageFormat.equals(Object)\nFindbugs:\n\nBug: org.apache.commons.lang3.text.ExtendedMessageFormat doesn't override java.text.MessageFormat.equals(Object)\nPattern id: EQ_DOESNT_OVERRIDE_EQUALS, type: Eq, category: STYLE\n\nThis class extends a class that defines an equals method and adds fields, but doesn't define an equals method itself. Thus, equality on instances of this class will ignore the identity of the subclass and the added fields. Be sure this is what is intended, and that you don't need to override the equals method. Even if you don't need to override the equals method, consider overriding it anyway to document the fact that the equals method for the subclass just return the result of invoking super.equals(o). \n",
    "desc_source": "jira"
  },
  "Lang_24": {
    "description": "NumberUtils.isNumber(String)  is not right when the String is \"1.1L\"\n\"1.1L\"  is not a Java Number . but NumberUtils.isNumber(String) return true.\n\nperhaps change:\n{code:java}\n            if (chars[i] == 'l'\n                || chars[i] == 'L') {\n                // not allowing L with an exponent\n                return foundDigit && !hasExp;\n            }\n{code}\nto:\n{code:java}\n            if (chars[i] == 'l'\n                || chars[i] == 'L') {\n                // not allowing L with an exponent\n                return foundDigit && !hasExp && !hasDecPoint;\n            }\n{code}",
    "desc_source": "jira"
  },
  "Lang_26": {
    "description": "FastDateFormat.format() outputs incorrect week of year because locale isn't respected\nFastDateFormat apparently doesn't respect the locale it was sent on creation when outputting week in year (e.g. \"ww\") in format(). It seems to use the settings of the system locale for firstDayOfWeek and minimalDaysInFirstWeek, which (depending on the year) may result in the incorrect week number being output.\n\nHere is a simple test program to demonstrate the problem by comparing with SimpleDateFormat, which gets the week number right:\n{code}\nimport java.util.Calendar;\nimport java.util.Date;\nimport java.util.Locale;\nimport java.text.SimpleDateFormat;\n\nimport org.apache.commons.lang.time.FastDateFormat;\n\npublic class FastDateFormatWeekBugDemo {\n    public static void main(String[] args) {\n        Locale.setDefault(new Locale(\"en\", \"US\"));\n        Locale locale = new Locale(\"sv\", \"SE\");\n\n        Calendar cal = Calendar.getInstance(); // setting locale here doesn't change outcome\n        cal.set(2010, 0, 1, 12, 0, 0);\n        Date d = cal.getTime();\n        System.out.println(\"Target date: \" + d);\n\n        FastDateFormat fdf = FastDateFormat.getInstance(\"EEEE', week 'ww\", locale);\n        SimpleDateFormat sdf = new SimpleDateFormat(\"EEEE', week 'ww\", locale);\n        System.out.println(\"FastDateFormat:   \" + fdf.format(d)); // will output \"FastDateFormat:   fredag, week 01\"\n        System.out.println(\"SimpleDateFormat: \" + sdf.format(d)); // will output \"SimpleDateFormat: fredag, week 53\"\n    }\n}\n{code}\nIf sv/SE is passed to Locale.setDefault() instead of en/US, both FastDateFormat and SimpleDateFormat output the correct week number.\n",
    "desc_source": "jira"
  },
  "Lang_27": {
    "description": "NumberUtils createNumber throws a StringIndexOutOfBoundsException when argument containing \"e\" and \"E\" is passed in\nNumberUtils createNumber throws a StringIndexOutOfBoundsException instead of NumberFormatException when a String containing both possible exponent indicators is passed in.\nOne example of such a String is \"1eE\".\n",
    "desc_source": "jira"
  },
  "Lang_28": {
    "description": "StringEscapeUtils.escapeXML() can't process UTF-16 supplementary characters\nSupplementary characters in UTF-16 are those whose code points are above 0xffff, that is, require more than 1 Java char to be encoded, as explained here: http://java.sun.com/developer/technicalArticles/Intl/Supplementary/\n\nCurrently, StringEscapeUtils.escapeXML() isn't aware of this coding scheme and treats each char as one character, which is not always right.\n\nA possible solution in class Entities would be:\n\n    public void escape(Writer writer, String str) throws IOException {\n        int len = str.length();\n        for (int i = 0; i < len; i++) {\n            int code = str.codePointAt(i);\n            String entityName = this.entityName(code);\n            if (entityName != null) {\n                writer.write('&');\n                writer.write(entityName);\n                writer.write(';');\n            } else if (code > 0x7F) {\n                    writer.write(\"&#\");\n                    writer.write(code);\n                    writer.write(';');\n            } else {\n                    writer.write((char) code);\n            }\n\n            if (code > 0xffff) {\n                    i++;\n            }\n        }\n    }\n\nBesides fixing escapeXML(), this will also affect HTML escaping functions. I guess that's a good thing, but please remember I have only tested escapeXML().\n",
    "desc_source": "jira"
  },
  "Lang_29": {
    "description": "SystemUtils.getJavaVersionAsFloat throws StringIndexOutOfBoundsException on Android runtime/Dalvik VM\nCan be replicated in the Android emulator quite easily.\n\nStack trace:\n\n{noformat}\n\nat org.apache.commons.lang.builder.ToStringBuilder.<clinit>(ToStringBuilder.java:98)\nE/AndroidRuntime( 1681): \t... 17 more\nE/AndroidRuntime( 1681): Caused by: java.lang.ExceptionInInitializerError\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.builder.ToStringStyle$MultiLineToStringStyle.<init>(ToStringStyle.java:2276)\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.builder.ToStringStyle.<clinit>(ToStringStyle.java:94)\nE/AndroidRuntime( 1681): \t... 18 more\nE/AndroidRuntime( 1681): Caused by: java.lang.StringIndexOutOfBoundsException\nE/AndroidRuntime( 1681): \tat java.lang.String.substring(String.java:1571)\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.SystemUtils.getJavaVersionAsFloat(SystemUtils.java:1153)\nE/AndroidRuntime( 1681): \tat org.apache.commons.lang.SystemUtils.<clinit>(SystemUtils.java:818)\n{noformat}",
    "desc_source": "jira"
  },
  "Lang_30": {
    "description": "StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly.\nStringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters.\n\nFor example, define a test fixture to be the Unicode character U+20000 where U+20000 is written in Java source as \"\\uD840\\uDC00\"\n\n\tprivate static final String CharU20000 = \"\\uD840\\uDC00\";\n\tprivate static final String CharU20001 = \"\\uD840\\uDC01\";\n\nYou can see Unicode supplementary characters correctly implemented in the JRE call:\n\n\tassertEquals(-1, CharU20000.indexOf(CharU20001));\n\nBut this is broken:\n\n\tassertEquals(false, StringUtils.containsAny(CharU20000, CharU20001));\n\tassertEquals(false, StringUtils.containsAny(CharU20001, CharU20000));\n\nThis is fine:\n\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20000));\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20001));\n\tassertEquals(true, StringUtils.contains(CharU20000, CharU20000));\n\tassertEquals(false, StringUtils.contains(CharU20000, CharU20001));\n\nbecause the method calls the JRE to perform the match.\n\nMore than you want to know:\n- http://java.sun.com/developer/technicalArticles/Intl/Supplementary/",
    "desc_source": "jira"
  },
  "Lang_31": {
    "description": "StringUtils methods do not handle Unicode 2.0+ supplementary characters correctly.\nStringUtils.containsAny methods incorrectly matches Unicode 2.0+ supplementary characters.\n\nFor example, define a test fixture to be the Unicode character U+20000 where U+20000 is written in Java source as \"\\uD840\\uDC00\"\n\n\tprivate static final String CharU20000 = \"\\uD840\\uDC00\";\n\tprivate static final String CharU20001 = \"\\uD840\\uDC01\";\n\nYou can see Unicode supplementary characters correctly implemented in the JRE call:\n\n\tassertEquals(-1, CharU20000.indexOf(CharU20001));\n\nBut this is broken:\n\n\tassertEquals(false, StringUtils.containsAny(CharU20000, CharU20001));\n\tassertEquals(false, StringUtils.containsAny(CharU20001, CharU20000));\n\nThis is fine:\n\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20000));\n\tassertEquals(true, StringUtils.contains(CharU20000 + CharU20001, CharU20001));\n\tassertEquals(true, StringUtils.contains(CharU20000, CharU20000));\n\tassertEquals(false, StringUtils.contains(CharU20000, CharU20001));\n\nbecause the method calls the JRE to perform the match.\n\nMore than you want to know:\n- http://java.sun.com/developer/technicalArticles/Intl/Supplementary/",
    "desc_source": "jira"
  },
  "Lang_32": {
    "description": "Use of ThreadLocals in ToStringStyle and HashCodeBuilder trigger memory leaks in container environments\nThe thread local in org.apache.commons.lang3.builder.ToStringStyle is created but never removed and no API is provided to remove it. If a webapp's use of LANG triggers the loading of this class, a reference chain will be created that will cause a memory leak on web application reload.\n\nSee http://markmail.org/thread/uetw2fdrsqgbh2cv for more info.",
    "desc_source": "jira"
  },
  "Lang_33": {
    "description": "ClassUtils.toClass(Object[]) throws NPE on null array element\nsee summary",
    "desc_source": "jira"
  },
  "Lang_34": {
    "description": "Use of ThreadLocals in ToStringStyle and HashCodeBuilder trigger memory leaks in container environments\nThe thread local in org.apache.commons.lang3.builder.ToStringStyle is created but never removed and no API is provided to remove it. If a webapp's use of LANG triggers the loading of this class, a reference chain will be created that will cause a memory leak on web application reload.\n\nSee http://markmail.org/thread/uetw2fdrsqgbh2cv for more info.",
    "desc_source": "jira"
  },
  "Lang_35": {
    "description": "ArrayUtils.add(T[] array, T element) can create unexpected ClassCastException\nArrayUtils.add(T[] array, T element) can create an unexpected ClassCastException.\n\nFor example, the following code compiles without a warning:\n\n{code}\nString[] sa = ArrayUtils.add(stringArray, aString);\n{code}\n\nand works fine, provided at least one of the parameters is non-null. However, if both parameters are null, the add() method returns an Object[] array, hence the Exception.\n\nIf both parameters are null, it's not possible to determine the correct array type to return, so it seems to me this should be disallowed.\n\nI think the method ought to be changed to throw IllegalParameterException when both parameters are null.\n",
    "desc_source": "jira"
  },
  "Lang_36": {
    "description": "NumberUtils.isNumber() Should Return True for Valid Number with a Trailing Decimal Place\nNumberUtils.isNumber() should return true for a valid number ending in a trailing decimal place; e.g., \"2.\" should be considered a number because new BigDecimal(\"2.\") works fine.  This could be done by adding the code below after line 1444, which is the if (chars[i] == 'e' || chars[i] == 'E') block.\n\nif (chars[i] == '.') {\n    if (hasDecPoint || hasExp) {\n        // two decimal points or dec in exponent   \n        return false;\n    }\n    return foundDigit; // single trailing decimal point after non-exponent is ok\n}",
    "desc_source": "jira"
  },
  "Lang_37": {
    "description": "ArrayUtils.addAll(T[] array1, T... array2) does not handle mixed types very well\nArrayUtils.addAll(T[] array1, T... array2) does not handle mixed array types very well.\n\nThe stack trace for \n\nNumber[] st = ArrayUtils.addAll(new Integer[]{1}, new Long[]{2L});\n\nstarts:\n\njava.lang.ArrayStoreException\n\tat java.lang.System.arraycopy(Native Method)\n\tat org.apache.commons.lang3.ArrayUtils.addAll(ArrayUtils.java:2962)\n\nwhich is not all that obvious.\n\nIt would be a lot clearer if the method threw an IlegalArgumentException or similar.",
    "desc_source": "jira"
  },
  "Lang_38": {
    "description": "DateFormatUtils.format does not correctly change Calendar TimeZone in certain situations\nIf a Calendar object is constructed in certain ways a call to Calendar.setTimeZone does not correctly change the Calendars fields.  Calling Calenar.getTime() seems to fix this problem.  While this is probably a bug in the JDK, it would be nice if DateFormatUtils was smart enough to detect/resolve this problem.\n\nFor example, the following unit test fails:\n\n{noformat}\n  public void testFormat_CalendarIsoMsZulu() {\n    final String dateTime = \"2009-10-16T16:42:16.000Z\";\n\n    // more commonly constructed with: cal = new GregorianCalendar(2009, 9, 16, 8, 42, 16)\n    // for the unit test to work in any time zone, constructing with GMT-8 rather than default locale time zone\n    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(\"GMT-8\"));\n    cal.clear();\n    cal.set(2009, 9, 16, 8, 42, 16);\n\n\n    FastDateFormat format = FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\", TimeZone.getTimeZone(\"GMT\"));\n    assertEquals(\"dateTime\", dateTime, format.format(cal));\n  }\n{noformat}\n\nHowever, this unit test passes:\n\n{noformat}\n  public void testFormat_CalendarIsoMsZulu() {\n    final String dateTime = \"2009-10-16T16:42:16.000Z\";\n    GregorianCalendar cal = new GregorianCalendar(TimeZone.getTimeZone(\"GMT-8\"));\n    cal.clear();\n    cal.set(2009, 9, 16, 8, 42, 16);\n    cal.getTime();\n\n    FastDateFormat format = FastDateFormat.getInstance(\"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\", TimeZone.getTimeZone(\"GMT\"));\n    assertEquals(\"dateTime\", dateTime, format.format(cal));\n  }\n{noformat}",
    "desc_source": "jira"
  },
  "Lang_39": {
    "description": "StringUtils replaceEach - Bug or Missing Documentation \nThe following Test Case for replaceEach fails with a null pointer exception.\nI have expected that all StringUtils methods are \"null-friendly\"\nThe use case is that i will stuff Values into the replacementList of which I do not want to check whether they are null.\nI admit the use case is not perfect, because it is unclear what happens on the replace.\nI outlined three expectations in the test case, of course only one should be met.\n\nIf it is decided that none of them should be possible, I propose to update the documentation with what happens when null is passed as replacement string\n\n{code}\nimport static org.junit.Assert.assertEquals;\n\nimport org.apache.commons.lang.StringUtils;\nimport org.junit.Test;\n\n\npublic class StringUtilsTest {\n\n\t@Test\n\tpublic void replaceEach(){\n\t\tString original = \"Hello World!\";\n\t\tString[] searchList = {\"Hello\", \"World\"};\n\t\tString[] replacementList = {\"Greetings\", null};\n\t\tString result = StringUtils.replaceEach(original, searchList, replacementList);\n\t\tassertEquals(\"Greetings !\", result);\n\t\t//perhaps this is ok as well\n                //assertEquals(\"Greetings World!\", result);\n                //or even\n\t\t//assertEquals(\"Greetings null!\", result);\n\t}\n\n\t\n}\n{code}",
    "desc_source": "jira"
  },
  "Lang_40": {
    "description": "Fix case-insensitive string handling\n{{String.to*Case()}} is locale-sensitive, this is usually not intended for case-insensitive comparisions. Please see [Common Bug #3|http://www.nabble.com/Re%3A-Common-Bugs-p14931921s177.html] for details.",
    "desc_source": "jira"
  },
  "Lang_41": {
    "description": "ClassUtils.getShortClassName() will not work with an array;  it seems to add a semicolon to the end.\nA semicolon is introduced into the class name at the end for all arrays...\n\nString sArray[] = new String[2];\nsArray[0] = \"mark\";\nsArray[1] = \"is cool\";\nString simpleString = \"chris\";\n\t\t\nassertEquals(\"String\", ClassUtils.getShortClassName(simpleString, null));\nassertEquals(\"String;\", ClassUtils.getShortClassName(sArray, null));",
    "desc_source": "jira"
  },
  "Lang_42": {
    "description": "StringEscapeUtils.escapeHtml incorrectly converts unicode characters above U+00FFFF into 2 characters\nCharacters that are represented as a 2 characters internaly by java are incorrectly converted by the function. The following test displays the problem quite nicely:\n\nimport org.apache.commons.lang.*;\n\npublic class J2 {\n    public static void main(String[] args) throws Exception {\n        // this is the utf8 representation of the character:\n        // COUNTING ROD UNIT DIGIT THREE\n        // in unicode\n        // codepoint: U+1D362\n        byte[] data = new byte[] { (byte)0xF0, (byte)0x9D, (byte)0x8D, (byte)0xA2 };\n\n        //output is: &amp;#55348;&amp;#57186;\n        // should be: &amp;#119650;\n        System.out.println(\"'\" + StringEscapeUtils.escapeHtml(new String(data, \"UTF8\")) + \"'\");\n    }\n}\n\nShould be very quick to fix, feel free to drop me an email if you want a patch.",
    "desc_source": "jira"
  },
  "Lang_43": {
    "description": "ExtendedMessageFormat: OutOfMemory with custom format registry and a pattern containing single quotes\nWhen using ExtendedMessageFormat with a custom format registry and a pattern conatining single quotes, an OutOfMemoryError will occur.\n\nExample that will cause error:\n\n{code:title=ExtendedMessageFormatTest.java|borderStyle=solid}\n\nprivate static Map<String, Object> formatRegistry = new HashMap<String, Object>();    \n    static {\n        formatRegistry.put(DummyFormatFactory.DUMMY_FORMAT, new DummyFormatFactory());\n    }\n    \n    public static void main(String[] args) {\n        ExtendedMessageFormat mf = new ExtendedMessageFormat(\"it''s a {dummy} 'test'!\", formatRegistry);\n        String formattedPattern = mf.format(new String[] {\"great\"});\n        System.out.println(formattedPattern);\n    }\n}\n\n{code}\n\nThe following change starting at line 421 on the 2.4 release seems to fix the problem:\n\n{code:title=ExtendedMessageFormat.java|borderStyle=solid}\nCURRENT (Broken):\nif (escapingOn && c[start] == QUOTE) {\n        return appendTo == null ? null : appendTo.append(QUOTE);\n}\n\nWORKING:\nif (escapingOn && c[start] == QUOTE) {\n        next(pos);\n        return appendTo == null ? null : appendTo.append(QUOTE);\n}\n{code}",
    "desc_source": "jira"
  },
  "Lang_44": {
    "description": "NumberUtils createNumber thows a StringIndexOutOfBoundsException when only an \"l\" is passed in.\nSeems to be similar to LANG-300, except that if you don't place a digit in front of the \"l\" or \"L\" it throws a StringIndexOutOfBoundsException instead.",
    "desc_source": "jira"
  },
  "Lang_45": {
    "description": "WordUtils.abbreviate bug when lower is greater than str.length\nIn WordUtils.abbreviate, upper is adjusted to the length of the string, then to lower.\nBut lower is never adjusted to the length of the string, so if lower is greater than str.lengt(), upper will be too...\nThen, str.substring(0, upper) throw a StringIndexOutOfBoundsException\n\nThe fix is to adjust lower to the length of the string",
    "desc_source": "jira"
  },
  "Lang_46": {
    "description": "StringEscapeUtils.escapeJava(String) escapes '/' characters\nCommons Lang 2.4 StringEscapeUtils.escapeJava(String) now escapes '/' characters, which is not a valid \"escapable\" character in Java strings.  I haven't tried the other Java escape/unescape methods to see if they have a similar problem, or that only Java \"escapable\" characters are escaped by escapeJava(String).\n\nThis bug may have appeared as an unintended side-effect of the fix for LANG-363.\n\nAlso the javadoc for escapeJava is now a little off, in that '/' should now be included in the sentence describing the differences between Java and Javascript strings, with respect to escaping rules.\n\nThe following is a JUnit3 test demonstrating the bug.\n\nimport junit.framework.TestCase;\n\nimport org.apache.commons.lang.StringEscapeUtils;\n\npublic class StringEscapeUtilsTest extends TestCase {\n    public void testEscapeJavaWithSlash() {\n        final String input = \"String with a slash (/) in it\";\n        \n        final String expected = input;\n        final String actual   = StringEscapeUtils.escapeJava( input );\n\n        /**\n         * In 2.4 StringEscapeUtils.escapeJava(String) escapes '/' characters,\n         * which are not a valid character to escape in a Java string.  \n         */\n        assertEquals( expected, actual );\n    }\n}\n\n",
    "desc_source": "jira"
  },
  "Lang_47": {
    "description": "StrBuilder appendFixedWidth does not handle nulls\nAppending a null value with fixed width causes a null pointer exception if getNullText() has not been set.",
    "desc_source": "jira"
  },
  "Lang_49": {
    "description": "infinite loop in Fraction.reduce when numerator == 0\nSummary pretty much says it all.",
    "desc_source": "jira"
  },
  "Lang_50": {
    "description": "FastDateFormat getDateInstance() and getDateTimeInstance() assume Locale.getDefault() won't change\nThe FastDateFormat getDateInstance() and getDateTimeInstance()  methods create the HashMap key from various items including the locale.\n\nIf the locale is null, then it is not made part of the key, but the stored object is created using the current default locale.\n\nIf the Locale is changed subsequently, then the wrong locale is applied.\n\nPatch for test case to follow.\n",
    "desc_source": "jira"
  },
  "Lang_51": {
    "description": "BooleanUtils.toBoolean() - invalid drop-thru in case statement causes StringIndexOutOfBoundsException\nThe method BooleanUtils.toBoolean() has a case statement; case 3 drops through to case 4; this can cause StringIndexOutOfBoundsException, for example with the test:\n\nassertEquals(false, BooleanUtils.toBoolean(\"tru\"));\n\nThe end of case 3 should return false.\n\nPatch to follow for source and unit test.",
    "desc_source": "jira"
  },
  "Lang_52": {
    "description": "StringEscapeUtils.escapeJavaScript() method did not escape '/' into '\\/', it will make IE render page uncorrectly\nIf Javascripts including'/', IE will parse the scripts uncorrectly, actually '/' should be escaped to '\\/'.\nFor example, document.getElementById(\"test\").value = '<script>alert(\\'aaa\\');</script>';this expression will make IE render page uncorrect, it should be document.getElementById(\"test\").value = '<script>alert(\\'aaa\\');<\\/script>';\n\nBtw, Spring's JavascriptEscape behavor is correct.\nTry  to run below codes, you will find the difference:\n  String s = \"<script>alert('aaa');</script>\";\n  String str = org.springframework.web.util.JavaScriptUtils.javaScriptEscape(s);\n  System.out.println(\"Spring JS Escape : \"+str);\n  str = org.apache.commons.lang.StringEscapeUtils.escapeJavaScript(s);\n  System.out.println(\"Apache Common Lang JS Escape : \"+ str);",
    "desc_source": "jira"
  },
  "Lang_53": {
    "description": "Dates.round() behaves incorrectly for minutes and seconds\nGet unexpected output for rounding by minutes or seconds.\n\npublic void testRound()\n{\n    Calendar testCalendar = Calendar.getInstance(TimeZone.getTimeZone(\"GMT\"));\n    testCalendar.set(2007, 6, 2, 8, 9, 50);\n    Date date = testCalendar.getTime();\n    System.out.println(\"Before round() \" + date);\n    System.out.println(\"After round()  \" + DateUtils.round(date, Calendar.MINUTE));\n}\n\n--2.1 produces\nBefore round() Mon Jul 02 03:09:50 CDT 2007\nAfter round()  Mon Jul 02 03:10:00 CDT 2007 -- this is what I would expect\n\n--2.2 and 2.3 produces\nBefore round() Mon Jul 02 03:09:50 CDT 2007\nAfter round()  Mon Jul 02 03:01:00 CDT 2007 -- this appears to be wrong\n",
    "desc_source": "jira"
  },
  "Lang_54": {
    "description": "LocaleUtils.toLocale() rejects strings with only language+variant\nLocaleUtils.toLocale() throws an exception on strings containing a language and a variant but no country code. For example : fr__POSIX\n\nThis string can be produced with the JDK by instanciating a Locale with an empty string for the country : new Locale(\"fr\", \"\", \"POSIX\").toString(). According to the javadoc for the Locale class a variant is allowed with just a language code or just a country code.\n\nCommons Configuration handles this case in its PropertyConverter.toLocale() method. I'd like to replace our implementation by the one provided by LocaleUtils, but our tests fail due to this case.",
    "desc_source": "jira"
  },
  "Lang_55": {
    "description": "StopWatch: suspend() acts as split(), if followed by stop()\nIn my opinion, it is a bug that suspend() acts as split(), if followed by stop(); see below:\n\n        StopWatch sw = new StopWatch();\n\n        sw.start();\n        Thread.sleep(1000);\n        sw.suspend();\n        // Time 1 (ok)\n        System.out.println(sw.getTime());\n\n        Thread.sleep(2000);\n        // Time 1 (again, ok)\n        System.out.println(sw.getTime());\n\n        sw.resume();\n        Thread.sleep(3000);\n        sw.suspend();\n        // Time 2 (ok)\n        System.out.println(sw.getTime());\n\n        Thread.sleep(4000);\n        // Time 2 (again, ok)\n        System.out.println(sw.getTime());\n\n        Thread.sleep(5000);\n        sw.stop();\n        // Time 2 (should be, but is Time 3 => NOT ok)\n        System.out.println(sw.getTime());\n\n\nsuspend/resume is like a pause, where time counter doesn't continue. So a following stop()-call shouldn't increase the time counter, should it?\n",
    "desc_source": "jira"
  },
  "Lang_56": {
    "description": "FastDateFormat.mRules is not transient or serializable\nReported by FindBugs.\n\nEither we need to make the Rule interface Serializable, or make mRules transient and add deserializing code to kick off init().",
    "desc_source": "jira"
  },
  "Lang_57": {
    "description": "NullPointerException in isAvailableLocale(Locale)\nFindBugs pointed out:\n\n   UwF: Field not initialized in constructor: org.apache.commons.lang.LocaleUtils.cAvailableLocaleSet\n\ncAvailableSet is used directly once in the source - and if availableLocaleSet() hasn't been called it will cause a NullPointerException.",
    "desc_source": "jira"
  },
  "Lang_58": {
    "description": "NumberUtils.createNumber throws NumberFormatException for one digit long\nNumberUtils.createNumber throws a NumberFormatException when parsing \"1l\", \"2l\" .. etc...\n\nIt works fine if you try to parse \"01l\" or \"02l\".  The condition isDigits(numeric.substring(1)), line 455 return false as numeric.substring(1) is an empty string for \"1l\"",
    "desc_source": "jira"
  },
  "Lang_59": {
    "description": "Bug in method appendFixedWidthPadRight of class StrBuilder causes an ArrayIndexOutOfBoundsException\nThere's a bug in method appendFixedWidthPadRight of class StrBuilder:\n\npublic StrBuilder appendFixedWidthPadRight(Object obj, int width, char padChar) {\n        if (width > 0) {\n            ensureCapacity(size + width);\n            String str = (obj == null ? getNullText() : obj.toString());\n            int strLen = str.length();\n            if (strLen >= width) {\n ==>            str.getChars(0, strLen, buffer, size);   <==== BUG: it should be str.getChars(0, width, buffer, size);\n            } else {\n                int padLen = width - strLen;\n                str.getChars(0, strLen, buffer, size);\n                for (int i = 0; i < padLen; i++) {\n                    buffer[size + strLen + i] = padChar;\n                }\n            }\n            size += width;\n        }\n        return this;\n    }\n\nThis is causing an ArrayIndexOutOfBoundsException, so this method is unusable when strLen > width.\n\nIt's counterpart method appendFixedWidthPadLeft seems to be ok.",
    "desc_source": "jira"
  },
  "Lang_60": {
    "description": "StrBuilder contains usages of thisBuf.length when they should use size\nWhile fixing LANG-294 I noticed that there are two other places in StrBuilder that reference thisBuf.length and unless I'm mistaken they shouldn't.",
    "desc_source": "jira"
  },
  "Lang_61": {
    "description": "StrBuilder.replaceAll and StrBuilder.deleteAll can throw ArrayIndexOutOfBoundsException.\nStrBuilder.replaceAll and StrBuilder.deleteAll can thrown ArrayIndexOutOfBoundsException's. Here are a couple of additions to the StrBuilderTest class that demonstrate this problem:\n\nStrBuilder.deleteAll() - added to testDeleteAll_String():\n\n        sb = new StrBuilder(\"\\n%BLAH%\\nDo more stuff\\neven more stuff\\n%BLAH%\\n\");\n        sb.deleteAll(\"\\n%BLAH%\");\n        assertEquals(\"\\nDo more stuff\\neven more stuff\\n\", sb.toString());\n\nthis causes the following error:\njava.lang.ArrayIndexOutOfBoundsException\n\tat java.lang.System.arraycopy(Native Method)\n\tat org.apache.commons.lang.text.StrBuilder.deleteImpl(StrBuilder.java:1114)\n\tat org.apache.commons.lang.text.StrBuilder.deleteAll(StrBuilder.java:1188)\n\tat org.apache.commons.lang.text.StrBuilderTest.testDeleteAll_String(StrBuilderTest.java:606)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat junit.framework.TestCase.runTest(TestCase.java:154)\n\tat junit.framework.TestCase.runBare(TestCase.java:127)\n\tat junit.framework.TestResult$1.protect(TestResult.java:106)\n\tat junit.framework.TestResult.runProtected(TestResult.java:124)\n\tat junit.framework.TestResult.run(TestResult.java:109)\n\tat junit.framework.TestCase.run(TestCase.java:118)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:208)\n\tat junit.framework.TestSuite.run(TestSuite.java:203)\n\tat org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)\n\n\nStrBuilder.replaceAll() - added to testReplaceAll_String_String():\n\n        sb = new StrBuilder(\"\\n%BLAH%\\nDo more stuff\\neven more stuff\\n%BLAH%\\n\");\n        sb.replaceAll(\"\\n%BLAH%\", \"\");\n        assertEquals(\"\\nDo more stuff\\neven more stuff\\n\", sb.toString());\n\nthis causes the exception:\n\njava.lang.ArrayIndexOutOfBoundsException\n\tat java.lang.System.arraycopy(Native Method)\n\tat org.apache.commons.lang.text.StrBuilder.replaceImpl(StrBuilder.java:1256)\n\tat org.apache.commons.lang.text.StrBuilder.replaceAll(StrBuilder.java:1339)\n\tat org.apache.commons.lang.text.StrBuilderTest.testReplaceAll_String_String(StrBuilderTest.java:763)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat junit.framework.TestCase.runTest(TestCase.java:154)\n\tat junit.framework.TestCase.runBare(TestCase.java:127)\n\tat junit.framework.TestResult$1.protect(TestResult.java:106)\n\tat junit.framework.TestResult.runProtected(TestResult.java:124)\n\tat junit.framework.TestResult.run(TestResult.java:109)\n\tat junit.framework.TestCase.run(TestCase.java:118)\n\tat junit.framework.TestSuite.runTest(TestSuite.java:208)\n\tat junit.framework.TestSuite.run(TestSuite.java:203)\n\tat org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:128)\n\tat org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)\n\tat org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)",
    "desc_source": "jira"
  },
  "Lang_62": {
    "description": "unescapeXml(\"&12345678;\") should be \"&12345678;\"\nFollowing test (in EntitiesTest.java) fails:\n\n    public void testNumberOverflow() throws Exception {\n        doTestUnescapeEntity(\"&#12345678;\", \"&#12345678;\");\n        doTestUnescapeEntity(\"x&#12345678;y\", \"x&#12345678;y\");\n        doTestUnescapeEntity(\"&#x12345678;\", \"&#x12345678;\");\n        doTestUnescapeEntity(\"x&#x12345678;y\", \"x&#x12345678;y\");\n    }\n\nMaximim value for char is 0xFFFF, so &#12345678; is invalid entity reference, and so should be left as is.",
    "desc_source": "jira"
  },
  "Lang_63": {
    "description": "DurationFormatUtils returns wrong result\nDurationFormatUtils returns wrong result.  oddly, it is only when Date is set to Dec 31, 2005\n\nThe following code will result in a String of -2 which is way off.\n\nI've tested against 2.1 and 2.2.\n\n        Calendar cal = Calendar.getInstance();\n        cal.set(Calendar.MONTH, Calendar.DECEMBER);\n        cal.set(Calendar.DAY_OF_MONTH, 31);\n        cal.set(Calendar.YEAR, 2005);\n        cal.set(Calendar.HOUR_OF_DAY, 0);\n        cal.set(Calendar.MINUTE, 0);\n        cal.set(Calendar.SECOND, 0);\n        cal.set(Calendar.MILLISECOND, 0);\n\n        String result = DurationFormatUtils.formatPeriod(cal.getTimeInMillis(), System.currentTimeMillis(), \"MM\");\n        System.out.println(result);\n",
    "desc_source": "jira"
  },
  "Lang_64": {
    "description": "ValuedEnum.compareTo(Object other) not typesafe - it easily could be...\nint org.apache.commons.lang.enums.ValuedEnum.compareTo(Object other)\n is not typesafe - if the int-values are the same, it will return \"0\" even for two totally different sub-classes of ValuedEnum",
    "desc_source": "jira"
  },
  "Lang_65": {
    "description": "[lang] DateUtils.truncate method is buggy when dealing with DST switching hours\nTry to truncate 2004-10-31 01:00:00 MDT by hour and you'll actually get 2004-10-\n31 01:00:00 MST, which is one hour after the input hour.\n\n    // truncate 2004-10-31 01:00:00 MDT\n    Date oct31_01MDT = new Date(1099206000000L);    \n    Date result = DateUtils.truncate(oct31_01MDT, Calendar.HOUR_OF_DAY);\n    assertEquals(oct31_01MDT, result);",
    "desc_source": "jira"
  },
  "JacksonCore_1": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_2": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_3": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_4": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_5": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_6": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_7": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_8": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_9": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_10": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_11": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_12": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_13": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_14": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_15": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_16": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_17": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_18": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_19": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_20": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_21": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_22": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_23": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_24": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_25": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonCore_26": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Compress_1": {
    "description": "CPIO reports unexpected EOF\nWhen unpacking an CPIO archive (made with the compress classes or even made with OSX cpio comandline tool) an EOF exception is thrown.\nHere is the testcode:\n\n        final File input = getFile(\"cmdcreated.cpio\");\n\n        final InputStream in = new FileInputStream(input);\n        CpioArchiveInputStream cin = new CpioArchiveInputStream(in);\n\n        CpioArchiveEntry entry = null;\n\n        while ((entry = (CpioArchiveEntry) cin.getNextCPIOEntry()) != null) {\n            File target = new File(dir, entry.getName());\n            final OutputStream out = new FileOutputStream(target);\n            IOUtils.copy(in, out);\n            out.close();\n        }\n\n        cin.close();\n\nStacktrace is here:\n\njava.io.EOFException\n\tat org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream.readFully(CpioArchiveInputStream.java:293)\n\tat org.apache.commons.compress.archivers.cpio.CpioArchiveInputStream.getNextCPIOEntry(CpioArchiveInputStream.java:168)\n\tat org.apache.commons.compress.archivers.cpio.CpioArchiveInputStreamTest.testCpioUnpack(CpioArchiveInputStreamTest.java:26)\n\t...\n\nThis happens with the first read access to the archive. It occured while my try to improve the testcases.\n\n",
    "desc_source": "jira"
  },
  "Compress_2": {
    "description": "Ar doesn't delete correct\nWhen working on the Testcases i figured out that a deletion from an Ar Archive is not as successful as it look at first glance.\nFor example: my bla.ar file contains test1.xml and test2.xml. I delete test2.xml\n\nThe \"getNextEntry\" Method just delivers test1.xml. Looks correct.\n\nBut checking the result file at commandline brings the following:\n\n$> ar -t /tmp/dir26673/bla.ar\ntest1.xml\ntest2.xml\n\nvi shows me that there is still the test2.xml entry in the archive,\neven when getNextEntry returns null.\n\nDeleting test2.xml and adding test.txt afterward brings the following:\n\n$> ar -t /tmp/dir24825/bla.ar\ntest.txt\nar: /tmp/dir24825/bla.ar: Inappropriate file type or format",
    "desc_source": "jira"
  },
  "Compress_3": {
    "description": "Are the public finish() methods ArchiveOutputStream implementations necessary and safe?\nSome of the ArchiveOutputStream implementations have public finish() methods. These are currently only called from the close() methods.\n\nSeems to me that there is no need to allow the finish() methods to be called externally, and the user can corrupt the output if they do.\n\nSurely the close() method is all that is needed?\n",
    "desc_source": "jira"
  },
  "Compress_4": {
    "description": "Are the public finish() methods ArchiveOutputStream implementations necessary and safe?\nSome of the ArchiveOutputStream implementations have public finish() methods. These are currently only called from the close() methods.\n\nSeems to me that there is no need to allow the finish() methods to be called externally, and the user can corrupt the output if they do.\n\nSurely the close() method is all that is needed?\n",
    "desc_source": "jira"
  },
  "Compress_5": {
    "description": "ZipArchiveInputStream doesn't report the end of a truncated archive\nIf a Zip archive is truncated, (e.g. because it is the first volume in a multi-volume archive) the ZipArchiveInputStream.read() method will not detect that fact. All calls to read() will return 0 bytes read. They will not return -1 (end of stream), nor will they throw any exception (which would seem like a good idea to me because the archive is truncated).\n\nI have tracked this problem to ZipArchiveInputStream.java, line 239. It contains a check\n\nif (read == 0 && inf.finished()) {\n    return -1;\n}\n\nFor truncated archives the read is always zero but the inf is never finished(). I suggest adding two lines below:\n\nif (read == 0 && inf.finished()) {\n    return -1;\n} else if (read == 0 && lengthOfLastRead == -1) {\n\tthrow new IOException(\"Truncated ZIP file\");\n}\n\nThis solves the problem in my tests.",
    "desc_source": "jira"
  },
  "Compress_6": {
    "description": "Creating zip files with many entries will ocassionally produce corrupted output\nOur application produces large numbers of zip files, often with 1000's of similarly named files contained within the zip. \nWhen we switched from the standard JDK zip classes to those in commons compress, we would ocassionally produce a zip file that had corrupted index entries and would fail to unzip successfully using 7-zip, winzip, etc.\n\nDebugging the zip creation showed that the the wrong offsets were being returned from the hashmap in ZipOutputStream for the entries that were being corrupted.  Further analysis revealed that this occurred when the filenames being added had a hash collision with another entry in the same output zip (which appears to happen quite frequently for us).\n\nThe issue appears to stem from the fact that ZipArchiveEntry can store the entry name either in its superclass if passed in on the ctor or in its own member attribute if set later via setName().  Not sure whether this functionality is really required?  Regardless, the root cause of the bug is that the equals() and hashCode() methods in ZipArchiveEntry do not always use the same filename value in their comparisons.  In fact if the filename of the entry is set in the ctor it will always treat two ZipArchiveEntries as equal.  This will break the offset hashmap whenever there is a hash collision as it will overwrite the previous entry, believeing it to be equal.\n\nPatch to follow.\n\n",
    "desc_source": "jira"
  },
  "Compress_7": {
    "description": "TarUtils.parseName does not properly handle characters outside the range 0-127\nif a tarfile contains files with special characters, the names of the tar entries are wrong.\n\nexample:\ncorrect name: 0302-0601-3\u00b1\u00b1\u00b1F06\u00b1W220\u00b1ZB\u00b1LALALA\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1\u00b1CAN\u00b1\u00b1DC\u00b1\u00b1\u00b104\u00b1060302\u00b1MOE.model\nname resolved by TarUtils.parseName: 0302-0101-3\uffb1\uffb1\uffb1F06\uffb1W220\uffb1ZB\uffb1HECKMODUL\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1\uffb1ECE\uffb1\uffb1DC\uffb1\uffb1\uffb107\uffb1060302\uffb1DOERN.model\n\nplease use: \nresult.append(new String(new byte[] { buffer[i] }));\n\ninstead of: \nresult.append((char) buffer[i]);\n\nto solve this encoding problem.",
    "desc_source": "jira"
  },
  "Compress_8": {
    "description": "TarArchiveEntry.parseTarHeader() includes the trailing space/NUL when parsing the octal size\nTarArchiveEntry.parseTarHeader() includes the trailing space/NUL when parsing the octal size.\n\nAlthough the size field in the header is 12 bytes, the last byte is supposed to be space or NUL - i.e. only 11 octal digits are allowed for the size.",
    "desc_source": "jira"
  },
  "Compress_9": {
    "description": "TarArchiveOutputStream.getBytesWritten() returns invalid value\nIt appears the TarArchiveOutputStream.getBytesWritten()returns zero or invalid value when queried.\nIn the code sample below, it returns zero, even after an sizeable file was processed.\nI've printed it twice, once before closing the output stream, and once after, just for the reference.\nIt is also demonstrable on multiple processed files.\n\nWithin the TarArchiveOutputStream.getBytesWritten() implementation, it appears the call for count(numToWrite) is made after the numToWrite is depleted in the process of actual byte writing. When call for count(numToWrite); is moved up, the returned values for TarArchiveOutputStream.getBytesWritten() are getting equal to the sum of the sizes of processed files. This is much closer to expected value (\"Returns the current number of bytes written to this stream.\") but still not correct, for that number should include the tar header sizes as well.\n\nAt any rate, please find the proposed patch below, merely moving count(numToWrite); up a few lines. This makes TarArchiveOutputStream.getBytesWritten() closer to true value.\n\n\nTest code:\n{code}\n@Test\n\tpublic void tartest() throws Exception {\n\t\t\n\t\tFileOutputStream myOutputStream = new FileOutputStream(\"C:/temp/tartest.tar\");\n\t\t\n\t\tArchiveOutputStream sTarOut = new ArchiveStreamFactory().createArchiveOutputStream(ArchiveStreamFactory.TAR, myOutputStream);\n\t\t\n\t\tFile sSource = new File(\"C:/share/od_l.txt\");\n\t\tTarArchiveEntry sEntry = new TarArchiveEntry(sSource);\n\t\tsTarOut.putArchiveEntry(sEntry);\n\t\t\n\t\tFileInputStream sInput = new FileInputStream(sSource);\n\t\tbyte[] cpRead = new byte[8192];\n\t\t\n\t\tint iRead = 0;\n\t\twhile ((iRead = sInput.read(cpRead)) > 0) {\n\t\t\tsTarOut.write(cpRead, 0, iRead);\n\t\t}\n\t\t\n\t\tsLog.info(\"Processed: \"+sTarOut.getBytesWritten()+\" bytes. File Len: \"+sSource.length());\n\t\t\n\t\tsInput.close();\n\t\tsTarOut.closeArchiveEntry();\n\t\tsTarOut.close();\n\n\t\tsLog.info(\"Processed: \"+sTarOut.getBytesWritten()+\" bytes. File Len: \"+sSource.length());\n\n\t\t\n\t\treturn;\n\t\t\t\n\t}\n{code}\n\nTest Output:\n{code}\nOct 21, 2011 9:09:28 AM com.cronsult.jndmpd.test.Backup tartest\nINFO: Processed: 0 bytes. File Len: 186974208\nOct 21, 2011 9:09:28 AM com.cronsult.jndmpd.test.Backup tartest\nINFO: Processed: 0 bytes. File Len: 186974208\n{code}\n\nProposed Patch:\n{code}\nIndex: src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\n===================================================================\n--- src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\t(revision 1187150)\n+++ src/main/java/org/apache/commons/compress/archivers/tar/TarArchiveOutputStream.java\t(working copy)\n@@ -276,6 +276,8 @@\n             // eliminate some of the buffer copying.\n             //\n         }\n+        \n+        count(numToWrite);\n \n         if (assemLen > 0) {\n             if ((assemLen + numToWrite) >= recordBuf.length) {\n@@ -325,7 +327,7 @@\n             wOffset += num;\n         }\n         \n-        count(numToWrite);\n+        \n     }\n \n     /**\n\n{code}",
    "desc_source": "jira"
  },
  "Compress_10": {
    "description": "Cannot Read Winzip Archives With Unicode Extra Fields\nI have a zip file created with WinZip containing Unicode extra fields. Upon attempting to extract it with org.apache.commons.compress.archivers.zip.ZipFile, ZipFile.getInputStream() returns null for ZipArchiveEntries previously retrieved with ZipFile.getEntry() or even ZipFile.getEntries(). See UTF8ZipFilesTest.patch in the attachments for a test case exposing the bug. The original test case stopped short of trying to read the entries, that's why this wasn't flagged up before. \n\nThe problem lies in the fact that inside ZipFile.java entries are stored in a HashMap. However, at one point after populating the HashMap, the unicode extra fields are read, which leads to a change of the ZipArchiveEntry name, and therefore a change of its hash code. Because of this, subsequent gets on the HashMap fail to retrieve the original values.\n\nZipFile.patch contains an (admittedly simple-minded) fix for this problem by reconstructing the entries HashMap after the Unicode extra fields have been parsed. The purpose of this patch is mainly to show that the problem is indeed what I think, rather than providing a well-designed solution.\n\nThe patches have been tested against revision 1210416.",
    "desc_source": "jira"
  },
  "Compress_11": {
    "description": "createArchiveInputStream detects text files less than 100 bytes as tar archives\nThe fix for COMPRESS-117 which modified ArchiveStreamFactory().createArchiveInputStream(inputstream) results in short text files (empirically seems to be those <= 100 bytes) being detected as tar archives which obviously is not desirable if one wants to know whether or not the files are archives.\nI'm not an expert on compressed archives but perhaps the heuristic that if a stream is interpretable as a tar file without an exception being thrown should only be applied on archives greater than 100 bytes?",
    "desc_source": "jira"
  },
  "Compress_12": {
    "description": "TarArchiveInputStream throws IllegalArgumentException instead of IOException\nTarArchiveInputStream is throwing  IllegalArgumentException instead of IOException on corrupt files, in direct contradiction to the Javadoc. Here is a stack-trace:\n\n{code}\njava.lang.IllegalArgumentException: Invalid byte -1 at offset 7 in '<some bytes>' len=8\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:86)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:790)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:308)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:198)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextEntry(TarArchiveInputStream.java:380)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarInputShop.<init>(TarInputShop.java:91)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarDriver.newTarInputShop(TarDriver.java:159)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarGZipDriver.newTarInputShop(TarGZipDriver.java:82)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarDriver.newInputShop(TarDriver.java:151)\n\tat de.schlichtherle.truezip.fs.archive.tar.TarDriver.newInputShop(TarDriver.java:47)\n\tat de.schlichtherle.truezip.fs.archive.FsDefaultArchiveController.mount(FsDefaultArchiveController.java:170)\n\tat de.schlichtherle.truezip.fs.archive.FsFileSystemArchiveController$ResetFileSystem.autoMount(FsFileSystemArchiveController.java:98)\n\tat de.schlichtherle.truezip.fs.archive.FsFileSystemArchiveController.autoMount(FsFileSystemArchiveController.java:47)\n\tat de.schlichtherle.truezip.fs.archive.FsArchiveController.autoMount(FsArchiveController.java:129)\n\tat de.schlichtherle.truezip.fs.archive.FsArchiveController.getEntry(FsArchiveController.java:160)\n\tat de.schlichtherle.truezip.fs.archive.FsContextController.getEntry(FsContextController.java:117)\n\tat de.schlichtherle.truezip.fs.FsDecoratingController.getEntry(FsDecoratingController.java:76)\n\tat de.schlichtherle.truezip.fs.FsDecoratingController.getEntry(FsDecoratingController.java:76)\n\tat de.schlichtherle.truezip.fs.FsConcurrentController.getEntry(FsConcurrentController.java:164)\n\tat de.schlichtherle.truezip.fs.FsSyncController.getEntry(FsSyncController.java:108)\n\tat de.schlichtherle.truezip.fs.FsFederatingController.getEntry(FsFederatingController.java:156)\n\tat de.schlichtherle.truezip.nio.file.TFileSystem.newDirectoryStream(TFileSystem.java:348)\n\tat de.schlichtherle.truezip.nio.file.TPath.newDirectoryStream(TPath.java:963)\n\tat de.schlichtherle.truezip.nio.file.TFileSystemProvider.newDirectoryStream(TFileSystemProvider.java:344)\n\tat java.nio.file.Files.newDirectoryStream(Files.java:400)\n\tat com.googlecode.boostmavenproject.GetSourcesMojo.convertToJar(GetSourcesMojo.java:248)\n\tat com.googlecode.boostmavenproject.GetSourcesMojo.download(GetSourcesMojo.java:221)\n\tat com.googlecode.boostmavenproject.GetSourcesMojo.execute(GetSourcesMojo.java:111)\n\tat org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:101)\n\t... 20 more\n{code}\n\nExpected behavior: TarArchiveInputStream should wrap the IllegalArgumentException in an IOException.",
    "desc_source": "jira"
  },
  "Compress_13": {
    "description": "ArchiveInputStream#getNextEntry(): Problems with WinZip directories with Umlauts\nThere is a problem when handling a WinZip-created zip with Umlauts in directories.\n\nI'm accessing a zip file created with WinZip containing a directory with an umlaut (\"\u00e4\") with ArchiveInputStream. When creating the zip file the unicode-flag of winzip had been active.\n\nThe following problem occurs when accessing the entries of the zip:\nthe ArchiveEntry for a directory containing an umlaut is not marked as a directory and the file names for the directory and all files contained in that directory contain backslashes instead of slashes (i.e. completely different to all other files in directories with no umlaut in their path).\n\nThere is no difference when letting the ArchiveStreamFactory decide which ArchiveInputStream to create or when using the ZipArchiveInputStream constructor with the correct encoding (I've tried different encodings CP437, CP850, ISO-8859-15, but still the problem persisted).\n\nThis problem does not occur when using the very same zip file but compressed by 7zip or the built-in Windows 7 zip functionality.",
    "desc_source": "jira"
  },
  "Compress_14": {
    "description": "Tar files created by AIX native tar, and which contain symlinks, cannot be read by TarArchiveInputStream\nA simple tar file created on AIX using the native ({{/usr/bin/tar}} tar utility) *and* which contains a symbolic link, cannot be loaded by TarArchiveInputStream:\n\n{noformat}\njava.io.IOException: Error detected parsing the header\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:201)\n\tat Extractor.extract(Extractor.java:13)\n\tat Extractor.main(Extractor.java:28)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.tools.ant.taskdefs.ExecuteJava.run(ExecuteJava.java:217)\n\tat org.apache.tools.ant.taskdefs.ExecuteJava.execute(ExecuteJava.java:152)\n\tat org.apache.tools.ant.taskdefs.Java.run(Java.java:771)\n\tat org.apache.tools.ant.taskdefs.Java.executeJava(Java.java:221)\n\tat org.apache.tools.ant.taskdefs.Java.executeJava(Java.java:135)\n\tat org.apache.tools.ant.taskdefs.Java.execute(Java.java:108)\n\tat org.apache.tools.ant.UnknownElement.execute(UnknownElement.java:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:597)\n\tat org.apache.tools.ant.dispatch.DispatchUtils.execute(DispatchUtils.java:106)\n\tat org.apache.tools.ant.Task.perform(Task.java:348)\n\tat org.apache.tools.ant.Target.execute(Target.java:390)\n\tat org.apache.tools.ant.Target.performTasks(Target.java:411)\n\tat org.apache.tools.ant.Project.executeSortedTargets(Project.java:1399)\n\tat org.apache.tools.ant.Project.executeTarget(Project.java:1368)\n\tat org.apache.tools.ant.helper.DefaultExecutor.executeTargets(DefaultExecutor.java:41)\n\tat org.apache.tools.ant.Project.executeTargets(Project.java:1251)\n\tat org.apache.tools.ant.Main.runBuild(Main.java:809)\n\tat org.apache.tools.ant.Main.startAnt(Main.java:217)\n\tat org.apache.tools.ant.launch.Launcher.run(Launcher.java:280)\n\tat org.apache.tools.ant.launch.Launcher.main(Launcher.java:109)\nCaused by: java.lang.IllegalArgumentException: Invalid byte 0 at offset 0 in '{NUL}1722000726 ' len=12\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:99)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:819)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:314)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:199)\n\t... 29 more\n{noformat}\n\nTested with 1.2 and the 1.4 nightly build from Feb 23 ({{Implementation-Build: trunk@r1292625; 2012-02-23 03:20:30+0000}})",
    "desc_source": "jira"
  },
  "Compress_15": {
    "description": "ZipArchiveInputStream and ZipFile don't produce equals ZipArchiveEntry instances\nI'm trying to use a ZipArchiveEntry coming from ZipArchiveInputStream that I stored somwhere for later with a ZipFile and it does not work.\n\nThe reason is that it can't find the ZipArchiveEntry in the ZipFile entries map. It is exactly the same zip file but both entries are not equals so the Map#get fail.\n\nAs far as I can see the main difference is that {{comment}} is null in ZipArchiveInputStream while it's en empty string in ZipFile. I looked at ZipArchiveInputStream and it looks like the comment (whatever it is) is simply not parsed while I can find some code related to the comment at the end of ZIipFile#readCentralDirectoryEntry.\n\nNote that java.util.zip does not have this issue. Did not checked what they do but the zip entries are equals.",
    "desc_source": "jira"
  },
  "Compress_16": {
    "description": "Too relaxed tar detection in ArchiveStreamFactory\nThe relaxed tar detection logic added in COMPRESS-117 unfortunately matches also some non-tar files like a [test AIFF file|https://svn.apache.org/repos/asf/tika/trunk/tika-parsers/src/test/resources/test-documents/testAIFF.aif] that Apache Tika uses. It would be good to improve the detection heuristics to still match files like the one in COMPRESS-117 but avoid false positives like the AIFF file in Tika.",
    "desc_source": "jira"
  },
  "Compress_17": {
    "description": "Tar file for Android backup cannot be read\nAttached tar file was generated by some kind of backup tool on Android. Normal tar utilities seem to handle it fine, but Commons Compress doesn't.\n\n{noformat}\njava.lang.IllegalArgumentException: Invalid byte 0 at offset 5 in '01750{NUL}{NUL}{NUL}' len=8\n    at org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:99)\n    at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:788)\n    at org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:308)\n{noformat}\n",
    "desc_source": "jira"
  },
  "Compress_18": {
    "description": "Long directory names can not be stored in a tar archive because of error when writing PAX headers\nTrying to add a directory to the TAR Archive that has a name longer than 100 bytes generates an exception with a stack trace similar to the following:\n\n{noformat}\njava.io.IOException: request to write '114' bytes exceeds size in header of '0' bytes for entry './PaxHeaders.X/layers/openstreetmap__osm.disy.net/.tiles/1.0.0/openstreetmap__osm.disy.net/default/'\n\n            at org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.write(TarArchiveOutputStream.java:385)\n\n            at java.io.OutputStream.write(Unknown Source)\n\n            at org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.writePaxHeaders(TarArchiveOutputStream.java:485)\n\n            at org.apache.commons.compress.archivers.tar.TarArchiveOutputStream.putArchiveEntry(TarArchiveOutputStream.java:312)\n\n            at net.disy.lib.io.tar.TarUtilities.addFile(TarUtilities.java:116)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:158)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.addDirectory(TarUtilities.java:162)\n\n            at net.disy.lib.io.tar.TarUtilities.tar(TarUtilities.java:77)\n\n            at net.disy.lib.io.tar.TarUtilities.tar(TarUtilities.java:42)\n\n            at net.disy.gisterm.tilecacheset.export.TileCacheSetExporter.tarTreeStructure(TileCacheSetExporter.java:262)\n\n            at net.disy.gisterm.tilecacheset.export.TileCacheSetExporter.export(TileCacheSetExporter.java:111)\n\n            at net.disy.gisterm.tilecacheset.desktop.controller.ExportController$1.run(ExportController.java:81)\n\n            ... 2 more\n{noformat}\n\nInformal source code investigation points to the problem being that for directory entries the code assumes that the length is 0 in putArchiveEntry (see TarArchiveOutputStream:321 ) but when writing the data, it actually writes some data (the filename) and the length written (filename size) is larger than the length expected (0).",
    "desc_source": "jira"
  },
  "Compress_19": {
    "description": "ZipException on reading valid zip64 file\nZipFile zip = new ZipFile(new File(\"ordertest-64.zip\")); throws ZipException \"central directory zip64 extended information extra field's length doesn't match central directory data.  Expected length 16 but is 28\".\n\nThe archive was created by using DotNetZip-WinFormsTool uzing zip64 flag (forces always to make zip64 archives).\n\nZip file is tested from the console: $zip -T ordertest-64.zip\n\nOutput:\ntest of ordertest-64.zip OK\n\nI can open the archive with FileRoller without problem on my machine, browse and extract it.\n",
    "desc_source": "jira"
  },
  "Compress_20": {
    "description": "IllegalArgumentException reading CPIO generated by Redline RPM\nhttp://redline-rpm.org/ creates CPIO archives with a non-zero file mode on the trailer. This causes an IllegalArgumentException when reading the file. I've attached a patch and test archive to fix this.",
    "desc_source": "jira"
  },
  "Compress_21": {
    "description": "Writing 7z empty entries produces incorrect or corrupt archive\nI couldn't find an exact rule that causes this incorrect behavior, but I tried to reduce it to some simple scenarios to reproduce it:\n\nInput: A folder with certain files -> tried to archive it.\nIf the folder contains more than 7 files the incorrect behavior appears.\n\nScenario 1: 7 empty files\nResult: The created archive contains a single folder entry with the name of the archive (no matter which was the name of the file)\n\nScenario 2: 7 files, some empty, some with content\nResult: The created archive contains a folder entry with the name of the archive and a number of file entries also with the name of the archive. The number of the entries is equal to the number of non empty files.\n\nScenario 3: 8 empty files\nResult: 7zip Manager cannot open archive and stops working.\n\nScenario 4.1: 8 files: some empty, some with content, last file (alphabetically) with content\nResult: same behavior as described for Scenario 2.\n\nScenario 4.2: 8 files, some empty, some with content, last file empy\nResult: archive is corrupt, the following message is received: \"Cannot open file 'archivename.7z' as archive\" (7Zip Manager does not crash).",
    "desc_source": "jira"
  },
  "Compress_22": {
    "description": "BZip2CompressorInputStream reads fewer bytes from truncated file than CPython's bz2 implementation\nJython includes support for decompressing bz2 files using commons compress and shares regression tests with CPython. The CPython test [test_read_truncated|https://bitbucket.org/jython/jython/src/b2890af7a5e817e30f6ca2325f6dcdb14a59f32b/lib-python/2.7/test/test_bz2.py?at=default#cl-331] in test_bz2.py passes under CPython but fails under Jython.\n\nThe BZip2CompressorInputStream is able to read 769 bytes from the truncated data rather than the 770 bytes that the CPython bz2 implementation can read.",
    "desc_source": "jira"
  },
  "Compress_23": {
    "description": "7z: 16 MB dictionary is too big\nI created an archiv with 7zip 9.20 containing the compress-1.7-src directory. Also tried it with 1.6 version and directory. I \n\ndownloaded the zip file and reziped it as 7z. The standard setting where used:\nCompression level: normal\nCompression method: lzma2\nDictionary size: 16 MB\nWord size: 32\nSolid Block size: 2 GB\n\nI get an exception if I try to open the file with the simple line of code:\nSevenZFile input = new SevenZFile(new File(arcName));\n\nMaybe it is a bug in the tukaani library, but I do not know how to report it to them.\nThe exception thrown:\n\norg.tukaani.xz.UnsupportedOptionsException: LZMA dictionary is too big for this implementation\n\tat org.tukaani.xz.LZMAInputStream.initialize(Unknown Source)\n\tat org.tukaani.xz.LZMAInputStream.<init>(Unknown Source)\n\tat org.apache.commons.compress.archivers.sevenz.Coders$LZMADecoder.decode(Coders.java:117)\n\tat org.apache.commons.compress.archivers.sevenz.Coders.addDecoder(Coders.java:48)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.readEncodedHeader(SevenZFile.java:278)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.readHeaders(SevenZFile.java:190)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.<init>(SevenZFile.java:94)\n\tat org.apache.commons.compress.archivers.sevenz.SevenZFile.<init>(SevenZFile.java:116)\n\tat compress.SevenZipError.main(SevenZipError.java:28)",
    "desc_source": "jira"
  },
  "Compress_24": {
    "description": "TarArchiveInputStream fails to read entry with big user-id value\nCaused by: java.lang.IllegalArgumentException: Invalid byte 52 at offset 7 in '62410554' len=8\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:130)\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctalOrBinary(TarUtils.java:175)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:953)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:940)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:324)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:247)\n\t... 5 more",
    "desc_source": "jira"
  },
  "Compress_25": {
    "description": "ZIP reads correctly with commons-compress 1.6, gives NUL bytes in 1.7\nWhen running the code below, commons-compress 1.6 writes:\n\n Content of test.txt:\n data\n\nBy comparison, commons-compress 1.7 writes\n\n Content of test.txt:\n ^@^@^@^@^@\n\npackage com.example.jrn;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveEntry;\nimport org.apache.commons.compress.archivers.zip.ZipArchiveInputStream;\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.lang.System;\n/**\n * Hello world!\n *\n */\npublic class App {\n  public static void main(String[] args) {\n    byte[] zip = {\n       (byte)0x50, (byte)0x4b, (byte)0x03, (byte)0x04, (byte)0x0a, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x03, (byte)0x7b,\n       (byte)0xd1, (byte)0x42, (byte)0x82, (byte)0xc5, (byte)0xc1, (byte)0xe6,\n       (byte)0x05, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x05, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)0x08, (byte)0x00, (byte)0x1c, (byte)0x00,\n       (byte)0x74, (byte)0x65, (byte)0x73, (byte)0x74, (byte)0x2e, (byte)0x74,\n       (byte)0x78, (byte)0x74, (byte)0x55, (byte)0x54, (byte)0x09, (byte)0x00,\n       (byte)0x03, (byte)0x56, (byte)0x62, (byte)0xbf, (byte)0x51, (byte)0x2a,\n       (byte)0x63, (byte)0xbf, (byte)0x51, (byte)0x75, (byte)0x78, (byte)0x0b,\n       (byte)0x00, (byte)0x01, (byte)0x04, (byte)0x01, (byte)0xff, (byte)0x01,\n       (byte)0x00, (byte)0x04, (byte)0x88, (byte)0x13, (byte)0x00, (byte)0x00,\n       (byte)0x64, (byte)0x61, (byte)0x74, (byte)0x61, (byte)0x0a, (byte)0x50,\n       (byte)0x4b, (byte)0x01, (byte)0x02, (byte)0x1e, (byte)0x03, (byte)0x0a,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x03,\n       (byte)0x7b, (byte)0xd1, (byte)0x42, (byte)0x82, (byte)0xc5, (byte)0xc1,\n       (byte)0xe6, (byte)0x05, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x05,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x08, (byte)0x00, (byte)0x18,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x01,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0xa0, (byte)0x81, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x74, (byte)0x65, (byte)0x73,\n       (byte)0x74, (byte)0x2e, (byte)0x74, (byte)0x78, (byte)0x74, (byte)0x55,\n       (byte)0x54, (byte)0x05, (byte)0x00, (byte)0x03, (byte)0x56, (byte)0x62,\n       (byte)0xbf, (byte)0x51, (byte)0x75, (byte)0x78, (byte)0x0b, (byte)0x00,\n       (byte)0x01, (byte)0x04, (byte)0x01, (byte)0xff, (byte)0x01, (byte)0x00,\n       (byte)0x04, (byte)0x88, (byte)0x13, (byte)0x00, (byte)0x00, (byte)0x50,\n       (byte)0x4b, (byte)0x05, (byte)0x06, (byte)0x00, (byte)0x00, (byte)0x00,\n       (byte)0x00, (byte)0x01, (byte)0x00, (byte)0x01, (byte)0x00, (byte)0x4e,\n       (byte)0x00, (byte)0x00, (byte)0x00, (byte)0x47, (byte)0x00, (byte)0x00,\n       (byte)0x00, (byte)0x00, (byte)00\n    };\n\n    ByteArrayInputStream bin = new ByteArrayInputStream(zip);\n    try {\n      ZipArchiveInputStream in = new ZipArchiveInputStream(bin);\n      try {\n        while (true) {\n          ZipArchiveEntry entry = in.getNextZipEntry();\n          if (entry == null) {\n            break;\n          }\n          byte[] buf = new byte[(int) entry.getSize()];\n          in.read(buf);\n          System.out.println(\"Content of \" + entry.getName() + \":\");\n          System.out.write(buf);\n        }\n      } finally {\n        in.close();\n      }\n    } catch (IOException e) {\n      System.err.println(\"IOException: \" + e);\n    }\n  }\n}",
    "desc_source": "jira"
  },
  "Compress_26": {
    "description": "IOUtils.skip does not work as advertised\nI am trying to feed a TarInputStream from a CipherInputStream.\nIt does not work, because IOUtils.skip() does not adhere to the contract it claims in javadoc:\n\n\"     * <p>This method will only skip less than the requested number of\n     * bytes if the end of the input stream has been reached.</p>\"\n\nHowever it does:\n\n            long skipped = input.skip(numToSkip);\n            if (skipped == 0) {\n                break;\n            }\n\nAnd the input stream javadoc says:\n\n\"     * This may result from any of a number of conditions; reaching end of file\n     * before <code>n</code> bytes have been skipped is only one possibility.\"\n\nIn the case of CipherInputStream, it stops at the end of each byte buffer.\n\nIf you check the IOUtils from colleagues at commons-io, they have considered this case in IOUtils.skip() where they use a read to skip through the stream.\nAn optimized version could combine trying to skip, then read then trying to skip again.",
    "desc_source": "jira"
  },
  "Compress_27": {
    "description": "Incorrect handling of NUL username and group Tar.gz entries\nWith version 1.8 of commons-compress it's no longer possible to decompress  files from an archive if the archive contains entries having null (or being empty?) set as username and/or usergroup. With version 1.7 this still worked now I get this exception:\n\n{code}\njava.io.IOException: Error detected parsing the header\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:249)\n\tat TestBed.AppTest.extractNoFileOwner(AppTest.java:30)\nCaused by: java.lang.IllegalArgumentException: Invalid byte 32 at offset 7 in '       {NUL}' len=8\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:134)\n\tat org.apache.commons.compress.archivers.tar.TarUtils.parseOctalOrBinary(TarUtils.java:173)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:953)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:940)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:324)\n\tat org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:247)\n\t... 27 more\n\n{code}\nThis exception leads to my suspision that the regression was introduced with the fix for this ticket COMPRESS-262, which has a nearly identical exception provided.\n\nSome test code you can run to verify it:\n\n{code}\npackage TestBed;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\n\nimport org.apache.commons.compress.archivers.tar.TarArchiveEntry;\nimport org.apache.commons.compress.archivers.tar.TarArchiveInputStream;\nimport org.apache.commons.compress.compressors.gzip.GzipCompressorInputStream;\nimport org.junit.Test;\n\n/**\n * Unit test for simple App.\n */\npublic class AppTest\n{\n\n    @Test\n    public void extractNoFileOwner()\n    {\n        TarArchiveInputStream tarInputStream = null;\n\n        try\n        {\n            tarInputStream =\n                new TarArchiveInputStream( new GzipCompressorInputStream( new FileInputStream( new File(\n                    \"/home/pknobel/redis-dist-2.8.3_1-linux.tar.gz\" ) ) ) );\n            TarArchiveEntry entry;\n            while ( ( entry = tarInputStream.getNextTarEntry() ) != null )\n            {\n                System.out.println( entry.getName() );\n                System.out.println(entry.getUserName()+\"/\"+entry.getGroupName());\n            }\n\n        }\n        catch ( FileNotFoundException e )\n        {\n            e.printStackTrace();\n        }\n        catch ( IOException e )\n        {\n            e.printStackTrace();\n        }\n    }\n\n}\n{code}\nWith 1.7 the TestCase outputed this:\n\n{code}\nredis-dist-2.8.3_1/bin/\n/\nredis-dist-2.8.3_1/bin/redis-server\njenkins/jenkins\nredis-dist-2.8.3_1/bin/redis-cli\njenkins/jenkins\n{code}\n\nWith 1.8 it's failing once it reaches the null valued entry, which is the first. The archive is created using maven assembly plugin, and I tried the same with maven ant task. Both generating an archive with not set username and groups for at least some entries.\n\nYou can download the archive from http://heli0s.darktech.org/redis/2.8.3_1/redis-dist-2.8.3_1-linux.tar.gz\n\nIf you run a tar -tvzf on the file you see this report:\n\n{code}\ndrwxr-xr-x 0/0               0 2014-04-18 09:43 redis-dist-2.8.3_1-SNAPSHOT/bin/\n-rwxr-xr-x pknobel/pknobel 3824588 2014-01-02 14:58 redis-dist-2.8.3_1-SNAPSHOT/bin/redis-cli\n-rwxr-xr-x pknobel/pknobel 5217234 2014-01-02 14:58 redis-dist-2.8.3_1-SNAPSHOT/bin/redis-server\n{code}\n\nThe user 0/0 probably indicates that it's not set although it's the root user id. A correctly root user file would show up as root/root",
    "desc_source": "jira"
  },
  "Compress_28": {
    "description": "TarArchiveInputStream silently finished when unexpected EOF occured\nI just found the following test case didn't raise an IOException as it used to be for a *tar trimmed on purpose* \n\n@Test\n  public void testCorruptedBzip2() throws IOException {\n    String archivePath = PathUtil.join(testdataDir, \"test.tar.bz2\");\n    TarArchiveInputStream input = null;\n    input = new TarArchiveInputStream(new BZip2CompressorInputStream(\n        GoogleFile.SYSTEM.newInputStream(archivePath), true));\n    ArchiveEntry nextMatchedEntry = input.getNextEntry();\n    while (nextMatchedEntry != null) {\n      logger.infofmt(\"Extracting %s\", nextMatchedEntry.getName());\n      String outputPath = PathUtil.join(\"/tmp/\", nextMatchedEntry.getName());\n      OutputStream out = new FileOutputStream(outputPath);\n      ByteStreams.copy(input, out);\n      out.close();\n      nextMatchedEntry = input.getNextEntry();\n    }\n  }",
    "desc_source": "jira"
  },
  "Compress_29": {
    "description": "ArchiveStreamFactory fails to pass on the encoding when creating some streams\nArchiveStreamFactory fails to pass on the encoding when creating the following streams (in some or all cases):\n* ArjArchiveInputStream\n* CpioArchiveInputStream\n* DumpArchiveInputStream\n* JarArchiveInputStream\n* JarArchiveOutputStream",
    "desc_source": "jira"
  },
  "Compress_30": {
    "description": "BZip2CompressorInputStream return value wrong when told to read to a full buffer.\nBZip2CompressorInputStream.read(buffer, offset, length) returns -1 when given an offset equal to the length of the buffer.\n\nThis indicates, not that the buffer was full, but that the stream was finished.\n\nIt seems like a pretty stupid thing to do - but I'm getting this when trying to use Kryo serialization (which is probably a bug on their part, too), so it does occur and has negative affects.\n\nHere's a JUnit test that shows the problem specifically:\n\n{noformat}\n\t@Test\n\tpublic void testApacheCommonsBZipUncompression () throws Exception {\n\t\t// Create a big random piece of data\n\t\tbyte[] rawData = new byte[1048576];\n\t\tfor (int i=0; i<rawData.length; ++i) {\n\t\t\trawData[i] = (byte) Math.floor(Math.random()*256);\n\t\t}\n\n\t\t// Compress it\n\t\tByteArrayOutputStream baos = new ByteArrayOutputStream();\n\t\tBZip2CompressorOutputStream bzipOut = new BZip2CompressorOutputStream(baos);\n\t\tbzipOut.write(rawData);\n\t\tbzipOut.flush();\n\t\tbzipOut.close();\n\t\tbaos.flush();\n\t\tbaos.close();\n\n\t\t// Try to read it back in\n\t\tByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());\n\t\tBZip2CompressorInputStream bzipIn = new BZip2CompressorInputStream(bais);\n\t\tbyte[] buffer = new byte[1024];\n\t\t// Works fine\n\t\tAssert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));\n\t\t// Fails, returns -1 (indicating the stream is complete rather than that the buffer \n\t\t// was full)\n\t\tAssert.assertEquals(0, bzipIn.read(buffer, 1024, 0));\n\t\t// But if you change the above expected value to -1, the following line still works\n\t\tAssert.assertEquals(1024, bzipIn.read(buffer, 0, 1024));\n\t\tbzipIn.close();\n\t}\n{noformat}\n",
    "desc_source": "jira"
  },
  "Compress_31": {
    "description": "Illegal argument exception when extracting .tgz file \nWhen attempting to unpack a .tgz file, I am receiving the illegal argument exception: java.lang.IllegalArgumentException: Invalid byte 0 at offset 5 in '05412{NUL}11' len=8. This is causing a java.io.IOException: Error detected parsing the header error. \n\nThis is being thrown when the function TarArchiveInputStream.getNextTarEntry() is called. \n\nHere is the code I am using. \n\n{code:java}\n            TarArchiveInputStream tarIn = new TarArchiveInputStream(\n                    new GZIPInputStream(\n                            new BufferedInputStream(\n                                    new FileInputStream(\n                                            tempDirPath + fileName))));\n\n            TarArchiveEntry entry = tarIn.getNextTarEntry();\n\n            while (entry != null) {\n                File path = new File(tempDirPath, entry.getName());\n                if (entry.isDirectory()) {\n                    path.mkdirs();\n                } else {          \n                    path.createNewFile();\n                    byte[] read = new byte[2048];\n                    BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(path));\n                    int len;\n                    while ((len = tarIn.read(read)) != -1) {\n                        bout.write(read, 0, len);\n                        System.out.print(new String(read, \"UTF-8\"));\n                    }\n                    bout.close();\n                    read = null;\n                }\n                entry = tarIn.getNextTarEntry();\n            }\n            tarIn.close();\n{code}\n\nHere is the full stack trace: \n\n[2015-02-12T23:17:31.944+0000] [glassfish 4.0] [SEVERE] [] [] [tid: _ThreadID=123 _ThreadName=Thread-4] [timeMillis: 1423783051944] [levelValue: 1000] [[\n  java.io.IOException: Error detected parsing the header\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:257)\n        at org.unavco.ws.tilt.ExtractTiltFile.extractFile(ExtractTiltFile.java:125)\n        at org.unavco.ws.tilt.ExtractTiltFile.run(ExtractTiltFile.java:59)\n        at org.unavco.ws.cache.ProcessDataFile.getFileData(ProcessDataFile.java:100)\n        at org.unavco.ws.cache.ProcessDataFile.getResultSet(ProcessDataFile.java:81)\n        at org.unavco.ws.tilt.TiltDsClient.write(TiltDsClient.java:47)\n        at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:76)\n        at org.glassfish.jersey.message.internal.StreamingOutputProvider.writeTo(StreamingOutputProvider.java:58)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor$TerminalWriterInterceptor.aroundWriteTo(WriterInterceptorExecutor.java:194)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:139)\n        at org.glassfish.jersey.server.internal.JsonWithPaddingInterceptor.aroundWriteTo(JsonWithPaddingInterceptor.java:103)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:139)\n        at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundWriteTo(MappableExceptionWrapperInterceptor.java:88)\n        at org.glassfish.jersey.message.internal.WriterInterceptorExecutor.proceed(WriterInterceptorExecutor.java:139)\n        at org.glassfish.jersey.message.internal.MessageBodyFactory.writeTo(MessageBodyFactory.java:1005)\n        at org.glassfish.jersey.server.ServerRuntime$Responder.writeResponse(ServerRuntime.java:471)\n        at org.glassfish.jersey.server.ServerRuntime$Responder.processResponse(ServerRuntime.java:333)\n        at org.glassfish.jersey.server.ServerRuntime$Responder.process(ServerRuntime.java:323)\n        at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:227)\n        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271)\n        at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267)\n        at org.glassfish.jersey.internal.Errors.process(Errors.java:315)\n        at org.glassfish.jersey.internal.Errors.process(Errors.java:297)\n        at org.glassfish.jersey.internal.Errors.process(Errors.java:267)\n        at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317)\n        at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:198)\n        at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:946)\n        at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:323)\n        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:372)\n        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:335)\n        at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:218)\n        at org.apache.catalina.core.StandardWrapper.service(StandardWrapper.java:1682)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:344)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:214)\n        at com.thetransactioncompany.cors.CORSFilter.doFilter(Unknown Source)\n        at com.thetransactioncompany.cors.CORSFilter.doFilter(Unknown Source)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:256)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:214)\n        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:316)\n        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:160)\n        at org.apache.catalina.core.StandardPipeline.doInvoke(StandardPipeline.java:734)\n        at org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:673)\n        at com.sun.enterprise.web.WebPipeline.invoke(WebPipeline.java:99)\n        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:174)\n        at org.apache.catalina.connector.CoyoteAdapter.doService(CoyoteAdapter.java:357)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:260)\n        at com.sun.enterprise.v3.services.impl.ContainerMapper.service(ContainerMapper.java:188)\n        at org.glassfish.grizzly.http.server.HttpHandler.runService(HttpHandler.java:191)\n        at org.glassfish.grizzly.http.server.HttpHandler.doHandle(HttpHandler.java:168)\n        at org.glassfish.grizzly.http.server.HttpServerFilter.handleRead(HttpServerFilter.java:189)\n        at org.glassfish.grizzly.filterchain.ExecutorResolver$9.execute(ExecutorResolver.java:119)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.executeFilter(DefaultFilterChain.java:288)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.executeChainPart(DefaultFilterChain.java:206)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.execute(DefaultFilterChain.java:136)\n        at org.glassfish.grizzly.filterchain.DefaultFilterChain.process(DefaultFilterChain.java:114)\n        at org.glassfish.grizzly.ProcessorExecutor.execute(ProcessorExecutor.java:77)\n        at org.glassfish.grizzly.nio.transport.TCPNIOTransport.fireIOEvent(TCPNIOTransport.java:838)\n        at org.glassfish.grizzly.strategies.AbstractIOStrategy.fireIOEvent(AbstractIOStrategy.java:113)\n        at org.glassfish.grizzly.strategies.WorkerThreadIOStrategy.run0(WorkerThreadIOStrategy.java:115)\n        at org.glassfish.grizzly.strategies.WorkerThreadIOStrategy.access$100(WorkerThreadIOStrategy.java:55)\n        at org.glassfish.grizzly.strategies.WorkerThreadIOStrategy$WorkerThreadRunnable.run(WorkerThreadIOStrategy.java:135)\n        at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.doWork(AbstractThreadPool.java:564)\n        at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.run(AbstractThreadPool.java:544)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IllegalArgumentException: Invalid byte 0 at offset 5 in '05412{NUL}11' len=8\n        at org.apache.commons.compress.archivers.tar.TarUtils.parseOctal(TarUtils.java:138)\n        at org.apache.commons.compress.archivers.tar.TarUtils.parseOctalOrBinary(TarUtils.java:169)\n        at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:951)\n        at org.apache.commons.compress.archivers.tar.TarArchiveEntry.parseTarHeader(TarArchiveEntry.java:940)\n        at org.apache.commons.compress.archivers.tar.TarArchiveEntry.<init>(TarArchiveEntry.java:324)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:255)\n        ... 63 more]]\n\n\n",
    "desc_source": "jira"
  },
  "Compress_32": {
    "description": "TarArchiveInputStream rejects uid or gid >= 0x80000000\nA POSIX-format archive that came from sysdiagnose produces NumberFormatException[1] when I try to read it with TarArchiveInputStream.\n\nThe relevant part of the .tar file looks like this:\n\n   18 uid=429496729\n\nThat's the uid of 'nobody' on Mac OS (on Mac OS, uid_t is 'unsigned int').\n\nPOSIX doesn't say anything about the width of the uid extended header[2], so I assume the tar file is okay. GNU tar doesn't have trouble with it.\n\nThe relevant code, in applyPaxHeadersToCurrentEntry:\n\n            } else if (\"gid\".equals(key)){\n                currEntry.setGroupId(Integer.parseInt(val));\n...\n            } else if (\"uid\".equals(key)){\n                currEntry.setUserId(Integer.parseInt(val));\n\nuid_t and gid_t are typically unsigned 32-bit integers, so these should presumably use Long.parseLong to handle integers with the top bit set (and TarArchiveEntry would need some modifications to handle large uid and gid, too).\n\n[1] java.lang.NumberFormatException: For input string: \"4294967294\"\n        at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)\n        at java.lang.Integer.parseInt(Integer.java:495)\n        at java.lang.Integer.parseInt(Integer.java:527)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.applyPaxHeadersToCurrentEntry(TarArchiveInputStream.java:488)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.paxHeaders(TarArchiveInputStream.java:415)\n        at org.apache.commons.compress.archivers.tar.TarArchiveInputStream.getNextTarEntry(TarArchiveInputStream.java:295)\n\n[2] http://pubs.opengroup.org/onlinepubs/9699919799/utilities/pax.html#tag_20_92_13_03\nuid\nThe user ID of the file owner, expressed as a decimal number using digits from the ISO/IEC 646:1991 standard. This record shall override the uid field in the following header block(s). When used in write or copy mode, pax shall include a uid extended header record for each file whose owner ID is greater than 2097151 (octal 7777777).",
    "desc_source": "jira"
  },
  "Compress_33": {
    "description": "CompressorStreamFactory doesn't handle deflate streams with a zlib header\nIf you take a zlib / deflate compressed file, with the zlib header (eg the test file bla.tar.deflatez) and pass it to CompressorStreamFactory.createCompressorInputStream, it won't be detected and you'll get a CompressorException(\"No Compressor found for the stream signature.\")\n\nWhile detecting header-less zlib files is probably too tricky to manage, those with the header ought to be possible to spot and handle",
    "desc_source": "jira"
  },
  "Compress_34": {
    "description": "Exception in X7875_NewUnix.parseFromLocalFileData when parsing 0-sized \"ux\" local entry\nWhen trying to detect content type of a zip file with Tika 1.10 (which uses Commons Compress 1.9 internally) in manner like this:\n\n{code}\n        byte[] content = ... // whole zip file.\n        String name = \"TR_01.ZIP\";\n        Tika tika = new Tika();\n        return tika.detect(content, name);\n{code}\n\nit throws an exception:\n\n{code}\njava.lang.ArrayIndexOutOfBoundsException: 13\n\tat org.apache.commons.compress.archivers.zip.X7875_NewUnix.parseFromLocalFileData(X7875_NewUnix.java:199)\n\tat org.apache.commons.compress.archivers.zip.X7875_NewUnix.parseFromCentralDirectoryData(X7875_NewUnix.java:220)\n\tat org.apache.commons.compress.archivers.zip.ExtraFieldUtils.parse(ExtraFieldUtils.java:174)\n\tat org.apache.commons.compress.archivers.zip.ZipArchiveEntry.setCentralDirectoryExtra(ZipArchiveEntry.java:476)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.readCentralDirectoryEntry(ZipFile.java:575)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.populateFromCentralDirectory(ZipFile.java:492)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:216)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:192)\n\tat org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:153)\n\tat org.apache.tika.parser.pkg.ZipContainerDetector.detectZipFormat(ZipContainerDetector.java:141)\n\tat org.apache.tika.parser.pkg.ZipContainerDetector.detect(ZipContainerDetector.java:88)\n\tat org.apache.tika.detect.CompositeDetector.detect(CompositeDetector.java:77)\n\tat org.apache.tika.Tika.detect(Tika.java:155)\n\tat org.apache.tika.Tika.detect(Tika.java:183)\n\tat org.apache.tika.Tika.detect(Tika.java:223)\n{code}\n\nThe zip file does contain two .jpg images and is not a \"special\" (JAR, Openoffice, ... ) zip file.\n\nUnfortunately, the contents of the zip file is confidential and so I cannot attach it to this ticket as it is, although I can provide the parameters supplied to\norg.apache.commons.compress.archivers.zip.X7875_NewUnix.parseFromLocalFileData(X7875_NewUnix.java:199) as caught by the debugger:\n\n{code}\ndata = {byte[13]@2103}\n 0 = 85\n 1 = 84\n 2 = 5\n 3 = 0\n 4 = 7\n 5 = -112\n 6 = -108\n 7 = 51\n 8 = 85\n 9 = 117\n 10 = 120\n 11 = 0\n 12 = 0\noffset = 13\nlength = 0\n{code}\n\nThis data comes from the local zip entry for the first file, it seems the method tries to read more bytes than is actually available in the buffer.\n\nIt seems that first 9 bytes of the buffer are 'UT' extended field with timestamp, followed by 0-sized 'ux' field (bytes 9-12) that is supposed to contain UID/GID - according to infozip's doc the 0-size is common for global dictionary, but the local dictionary should contain complete data. In this case for some reason it does contain 0-sized data.\n\nNote that 7zip and unzip can unzip the file without even a warning, so Commons Compress should be also able to handle that file correctly without choking on that exception.",
    "desc_source": "jira"
  },
  "Compress_35": {
    "description": "TAR checksum fails when checksum is right aligned\nThe linked TAR has a checksum with zero padding on the left instead of the expected {{NULL-SPACE}} terminator on the right. As a result the last two digits of the stored checksum are lost and the otherwise valid checksum is treated as invalid.\n\nGiven that the code already checks for digits being in range before adding them to the stored sum, is it necessary to only look at the first 6 octal digits instead of the whole field?",
    "desc_source": "jira"
  },
  "Compress_36": {
    "description": "Calling SevenZFile.read() on empty SevenZArchiveEntry throws IllegalStateException\nI'm pretty sure COMPRESS-340 breaks reading empty archive entries. When calling getNextEntry() and that entry has no content, the code jumps into the first block at line 830 (SevenZFile.class), clearing the deferredBlockStreams. When calling entry.read(...) afterwards an IllegalStateException (\"No current 7z entry (call getNextEntry() first).\") is thrown. IMHO, there should be another check for entry.getSize() == 0.\n\nThis worked correctly up until 1.10.\n",
    "desc_source": "jira"
  },
  "Compress_37": {
    "description": "Parsing PAX headers fails with NegativeArraySizeException\nThe {{TarArchiveInputStream.parsePaxHeaders}} method fails with a {{NegativeArraySizeException}} when there is an empty line at the end of the headers.\n\nThe inner loop starts reading the length, but it gets a newline (10) and ends up subtracting '0' (48) from it; the result is a negative length that blows up an attempt to allocate the {{rest}} array.\n\nI would say that a check to see if {{ch}} is less the '0' and break the loop if it is.\n\nI used {{npm pack aws-sdk@2.2.16}} to generate a tarball with this issue.",
    "desc_source": "jira"
  },
  "Compress_38": {
    "description": "PAX header entry name ending with / causes problems\nThere seems to be a problem when a PAX header entry (link flag is 'x') has a name ending with \"/\". The {{TarArchiveEntry.isDirectory()}} check ends up returning {{true}} because of the trailing slash which means no content can be read from the entry. PAX header parsing effectively finds nothing and the stream is not advanced; this leaves the stream in a bad state as the next entry's header is actually read from the header contents.\n\nIf the name is modified to remove the trailing slash when the link flag indicates a PAX header everything seems to work fine. That would be one potential fix in {{parseTarHeader}}. Changing {{isDirectory}} to return {{false}} if {{isPaxHeader}} is {{true}} (before the trailing \"/\" check) would probably also fix the issue (though I can't verify that in the debugger like I can with changing the name).\n\nSo far I have only seen this when using Docker to save images that contain a yum database. For example:\n{noformat}\ndocker pull centos:latest && docker save centos:latest | tar x --include \"*/layer.tar\"\n{noformat}\nWill produce at least one \"layer.tar\" that exhibits this issue. If I come across a smaller TAR for testing I will attach it.",
    "desc_source": "jira"
  },
  "Compress_39": {
    "description": "Defective .zip-archive produces problematic error message\nA truncated .zip-File produces an java.io.EOFException conatining a hughe amount of byte[]-data in the error-message - leading to beeps and crippeling workload in an potential console-logger.\n\n",
    "desc_source": "jira"
  },
  "Compress_40": {
    "description": "Overflow in BitInputStream\nin Class BitInputStream.java(\\src\\main\\java\\org\\apache\\commons\\compress\\utils),\nfuncion:\n\n public long readBits(final int count) throws IOException {\n        if (count < 0 || count > MAXIMUM_CACHE_SIZE) {\n            throw new IllegalArgumentException(\"count must not be negative or greater than \" + MAXIMUM_CACHE_SIZE);\n        }\n        while (bitsCachedSize < count) {\n            final long nextByte = in.read();\n            if (nextByte < 0) {\n                return nextByte;\n            }\n            if (byteOrder == ByteOrder.LITTLE_ENDIAN) {\n                bitsCached |= (nextByte << bitsCachedSize);\n            } else {\n                bitsCached <<= 8;\n                bitsCached |= nextByte;\n            }\n            bitsCachedSize += 8;\n        }\n\n        final long bitsOut;\n        if (byteOrder == ByteOrder.LITTLE_ENDIAN) {\n            bitsOut = (bitsCached & MASKS[count]);\n            bitsCached >>>= count;\n        } else {\n            bitsOut = (bitsCached >> (bitsCachedSize - count)) & MASKS[count];\n        }\n        bitsCachedSize -= count;\n        return bitsOut;\n    }\n\n\n\nI think here \"bitsCached |= (nextByte << bitsCachedSize);\" will overflow in some cases. for example, below is a test case:\n\npublic static void test() {\n\n        ByteArrayInputStream in = new ByteArrayInputStream(new byte[]{87, 45, 66, 15,\n                                                                      90, 29, 88, 61, 33, 74});\n        BitInputStream bin = new BitInputStream(in, ByteOrder.LITTLE_ENDIAN);\n        try {\n            long ret = bin.readBits(5);\n            ret = bin.readBits(63);\n            ret = bin.readBits(12);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n}\n\noverflow occur in \"bin.readBits(63);\" , so ,result in wrong result from  \"bin.readBits(12);\" \n\n",
    "desc_source": "jira"
  },
  "Compress_41": {
    "description": "ZipArchiveInputStream.getNextZipEntry() should differentiate between \"invalid entry encountered\" and \"no more entries\"\nZipArchiveInputStream.getNextZipEntry() currently returns null if an invalid entry is encountered.  Thus, it's not possible to differentiate between \"no more entries\" and \"invalid entry encountered\" conditions.\n\nInstead, it should throw an exception if an invalid entry is encountered.\n\nI've created a test case and fix. I will submit a pull request shortly.",
    "desc_source": "jira"
  },
  "Compress_42": {
    "description": "isUnixSymlink returns true for Zip entries with Unix permissions 177777\nThis issue was originally reported in MASSEMBLY-842, but it seems the root cause in inside Commons Compress.\n\nConsider the attached {{invalid-entry.jar}}, whose contents, as shown by the {{zipinfo}} utility, is:\n\n{noformat}\n?rwsrwsrwt  2.0 unx        0 b- stor 17-Jan-15 16:06 META-INF/maven/\ndrwxr-xr-x  2.0 unx        0 b- stor 17-Jan-15 16:06 META-INF/\n{noformat}\n\nThere are some JAR files created by the Maven Assembly Plugin with content similar to this, and the entry {{META-INF/maven/}} has permissions 177777 (octal). Constructing a {{ZipFile}} from this file, the method {{isUnixSymlink}} incorrectly returns {{true}} for the entry {{META-INF/maven/}} (and it correctly returns {{false}} for the entry {{META-INF/}}.\n\nHere is a sample Java code that can be used to see the behaviour:\n\n{code:java}\npublic static void main(String[] args) throws IOException {\n    try (ZipFile zipFile = new ZipFile(new File(\"invalid-entry.jar\"))) {\n        printAttributes(zipFile, \"META-INF/\");\n        printAttributes(zipFile, \"META-INF/maven/\");\n    }\n}\n\nprivate static void printAttributes(ZipFile zipFile, String name) {\n    ZipArchiveEntry entry = zipFile.getEntriesInPhysicalOrder(name).iterator().next();\n    System.out.printf(\"%-17s: symlink:%-5s - unixMode:%s%n\", name, entry.isUnixSymlink(), entry.getUnixMode());\n}\n{code}\n\nThis code outputs:\n\n{noformat}\nMETA-INF/        : symlink:false - unixMode:16877\nMETA-INF/maven/  : symlink:true  - unixMode:65535\n{noformat}\n\nThe {{?rwsrwsrwt}} permissions show that the Zip entry is broken in the first place, but I think {{isUnixSymlink}} should still return {{false}} in that case, and not consider this entry to be a symlink.\n\nIt seems the fix would be to update {{isUnixSymlink}} and check whether the unix mode is equal to {{SHORT_MASK}}, and return {{false}} in that case as it would indicate a broken entry. This change does not break any existing tests, but I'm not sure if this is the proper fix.\n\n{code:java}\npublic boolean isUnixSymlink() {\n    int unixMode = getUnixMode();\n    return unixMode == SHORT_MASK ? false : (unixMode & UnixStat.LINK_FLAG) == UnixStat.LINK_FLAG;\n}\n{code}\n",
    "desc_source": "jira"
  },
  "Compress_43": {
    "description": "[Zip] Local `Version Needed To Extract` does not match Central Directory\nHi,\n\nThis is followup on an issue reported on Plexus Archiver - https://github.com/codehaus-plexus/plexus-archiver/issues/57\n\nPlexus Archiver uses {{ZipArchiveOutputStream}} to create zip archives. It constructs the {{ZipArchiveOutputStream}} using {{BufferedOutputStream}}. As a result the output do not provide random access and additional data descriptor records are added. Unfortunately this leads to different values being set for {{version needed to extract}} field in the local file header and in the central directory. It looks like that the root cause is the way the local header {{version needed to extract}} field value is calculated:\n{code:java}\n        if (phased &&  !isZip64Required(entry.entry, zip64Mode)){\n            putShort(INITIAL_VERSION, buf, LFH_VERSION_NEEDED_OFFSET);\n        } else {\n            putShort(versionNeededToExtract(zipMethod, hasZip64Extra(ze)), buf, LFH_VERSION_NEEDED_OFFSET);\n        }\n{code}\n\nAs you can see the need for data descriptors is not taken into account. On other hand when the central directory is created the following is used to determine the minimum required version\n\n{code:java}\n    private int versionNeededToExtract(final int zipMethod, final boolean zip64) {\n        if (zip64) {\n            return ZIP64_MIN_VERSION;\n        }\n        // requires version 2 as we are going to store length info\n        // in the data descriptor\n        return (isDeflatedToOutputStream(zipMethod)) ?\n                DATA_DESCRIPTOR_MIN_VERSION :\n                INITIAL_VERSION;\n    }\n{code}\n\nAs a side note: I'm not a zip expert by any means so I could be wrong, but my understanding is that if Deflate compression is used then the minimum required version should be 2.0 regardless if data descriptors are used or not.",
    "desc_source": "jira"
  },
  "Compress_44": {
    "description": "NullPointerException defect in ChecksumCalculatingInputStream#getValue()\nNullPointerException defect in ChecksumCalculatingInputStream#getValue() detected as stated in pull request 33: https://github.com/apache/commons-compress/pull/33\n\nFurthermore the following test describes the problem:\n\n{code:java}\n    @Test(expected = NullPointerException.class) //I assume this behaviour to be a bug or at least a defect.\n    public void testGetValueThrowsNullPointerException() {\n\n        ChecksumCalculatingInputStream checksumCalculatingInputStream = new ChecksumCalculatingInputStream(null,null);\n\n        checksumCalculatingInputStream.getValue();\n\n\n    }\n{code}\n\n",
    "desc_source": "jira"
  },
  "Compress_45": {
    "description": "TarUtils.formatLongOctalOrBinaryBytes never uses result of formatLongBinary\nif the length < 9, formatLongBinary is executed, then overwritten by the results of formatBigIntegerBinary. \n\nIf the results are not ignored, a unit test would fail.\n\nAlso, do the binary hacks  need to support negative numbers? ",
    "desc_source": "jira"
  },
  "Compress_46": {
    "description": "Tests failing under jdk 9 : one reflection issue, one change to ZipEntry related issue\nX5455_ExtendedTimestampTest is failing under JDK 9 , due to what appears to be a bogus value returned from getTime().  It seems like the test failure might be due to the changes introduced for this: \nhttps://bugs.openjdk.java.net/browse/JDK-8073497\n\nTests were run using intelliJ TestRunner, using the openjdk9 build from the tip of the jdk9 tree (not dev).  I believe that this is at most one commit away from what will be the RC (which was delayed at the last minute due to two issues, one of which was javadoc related, and the other hotspot. \n",
    "desc_source": "jira"
  },
  "Compress_47": {
    "description": "ZipArchiveInputStream#getNextZipEntry should verify compressed size is known for bzip2, implode etc.\n{code}\r\n        if (current.entry.getCompressedSize() != ArchiveEntry.SIZE_UNKNOWN) {\r\n            if (current.entry.getMethod() == ZipMethod.UNSHRINKING.getCode()) {\r\n                current.in = new UnshrinkingInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\r\n            } else if (current.entry.getMethod() == ZipMethod.IMPLODING.getCode()) {\r\n                current.in = new ExplodingInputStream(\r\n                        current.entry.getGeneralPurposeBit().getSlidingDictionarySize(),\r\n                        current.entry.getGeneralPurposeBit().getNumberOfShannonFanoTrees(),\r\n                        new BoundedInputStream(in, current.entry.getCompressedSize()));\r\n            } else if (current.entry.getMethod() == ZipMethod.BZIP2.getCode()) {\r\n                current.in = new BZip2CompressorInputStream(new BoundedInputStream(in, current.entry.getCompressedSize()));\r\n            }\r\n        }\r\n{code}\r\n\r\nnever sets {{current.in}} if the compressed size is unknown which probably leads to a NullPointerException in {{read}} later. We should fail early with a useful error message instead.",
    "desc_source": "jira"
  },
  "Collections_1": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_2": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_3": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_4": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_5": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_6": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_7": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_8": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_9": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_10": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_11": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_12": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_13": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_14": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_15": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_16": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_17": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_18": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_19": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_20": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_21": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_22": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_23": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_24": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Collections_25": {
    "description": "IteratorUtils.collatedIterator do not use natural ordering if no comparator was provided\nIn case a null comparator was provided natural ordering should be used, as stated in the javadoc.\n\nIn fact an exception is thrown the first time the returned iterator is used.",
    "desc_source": "jira"
  },
  "Collections_26": {
    "description": "MultiKey subclassing has deserialization problem since COLLECTIONS-266: either declare protected readResolve() or MultiKey must be final\nMultiKey from collections 4 provides a transient hashCode and a *private* readResolve to resolve COLLECTIONS-266: Issue with MultiKey when serialized/deserialized via RMI.\n\nUnfortunately the solution does not work in case of *subclassing*: readResolve in MultiKey should be declared *protected* readResolve() to be called during deserialization of the subclass. Otherwise MultiKey must be final to avoid such subclassing.\n\n*Testcase*:\n{code:java|title=MultiKeySerializationTest.java}\npackage de.ivu.test.common.collections4;\n\nimport static org.junit.Assert.assertEquals;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\n\nimport org.apache.commons.collections4.keyvalue.MultiKey;\nimport org.junit.Test;\n\npublic class MultiKeySerializationTest {\n\n    @Test\n    @SuppressWarnings(\"unchecked\")\n    public void testReadResolveEqualHashCode()\n            throws IOException, ClassNotFoundException {\n        class MultiKey2<A, B>\n                extends MultiKey {\n\n            private static final long serialVersionUID = 1928896152249821416L;\n\n            public MultiKey2(A key1, B key2) {\n                super(key1, key2);\n            }\n\n            public A getFirst() {\n                return (A) getKey(0);\n            }\n\n            public B getSecond() {\n                return (B) getKey(1);\n            }\n            \n            // FIXME: MultiKey should either declare protected readResolve() or must be final.\n        }\n        MultiKey2<String, String> one = new MultiKey2<>(\"bla\", \"blub\");\n        System.out.println(one.hashCode());\n        ByteArrayOutputStream byteOut = new ByteArrayOutputStream();\n        ObjectOutputStream out = new ObjectOutputStream(byteOut);\n        out.writeObject(one);\n        out.close();\n        byte[] serialized = byteOut.toByteArray();\n        ByteArrayInputStream byteIn = new ByteArrayInputStream(serialized);\n        ObjectInputStream in = new ObjectInputStream(byteIn);\n        MultiKey2<String, String> two = (MultiKey2<String, String>) in.readObject();\n        System.out.println(two.hashCode());\n        assertEquals(\"hashCode must be equal - please check for protected readResolve in MultiKey*\", one.hashCode(),\n            two.hashCode());\n    }\n}\n{code}\n\n*Fix:*\n{code:java|title=MultiKey.java}\n@@ -274,7 +274,7 @@\n      * only stable for the same process).\n      * @return the instance with recalculated hash code\n      */\n-    private Object readResolve() {\n+    protected Object readResolve() {\n         calculateHashCode(keys);\n         return this;\n     }\n{code}",
    "desc_source": "jira"
  },
  "Collections_27": {
    "description": "Arbitrary remote code execution with InvokerTransformer\nWith {{InvokerTransformer}} serializable collections can be build that execute arbitrary Java code. {{sun.reflect.annotation.AnnotationInvocationHandler#readObject}} invokes {{#entrySet}} and {{#get}} on a deserialized collection. If you have an endpoint that accepts serialized Java objects (JMX, RMI, remote EJB, ...) you can combine the two to create arbitrary remote code execution vulnerability.\n\nI don't know of a good fix short of removing {{InvokerTransformer}} or making it not Serializable. Both probably break existing applications.\n\nThis is not my research, but has been discovered by other people.\n\nhttps://github.com/frohoff/ysoserial\n\nhttp://foxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-application-have-in-common-this-vulnerability/\n",
    "desc_source": "jira"
  },
  "Collections_28": {
    "description": "PatriciaTrie prefixMap clear throws NullPointerException\nClearing all entries of a prefixMap returned by PatriciaTrie using the {{clear}} method throws a NullPointerException. The workaround of removing each entry using the {{remove}} method seems to work.\n\nHere are the test cases for the bug and the workaround:\n\n{code:java}\npublic class PatriciaTrieTest {\n\n    private Trie<String, Integer> trie;\n\n    @Before\n    public void setUp() {\n        trie = new PatriciaTrie<Integer>();\n        trie.put(\"Anna\", 1);\n        trie.put(\"Anael\", 2);\n        trie.put(\"Analu\", 3);\n        trie.put(\"Andreas\", 4);\n        trie.put(\"Andrea\", 5);\n        trie.put(\"Andres\", 6);\n        trie.put(\"Anatole\", 7);\n    }\n\n    @Test\n    public void testPrefixMapClear() {\n        SortedMap<String, Integer> prefixMap = trie.prefixMap(\"And\");\n        assertEquals(new HashSet<>(Arrays.asList(\"Andrea\", \"Andreas\", \"Andres\")), prefixMap.keySet());\n        assertEquals(Arrays.asList(5, 4, 6), new ArrayList<>(prefixMap.values()));\n\n        prefixMap.clear();\n        assertTrue(prefixMap.keySet().isEmpty());\n        assertTrue(prefixMap.values().isEmpty());\n        assertEquals(new HashSet<>(Arrays.asList(\"Anael\", \"Analu\", \"Anatole\", \"Anna\")), trie.keySet());\n        assertEquals(Arrays.asList(2, 3, 7, 1), new ArrayList<>(trie.values()));\n    }\n\n    @Test\n    public void testPrefixMapClearUsingRemove() {\n        SortedMap<String, Integer> prefixMap = trie.prefixMap(\"And\");\n        assertEquals(new HashSet<>(Arrays.asList(\"Andrea\", \"Andreas\", \"Andres\")), prefixMap.keySet());\n        assertEquals(Arrays.asList(5, 4, 6), new ArrayList<>(prefixMap.values()));\n\n        Set<String> keys = new HashSet<String>(prefixMap.keySet());\n        for (final String key : keys) {\n            prefixMap.remove(key);\n        }\n        assertTrue(prefixMap.keySet().isEmpty());\n        assertTrue(prefixMap.values().isEmpty());\n        assertEquals(new HashSet<>(Arrays.asList(\"Anael\", \"Analu\", \"Anatole\", \"Anna\")), trie.keySet());\n        assertEquals(Arrays.asList(2, 3, 7, 1), new ArrayList<>(trie.values()));\n    }\n\n}\n{code}\n\nThe stacktrace of the NullPointerException thrown by the {{testPrefixMapClear}} test case is:\n{noformat}\njava.lang.NullPointerException\n\tat org.apache.commons.collections4.trie.AbstractPatriciaTrie$PrefixRangeEntrySet$EntryIterator.remove(AbstractPatriciaTrie.java:2370)\n\tat java.util.AbstractCollection.clear(AbstractCollection.java:432)\n\tat java.util.AbstractMap.clear(AbstractMap.java:288)\n\tat PatriciaTrieTest.testPrefixMapClear(PatriciaTrieTest.java:39)\n{noformat}",
    "desc_source": "jira"
  },
  "Closure_1": {
    "description": "function arguments should not be optimized away\nFunction arguments should not be optimized away, as this comprimizes the function's length property.\r\n\r\n<b>What steps will reproduce the problem?</b>\n\r\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\nfunction foo (bar, baz) {\r\n  return bar;\r\n}\r\nalert (foo.length);\r\nfunction foo (bar, baz) {\r\n  return bar;\r\n}\r\nalert (foo.length);\r\n\r\n--------------------------------------\r\n\r\nWhat is the expected output?\r\n\r\nfunction foo(a,b){return a}alert(foo.length);\r\n\r\n--------------------------------------\r\n\r\nWhat do you see instead?\r\n\r\nfunction foo(a){return a}alert(foo.length);\r\n\r\n--------------------------------------\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nI'm using the product from the web page http://closure-compiler.appspot.com/home\r\n\r\nI'm using Firefox 3.6.10 on Ubuntu 10.0.4\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nThe function's length property is essential to many techniques, such as currying functions.",
    "desc_source": "google"
  },
  "Closure_2": {
    "description": "combining @interface and multiple @extends can crash compiler\nCompile this:\r\n---------------------------------\r\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @warning_level VERBOSE\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\n/**\r\n * @interface\r\n * @extends {unknown_1}\r\n * @extends {unknown_2}\r\n */\r\nfunction Foo() {}\r\n---------------------------------\r\n\r\n=&gt; Get this..\r\n---------------------------------------\r\n23: java.lang.NullPointerException\r\n\tat com.google.javascript.jscomp.TypeCheck.checkInterfaceConflictProperties(TypeCheck.java:1544)\r\n\tat com.google.javascript.jscomp.TypeCheck.visitFunction(TypeCheck.java:1635)\r\n\tat com.google.javascript.jscomp.TypeCheck.visit(TypeCheck.java:761)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:509)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:502)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:502)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseWithScope(NodeTraversal.java:347)\r\n\tat com.google.javascript.jscomp.TypeCheck.check(TypeCheck.java:400)\r\n\tat com.google.javascript.jscomp.TypeCheck.process(TypeCheck.java:371)\r\n\tat com.google.javascript.jscomp.DefaultPassConfig$29$1.process(DefaultPassConfig.java:1209)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(PhaseOptimizer.java:303)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(PhaseOptimizer.java:279)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(PhaseOptimizer.java:191)\r\n\tat com.google.javascript.jscomp.Compiler.check(Compiler.java:814)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Compiler.java:729)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Compiler.java:85)\r\n\tat com.google.javascript.jscomp.Compiler$2.call(Compiler.java:637)\r\n\tat com.google.javascript.jscomp.Compiler$2.call(Compiler.java:634)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:694)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:634)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:590)\r\n\tat com.google.javascript.jscomp.webservice.backend.CompilerInvokerImpl.compile(CompilerInvokerImpl.java:47)\r\n\tat com.google.javascript.jscomp.webservice.backend.ServerController.executeRequest(ServerController.java:177)\r\n\tat com.google.javascript.jscomp.webservice.backend.CompilationRequestHandler.serviceParsedRequest(CompilationRequestHandler.java:180)\r\n\tat com.google.javascript.jscomp.webservice.backend.CompilationRequestHandler.service(CompilationRequestHandler.java:162)\r\n\tat com.google.javascript.jscomp.webservice.frontend.CompilationServlet.doPost(CompilationServlet.java:83)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:637)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\r\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)\r\n\tat com.google.apphosting.utils.servlet.ParseBlobUploadFilter.doFilter(ParseBlobUploadFilter.java:102)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.apphosting.runtime.jetty.SaveSessionFilter.doFilter(SaveSessionFilter.java:35)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:43)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)\r\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\r\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\r\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)\r\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)\r\n\tat com.google.apphosting.runtime.jetty.AppVersionHandlerMap.handle(AppVersionHandlerMap.java:266)\r\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\r\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\r\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\r\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:923)\r\n\tat com.google.apphosting.runtime.jetty.RpcRequestParser.parseAvailable(RpcRequestParser.java:76)\r\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\r\n\tat com.google.apphosting.runtime.jetty.JettyServletEngineAdapter.serviceRequest(JettyServletEngineAdapter.java:146)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.run(JavaRuntime.java:447)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable.runInContext(TraceContext.java:454)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable$1.run(TraceContext.java:461)\r\n\tat com.google.tracing.TraceContext.runInContext(TraceContext.java:703)\r\n\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContextNoUnref(TraceContext.java:338)\r\n\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContext(TraceContext.java:330)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable.run(TraceContext.java:458)\r\n\tat com.google.apphosting.runtime.ThreadGroupPool$PoolEntry.run(ThreadGroupPool.java:251)\r\n\tat java.lang.Thread.run(Thread.java:679)\r\n\r\nOriginal Post Data: \r\noutput_format=json&amp;output_info=compiled_code&amp;output_info=warnings&amp;output_info=errors&amp;output_info=statistics&amp;compilation_level=SIMPLE_OPTIMIZATIONS&amp;warning_level=VERBOSE&amp;output_file_name=default.js&amp;js_code=%2F**%0A*%20%40interface%0A*%20%40extends%20%7BA%7D%0A*%20%40extends%20%7BB%7D%0A*%2F%0Afunction%20Foo()%20%7B%7D\r\n------------------\r\n\r\n\r\nSeems like a combination of @interface plus more than one @extend and where at least one of the @extend types are unknown causes a crash.\r\n\r\nRegards\r\n/ Fredrik Blomqvist",
    "desc_source": "google"
  },
  "Closure_3": {
    "description": "optimization fails with variable in catch clause\nEnter the following in the closure service:\r\n\r\nfunction getStack() {\r\n  var getErrorObject = function() {\r\n    try {\r\n      throw Error(&quot;&quot;);\r\n    } catch(err) {\r\n      return err;\r\n    }\r\n  };\r\n  return getErrorObject().stack;\r\n}\r\nwindow['getStackTrace']=getStack;\r\n\r\nUse Optimization = Simple. Note the following result:\r\n\r\nfunction getStack() \r\n{ \r\n  try \r\n  { \r\n    throw Error(&quot;&quot;); \r\n  }\r\n  catch(a) \r\n  { \r\n  } \r\n  return a.stack \r\n} \r\nwindow.getStackTrace = getStack;\r\n\r\nThe scope of the variable a is limited to the catch clause, but the compiler references it illegally as the return value of the inlined function.",
    "desc_source": "google"
  },
  "Closure_4": {
    "description": "Converting from an interface type to a constructor which @implements itself causes stack overflow.\n// Options: --externs externs/es3.js --property_renaming OFF --variable_renaming OFF --jscomp_warning=checkTypes --js=t.js\r\n\r\n\r\n// File: t.js\r\n/**\r\n * @interface\r\n */\r\nvar OtherType = function() {}\r\n\r\n/**\r\n * @implements {MyType}\r\n * @constructor\r\n */\r\nvar MyType = function() {}\r\n\r\n/**\r\n * @type {MyType}\r\n */\r\nvar x = /** @type {!OtherType} */ (new Object());\r\n\r\nGet Infinite recursion in:\r\n\r\nPrototypeObjectType.isSubtype @ 350\r\n\r\nOptions:\r\n\r\n- prevent cycles in the inheritance/implements graph\r\n- detect cycles after they are created and exit compilation before any subsequent passes run\r\n- detect and remove cycles after they are created but before any subsequent passes run\r\n- make every subsequent pass robust against cycles in that graph",
    "desc_source": "google"
  },
  "Closure_5": {
    "description": "Compiler ignores 'delete' statements, can break functionality.\nWhen the compiler rewrites internally-referenced object variables to non-object  variables, as in the example below, it ignores 'delete' statements. These delete statements work as expected with the objects originally written, but don't function the same when the variables are no longer object properties. See:\r\n\r\n(function(arg) {\r\n  var foo = {};\r\n\r\n  foo.bar = arg;\r\n\r\n  console.log(foo.bar);\r\n\r\n  delete foo.bar;\r\n\r\n  console.log(foo.bar);\r\n})();\r\n\r\nCompiles to (simple setting):\r\n(function(a){console.log(a);delete a;console.log(a)})();\r\n\r\nPerhaps the compiler needs to look for these delete statements and change them to setting the rewritten variable to undefined instead.",
    "desc_source": "google"
  },
  "Closure_6": {
    "description": "better 'this' type checking\n/** @constructor */\r\nfunction F() {}\r\nF.prototype.bar = function() { this.baz(); };\r\nF.prototype.baz = function() { };\r\n\r\n/** @constructor */\r\nfunction G() {}\r\nG.prototype.bar = F.prototype.bar;\r\n\r\nWe should notice that &quot;F.prototype.bar&quot; and &quot;G.prototype.bar&quot; have different &quot;this&quot; types, and emit a warning.",
    "desc_source": "google"
  },
  "Closure_7": {
    "description": "Bad type inference with goog.isFunction and friends\nexperimental/johnlenz/typeerror/test.js:16: WARNING - Property length\r\nnever defined on Number\r\n      var i = object.length;\r\n\r\n\r\nThis is the reduced test case:\r\n\r\n/**\r\n * @param {*} object Any object.\r\n * @return {boolean}\r\n */\r\ntest.isMatched = function(object) {\r\n  if (goog.isDef(object)) {\r\n    if (goog.isFunction(object)) {\r\n      // return object();\r\n    } else if (goog.isBoolean(object)) {\r\n      // return object;\r\n    } else if (goog.isString(object)) {\r\n      // return test.isDef(object);\r\n    } else if (goog.isArray(object)) {\r\n      var i = object.length;\r\n    }\r\n  }\r\n  return false;\r\n};",
    "desc_source": "google"
  },
  "Closure_8": {
    "description": "Obfuscated code triggers TypeError in Firefox\nThe Closure Compiler is a great tool, but I'm having problems with it. It often produces code that triggers TypeError in Firefox, even though original code does not. Here is why. The original code may look as follows:\r\n\r\nfunction(argument){\r\n...//use argument\r\nvar variable = ...;\r\n...//argument not used anymore\r\n}\r\n\r\nBut often Closure Compiler will translate it to:\r\nfunction(a){\r\n...\r\nvar a = ...;\r\n...\r\n}\r\n\r\nThis is not wrong JS, since argument is no longer used, Closure Compiler tries to reuse the name 'a' for something else.\r\n\r\nThis triggers the following in Firefox 13-15:\r\nTypeError: variable a re-declares argument\r\n\r\nStill, the resulting code is correct and runs, but it's very annoying debugging it when I'm getting all the time a lot of TypeErrors in the console.\r\n\r\nAlso, our customers have noticed these TypeErrors when testing the product and it undermines our code reliability.\r\n\r\nCould you please rename variables in such a way as to avoid these TypeErrors (not to rename vars in a way that will coincide with function argument names)?\r\n\r\n<b>What steps will reproduce the problem?</b>\nThis happens reproducibly on our real-life JS input, which I cannot submit for various reasons. If my problem description is not clear enough, please make a comment and I will try to construct some artificial example that also triggers the TypeError.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThe expected output is obfuscated code with variables renamed to unique names, in order not to trigger TypeError in Firefox. Instead I see variables renamed to the same name, which runs OK, but Firefox complains with TypeError.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nClosure Compiler (http://code.google.com/closure/compiler)\r\nVersion: 20120917 (revision 2180)\r\nBuilt on: 2012/09/17 14:33\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_9": {
    "description": "Compiler fails to find amd module in a subdirectory\n<b>What steps will reproduce the problem?</b>\n\r\n1. Create 1st AMD module in lib/Foo.js\r\n2. Create 2nd AMD module in Bar.js depending on lib/Foo.js\r\n3. Try to compile both files with Bar.js as main module\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\njava -jar compiler.jar --transform_amd_modules --process_common_js_modules --common_js\r\n_entry_module=Bar.js --compilation_level=ADVANCED_OPTIMIZATIONS --js_output_file=out.js --js=Bar.js --js=lib/Foo.js\r\nERROR - required entry point &quot;module$lib$Foo&quot; never provided\r\n\r\n1 error(s), 0 warning(s)\r\nmake: *** [out.js] Error 1\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nLatest version from trunk including fix for issue #804\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nFind minimal not-working example attached with Makefile. The same setup has been working prior to fix for #804 (although with backslashes). This feature does not seem to have enough unit test coverage.",
    "desc_source": "google"
  },
  "Closure_10": {
    "description": "Wrong code generated if mixing types in ternary operator\n<b>What steps will reproduce the problem?</b>\n1. Use Google Closure Compiler to compile this code:\r\n\r\n    var a =(Math.random()&gt;0.5? '1' : 2 ) + 3 + 4;\r\n\r\nYou can either simple or advanced. It doesn't matter\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nI'm seeing this as a result:\r\n    var a = (0.5 &lt; Math.random() ? 1 : 2) + 7;\r\n\r\nThis is obviously wrong as the '1' string literal got converted to a number, and 3+4 got combined into 7 while that's not ok as '1' + 3 + 4 = '134', not '17'.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nSeems like this issue happens only when you are mixing types together. If both 1 and 2 are string literals or if they are both numbers it won't happen. I was also a little surprised to see this happening in simple mode as it actually breaks the behavior.",
    "desc_source": "google"
  },
  "Closure_11": {
    "description": "Record type invalid property not reported on function with @this annotation\nCode:\r\n\r\nvar makeClass = function(protoMethods) {\r\n  var clazz = function() {\r\n    this.initialize.apply(this, arguments);\r\n  }\r\n  for (var i in protoMethods) {\r\n    clazz.prototype[i] = protoMethods[i];\r\n  }\r\n\r\n  return clazz;\r\n}\r\n\r\n/**\r\n * @constructor\r\n * @param {{name: string, height: number}} options\r\n */\r\nvar Person = function(options){};\r\nPerson = makeClass(/** @lends Person.prototype */ {\r\n  /**\r\n   * @this {Person}\r\n   * @param {{name: string, height: number}} options\r\n   */\r\n  initialize: function(options) {\r\n    /** @type {string} */ this.name_ = options.thisPropDoesNotExist;\r\n  },\r\n\r\n  /**\r\n   * @param {string} message\r\n   * @this {Person}\r\n   */\r\n  say: function(message) {\r\n    window.console.log(this.name_ + ' says: ' + message);\r\n  }\r\n});\r\n\r\n\r\nvar joe = new Person({name: 'joe', height: 300});\r\njoe.say('hi');\r\n\r\n\r\ncompiled with:\r\njava -jar build/compiler.jar --formatting=PRETTY_PRINT --jscomp_error=checkTypes --jscomp_error=externsValidation --compilation_level=SIMPLE_OPTIMIZATIONS repro.js\r\n\r\n\r\nI would expect an error on this line:\r\n    /** @type {string} */ this.name_ = options.thisPropDoesNotExist;\r\n\r\nwhich works in other contexts.\r\n\r\nThanks!",
    "desc_source": "google"
  },
  "Closure_12": {
    "description": "Try/catch blocks incorporate code not inside original blocks\n<b>What steps will reproduce the problem?</b>\n\r\nStarting with this code:\r\n\r\n-----\r\nfunction a() {\r\n var x = '1';\r\n try {\r\n  x += somefunction();\r\n } catch(e) {\r\n }\r\n x += &quot;2&quot;;\r\n try {\r\n  x += somefunction();\r\n } catch(e) {\r\n }\r\n document.write(x);\r\n}\r\n\r\na();\r\na();\r\n-----\r\n\r\nIt gets compiled to:\r\n\r\n-----\r\nfunction b() {\r\n  var a;\r\n  try {\r\n    a = &quot;1&quot; + somefunction()\r\n  }catch(c) {\r\n  }\r\n  try {\r\n    a = a + &quot;2&quot; + somefunction()\r\n  }catch(d) {\r\n  }\r\n  document.write(a)\r\n}\r\nb();\r\nb();\r\n-----\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nThe problem is that it's including the constant &quot;1&quot; and &quot;2&quot; inside the try block when the shouldn't be. When executed uncompiled, the script prints &quot;1212&quot;. When compiled, the script prints &quot;undefinedundefined&quot;.\r\n\r\nThis behavior doesn't happen if the entire function gets inlined, or if the code between the two try blocks is sufficiently complex.\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nClosure Compiler (http://code.google.com/closure/compiler)\r\nVersion: 20120430 (revision 1918)\r\nBuilt on: 2012/04/30 18:02\r\njava version &quot;1.6.0_33&quot;\r\nJava(TM) SE Runtime Environment (build 1.6.0_33-b03-424-11M3720)\r\nJava HotSpot(TM) 64-Bit Server VM (build 20.8-b03-424, mixed mode)",
    "desc_source": "google"
  },
  "Closure_13": {
    "description": "true/false are not always replaced for !0/!1\n<b>What steps will reproduce the problem?</b>\n\r\nfunction some_function() {\r\n  var fn1;\r\n  var fn2;\r\n\r\n  if (any_expression) {\r\n    fn2 = external_ref;\r\n    fn1 = function (content) {\r\n      return fn2();\r\n    }\r\n  }\r\n\r\n  return {\r\n    method1: function () {\r\n      if (fn1) fn1();\r\n      return true;\r\n    },\r\n    method2: function () {\r\n      return false;\r\n    }\r\n  }\r\n}\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nWe expect that true/false will be replaced for !0/!1, but it doesn't happend.\r\n\r\nfunction some_function() {\r\n  var a, b;\r\n  any_expression &amp;&amp; (b = external_ref, a = function () {\r\n    return b()\r\n  });\r\n  return {\r\n    method1: function () {\r\n      a &amp;&amp; a();\r\n      return true\r\n    },\r\n    method2: function () {\r\n      return false\r\n    }\r\n  }\r\n};\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nThis is output for latest official build.\r\nI also got the same output for 20120430, 20120305. But 20111117 is OK.\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nHere is just one of example. I found too many non-replaced true/false in compiler output. Replacement non-replaced true/false to !1/!0 in conpiler output saves 1-2 kb for 850 kb js file.",
    "desc_source": "google"
  },
  "Closure_14": {
    "description": "bogus 'missing return' warning\nThe following sample code compiles with &quot;Missing return statement. Function expected to return boolean.&quot; warning:\r\n\r\n/**\r\n * @return {boolean}\r\n */\r\nfunction fb(a)\r\n{\r\n    try\r\n    {\r\n        alert(a);      // Some method, which can throw\r\n        if (a &gt; 0)\r\n            return false;\r\n    }\r\n    finally\r\n    {\r\n        a = 5;\r\n    }\r\n    \r\n    return true;\r\n}",
    "desc_source": "google"
  },
  "Closure_15": {
    "description": "Switched order of \"delete key\" and \"key in\" statements changes semantic\n// Input:\r\n\r\nvar customData = { key: 'value' };\r\n\r\nfunction testRemoveKey( key ) {\r\n\tvar dataSlot = customData,\r\n\t\tretval = dataSlot &amp;&amp; dataSlot[ key ],\r\n\t\thadKey = dataSlot &amp;&amp; ( key in dataSlot );\r\n\r\n\tif ( dataSlot )\r\n\t\tdelete dataSlot[ key ];\r\n\r\n\treturn hadKey ? retval : null;\r\n};\r\n\r\nconsole.log( testRemoveKey( 'key' ) ); // 'value'\r\nconsole.log( 'key' in customData ); // false\r\n\r\n\r\n// Compiled version:\r\n\r\nvar customData={key:&quot;value&quot;};function testRemoveKey(b){var a=customData,c=a&amp;&amp;a[b];a&amp;&amp;delete a[b];return a&amp;&amp;b in a?c:null}console.log(testRemoveKey(&quot;key&quot;));console.log(&quot;key&quot;in customData);\r\n\r\n// null\r\n// false\r\n\r\n\r\n&quot;b in a&quot; is executed after &quot;delete a[b]&quot; what obviously doesn't make sense in this case.\r\n\r\n\r\nReproducible on: http://closure-compiler.appspot.com/home and in &quot;Version: 20120430 (revision 1918) Built on: 2012/04/30 18:02&quot;",
    "desc_source": "google"
  },
  "Closure_16": {
    "description": "JSCompiler does not recursively resolve typedefs\ngoog.provide('a.b.c');\r\n\r\ngoog.scope(function() {\r\nvar b = a.b;\r\nvar c = b.c;\r\n\r\n/** @typedef {string} */\r\nc.MyType;\r\n\r\n/** @param {c.MyType} x The variable. */\r\nc.myFunc = function(x) {};\r\n\r\n});\r\n\r\nresults in a compiler error.\r\n\r\ngiven that JSCompiler *does* recursively resolve other names, this appears to be a bug rather than an intended limitation.",
    "desc_source": "google"
  },
  "Closure_17": {
    "description": "@const dumps type cast information\nThe following code compiles fine:\r\n\r\n/**\r\n* Class defining an interface with two numbers.\r\n* @interface\r\n*/\r\nfunction TwoNumbers() {}\r\n\r\n/** @type number */\r\nTwoNumbers.prototype.first;\r\n\r\n/** @type number */\r\nTwoNumbers.prototype.second;\r\n\r\nvar SOME_DEFAULT =\r\n  /** @type {TwoNumbers} */ ({first: 1, second: 2});\r\n\r\n/**\r\n * Class with a two number member.\r\n * @constructor\r\n */\r\nfunction HasTwoNumbers() {\r\n  /** @type {TwoNumbers} */\r\n  this.twoNumbers = this.getTwoNumbers();\r\n}\r\n\r\n/**\r\n * Get the default two numbers.\r\n * @return {TwoNumbers}\r\n */\r\nHasTwoNumbers.prototype.getTwoNumbers = function() {\r\n  return SOME_DEFAULT;\r\n};\r\n\r\nNow realizing that SOME_DEFAULTS is actually a preset constant which should not change I would like to say for that line (just adding an @const)\r\n\r\n/** @const */ var SOME_DEFAULT =\r\n  /** @type {TwoNumbers} */ ({first: 1, second: 2});\r\n\r\nHowever that starts throwing warnings as adding the @const makes the compiler dump the type. (Does the value get inlined without the typecast?)\r\n\r\nExpected:\r\nCompiles fine.\r\n\r\nError can be reproduced on:\r\nhttp://closure-compiler.appspot.com/home\r\ncopy-past the attached file in there, it throws a warning and does not compile.",
    "desc_source": "google"
  },
  "Closure_18": {
    "description": "Dependency sorting with closurePass set to false no longer works.\n<b>What steps will reproduce the problem?</b>\n\r\n1. Instantiate new instance of Compiler\r\n\r\n2. Set closurePass to false to prevent goog.require/goog.provide removal.\r\ncompilerOptions.setClosurePass(false);\r\n\r\n3. Turn dependency sorting on.\r\nDependencyOptions dependencyOptions = new DependencyOptions();\r\ndependencyOptions.setDependencySorting(true);\r\n\r\n4. Compile js code\r\n\r\n\r\nWhat is the expected output? \r\nDependent files should be sorted and concatenated in their dependent order.\r\n\r\nWhat do you see instead?\r\nDependent files are not sorted.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n&gt; r1824\r\nmac OS 10.7\r\n\r\n\r\n<b>Please provide any additional information below.</b>\nThis worked in the r1810 release. However, it looks like this was changed in r1824. The compiler now expects closurePass to be true for dependency sorting to work.\r\nhttp://code.google.com/p/closure-compiler/source/detail?path=/trunk/src/com/google/javascript/jscomp/Compiler.java&amp;r=1824\r\n\r\nWhat we are looking for is a way to sort dependencies and concatenate all files in their dependent order without removing the goog.require/goog.provide js calls. Turning closurePass to true causes the goog calls to be replaced. We use this methodology in local development to test our JS code.\r\n\r\nThanks!",
    "desc_source": "google"
  },
  "Closure_19": {
    "description": "Type refining of 'this' raises IllegalArgumentException\n<b>What steps will reproduce the problem?</b>\n1. goog.isFunction(this) or goog.isObject(this) or goog.isNull(this) etc.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nExpected: normal compilation, checking the type of this\r\nActual output:\r\n\r\n23: java.lang.IllegalArgumentException: Node cannot be refined. \r\nTHIS 1 [source_file: Input_0] : global this\r\n\r\n\tat com.google.javascript.jscomp.type.ChainableReverseAbstractInterpreter.declareNameInScope(ChainableReverseAbstractInterpreter.java:172)\r\n\tat com.google.javascript.jscomp.type.ClosureReverseAbstractInterpreter.restrictParameter(ClosureReverseAbstractInterpreter.java:240)\r\n\tat com.google.javascript.jscomp.type.ClosureReverseAbstractInterpreter.getPreciserScopeKnowingConditionOutcome(ClosureReverseAbstractInterpreter.java:221)\r\n\tat com.google.javascript.jscomp.TypeInference.branchedFlowThrough(TypeInference.java:239)\r\n\tat com.google.javascript.jscomp.TypeInference.branchedFlowThrough(TypeInference.java:59)\r\n\tat com.google.javascript.jscomp.DataFlowAnalysis$BranchedForwardDataFlowAnalysis.flow(DataFlowAnalysis.java:448)\r\n\tat com.google.javascript.jscomp.DataFlowAnalysis.analyze(DataFlowAnalysis.java:213)\r\n\tat com.google.javascript.jscomp.DataFlowAnalysis.analyze(DataFlowAnalysis.java:181)\r\n\tat com.google.javascript.jscomp.TypeInferencePass.inferTypes(TypeInferencePass.java:90)\r\n\tat com.google.javascript.jscomp.TypeInferencePass$TypeInferringCallback.enterScope(TypeInferencePass.java:106)\r\n\tat com.google.javascript.jscomp.NodeTraversal.pushScope(NodeTraversal.java:581)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseWithScope(NodeTraversal.java:345)\r\n\tat com.google.javascript.jscomp.TypeInferencePass.inferTypes(TypeInferencePass.java:81)\r\n\tat com.google.javascript.jscomp.TypeInferencePass.process(TypeInferencePass.java:74)\r\n\tat com.google.javascript.jscomp.DefaultPassConfig$24$1.process(DefaultPassConfig.java:1119)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(PhaseOptimizer.java:296)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(PhaseOptimizer.java:273)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(PhaseOptimizer.java:187)\r\n\tat com.google.javascript.jscomp.Compiler.check(Compiler.java:768)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Compiler.java:683)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Compiler.java:79)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Compiler.java:586)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Compiler.java:583)\r\n\tat com.google.javascript.jscomp.Compiler$2.run(Compiler.java:628)\r\n\tat com.google.javascript.jscomp.Compiler.runCallable(Compiler.java:651)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:601)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:583)\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nAny version (local and http://closure-compiler.appspot.com/).\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nA workaround is to assign 'this' to a variable. &quot;var a=this;goog.isNull(a)&quot; works.",
    "desc_source": "google"
  },
  "Closure_20": {
    "description": "String conversion optimization is incorrect\n<b>What steps will reproduce the problem?</b>\n\r\nvar f = {\r\n  valueOf: function() { return undefined; }\r\n}\r\nString(f)\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nExpected output: &quot;[object Object]&quot;\r\nActual output: &quot;undefined&quot;\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nAll versions (http://closure-compiler.appspot.com/ as well).\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nThe compiler optimizes String(x) calls by replacing them with x + ''. This is correct in most cases, but incorrect in corner cases like the one mentioned above.",
    "desc_source": "google"
  },
  "Closure_21": {
    "description": "Classify non-rightmost expressions as problematic\n<b>Purpose of code changes:</b>\nWhen it comes to an expression involving the comma operator, only the\r\nfirst element of such a sequence is checked for being free of side\r\neffects. If the element is free of side effects, it is classified as\r\nproblematic and a warning is issued.\r\n\r\nAs other non-rightmost elements are not checked for being free of side\r\neffects and therefore cannot be classified as problematic, this leads\r\nto unexpected behavior:\r\n\r\n1. foo((1, 2, 42)) is transformed into foo((1, 3)) and a warning is\r\nissued only with regard to the first element.\r\n2. foo((bar(), 2, 42)) is transformed into foo((bar(), 3)) and no\r\nwarning is issued.\r\n3. foo(((1, 2, 3), (4, 5, 42))) is transformed into foo((1, 4, 42)) and\r\nwarnings are issued with regard to the first elements of inner\r\nsequences only.",
    "desc_source": "google"
  },
  "Closure_22": {
    "description": "Classify non-rightmost expressions as problematic\n<b>Purpose of code changes:</b>\nWhen it comes to an expression involving the comma operator, only the\r\nfirst element of such a sequence is checked for being free of side\r\neffects. If the element is free of side effects, it is classified as\r\nproblematic and a warning is issued.\r\n\r\nAs other non-rightmost elements are not checked for being free of side\r\neffects and therefore cannot be classified as problematic, this leads\r\nto unexpected behavior:\r\n\r\n1. foo((1, 2, 42)) is transformed into foo((1, 3)) and a warning is\r\nissued only with regard to the first element.\r\n2. foo((bar(), 2, 42)) is transformed into foo((bar(), 3)) and no\r\nwarning is issued.\r\n3. foo(((1, 2, 3), (4, 5, 42))) is transformed into foo((1, 4, 42)) and\r\nwarnings are issued with regard to the first elements of inner\r\nsequences only.",
    "desc_source": "google"
  },
  "Closure_23": {
    "description": "tryFoldArrayAccess does not check for side effects\n<b>What steps will reproduce the problem?</b>\n1. Compile the following program with simple or advanced optimization:\r\nconsole.log([console.log('hello, '), 'world!'][1]);\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThe expected output would preserve side effects. It would not transform the program at all or transform it into:\r\n\r\nconsole.log((console.log(&quot;hello&quot;), &quot;world!&quot;));\r\n\r\nInstead, the program is transformed into:\r\n\r\nconsole.log(&quot;world!&quot;);\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nRevision 2022. Ubuntu 12.04.\r\n\r\n<b>Please provide any additional information below.</b>\ntryFoldArrayAccess in com.google.javascript.jscomp.PeepholeFoldConstants should check whether   every array element that is not going to be preserved has no side effects.",
    "desc_source": "google"
  },
  "Closure_24": {
    "description": "goog.scope doesn't properly check declared functions\nThe following code is a compiler error:\r\n\r\ngoog.scope(function() {\r\n  var x = function(){};\r\n});\r\n\r\nbut the following code is not:\r\n\r\ngoog.scope(function() {\r\n  function x() {}\r\n});\r\n\r\nBoth code snippets should be a compiler error, because they prevent the goog.scope from being unboxed.",
    "desc_source": "google"
  },
  "Closure_25": {
    "description": "anonymous object type inference behavior is different when calling constructors\nThe following compiles fine with:\r\njava -jar build/compiler.jar --compilation_level=ADVANCED_OPTIMIZATIONS --jscomp_error=accessControls --jscomp_error=checkTypes --jscomp_error=checkVars --js ~/Desktop/reverse.js\r\n\r\nreverse.js:\r\n/**\r\n * @param {{prop1: string, prop2: (number|undefined)}} parry\r\n */\r\nfunction callz(parry) {\r\n  if (parry.prop2 &amp;&amp; parry.prop2 &lt; 5) alert('alright!');\r\n  alert(parry.prop1);\r\n}\r\n\r\ncallz({prop1: 'hi'});\r\n\r\n\r\n\r\nHowever, the following does not:\r\n/**\r\n * @param {{prop1: string, prop2: (number|undefined)}} parry\r\n * @constructor\r\n */\r\nfunction callz(parry) {\r\n  if (parry.prop2 &amp;&amp; parry.prop2 &lt; 5) alert('alright!');\r\n  alert(parry.prop1);\r\n}\r\n\r\nnew callz({prop1: 'hi'});\r\n\r\n\r\n/Users/dolapo/Desktop/reverse.js:10: ERROR - actual parameter 1 of callz does not match formal parameter\r\nfound   : {prop1: string}\r\nrequired: {prop1: string, prop2: (number|undefined)}\r\nnew callz({prop1: 'hi'});\r\n\r\n\r\n\r\nThanks!",
    "desc_source": "google"
  },
  "Closure_26": {
    "description": "ProcessCommonJSModules module$exports failures when checkTypes enabled\nIf you define a module (echo.js) as:\r\ndefine(function() { return {\r\n  echo: function(val) {\r\n    window.console.log(val);\r\n  }\r\n}});\r\n\r\nand an entry point* that does not define any new modules as:\r\nvar echo = require('echo');\r\necho.echo('hello world');\r\n\r\nand compile with:\r\njava -jar build/compiler.jar --formatting=PRETTY_PRINT --jscomp_error=checkTypes --compilation_level=SIMPLE_OPTIMIZATIONS --transform_amd_modules --process_common_js_modules --js=echo.js --js=echo-main.js --common_js_entry_module=echo-main.js\r\n\r\nYou get the error:\r\necho-main.js:1: ERROR - Property module$exports never defined on module$echo_main\r\n\r\nwhich is probably happening because of ProcessCommonJSModules#emitOptionalModuleExportsOverride is testing a property that doesn't exist. I can try to cook up a patch but it would probably fall back to using goog.isDef and there's probably a cleaner way :)\r\n\r\n\r\n\r\n\r\n*p.s what is the intended definition of entry points that do not define new modules. the following leaves a call to a require function:\r\nrequire(['echo'], function(echo) {\r\n  echo.echo('hello world');\r\n});",
    "desc_source": "google"
  },
  "Closure_27": {
    "description": "Error trying to build try-catch block (AST)\n1. EXAMPLE\r\n\r\nNode nodeTry = IR.block(\r\n  IR.var(\r\n    IR.name(&quot;testing&quot;), \r\n    IR.number(11)\r\n  )\r\n);\r\nNode nodeCatch = IR.catchNode(\r\n  IR.name(&quot;blabla&quot;),\r\n    IR.block(\r\n      IR.var(\r\n        IR.name(&quot;testing&quot;),\r\n\tIR.number(22)\r\n      )\r\n    )\r\n);\r\nIR.tryCatch(nodeTry, nodeCatch);\r\n\r\n\r\n2. THROWS ERROR\r\n\r\nException in thread &quot;main&quot; java.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nnull\r\n  Node(FUNCTION tt): input.js:2:4\r\n    function tt() {\r\n  Parent(BLOCK): input.js:1:4\r\ntry {\r\n\r\n\r\n3. SOLUTION\r\n\r\nIR.block is verifing the catch node is a statement which it isnt.",
    "desc_source": "google"
  },
  "Closure_28": {
    "description": "constant functions not inlined aggressively enough\nIf you call a function that returns 'false' enough times under certain conditions, it doesn't get inlined.\r\n\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\nfunction f() { return false; }\r\nif (!f()) alert('hi'); // repeat this about 25 times",
    "desc_source": "google"
  },
  "Closure_29": {
    "description": "closure compiler screws up a perfectly valid isFunction() implementation\nhi, this function does not get compiled correctly via google closure compiler\r\n\r\n isFunction = function(functionToCheck) {\r\n    var getType;\r\n    getType = {}; //just an object\r\n    return functionToCheck &amp;&amp; getType.toString.apply(functionToCheck) === '[object Function]';\r\n  };\r\n\r\ngets compiled into \r\n\r\nisFunction = function(a) {\r\n  return a &amp;&amp; &quot;[object Function]&quot; === (void 0).apply(a)\r\n};\r\n\r\nto make it work, we have to use an array instead of an object (even though we just want to call the object toString method)\r\n\r\n  isFunction = function(functionToCheck) {\r\n    var getType;\r\n    getType = []; //not it's an array \r\n    return functionToCheck &amp;&amp; getType.toString.apply(functionToCheck) === '[object Function]';\r\n  };\r\n\r\ngets compiled into\r\n\r\nisFunction = function(a) {\r\n  var b;\r\n  b = [];\r\n  return a &amp;&amp; &quot;[object Function]&quot; === b.toString.apply(a)\r\n};\r\n\r\nand it does what it should do. \r\n\r\ni wasted an hour to find that bug. bugs me. great tool otherwise.",
    "desc_source": "google"
  },
  "Closure_30": {
    "description": "Combining temporary strings are over-optimized in advanced build\n<b>What steps will reproduce the problem?</b>\n1. This bug only manifests itself in large code bases. How large, and what the specifics are, I haven't yet worked out, since the output differs. But the principle code is:\r\n\r\nsgxColorRGBA.prototype.asHex = function() {\r\n\tvar hexString = &quot;&quot;;\r\n\t\r\n\tstr = (sgxFloor(this.r*255)).toString(16);\r\n\tif (str.length &lt; 2) { str = &quot;0&quot;+str; }\r\n\thexString += str;\r\n\r\n\tstr = (sgxFloor(this.g*255)).toString(16);\r\n\tif (str.length &lt; 2) { str = &quot;0&quot;+str; }\r\n\thexString += str;\r\n\r\n\tstr = (sgxFloor(this.b*255)).toString(16);\r\n\tif (str.length &lt; 2) { str = &quot;0&quot;+str; }\r\n\thexString += str;\r\n\r\n\tstr = (sgxFloor(this.a*255)).toString(16);\r\n\tif (str.length &lt; 2) { str = &quot;0&quot;+str; }\r\n\thexString += str;\r\n\r\n\treturn hexString;\r\n}\r\n\r\nNote that 'str' is not declared as var.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nI see this:\r\nsgxColorRGBA.prototype.pb = function() {\r\n  str = A(255 * this.A).toString(16);\r\n  2 &gt; str.length &amp;&amp; (str = &quot;0&quot; + str);\r\n  str = A(255 * this.w).toString(16);\r\n  2 &gt; str.length &amp;&amp; (str = &quot;0&quot; + str);\r\n  str = A(255 * this.s).toString(16);\r\n  2 &gt; str.length &amp;&amp; (str = &quot;0&quot; + str);\r\n  str = A(255 * this.r).toString(16);\r\n  2 &gt; str.length &amp;&amp; (str = &quot;0&quot; + str);\r\n  return&quot;&quot; + str + str + str + str\r\n};\r\n\r\nObviously, repeatedly adding 'str' is broken in the final line, compared to the original. So whatever is aggregating the result is seeing a temporary 'str' reference and combining it, I guess. If 'str' is declared as var, the problem goes away.\r\n\r\nI'd expect a warning, at least.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nLive at http://closure-compiler.appspot.com\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nAs a stand-alone method, both 'var str' and 'str' works. It's only when the project hits a certain (undetermined) size that it fails.",
    "desc_source": "google"
  },
  "Closure_31": {
    "description": "Add support for --manage_closure_dependencies and --only_closure_dependencies with compilation level WHITESPACE_ONLY\nThe compiler options --manage_closure_dependencies and --only_closure_dependencies are currently ignored with compilation level WHITESPACE_ONLY. It would be helpful for testing, if dependency management were supported for WHITESPACE_ONLY in addition to SIMPLE_OPTIMIZATIONS and ADVANCED_OPTIMIZATIONS. For example, both Closure Builder and plovr automatically manage dependencies for all compilation levels.\r\n\r\nThe proposed change (see attached diff) does not automatically manage dependencies, but it enables dependency management if either --manage_closure_dependencies or --only_closure_dependencies is specified, or if at least one --closure_entry_point is specified.\r\n\r\nThe attached diff passed the JUnit tests: ant test",
    "desc_source": "google"
  },
  "Closure_32": {
    "description": "Preserve doesn't preserve whitespace at start of line\n<b>What steps will reproduce the problem?</b>\n\r\nCode such as:\r\n/**\r\n * @preserve\r\n\r\nThis\r\n  was\r\n    ASCII\r\n       Art\r\n\r\n*/\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nThe words line up on the left:\r\n/*\r\nThis\r\nwas\r\nASCII\r\nArt\r\n*/\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nLive web verison.\r\n\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_33": {
    "description": "weird object literal invalid property error on unrelated object prototype\nApologies in advance for the convoluted repro case and the vague summary.\r\n\r\nCompile the following code (attached as repro.js) with:\r\njava -jar build/compiler.jar --compilation_level=ADVANCED_OPTIMIZATIONS --jscomp_error=accessControls --jscomp_error=checkTypes --jscomp_error=checkVars --js repro.js *\r\n\r\n/**\r\n * @param {{text: string}} opt_data\r\n * @return {string}\r\n */\r\nfunction temp1(opt_data) {\r\n  return opt_data.text;\r\n}\r\n\r\n/**\r\n * @param {{activity: (boolean|number|string|null|Object)}} opt_data\r\n * @return {string}\r\n */\r\nfunction temp2(opt_data) {\r\n  /** @notypecheck */\r\n  function __inner() {\r\n    return temp1(opt_data.activity);\r\n  }\r\n  return __inner();\r\n}\r\n\r\n/**\r\n * @param {{n: number, text: string, b: boolean}} opt_data\r\n * @return {string}\r\n */\r\nfunction temp3(opt_data) {\r\n  return 'n: ' + opt_data.n + ', t: ' + opt_data.text + '.';\r\n}\r\n\r\nfunction callee() {\r\n  var output = temp3({\r\n    n: 0,\r\n    text: 'a string',\r\n    b: true\r\n  })\r\n  alert(output);\r\n}\r\n\r\ncallee();\r\n\r\n\r\nyields:\r\nrepro.js:30: ERROR - actual parameter 1 of temp3 does not match formal parameter\r\nfound   : {b: boolean, n: number, text: (string|undefined)}\r\nrequired: {b: boolean, n: number, text: string}\r\n  var output = temp3({\r\n\r\nIt seems like temp3 is actually being called with the right type {b: boolean, n: number, text: string} though it seems to think that text is a (string|undefined)\r\nThis seems to happen because of the seemingly unrelated code in functions temp1 and temp2. If I change the name of the text property (as in repro3.js) it works.\r\nAdditionally, if I fix the type of the activity property in the record type of temp2 it works (as in repro2.js)\r\n\r\nThis comes up in our codebase in some situations where we don't have type info for all the objects being passed into a function. It's always a tricky one to find because it reports an error at a location that looks correct.\r\n\r\n\r\n* it also fails with SIMPLE_OPTIMIZATIONS",
    "desc_source": "google"
  },
  "Closure_34": {
    "description": "StackOverflowError exception when running closure compiler (javascript attached)\n<b>What steps will reproduce the problem?</b>\n\r\n1. I'm trying to run: java -jar compiler.jar --js AdMedia.eam.js --js_output_file AdMedia.eam.min.js\r\n2. AdMedia.eam.js is attached.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nI get the following exception:\r\njava.lang.RuntimeException: java.lang.RuntimeException: java.lang.StackOverflowError\r\n        at com.google.javascript.jscomp.Compiler.runCallable(Compiler.java:643)\r\n        at com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:588)\r\n        at com.google.javascript.jscomp.Compiler.toSource(Compiler.java:1492)\r\n        at com.google.javascript.jscomp.AbstractCommandLineRunner.processResults(AbstractCommandLineRunner.java:788)\r\n        at com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(AbstractCommandLineRunner.java:726)\r\n        at com.google.javascript.jscomp.AbstractCommandLineRunner.run(AbstractCommandLineRunner.java:334)\r\n        at com.google.javascript.jscomp.CommandLineRunner.main(CommandLineRunner.java:871)\r\nCaused by: java.lang.RuntimeException: java.lang.StackOverflowError\r\n        at com.google.javascript.jscomp.Compiler.runCallable(Compiler.java:643)\r\n        at com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:588)\r\n        at com.google.javascript.jscomp.Compiler.toSource(Compiler.java:1608)\r\n        at com.google.javascript.jscomp.Compiler$5.call(Compiler.java:1503)\r\n        at com.google.javascript.jscomp.Compiler$5.call(Compiler.java:1492)\r\n        at com.google.javascript.jscomp.Compiler$2.run(Compiler.java:615)\r\n        at java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.StackOverflowError\r\n        at com.google.javascript.jscomp.CodeGenerator.add(CodeGenerator.java:91)\r\n        at com.google.javascript.jscomp.CodeGenerator.addExpr(CodeGenerator.java:881)\r\n        at com.google.javascript.jscomp.CodeGenerator.add(CodeGenerator.java:103)\r\n        at com.google.javascript.jscomp.CodeGenerator.addExpr(CodeGenerator.java:881)\r\n        at com.google.javascript.jscomp.CodeGenerator.add(CodeGenerator.java:103)\r\n        at com.google.javascript.jscomp.CodeGenerator.addExpr(CodeGenerator.java:881)\r\n        at com.google.javascript.jscomp.CodeGenerator.add(CodeGenerator.java:103)\r\n        at com.google.javascript.jscomp.CodeGenerator.addExpr(CodeGenerator.java:881)\r\n        at com.google.javascript.jscomp.CodeGenerator.add(CodeGenerator.java:103)\r\n        at com.google.javascript.jscomp.CodeGenerator.addExpr(CodeGenerator.java:881)\r\n        at com.google.javascript.jscomp.CodeGenerator.add(CodeGenerator.java:103)\r\n        at com.google.javascript.jscomp.CodeGenerator.addExpr(CodeGenerator.java:881)\r\n.\r\n.\r\n.\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nClosure:\r\nClosure Compiler (http://code.google.com/closure/compiler)\r\nVersion: 20120305 (revision 1810)\r\nBuilt on: 2012/03/05 20:55\r\n\r\nJava:\r\njava version &quot;1.6.0_31&quot;\r\nJava(TM) SE Runtime Environment (build 1.6.0_31-b05)\r\nJava HotSpot(TM) Client VM (build 20.6-b01, mixed mode, sharing)\r\n\r\nWindows 7 (64-bit)\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nWorks fine on the following Java version:\r\njava version &quot;1.7.0&quot;\r\nJava(TM) SE Runtime Environment (build 1.7.0-b147)\r\nJava HotSpot(TM) 64-Bit Server VM (build 21.0-b17, mixed mode)",
    "desc_source": "google"
  },
  "Closure_35": {
    "description": "assignment to object in conditional causes type error on function w/ record type return type\nslightly dodgy code :)\r\n\r\n/** @returns {{prop1: (Object|undefined), prop2: (string|undefined), prop3: (string|undefined)}} */\r\nfunction func(a, b) {\r\n  var results;\r\n  if (a) {\r\n    results = {};\r\n    results.prop1 = {a: 3};\r\n  }\r\n  if (b) {\r\n    results = results || {};\r\n    results.prop2 = 'prop2';\r\n  } else {\r\n    results = results || {};\r\n    results.prop3 = 'prop3';\r\n  }\r\n  return results;\r\n}\r\nresults in this error:\r\n\r\n\r\nJSC_TYPE_MISMATCH: inconsistent return type\r\nfound   : ({prop1: {a: number}}|{})\r\nrequired: {prop1: (Object|null|undefined), prop2: (string|undefined), prop3: (string|undefined)} at line 18 character 7\r\nreturn results;\r\n\r\n\r\n\r\ndefining results on the first line on the function causes it the world.\r\nthe still dodgy, but slightly less so, use of this is if the function return type were that record type|undefined and not all branches were guaranteed to be executed.",
    "desc_source": "google"
  },
  "Closure_36": {
    "description": "goog.addSingletonGetter prevents unused class removal\n<b>What steps will reproduce the problem?</b>\n\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// @use_closure_library true\r\n// @formatting pretty_print,print_input_delimiter\r\n// @warning_level VERBOSE\r\n// @debug true\r\n// ==/ClosureCompiler==\r\n\r\ngoog.provide('foo');\r\n\r\nvar foo = function() { this.values = []; };\r\ngoog.addSingletonGetter(foo);\r\n\r\nfoo.prototype.add = function(value) {this.values.push(value)};\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nExpect: The code is completely removed.\r\n\r\nInstead:\r\n\r\n(function($ctor$$) {\r\n  $ctor$$.$getInstance$ = function $$ctor$$$$getInstance$$() {\r\n    return $ctor$$.$instance_$ || ($ctor$$.$instance_$ = new $ctor$$)\r\n  }\r\n})(function() {\r\n});\r\n\r\n\r\nWhat version of the product are you using? On what operating system?\r\n\r\nhttp://closure-compiler.appspot.com on Feb 28, 2012\r\n\r\nPlease provide any additional information below.",
    "desc_source": "google"
  },
  "Closure_37": {
    "description": "incomplete function definition crashes the compiler when ideMode is enabled\nThe code:\r\n\r\nf f f ;\r\nfunction t\r\n\r\nThe cause:\r\n\r\nRhino is creating an incomplete FUNCTION node.  We could fix this in Rhino or the IRFactory.  If it is invalid in Rhino we should fix it there, I'm not sure how to determine this so maybe we should fix it in the IRFactory and be done with it.\r\n\r\nThe stack trace:\r\n\r\nCaused by: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nat com.google.common.base.Preconditions.checkState(Preconditions.java:135)\r\nat com.google.javascript.jscomp.NodeTraversal.traverseFunction(NodeTraversal.java:544)\r\nat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:493)\r\nat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:501)\r\nat com.google.javascript.jscomp.NodeTraversal.traverse(NodeTraversal.java:281)\r\nat com.google.javascript.jscomp.NodeTraversal.traverse(NodeTraversal.java:459)\r\nat com.google.javascript.jscomp.PrepareAst.process(PrepareAst.java:70)\r\nat com.google.javascript.jscomp.Compiler.prepareAst(Compiler.java:1836)\r\nat com.google.javascript.jscomp.JsAst.parse(JsAst.java:100)\r\nat com.google.javascript.jscomp.JsAst.getAstRoot(JsAst.java:53)\r\nat com.google.javascript.jscomp.CompilerInput.getAstRoot(CompilerInput.java:120)\r\nat com.google.javascript.jscomp.Compiler.parseInputs(Compiler.java:1303)\r\nat com.google.javascript.jscomp.Compiler.parse(Compiler.java:697)",
    "desc_source": "google"
  },
  "Closure_38": {
    "description": "Identifier minus a negative number needs a space between the \"-\"s\n<b>What steps will reproduce the problem?</b>\n1. Compile the attached file with      java -jar build/compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS --js bulletfail.js --js_output_file cc.js\r\n2. Try to run the file in a JS engine, for example           node cc.js\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nThe file does not parse properly, because it contains\r\n\r\n  g--0.0\r\n\r\nThis is subtraction of a negative number, but it looks like JS engines interpret it as decrementing g, and then fail to parse the 0.0. (g- -0.0, with a space, would parse ok.)\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nTrunk closure compiler on Ubuntu\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_39": {
    "description": "externExport with @typedef can generate invalid externs\n<b>What steps will reproduce the problem?</b>\n1. Create a file that has a @typedef and code referencing the type def above and below the typedef declaration.\r\n2. Run the closure compiler and grab the externExport string stored on the last result for review.\r\n3. I have attached both source and output files displaying the issue.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nThe code above the @typedef references the aliased name of the @typedef as expected however the code below the @typedef tries embedding the body of the @typedef and ends up truncating it if the length is too long with a &quot;...&quot;. This throws bad type errors when compiling against this extern. What is odd is this only seems to be the case when the parameter with the type is optional. When neither are optional it embeds the types, which is not a big deal, except when types are long; they get truncated and throw errors.\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nplovr built from revision 3103:d6db24beeb7f\r\nRevision numbers for embedded Closure Tools:\r\nClosure Library:    1374\r\nClosure Compiler:   1559\r\nClosure Templates:    23\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_40": {
    "description": "smartNameRemoval causing compiler crash\n<b>What steps will reproduce the problem?</b>\nCompiler the following code in advanced mode:\r\n\r\n{{{\r\nvar goog = {};\r\ngoog.inherits = function(x, y) {};\r\nvar ns = {};\r\n/** @constructor */ ns.PageSelectionModel = function(){};\r\n\r\n/** @constructor */ \r\nns.PageSelectionModel.FooEvent = function() {};\r\n/** @constructor */ \r\nns.PageSelectionModel.SelectEvent = function() {};\r\ngoog.inherits(ns.PageSelectionModel.ChangeEvent, ns.PageSelectionModel.FooEvent);\r\n}}}\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThe compiler will crash. The last var check throws an illegal state exception because it knows something is wrong.\r\n\r\nThe crash is caused by smartNameRemoval. It has special logic for counting references in class-defining function calls (like goog.inherits), and it isn't properly creating a reference to PageSelectionModel.",
    "desc_source": "google"
  },
  "Closure_41": {
    "description": "In ADVANCED mode, Compiler fails to warn about overridden methods with different signatures.\nIn ADVANCED mode, Compiler fails to warn about overridden methods with different signatures. The following code only warns in the one instance noted in the comment, whereas I would expect it to complain about the declarations of both Bar.prototype.add and Bar.prototype.sub, as they claim @inheritDoc, but have seemingly different signatures from that of their superclass methods.\r\n\r\nIt would be helpful to have such a warning so that when you change the signature of a superclass method, you can run the Compiler to trigger warnings and find all of the other signatures that you need to update.\r\n\r\nRun the following:\r\n\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// @use_closure_library true\r\n// ==/ClosureCompiler==\r\n\r\ngoog.provide('Foo');\r\ngoog.provide('Bar');\r\n\r\n\r\n/** @constructor */\r\nFoo = function() {};\r\n\r\n\r\n/**\r\n * @param {number} a\r\n * @param {number} b\r\n * @return {number}\r\n */\r\nFoo.prototype.add = function(a, b) {\r\n  return a + b;\r\n};\r\n\r\n\r\n/**\r\n * @param {number} a\r\n * @param {number} b\r\n * @return {number}\r\n */\r\nFoo.prototype.sub = goog.abstractMethod;\r\n\r\n\r\n/**\r\n * @constructor\r\n * @extends {Foo}\r\n */\r\nBar = function() {\r\n  goog.base(this);\r\n};\r\ngoog.inherits(Bar, Foo);\r\n\r\n\r\n/** @inheritDoc */\r\nBar.prototype.add = function(one) {\r\n  return one;\r\n};\r\n\r\n\r\n/** @inheritDoc */\r\nBar.prototype.sub = function(one) {\r\n  return one;\r\n};\r\n\r\n\r\nvar foo = /** @type {Foo} */ (new Bar());\r\nalert(foo.add(3, 4));\r\n\r\nvar bar = new Bar();\r\n// THIS PRODUCES JSC_WRONG_ARGUMENT_COUNT\r\nalert(bar.add(3, 4));",
    "desc_source": "google"
  },
  "Closure_42": {
    "description": "Simple \"Whitespace only\" compression removing \"each\" keyword from \"for each (var x in arr)\" loop\n<b>What steps will reproduce the problem?</b>\nSee below code snippet before after compression\r\n\r\n---Before---\r\ncontactcenter.screenpop.updatePopStatus = function(stamp, status) {\r\nfor each ( var curTiming in this.timeLog.timings ) {\r\nif ( curTiming.callId == stamp ) {\r\ncurTiming.flag = status;\r\nbreak;\r\n}\r\n}\r\n};\r\n---After---\r\ncontactcenter.screenpop.updatePopStatus=function(stamp,status){for(var curTiming in this.timeLog.timings)if(curTiming.callId==stamp){curTiming.flag=status;break}};\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n---each keyword should be preserved\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n<b>Please provide any additional information below.</b>\nfor each (** in **) ---&gt;  returns object value\r\nfor (** in **) --&gt; returns index",
    "desc_source": "google"
  },
  "Closure_43": {
    "description": "@lends does not work unless class is defined beforehand\n<b>What steps will reproduce the problem?</b>\nWith advanced optimizations enabled as well as type checking (--jscomp_error=checkTypes), try to use @lends in the same way it's used on the jsdoc page at http://code.google.com/p/jsdoc-toolkit/wiki/TagLends - using either a utility method called &quot;makeClass&quot; or another method of class constructing such as John Resig's method at http://ejohn.org/blog/simple-javascript-inheritance/\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nExpected output is to have code compiled but instead I get a compile error such as:\r\n\r\nERROR - Variable Person.prototype not declared before @lends annotation.\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nLatest svn build, OS X.",
    "desc_source": "google"
  },
  "Closure_44": {
    "description": "alert(/ / / / /)\nalert(/ / / / /);\r\noutput: alert(/ /// /);\r\nshould be: alert(/ // / /);",
    "desc_source": "google"
  },
  "Closure_45": {
    "description": "Assignment removed when used as an expression result to Array.push\n<b>What steps will reproduce the problem?</b>\n1. Open online closure-compiler\r\n2. Input code:\r\n  function f() {\r\n    var a = [], b;\r\n    a.push(b = []);\r\n    b[0] = 1;\r\n    return a;\r\n  }\r\n3. Press [Compile]\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nExcept OK.\r\nOutput: function f(){var a=[];a.push([]);return a}; //wrong\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nCurrent online version.",
    "desc_source": "google"
  },
  "Closure_46": {
    "description": "ClassCastException during TypeCheck pass\n<b>What steps will reproduce the problem?</b>\n1. Compile code that has a ProxyObjectType that references a RecordType.  For example, we have a NamedType in a typedef that references a RecordType.\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nPatch attached.  Is this the correct fix?",
    "desc_source": "google"
  },
  "Closure_47": {
    "description": "Original source line numbers are one-based in source maps.\nGenerated source line/column numbers and original column numbers are zero-based. Original source line numbers should be zero based as well.",
    "desc_source": "google"
  },
  "Closure_48": {
    "description": "Type checking error when replacing a function with a stub after calling.\nGiven the following Javascript:\r\n\r\n  /** @constructor */\r\n  var myclass = function() {\r\n  }\r\n  \r\n  /** @param {boolean} success */\r\n  myclass.prototype.fn = function(success) { }\r\n  \r\n  myclass.prototype.test = function() {\r\n    this.fn();\r\n    this.fn = function() { };\r\n  }\r\n\r\nI would expect an error at both lines of test(). Instead, the second line causes the error in the first not to be reported.",
    "desc_source": "google"
  },
  "Closure_49": {
    "description": "Incorrect output if a function is assigned to a variable, and the function contains a variable with the same name\n<b>What steps will reproduce the problem?</b>\n\r\n 1. Enter the following into the online compiler\r\n\r\n  var foo = function bar(){\r\n    var bar;\r\n    alert(bar)\r\n  };\r\n\r\n 2.  Compile using simple optimization\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\n I'd expect to see\r\n\r\n  var foo = function() {\r\n    alert(void 0)\r\n  };\r\n\r\n Instead I see\r\n\r\n  var foo = function bar() {\r\n    alert(bar)\r\n  };\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\n Using http://closure-compiler.appspot.com/home\r\n\r\n<b>Please provide any additional information below.</b>\n\r\n The compiled output is correct if you remove the &quot;var foo =&quot; part, or if you rename the function from &quot;bar&quot; to something else.",
    "desc_source": "google"
  },
  "Closure_50": {
    "description": "Optimisation: convert array.join(\",\") to array.join()\n<b>What steps will reproduce the problem?</b>\n\r\nCompile this code:\r\n\r\nvar variable = confirm(&quot;value from user&quot;);\r\nvar array = [ &quot;constant&quot;, variable ];\r\nalert( array.join(&quot;,&quot;) );\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\n$ java -jar /usr/local/slando/lib/Google/compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS --js foo.js\r\nvar a=[&quot;constant&quot;,confirm(&quot;value from user&quot;)];alert(a.join(&quot;,&quot;));\r\n\r\nWe could save three bytes here by producing:\r\n\r\nvar a=[&quot;constant&quot;,confirm(&quot;value from user&quot;)];alert(a.join());\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\n$ java -jar /usr/local/slando/lib/Google/compiler.jar --version\r\nClosure Compiler (http://code.google.com/closure/compiler)\r\nVersion: 1180\r\nBuilt on: 2011/06/15 21:40\r\n\r\nRunning on Linux 2.6.18\r\n\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nHere's a common pattern this would be useful in:\r\n\r\nvar my_jquery_selectors = [];\r\n// ... append to my_jquery_selectors from various parts of the codebase ...\r\n$(my_jquery_selectors.join(&quot;,&quot;)).html(&quot;the code is more readable with the comma left in place&quot;);",
    "desc_source": "google"
  },
  "Closure_51": {
    "description": "-0.0 becomes 0 even in whitespace mode\nAffects dart: http://code.google.com/p/dart/issues/detail?id=146",
    "desc_source": "google"
  },
  "Closure_52": {
    "description": "Converts string properties into numbers in literal object definitions\n<b>What steps will reproduce the problem?</b>\n1. Minimize the following script:\r\n\r\nvar lit = {&quot;0102&quot;:&quot;Zero One Zero Two&quot;};\r\nalert(lit[&quot;0102&quot;]);\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nExpected:\r\nvar lit={&quot;0102&quot;:&quot;Zero One Zero Two&quot;};alert(lit[&quot;0102&quot;]);\r\n\r\nActual:\r\nvar lit={102:&quot;Zero One Zero Two&quot;};alert(lit[&quot;0102&quot;]);\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nr1459\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_53": {
    "description": "compiler-20110811 crashes with index(1) must be less than size(1)\n<b>What steps will reproduce the problem?</b>\nRun compiler on https://raw.github.com/scottschiller/SoundManager2/master/script/soundmanager2-nodebug.js\r\n\r\nYou can copy this into the Appspot closure compiler to see the error:\r\n// ==ClosureCompiler==\r\n// @output_file_name default.js\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @code_url https://raw.github.com/scottschiller/SoundManager2/master/script/soundmanager2-nodebug.js\r\n// ==/ClosureCompiler==\r\n\r\nI've attached a dump of the error from appspot.\r\n\r\n(This is the popular SoundManager library for HTML5 audio)\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nGot crash...\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nLatest (compiler-20110811). We were previously using the June build, and had no problems\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_54": {
    "description": "Prototype methods can't be used from the constructor in case prototype is explicitly defined.\nConsider the following source code:\r\nhttp://trac.webkit.org/browser/trunk/Source/WebCore/inspector/front-end/DOMAgent.js\r\n\r\nWhen I mark WebInspector.DOMAgent as a @constructor, I get the following warning.\r\n\r\nSource/WebCore/inspector/front-end/DOMAgent.js:48: WARNING - Property _setAttributesPayload never defined on WebInspector.DOMNode\r\n        this._setAttributesPayload(payload.attributes);\r\n\r\nIt sounds like the problem is in the way we define prototypes in line 83-ish. That's the way WebKit style tells us to do.",
    "desc_source": "google"
  },
  "Closure_55": {
    "description": "Exception when emitting code containing getters\nConsider the following source code: http://trac.webkit.org/browser/trunk/Source/WebCore/inspector/front-end/Settings.js#L123\r\n\r\nFollowing exception fires unless I remove the &quot;get name()&quot; getter from the code.\r\n\r\njava.lang.RuntimeException: java.lang.IllegalStateException: Expected function but was call Reference node CALL 128 [free_call: 1] [source_file: Settings.js]\r\n\tat com.google.javascript.jscomp.Compiler.runCallable(Compiler.java:629)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:574)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:556)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:515)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(AbstractCommandLineRunner.java:662)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(AbstractCommandLineRunner.java:295)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(CommandLineRunner.java:758)\r\nCaused by: java.lang.IllegalStateException: Expected function but was call Reference node CALL 128 [free_call: 1] [source_file: Settings.js]\r\n\tat com.google.javascript.jscomp.AstValidator$1.handleViolation(AstValidator.java:51)\r\n\tat com.google.javascript.jscomp.AstValidator.violation(AstValidator.java:763)\r\n\tat com.google.javascript.jscomp.AstValidator.validateNodeType(AstValidator.java:768)\r\n\tat com.google.javascript.jscomp.AstValidator.validateFunctionExpression(AstValidator.java:359)\r\n\tat com.google.javascript.jscomp.AstValidator.validateObjectLitGetKey(AstValidator.java:696)\r\n\tat com.google.javascript.jscomp.AstValidator.validateObjectLitKey(AstValidator.java:677)\r\n\tat com.google.javascript.jscomp.AstValidator.validateObjectLit(AstValidator.java:670)\r\n\tat com.google.javascript.jscomp.AstValidator.validateExpression(AstValidator.java:252)\r\n\tat com.google.javascript.jscomp.AstValidator.validateAssignmentExpression(AstValidator.java:603)\r\n\tat com.google.javascript.jscomp.AstValidator.validateExpression(AstValidator.java:219)\r\n\tat com.google.javascript.jscomp.AstValidator.validateExprStmt(AstValidator.java:476)\r\n\tat com.google.javascript.jscomp.AstValidator.validateStatement(AstValidator.java:126)\r\n\tat com.google.javascript.jscomp.AstValidator.validateScript(AstValidator.java:89)\r\n\tat com.google.javascript.jscomp.AstValidator.validateCodeRoot(AstValidator.java:79)\r\n\tat com.google.javascript.jscomp.AstValidator.process(AstValidator.java:63)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(PhaseOptimizer.java:273)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(PhaseOptimizer.java:250)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(PhaseOptimizer.java:168)\r\n\tat com.google.javascript.jscomp.Compiler.optimize(Compiler.java:1634)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Compiler.java:664)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Compiler.java:70)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Compiler.java:559)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Compiler.java:556)\r\n\tat com.google.javascript.jscomp.Compiler$2.run(Compiler.java:601)\r\n\tat java.lang.Thread.run(Thread.java:680)",
    "desc_source": "google"
  },
  "Closure_56": {
    "description": "Last warning or error in output is truncated\nThe last error or warning statement written to the output appears to be getting truncated. It's causing a problem for my error / warning parser.\r\n\r\nTo reproduce, create a file called test.js and add the following content to it:\r\n\r\n---------------\r\nalert(foo);\r\nalert(bar);\r\n---------------\r\n\r\nWhen compiled, the output looks like this:\r\n\r\n---------------\r\n&gt;java -jar compiler.jar --warning_level VERBOSE --js test.js\r\ntest.js:1: ERROR - variable foo is undefined\r\nalert(foo);\r\n      ^\r\n\r\ntest.js:2: ERROR - variable bar is undefined\r\n\r\n2 error(s), 0 warning(s)\r\n---------------\r\n\r\nIf you look at the last error includes neither the line the error occurred on nor the column-indicating caret. This happens with warnings as well.\r\n\r\nTested against r1257 committed 2011-07-11 11:11:32 -0700.",
    "desc_source": "google"
  },
  "Closure_57": {
    "description": "compiler crashes when  goog.provide used with non string\n<b>What steps will reproduce the problem?</b>\n1. insert  goog.provide(some.function);\r\n2. compile.\r\n<b>3.</b>\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nThis should give an error diagnostic. What it gives is:\r\n\r\njava.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease email js-compiler@google.com with this stack trace.\r\nGETPROP 17 [originalname: Spike] [source_file: file.js] is not a string node\r\n Node(CALL): file.js:17:12\r\ngoog.provide(mine.Spike);\r\n...\r\n[stack traces...]\r\n\r\nI think this is the current build as of the day of this report.",
    "desc_source": "google"
  },
  "Closure_58": {
    "description": "Online CC bug: report java error.\n<b>What steps will reproduce the problem?</b>\n1. open http://closure-compiler.appspot.com/\r\n2. input js code:\r\n  function keys(obj) {\r\n    var a = [], i = 0;\r\n    for (a[i++] in obj)\r\n      ;\r\n    return a;\r\n  }\r\n3. press [compile] button.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nExcept OK. See java error.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nOnline CC version.",
    "desc_source": "google"
  },
  "Closure_59": {
    "description": "Cannot exclude globalThis checks through command line\n<b>What steps will reproduce the problem?</b>\n1. Run command line utility\r\n2. Supply flags --warning_level VERBOSE --jscomp_off globalThis --jscomp_off nonStandardJsDocs\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nI expect that globalThis and nonStandardJsDocs warnings will be ignored. Only nonStandardJsDocs warnings are ignored.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nVersion 1180\r\nSun OS 5.10\r\n\r\n<b>Please provide any additional information below.</b>\n--jscomp_error also doesn't work with globalThis (works with nonStandardJSDocs).",
    "desc_source": "google"
  },
  "Closure_60": {
    "description": "void function () {}(); wrongly identified as having no side effects\nThis code results in the execution of the function and should not be identified as having no side effects.",
    "desc_source": "google"
  },
  "Closure_61": {
    "description": "Closure removes needed code.\n<b>What steps will reproduce the problem?</b>\n1. Try the following code, in Simple mode\r\nMath.blah = function(test) { test.a = 5; };\r\nvar test = new Object();\r\nMath.blah(test); \r\n2. The output is\r\nMath.blah=function(a){a.a=5};var test={};\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nNote that Math.blah(test) was removed. It should not be. It issues a warning: JSC_USELESS_CODE: Suspicious code. This code lacks side-effects. Is there a bug? at line 4 character 9\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nTested on Google hosted Closure service.\r\n\r\n<b>Please provide any additional information below.</b>\nClosure seems to be protective about Math in particular, and doesn't like people messing around with her? So, when I try the following code:-\r\nvar n = {};\r\nn.blah = function(test) { test.a = 5; };\r\nvar test = new Object();\r\nn.blah(test);\r\n\r\nIt works. When I replace n by Math, then again, Closure kicks out blah. I need that poor fellow. Please talk some sense into it.",
    "desc_source": "google"
  },
  "Closure_62": {
    "description": "Column-indicating caret is sometimes not in error output\nFor some reason, the caret doesn't always show up in the output when there are errors.\r\n\r\nWhen test.js looks like this:\r\n\r\n\r\n&gt;alert(1;\r\n\r\n\r\n, the output is this:\r\n\r\n\r\n&gt;java -jar compiler.jar --js test.js\r\ntest.js:1: ERROR - Parse error. missing ) after argument list\r\n\r\n1 error(s), 0 warning(s)\r\n\r\n\r\nHowever, when test.js looks like this (notice the line break after the semicolon):\r\n\r\n\r\n&gt;alert(1;\r\n&gt;\r\n\r\n\r\n, the output is this:\r\n\r\n\r\n&gt;java -jar compiler.jar --js test.js\r\ntest.js:1: ERROR - Parse error. missing ) after argument list\r\nalert(1;\r\n        ^\r\n\r\n1 error(s), 0 warning(s)\r\n\r\n\r\nThat's the simplest reproduction of the problem that I could come up with, but I just encountered the problem in a file with ~100 LOC in it. This is the first time I believe I've run into the problem, but when it happens, my error parser fails and it becomes a pain to track down the raw output to find the actual problem.\r\n\r\nTested against r1171, committed 6/10 08:06. The problem is present going back to at least r1000, so this isn't a new issue.",
    "desc_source": "google"
  },
  "Closure_64": {
    "description": "--language_in=ECMASCRIPT5_STRICT results in 1 'use strict' per input file\n<b>What steps will reproduce the problem?</b>\n1.  Create a JS file called &quot;get_num.js&quot; with the contents &quot;var getNum = function() { return 5; };&quot;\r\n2.  Create a JS file called &quot;alert.js&quot; with the contents &quot;alert(getNum());&quot;\r\n3.  Compile the two files with the following command:\r\n\r\njava -jar compiler.jar --language_in=ECMASCRIPT5_STRICT --compilation_level=ADVANCED_OPTIMIZATIONS --warning_level=VERBOSE --js get_num.js --js alert.js\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nI would expect the output to be:\r\n\r\n'use strict';alert(5);\r\n\r\nor, if the compiler wants to be really clever, just &quot;alert(5)&quot; since this is already ES5 Strict compliant.\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nHead on Mac OS X\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nhttps://groups.google.com/forum/#!topic/closure-compiler-discuss/TOLXpePju5Q",
    "desc_source": "google"
  },
  "Closure_65": {
    "description": "String escaping mishandles null byte\n<b>What steps will reproduce the problem?</b>\n1. Run:\r\nvar x = &quot;\\u00003&quot;; if (x.length &lt; 2) { alert(&quot;fail&quot;); } else { alert(&quot;win&quot;); }\r\n2. Compile and run\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n&quot;win&quot; is expected. &quot;fail&quot; is observed\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nr1167 on OS x 10.6\r\n\r\n<b>Please provide any additional information below.</b>\nThe problem is here: http://code.google.com/p/closure-compiler/source/browse/trunk/src/com/google/javascript/jscomp/CodeGenerator.java#1015\r\n\r\nHere's a patch that fixes it:\r\n$ svn diff\r\nIndex: src/com/google/javascript/jscomp/CodeGenerator.java\r\n===================================================================\r\n--- src/com/google/javascript/jscomp/CodeGenerator.java\t(revision 1167)\r\n+++ src/com/google/javascript/jscomp/CodeGenerator.java\t(working copy)\r\n@@ -1012,7 +1012,7 @@\r\n     for (int i = 0; i &lt; s.length(); i++) {\r\n       char c = s.charAt(i);\r\n       switch (c) {\r\n-        case '\\0': sb.append(&quot;\\\\0&quot;); break;\r\n+        case '\\0': sb.append(&quot;\\\\000&quot;); break;\r\n         case '\\n': sb.append(&quot;\\\\n&quot;); break;\r\n         case '\\r': sb.append(&quot;\\\\r&quot;); break;\r\n         case '\\t': sb.append(&quot;\\\\t&quot;); break;\r\n\r\nYou could also lookahead and output &quot;\\\\000&quot; only if the following char is 0-7 (octal valid) and otherwise output &quot;\\\\0&quot;. Is 2 bytes worth the complexity?",
    "desc_source": "google"
  },
  "Closure_66": {
    "description": "@enum does not type correctly\n<b>What steps will reproduce the problem?</b>\n\r\n1. create an enum with any syntax\r\nmy example:\r\n/** \r\n@type {Object}\r\n*/\r\nvar NS = {};\r\n\r\n/**\r\n@enum {number}\r\n*/\r\nNS.keys = { \r\n\ta: 1, \r\n\tb: 2, \r\n\tc: 3\r\n};\r\n\r\n/**\r\n@enum\r\n*/\r\nwindow['gKEYS'] = NS.keys;\r\n\r\n\r\n2. complie with --compilation_level ADVANCED_OPTIMIZATIONS --summary_detail_level 3 --warning_level VERBOSE\r\n\r\n3. look at the % typed\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nit shouldn't count the enum as un-typed; it does...\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nVersion: 1043\r\nBuilt on: 2011/05/02 19:47\r\n\r\n<b>Please provide any additional information below.</b>\n\r\ni also tried to tersely coerce the type, eg:\r\n/** @type {number} */ a:  (/** @type {number} */(1)),\r\n\r\nwhich has no effect.",
    "desc_source": "google"
  },
  "Closure_67": {
    "description": "Advanced compilations renames a function and then deletes it, leaving a reference to a renamed but non-existent function\nIf we provide the below code to advanced:\r\n\r\n\r\nfunction A() {\r\nthis._x = 1;\r\n}\r\n\r\nA.prototype['func1'] = // done to save public reference to func1\r\nA.prototype.func1 = function() {\r\n  this._x = 2;\r\n  this.func2();\r\n}\r\n\r\nA.prototype.func2 = function() {\r\n  this._x = 3;\r\n  this.func3();\r\n}\r\n\r\nwindow['A'] = A;\r\n\r\n\r\nWe get the output:\r\n\r\n\r\nfunction a() {\r\n  this.a = 1\r\n}\r\na.prototype.func1 = a.prototype.b = function() {\r\n  this.a = 2;\r\n  this.c() // Problem!\r\n};\r\nwindow.A = a;\r\n\r\n\r\nSo the compiler emits no errors, and renames 'func2' to 'c' but ends up throwing away the definition of that function!\r\n\r\nThe problem arises when I use:\r\n\r\nA.prototype['func1'] = // done to save public reference to func1\r\nA.prototype.func1 = function() {\r\n...\r\n}\r\n\r\nThe ['func1'] line is apparently enough to save the reference correctly, but also has the side effect of causing the function innards to do the wrong thing.\r\n\r\nI can of course instead write it as:\r\n\r\nA.prototype['func1'] = A.prototype.func1;\r\nA.prototype.func1 = function() {\r\n  this._x = 2;\r\n  this.func2();\r\n}\r\n\r\nIn which case Advanced will compile correctly and the results will also be valid.\r\n\r\nfunction a() {\r\n  this.a = 1\r\n}\r\na.prototype.func1 = a.prototype.b;\r\na.prototype.b = function() {\r\n  this.a = 2;\r\n  this.a = 3 // func2, correctly minified\r\n};\r\nwindow.A = a;\r\n\r\n\r\nFor now I can just use the expected way of declaring that func1 export, but since the compiler returns with no errors or warnings and creates a function with no definition, it seems worth reporting.",
    "desc_source": "google"
  },
  "Closure_68": {
    "description": "Cryptic error message on invalid \"@type function\" annotation\n<b>What steps will reproduce the problem?</b>\n1.  test.js:\r\n\r\n    /**\r\n     * @type function\r\n     */\r\n    var callback;\r\n\r\n2. java -jar compiler.jar --js test.js \r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nWarning reported is:\r\n\r\ntest.js:3: WARNING - Parse error. Unexpected end of file\r\n */\r\n  ^\r\n\r\nExpected to see the actual warning (e.g., &quot;expected '('&quot;, for the *previous* line)\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\ncompiler-20110502\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nSimply adding &quot;()&quot; to it (&quot;@type function()&quot;) removes the warning, but it would be much more effective if it could communicate that properly.",
    "desc_source": "google"
  },
  "Closure_69": {
    "description": "Compiler should warn/error when instance methods are operated on\n<b>What steps will reproduce the problem?</b>\n1. Compile and run the following code:\r\n  goog.require('goog.graphics.Path');\r\n  function demo() {\r\n    var path = new goog.graphics.Path();\r\n    var points = [[1,1], [2,2]];\r\n    for (var i = 0; i &lt; points.length; i++) {\r\n      (i == 0 ? path.moveTo : path.lineTo)(points[i][0], points[i][1]);\r\n    }\r\n  }\r\n  goog.exportSymbol('demo', demo);\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nI expect it to either work or produce a warning.  In this case, the latter since there's an error in the javascript - when calling path.moveTo(x, y), &quot;this&quot; is set correctly to the path element in the moveTo function.  But when the function is operated on, as in (i == 0 ? path.moveTo : path.lineTo)(x, y), it's no longer an instance method invocation, so &quot;this&quot; reverts to the window object.  In this case, an error results because moveTo references a field in Path that is now &quot;undefined&quot;.  Better would be to issue a warning/error that an instance method is being converted to a normal function (perhaps only if it references this).\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nUnknown (it's built into my build tools) - I presume this issue is present in all builds.  Running on ubuntu.\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_70": {
    "description": "unexpected typed coverage of less than 100%\n<b>What steps will reproduce the problem?</b>\n1. Create JavaScript file:\r\n/*global window*/\r\n/*jslint sub: true*/\r\n/**\r\n * @constructor\r\n * @param {!Element} element\r\n */\r\nfunction Example(element) {\r\n    /**\r\n     * @param {!string} ns\r\n     * @param {!string} name\r\n     * @return {undefined}\r\n     */\r\n    this.appendElement = function appendElement(ns, name) {\r\n        var e = element.ownerDocument.createElementNS(ns, name);\r\n        element.appendChild(e);\r\n    };\r\n}\r\nwindow[&quot;Example&quot;] = Example;\r\n2. compile it:\r\njava -jar compiler.jar --jscomp_error checkTypes --summary_detail_level 3 --js v.js --js_output_file compiled.js\r\n3. observe the outcome:\r\n0 error(s), 0 warning(s), 73.7% typed\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThis was expected:\r\n0 error(s), 0 warning(s), 100% typed\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nClosure Compiler Version: 964, Built on: 2011/04/05 14:31 on GNU/Linux.\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_71": {
    "description": "no warnings when @private prop is redeclared on subclass\n<b>What steps will reproduce the problem?</b>\n/** @constructor */ function Foo() { /** @private */ this.x_ = 3; }\r\n\r\nthen, in a separate file:\r\n/** @constructor \r\n * @extends {Foo} */ function SubFoo() { /** @private */ this.x_ = 3; }\r\n\r\nthen, compile with --jscomp_error=visibility\r\n\r\nExpected: You should get an error.\r\nActual: No error.\r\n\r\nYou get an error as appropriate if the second @private annotation is removed.",
    "desc_source": "google"
  },
  "Closure_72": {
    "description": "Internal Compiler Error on Bullet\n<b>What steps will reproduce the problem?</b>\n1. The attachment is the Bullet physics library, compiled from C++ to JS using Emscripten.\r\n2. I tried to compile it using the Closure Compiler, latest downloadable version (Apr 5 2011), with\r\n\r\njava -jar apr5compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS --variable_map_output_file js.vars --js bullet_1_1_q1.js --js_output_file bullet_1_1_q1.cc.js\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nI would expect it to compile successfully. Instead it halts (after a few hours) with\r\n\r\n\r\n==================\r\njava.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nnull\r\n  Node(LABEL): bullet_1_1_q1.js:60150:8\r\n        $for_body$5: while(1) { \r\n  Parent(BLOCK): bullet_1_1_q1.js:60043:26\r\n      if (__label__ == 0) {\r\n\r\n\tat com.google.javascript.jscomp.Compiler.runCallable(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(Unknown Source)\r\nCaused by: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nnull\r\n  Node(LABEL): bullet_1_1_q1.js:60150:8\r\n        $for_body$5: while(1) { \r\n  Parent(BLOCK): bullet_1_1_q1.js:60043:26\r\n      if (__label__ == 0) {\r\n\r\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:129)\r\n\tat com.google.javascript.jscomp.RenameLabels$ProcessLabels.shouldTraverse(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseFunction(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(Unknown Source)\r\n\tat com.google.javascript.jscomp.RenameLabels.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.optimize(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$2.run(Unknown Source)\r\n\tat java.lang.Thread.run(Thread.java:662)\r\nCaused by: java.lang.IllegalStateException\r\n\t... 40 more\r\n==================\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nThe Closure Compiler download from Apr 5 2011, on Ubuntu 10.04 32 bit.",
    "desc_source": "google"
  },
  "Closure_73": {
    "description": "Codepoint U+007f appears raw in output\n<b>What steps will reproduce the problem?</b>\n1. Open http://closure-compiler.appspot.com/home in your browser\r\n2. Enter the source code: alert('\\x7f')\r\n3. Hit the &quot;Compile&quot; button.\r\n\r\nWhat is the expected output?\r\nalert(&quot;\\x7f&quot;)\r\n\r\nWhat do you see instead?\r\nalert(&quot;\u007f&quot;);\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nThe version live on 11 April 2011.\r\n\r\n<b>Please provide any additional information below.</b>\nCodepoint U+007f is a delete control character and is the only non-printable ASCII codepoint that is not &lt;= U+0020.  http://www.fileformat.info/info/unicode/char/7f/index.htm\r\n\r\nIt should probably not appear raw in emitted source code because, it can confuse encoders.",
    "desc_source": "google"
  },
  "Closure_74": {
    "description": "Obvious optimizations don't works in \"inline if\"\nTry it (advanced mode):\r\n    alert(true == null ? a() : b());\r\n\r\nEVER true != null, in this case, EVER will trigger b(), but we get:\r\n    alert(!0 == null ? a() : b());\r\n\r\nSame for:\r\n    alert(true == false ? a() : b());\r\n\r\nReal life use:\r\n    function sum(a, b){\r\n      return (a == true ? 2 : a) + b;\r\n    }\r\n    alert(sum(true, 1));\r\n\r\nResults in:\r\n    alert((!0 == !0 ? 2 : 1) + 1);\r\n\r\nBut correct is:\r\n    alert(3);",
    "desc_source": "google"
  },
  "Closure_75": {
    "description": "closure compiled swfobject error\nswfobject.js code\r\n\r\nfunction urlEncodeIfNecessary(s) {\r\n\tvar regex = /[\\\\\\&quot;&lt;&gt;\\.;]/;\r\n\tvar hasBadChars = regex.exec(s) != null;\r\n\treturn hasBadChars &amp;&amp; typeof encodeURIComponent != UNDEF ? encodeURIComponent(s) : s;\r\n}\r\n\r\nclosure compiled:\r\n\r\nfunction Z(a){return/[\\&quot;&lt;&gt;.;]/.exec(a)!=\r\nnull&amp;&amp;typeof encodeURIComponent!=j?encodeURIComponent(a):a}\r\n\r\nbut it's error.and minify erray:\r\nFatal error: Uncaught exception 'JSMin_UnterminatedStringException' with message 'Unterminated String: '&quot;&lt;&gt;.;]/.exec(a)!=''\r\n\r\nreturn/[\\&quot;&lt;&gt;.;]/ to  return /[\\&quot;&lt;&gt;.;]/   that's OK\r\n\r\n\r\nie = !+&quot;\\v1&quot;,   closure compiled to   ie=!1,    my god!!",
    "desc_source": "google"
  },
  "Closure_76": {
    "description": "Assignments within conditions are sometimes incorrectly removed\n<b>What steps will reproduce the problem?</b>\n\r\n1. See attachment.\r\n2. Run original.\r\n3. Run compiled.\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\n* Both should return &quot;true&quot;\r\n* Original does return &quot;true&quot;\r\n* Compiled returns &quot;undefined&quot;\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nClosure Compiler (http://code.google.com/closure/compiler)\r\nVersion: 706\r\nBuilt on: 2011/01/19 19:53\r\n\r\nMac OS X 10.6\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nIn the attached reduction if the &quot;echo&quot; functions aren't used then the entire body of the function is compiled away, they are there to demonstrate that the first assignment in the condition is removed.\r\n\r\n\r\nOriginal:\r\n\r\nfunction reduction()\r\n{\r\n    var a, b;\r\n    if (echo(b = true) || echo(b = false))\r\n        a = b;\r\n    else\r\n        a = null;\r\n    return a;\r\n}\r\n\r\n\r\nCompiled:\r\n\r\nfunction reduction() {\r\n    var a;\r\n    return echo(true) || echo(a = false) ? a: null\r\n}",
    "desc_source": "google"
  },
  "Closure_77": {
    "description": "\\0 \\x00 and \\u0000 are translated to null character\n<b>What steps will reproduce the problem?</b>\n1. write script with string constant &quot;\\0&quot; or &quot;\\x00&quot; or &quot;\\u0000&quot;\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nI expected a string literal with &quot;\\0&quot; (or something like that)\r\nand instead get a string literal with three null character values.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\ncompiler-20110119.zip on windows 7 x64\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nThis is causing an issue with IE9 and jQuery.getScript. It causes IE9 to interpret the null character as the end of the file instead of a null character.",
    "desc_source": "google"
  },
  "Closure_78": {
    "description": "division by zero wrongly throws JSC_DIVIDE_BY_0_ERROR\n<b>What steps will reproduce the problem?</b>\n\r\nunaliased division by zero `1/0`\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nI expect minified code, but an error is thrown instead.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nappspot\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nDivision by zero is a perfectly sane operation in ECMAScript. See 11.5.2 [0] of the ECMAScript 5 specification. Aliased division by zero `(n=1)/0` is permitted.\r\n\r\n[0] http://es5.github.com/#x11.5.2",
    "desc_source": "google"
  },
  "Closure_79": {
    "description": "RuntimeException when compiling with extern prototype\n<b>What steps will reproduce the problem?</b>\n\r\n1. java -jar compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS --externs prototype.js --js bootloader.js\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\njava.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nnull\r\n  Node(FUNCTION ): prototype.js:213:11\r\n  function Str(key, holder, stack) {\r\n  Parent(BLOCK): prototype.js:160:12\r\n(function() {\r\n\r\n\tat com.google.javascript.jscomp.Compiler.runCallable(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(Unknown Source)\r\nCaused by: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nnull\r\n  Node(FUNCTION ): prototype.js:213:11\r\n  function Str(key, holder, stack) {\r\n  Parent(BLOCK): prototype.js:160:12\r\n(function() {\r\n\r\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:129)\r\n\tat com.google.javascript.jscomp.Normalize$DuplicateDeclarationHandler.onRedeclaration(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.declareVar(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanVars(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.scanRoot(Unknown Source)\r\n\tat com.google.javascript.jscomp.SyntacticScopeCreator.createScope(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.getScope(Unknown Source)\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nVersion: 706\r\nBuilt on: 2011/01/19 19:53\r\n\r\nMac OS X 10.6.0",
    "desc_source": "google"
  },
  "Closure_80": {
    "description": "Unexpected expression nodeDELPROP 1\nAs of version 20110119 of the closure compiler, the following code produces an error when it's compiled with advanced compilation enabled:\r\n\r\n    function x() { return delete a; }\r\n\r\n\r\nThe exact output of the compiler:\r\n\r\n\r\njava.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nUnexpected expression nodeDELPROP 1 [sourcename: stdin]\r\n parent:RETURN 1 [sourcename: stdin]\r\n  Node(RETURN): stdin:1:15\r\nfunction x() { return delete a; }\r\n  Parent(BLOCK): stdin:1:13\r\nfunction x() { return delete a; }\r\n\r\n\tat com.google.javascript.jscomp.Compiler.runCallable(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(Unknown Source)\r\nCaused by: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nUnexpected expression nodeDELPROP 1 [sourcename: stdin]\r\n parent:RETURN 1 [sourcename: stdin]\r\n  Node(RETURN): stdin:1:15\r\nfunction x() { return delete a; }\r\n  Parent(BLOCK): stdin:1:13\r\nfunction x() { return delete a; }\r\n\r\n\tat com.google.javascript.jscomp.NodeUtil.evaluatesToLocalValue(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeUtil.evaluatesToLocalValue(Unknown Source)\r\n\tat com.google.javascript.jscomp.PureFunctionIdentifier$FunctionAnalyzer.visit(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseFunction(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(Unknown Source)\r\n\tat com.google.javascript.jscomp.PureFunctionIdentifier.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PureFunctionIdentifier$Driver.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.optimize(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$2.run(Unknown Source)\r\n\tat java.lang.Thread.run(Thread.java:680)\r\nCaused by: java.lang.IllegalStateException: Unexpected expression nodeDELPROP 1 [sourcename: stdin]\r\n parent:RETURN 1 [sourcename: stdin]\r\n\t... 23 more",
    "desc_source": "google"
  },
  "Closure_81": {
    "description": "An unnamed function statement statements should generate a parse error\nAn unnamed function statement statements should generate a parse error, but it does not, for example:\r\n\r\nfunction () {};\r\n\r\nNote: Unnamed function expression are legal:\r\n\r\n(function(){});",
    "desc_source": "google"
  },
  "Closure_82": {
    "description": ".indexOf fails to produce missing property warning\nThe following code compiled with VERBOSE warnings or with the missingProperties check enabled fails to produce a warning or error:\r\n\r\nvar s = new String(&quot;hello&quot;);\r\nalert(s.toLowerCase.indexOf(&quot;l&quot;));\r\n\r\nHowever, other string functions do properly produce the warning:\r\n\r\nvar s = new String(&quot;hello&quot;);\r\nalert(s.toLowerCase.substr(0, 1));",
    "desc_source": "google"
  },
  "Closure_83": {
    "description": "Cannot see version with --version\n<b>What steps will reproduce the problem?</b>\n1. Download sources of latest (r698) command-line version of closure compiler.\r\n2. Build (with ant from command line).\r\n3. Run compiler (java -jar compiler.jar --version).\r\n\r\nWhat is the expected output?\r\nClosure Compiler (http://code.google.com/closure/compiler)\r\nVersion: 698\r\nBuilt on: 2011/01/17 12:16\r\n\r\nWhat do you see instead?\r\n\u041e\u043f\u0446\u0438\u044f &quot;--version&quot; \u0442\u0440\u0435\u0431\u0443\u0435\u0442 \u043e\u043f\u0435\u0440\u0430\u043d\u0434\r\n(Option &quot;--version&quot; requires operand)\r\nand full list of options with description.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nLatest source of command-line compiler from SVN (r698). OS Linux Mint 7, Sun Java 1.6.0_22.\r\n\r\n<b>Please provide any additional information below.</b>\nWhen running compiler with\r\njava -jar compiler.jar --version ?\r\nit shows error message, then version info, then full list of options.",
    "desc_source": "google"
  },
  "Closure_84": {
    "description": "Invalid left-hand side of assignment not detected\n<b>What steps will reproduce the problem?</b>\nCompile this:\r\n  var x=0,y=1;x||y=8\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nI expect an error, because this is parsed as (x||y)=8, which is an invalid left-hand side of an assignment. Instead, I get\r\n  var x=0,y=1;x||y=8;\r\nwhich, like the input, is invalid code.",
    "desc_source": "google"
  },
  "Closure_85": {
    "description": "Reproduceable crash with switch statement\nWhen attempting to compile the following code with default options (-jar compiler.jar --js filename) always produces the same error.\r\n\r\nfunction a(b) {\r\n  switch (b.v) {\r\n    case 'SWITCH':\r\n      if (b.i &gt;= 0) {\r\n        return b.o;\r\n      } else {\r\n        return undefined;\r\n      }\r\n      break;\r\n  }\r\n}\r\n\r\nWhenever I try and compile the above script I get a RuntimeException thrown:\r\n\r\nINTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nnull\r\n  Node(BREAK): C:\\test.js:11:3\r\n      break;\r\n  Parent: NULL\r\n\r\nThe result of calling --version on compiler.jar:\r\n\r\nVersion: 20100917 (revision 440)\r\nBuilt on: 2010/09/17 17:55\r\n\r\nThe result of calling -version on java.exe:\r\n\r\njava version &quot;1.6.0_11&quot;\r\nJava(TM) SE Runtime Environment (build 1.6.0_11-b03)\r\nJava HotSpot(TM) Client VM (build 11.0-b16, mixed mode, sharing)\r\n\r\nAnyone else with the same issue - to work around in the short term, comment out the &quot;break;&quot; line.",
    "desc_source": "google"
  },
  "Closure_86": {
    "description": "side-effects analysis incorrectly removing function calls with side effects\nSample Code:\r\n---\r\n/** @constructor */\r\nfunction Foo() {\r\n  var self = this;\r\n  window.setTimeout(function() {\r\n    window.location = self.location;\r\n  }, 0);\r\n}\r\n\r\nFoo.prototype.setLocation = function(loc) {\r\n  this.location = loc;\r\n};\r\n\r\n(new Foo()).setLocation('http://www.google.com/');\r\n---\r\n\r\nThe setLocation call will get removed in advanced mode.",
    "desc_source": "google"
  },
  "Closure_87": {
    "description": "IE8 error: Object doesn't support this action\n<b>What steps will reproduce the problem?</b>\n1. Use script with fragment like\r\n    if (e.onchange) {\r\n      e.onchange({\r\n        _extendedByPrototype: Prototype.emptyFunction,\r\n        target: e\r\n      });\r\n    }\r\n2. Compile with Compiler (command-line, latest version)\r\n3. Use in IE8\r\n\r\nWhat is the expected output?\r\nScript:\r\nif(b.onchange){b.onchange({_extendedByPrototype:Prototype.emptyFunction,target\r\n:b})}\r\n\r\nWhat do you see instead?\r\nScript:\r\nb.onchange&amp;&amp;b.onchange({_extendedByPrototype:Prototype.emptyFunction,target\r\n:b})\r\nIE8:\r\nError message &quot;Object doesn't support this action&quot;\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nVersion: 20100917 (revision 440)\r\nBuilt on: 2010/09/17 17:55",
    "desc_source": "google"
  },
  "Closure_88": {
    "description": "Incorrect assignment removal from expression in simple mode.\nfunction closureCompilerTest(someNode) {\r\n   var nodeId;\r\n   return ((nodeId=someNode.id) &amp;&amp; (nodeId=parseInt(nodeId.substr(1))) &amp;&amp; nodeId&gt;0);\r\n}\r\n\r\nCOMPILES TO:\r\n\r\nfunction closureCompilerTest(b){var a;return b.id&amp;&amp;(a=parseInt(a.substr(1)))&amp;&amp;a&gt;0};\r\n\r\n&quot;nodeId=someNode.id&quot; is replaced with simply &quot;b.id&quot; which is incorrect as the value of &quot;nodeId&quot; is used.",
    "desc_source": "google"
  },
  "Closure_89": {
    "description": "Compiler removes function properties that it should not\nThe Compiler appears to remove properties that are added to functions. I do not believe that it should do such a thing. In the following example, I add a property named &quot;alwaysCall&quot; to a function that I check later. The property appears to be stripped, which changes the behavior of the program. To see this in action run the following through http://closure-compiler.appspot.com/home:\r\n\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// @use_closure_library true\r\n// @formatting pretty_print\r\n// ==/ClosureCompiler==\r\n\r\nvar lastMsg;\r\nvar map = {};\r\n\r\nvar addToMap = function(key, func) {\r\n  map[key] = func;\r\n};\r\n\r\nvar f1 = function() { alert('f1'); };\r\nf1.alwaysCall = true;\r\nvar f2 = function() { alert('f2'); };\r\n\r\naddToMap('f1', f1);\r\naddToMap('f2', f2);\r\n\r\nvar callFunctionByKey = function(key) {\r\n  var f = map[key];\r\n  if (f.alwaysCall) f();\r\n};\r\n\r\ncallFunctionByKey(Math.random() &gt; 0.5 ? 'f1' : 'f2');\r\n\r\n\r\nThe compiled code is:\r\n\r\n\r\nvar a = {};\r\na.f1 = function() {\r\n  alert(&quot;f1&quot;)\r\n};\r\na.f2 = function() {\r\n  alert(&quot;f2&quot;)\r\n};\r\nvar b = a[Math.random() &gt; 0.5 ? &quot;f1&quot; : &quot;f2&quot;];\r\nb.a &amp;&amp; b();\r\n\r\nNote that a.f1 does not have a property defined on it anymore, though it still appears to be checked on this line of code:\r\n\r\nb.a &amp;&amp; b();\r\n\r\nSo it looks like it is missing the following:\r\n\r\na.f1.a =  true;\r\n\r\nFor now, I can workaround this by quoting the property:\r\n\r\nf1['alwaysCall'] = true;\r\n\r\n// In callFunctionByKey:\r\nif (f['alwaysCall']) f();\r\n\r\nBut that seems as though it should not be necessary.",
    "desc_source": "google"
  },
  "Closure_90": {
    "description": "@this emits warning when used with a typedef\n<b>What steps will reproduce the problem?</b>\n\r\n1. Compile this with r520:\r\n\r\ngoog.provide('bug');\r\n\r\n/**\r\n * @this {bug.Thing}\r\n */\r\nbug.sharedMethod = function() {};\r\n\r\n/**\r\n * @constructor\r\n */\r\nbug.A = function() {};\r\n\r\n/**\r\n * @constructor\r\n */\r\nbug.B = function() {};\r\n\r\n/**\r\n * @type {bug.A|bug.B}\r\n */\r\nbug.Thing = goog.typedef;\r\n\r\n2. Observe this warning:\r\n\r\nOct 28, 2010 9:59:15 PM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process\r\nINFO: sanityCheckVars\r\nOct 28, 2010 9:59:15 PM com.google.javascript.jscomp.LoggerErrorManager println\r\nWARNING: /home/elf/JSPATH/compiler_bug_this_typedef.js:6: WARNING - @this type of a function must be an object\r\nActual type: (bug.A|bug.B|null)\r\nbug.sharedMethod = function() {};\r\n\r\n\r\nNote that @this {!bug.Thing} doesn't work either, while @this {bug.A|bug.B} works.  This code did not emit a warning in r481.\r\n\r\nThis code is what caused me to run into http://code.google.com/p/closure-compiler/issues/detail?id=268",
    "desc_source": "google"
  },
  "Closure_91": {
    "description": "support @lends annotation\nSome javascript toolkits (dojo, base, etc.) have a special way of declaring (what java calls) classes, for example in dojo:\r\n\r\ndojo.declare(&quot;MyClass&quot;, [superClass1, superClass2], { \r\n    foo: function(){ ... } \r\n    bar: function(){ ... } \r\n}); \r\n\r\nJSDoc (or at least JSDoc toolkit) supports this via annotations: \r\n\r\n/** \r\n * @name MyClass \r\n * @class \r\n * @extends superClass1 \r\n * @extends superClass2 \r\n */ \r\ndojo.declare(&quot;MyClass&quot;, [superClass1, superClass2], /** @lends \r\nMyClass.prototype */ { \r\n    foo: function(){ ... } \r\n    bar: function(){ ... } \r\n}); \r\n\r\nThe @lends keyword in particular is useful since it tells JSDoc that foo and bar are part of MyClass's prototype.   But closure compiler isn't picking up on that, thus I get a bunch of errors about &quot;dangerous use of this&quot; inside of foo() and bar(). \r\n\r\nSo, can @lends support be added to the closure compiler?\r\n\r\nThe workaround is to use @this on every method, but not sure if that is sufficient to make advanced mode compilation work correctly.",
    "desc_source": "google"
  },
  "Closure_92": {
    "description": "bug with implicit namespaces across modules\nIf there are three modules, the latter two of which depend on the root module:\r\n\r\n// Module A\r\ngoog.provide('apps');\r\n\r\n// Module B\r\ngoog.provide('apps.foo.bar.B');\r\n\r\n// Module C\r\ngoog.provide('apps.foo.bar.C');\r\n\r\nand this is compiled in SIMPLE_OPTIMIZATIONS mode, the following code will be produced:\r\n\r\n// Module A\r\nvar apps={};apps.foo.bar={};apps.foo={};\r\n\r\n// Module B\r\napps.foo.bar.B={};\r\n\r\n// Module C\r\napps.foo.bar.C={};\r\n\r\nThis will result in a runtime error in Module A because apps.foo.bar is assigned before apps.foo.\r\n\r\nThe patch for the fix (with regression test) is available at:\r\nhttp://codereview.appspot.com/2416041",
    "desc_source": "google"
  },
  "Closure_94": {
    "description": "closure-compiler @define annotation does not allow line to be split on 80 characters.\n<b>What steps will reproduce the problem?</b>\n1.  Create a JavaScript file with the followiing:\r\n/** @define {string} */\r\nvar CONSTANT = &quot;some very long string name that I want to wrap &quot; +\r\n               &quot;and so break using a + since I don't want to &quot; +\r\n               &quot;introduce a newline into the string.&quot;\r\n2.  Run closure-compiler on the .js file.\r\n3.  See it generate an error on the '+'.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nIt should work, since the line is assigning a constant value to the var.\r\n\r\n<b>Please provide any additional information below.</b>\nRemoving the '+' and making the string all one line does work correctly.",
    "desc_source": "google"
  },
  "Closure_95": {
    "description": "Use @public tag to prevent compression of symbol names\nGiven this input code:\r\n\r\n\tGlow = {};\r\n\t/** @public */ Glow.versions = [1,2,3];\r\n\tGlow.showVersions = function() { alert(Glow.versions); }\r\n\t\r\n\t// exports\r\n\twindow['Glow'] = Glow;\r\n\tGlow['versions'] = Glow.versions;\r\n\tGlow['showVersions'] = Glow.showVersions;\r\n\r\nThe compiler (with ADVANCED_OPTIMIZATIONS on) will produce the following\r\noutput code:\r\n\r\n\tGlow = {};\r\n\tGlow.a = [1, 2, 3];\r\n\tGlow.b = function() { alert(Glow.a) };\r\n\twindow.Glow = Glow;\r\n\tGlow.versions = Glow.a;\r\n\tGlow.showVersions = Glow.b\r\n\r\nFrom outside the Glow library, a user may do the following (in their own,\r\nuncompressed code):\r\n\r\n\tGlow.versions = [4,5,6];\r\n\tGlow.showVersions();\r\n\r\nOnly in the compiled code will the user-code produces &quot;1,2,3&quot; instead of\r\nthe expected &quot;4,5,6&quot;. This is because the compiler renamed the reference to\r\n[1,2,3] in `showVersions()` to &quot;Glow.a&quot;, whilst the user assigned a new\r\narray to &quot;Glow.versions&quot;, and therefore the two different names now refer\r\nto two different arrays.\r\n\r\nI can avoid this by using the stringy-name to refer to Glow[&quot;versions&quot;],\r\nbut I would then have to do that everywhere in my code which is a annoying\r\nand bug-prone (if I or someone else should ever forget). I'd prefer to tell\r\nthe compiler once about my wish to have a property name left uncompresed,\r\nrather than relying on a side effect (the fact that the compiler won't\r\ncompress stringy-named properties) and then having to invoke that\r\nside-effect consistently everywhere.\r\n\r\nInstead I'm requesting that when the compiler sees a property is marked by\r\nthe author as @public it should then leave that name uncompressed everywhere.\r\n\r\nSo, given the input code above, the desired output would be:\r\n\r\n\tGlow = {};\r\n\tGlow.versions = [1, 2, 3];\r\n\tGlow.b = function() { alert(Glow.versions) };\r\n\twindow.Glow = Glow;\r\n\tGlow.versions = Glow.versions; // not needed now\r\n\tGlow.showVersions = Glow.b\r\n\r\nI'm not fixed on a particular tag, but @public seems an obvious choice, and\r\nI'd prefer to use tags that already exist in JsDoc Toolkit.\r\n\r\nNote that my proposed feature is different than the `@export Glow.versions`\r\ntag proposal, as that tag would merely be a shortcut for &quot;Glow['versions']\r\n= Glow.versions;&quot;, which, as I've shown above, doesn't solve this problem.",
    "desc_source": "google"
  },
  "Closure_96": {
    "description": "Missing type-checks for var_args notation\n<b>What steps will reproduce the problem?</b>\n1. Compile this:\r\n//-------------------------------------\r\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @warning_level VERBOSE\r\n// @output_file_name default.js\r\n// @formatting pretty_print\r\n// ==/ClosureCompiler==\r\n\r\n/**\r\n* @param {...string} var_args\r\n*/\r\nfunction foo(var_args) {\r\n    return arguments.length;\r\n}\r\n\r\nfoo('hello'); // no warning - ok\r\nfoo(123); // warning - ok\r\nfoo('hello', 123); // no warning! error.\r\n//-------------------------------------\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nShould get a type-mismatch warning for the second parameter in the third foo() call.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nBoth online compiler and the 20100616 release.\r\n\r\n<b>Please provide any additional information below.</b>\nSeems like the type-checker treats 'var_args' as a single param and thus fails to type check the subsequent parameters.\r\n\r\n// Fredrik",
    "desc_source": "google"
  },
  "Closure_97": {
    "description": "Unsigned Shift Right (>>>) bug operating on negative numbers\n<b>What steps will reproduce the problem?</b>\ni = -1 &gt;&gt;&gt; 0 ;\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nExpected: i = -1 &gt;&gt;&gt; 0 ;  // or // i = 4294967295 ;\r\nInstead: i = -1 ;\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nThe UI version as of 7/18/2001 (http://closure-compiler.appspot.com/home)\r\n\r\n<b>Please provide any additional information below.</b>\n-1 &gt;&gt;&gt; 0 == 4294967295 == Math.pow( 2, 32 ) - 1\r\nTest in any browser and/or See ECMA-262-5 11.7.3",
    "desc_source": "google"
  },
  "Closure_98": {
    "description": "bad variable inlining in closure\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// @formatting pretty_print\r\n// ==/ClosureCompiler==\r\n\r\nfunction foo() {\r\n var arr = [1, 2, 3, 4, 5];\r\n for (var i = 0, l = arr.length; i &lt; l; i++) {\r\n   var j = arr[i];\r\n   (function() {\r\n     var k = j;\r\n     setTimeout(function() { console.log(k); }, 0);\r\n   })();\r\n }\r\n}\r\nfoo();\r\n\r\n&quot;k&quot; will get incorrectly inlined.",
    "desc_source": "google"
  },
  "Closure_99": {
    "description": "Prototypes declared with quotes produce a JSC_USED_GLOBAL_THIS warning.\nCompiling the following code (in advanced optimizations with VERBOSE\r\nwarning levels):\r\n\r\n/** @constructor */\r\nfunction MyClass() {}\r\nMyClass.prototype[&quot;MyMethod&quot;] = function(a) {\r\n  this.a = a;\r\n}\r\nwindow[&quot;MyClass&quot;] = MyClass;\r\n\r\nResults in the following warning: &quot;dangerous use of the global this\r\nobject.&quot; This notation is convenient to declare a prototype that is purely\r\nused for export purposes. The warning can be suppressed by using an @this\r\nnotation.\r\n\r\nGiven the following externs:\r\n\r\n/**@interface */\r\nfunction MyParent() {}\r\n/** @param {*} a */\r\nMyParent.prototype.MyMethod = function(a) {}\r\n\r\nAnd the following code:\r\n\r\n/**\r\n* @constructor\r\n* @implements {MyParent}\r\n*/\r\nfunction MyClass() {}\r\nMyClass.prototype[&quot;MyMethod&quot;] = function(a) {\r\n  this.a2 = a;\r\n}\r\nwindow[&quot;MyClass&quot;] = MyClass;\r\n\r\nThe compiler also produces the waring: &quot;property MyMethod on interface\r\nMyParent is not implemented by type MyClass&quot;.",
    "desc_source": "google"
  },
  "Closure_100": {
    "description": "Only assignment to \"this\" issues a \"dangerous use of the global this object\" warning.\n<b>What steps will reproduce the problem?</b>\n1. Compile this:\r\n//////////////////////////////////////////\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\n/** @constructor */\r\nfunction Foo()\r\n{\r\n    this._bar = null;\r\n};\r\n\r\n/** @this {Foo} */\r\nfunction writeMethodWithAnnotation()\r\n{\r\n   this._bar = 123; // no warning. ok\r\n}\r\n\r\n/** @this {Foo} */\r\nfunction readMethodWithAnnotation()\r\n{\r\n   return this._bar; // no warning. ok\r\n}\r\n\r\n//----\r\n\r\nfunction writeMethodWithoutAnnotation()\r\n{\r\n   this._bar = 123; // warning. ok.\r\n}\r\n\r\nfunction readMethodWithoutAnnotation()\r\n{\r\n   return this._bar; // &lt;- No warning!\r\n}\r\n//////////////////////////////////////////\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n- Should get two &quot;dangerous use of the global this object&quot; warnings in the \r\nreadMethodWithAnnotation and writeMethodWithoutAnnotation functions.\r\n- Only writeMethodWithoutAnnotation warns.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nBoth 20100330 and online compiler.\r\n\r\n<b>Please provide any additional information below.</b>\nref: http://code.google.com/closure/compiler/docs/js-for-compiler.html \r\n&quot;To prevent compiler warnings, you must use a @this annotation whenever \r\nthis appears in a function that is neither a prototype method nor a \r\nfunction marked as a @constructor.&quot;\r\n\r\nThis also means the example code in the docs won't trig a warning.\r\n-----\r\n/**\r\n * Returns the roster widget element.\r\n * @this {Widget} &lt;-- currently this doesn't matter\r\n * @return {Element}\r\n */\r\nfunction() {\r\n  return this.getComponent().getElement();\r\n});\r\n------\r\n\r\n// Fredrik",
    "desc_source": "google"
  },
  "Closure_101": {
    "description": "--process_closure_primitives can't be set to false\n<b>What steps will reproduce the problem?</b>\n1. compile a file with &quot;--process_closure_primitives false&quot;\r\n2. compile a file with &quot;--process_closure_primitives true&quot; (default)\r\n3. result: primitives are processed in both cases.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThe file should still have its goog.provide/require tags in place.\r\nInstead they are processed.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\ncurrent SVN (also tried two of the preceding binary releases with same \r\nresult)\r\n\r\n<b>Please provide any additional information below.</b>\nFlag can't be set to false due to a missing &quot;else&quot; in the command-line \r\nparser.",
    "desc_source": "google"
  },
  "Closure_102": {
    "description": "compiler assumes that 'arguments' can be shadowed\nThe code:\r\nfunction name() {\r\n   var arguments = Array.prototype.slice.call(arguments, 0);\r\n}\r\n\r\ngets compiled to:\r\nfunction name(){ var c=Array.prototype.slice.call(c,0); }\r\n\r\nThanks to tescosquirrel for the report.",
    "desc_source": "google"
  },
  "Closure_103": {
    "description": "Compiler gives false error with respect to unreachable code\nTry compiling the following in the Closure Compiler UI:\r\n\r\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\nfunction instanceOf(value, type) {\r\n  try {\r\n    // first try built-in test -- if it succeeds, we're golden.\r\n    if (value instanceof type) {\r\n      return true;\r\n    }\r\n  } catch (exception) {\r\n    if (exception instanceof TypeError) {\r\n      throw exception; // indicates that &quot;type&quot; is not a type\r\n    }\r\n    // Otherwise, assume the exception was caused by \r\n    // the Firefox 1.0.3 bug.  Work around it.\r\n    return (type === Object);\r\n  }\r\n}\r\n\r\nThe Compiler issues the following warning:\r\n\r\nJSC_UNREACHABLE_CODE: unreachable code at line 7 character 0\r\n  } catch (exception) {\r\n\r\nThis code is from a Firefox extension (Chickenfoot) where (at least\r\nhistorically) calling instanceof in this manner could throw a security\r\nexception (or something else, I forget what -- Chickenfoot has been around\r\nsince Firefox 1.0) which is why the catch blocks is there and is indeed\r\nreachable.",
    "desc_source": "google"
  },
  "Closure_104": {
    "description": "Typos in externs/html5.js\nLine 354:\r\nCanvasRenderingContext2D.prototype.globalCompositingOperation;\r\n\r\nLine 366:\r\nCanvasRenderingContext2D.prototype.mitreLimit;\r\n\r\nThey should be globalCompositeOperation and miterLimit, respectively.",
    "desc_source": "google"
  },
  "Closure_105": {
    "description": "Array Join Munged Incorrectly\n$.fn.hasClass = function(selector) {\r\n\treturn ( this.length &gt; 0 ? \r\n\t\t\t\t!( ( ['', this[0].className, ''].join(' ') ).indexOf( ['', selector, \r\n''].join(' ') ) == -1 )\r\n\t\t\t\t: false );\r\n};\r\n\r\nmunges into\r\n\r\n$.fn.hasClass=function(a){return this.length&gt;0?\r\n(&quot;&quot;+this[0].className).indexOf(&quot;&quot;+a)!=-1:false};\r\n\r\nwhich is not identical. Looks like there might be an issue with join and ' '.",
    "desc_source": "google"
  },
  "Closure_106": {
    "description": "Exception thrown from com.google.javascript.jscomp.CollapseProperties.addStubsForUndeclaredProperties\nThe attached javascript file results in a Java exception being thrown when compiling with ADVANCED_OPTIMIZATIONS\r\n\r\n[~/Projects/Music Theory/trunk] # java -jar ./ext/closure-compiler/compiler.jar --js /tmp/musictheory.net/v2/js/core.js --compilation_level \r\nADVANCED_OPTIMIZATIONS\r\njava.lang.RuntimeException: java.lang.IllegalArgumentException\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCompilerRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCompilerRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CompilerRunner.main(Unknown Source)\r\nCaused by: java.lang.IllegalArgumentException\r\n\tat com.google.common.base.Preconditions.checkArgument(Preconditions.java:71)\r\n\tat com.google.javascript.jscomp.CollapseProperties.addStubsForUndeclaredProperties(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.updateObjLitOrFunctionDeclarationAtAssignNode(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.updateObjLitOrFunctionDeclaration(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.optimize(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$2.run(Unknown Source)\r\n\tat java.lang.Thread.run(Thread.java:637)\r\n\r\nI'm guessing that I did something wrong in my script which adds the goog.exportSymbol() calls, but it probably should give me a nice warning or error instead \r\nof throwing a Java exception ;)",
    "desc_source": "google"
  },
  "Closure_107": {
    "description": "Variable names prefixed with MSG_ cause error with advanced optimizations\nVariables named something with MSG_ seem to cause problems with the module system, even if no modules are used in the code.\r\n\r\n$ echo &quot;var MSG_foo='bar'&quot; | closure --compilation_level ADVANCED_OPTIMIZATIONS\r\nstdin:1: ERROR - message not initialized using goog.getMsg\r\nvar MSG_foo='bar'\r\n    ^\r\n\r\nIt works fine with msg_foo, MSG2_foo, etc.",
    "desc_source": "google"
  },
  "Closure_108": {
    "description": "precondition crash: goog.scope local with aliased in the type declaration\nvar goog = {};\r\ngoog.scope;\r\n\r\nvar ns = {};\r\nns.sub = {};\r\n/** @constructor */\r\nns.sub.C = function() {};\r\n\r\n\r\ngoog.scope(function() {\r\n  var sub = ns.sub;\r\n  /** @type {sub.C} */\r\n  var x = null;\r\n});\r\n\r\n\r\nproduces:\r\n\r\njava.lang.IllegalStateException at com.google.common.base.Preconditions.checkState(Preconditions.java:137) at com.google.javascript.jscomp.ScopedAliases$AliasedTypeNode.applyAlias(ScopedAliases.java:236) at com.google.javascript.jscomp.ScopedAliases.hotSwapScript(ScopedAliases.java:147) at com.google.javascript.jscomp.ScopedAliases.process(ScopedAliases.java:128) at",
    "desc_source": "google"
  },
  "Closure_109": {
    "description": "Constructor types that return all or unknown fail to parse\nConstructor types that return the all type or the unknown type currently fail to parse:\r\n\r\n/** @type {function(new:?)} */ var foo = function() {};\r\n/** @type {function(new:*)} */ var bar = function() {};\r\n\r\nfoo.js:1: ERROR - Bad type annotation. type not recognized due to syntax error\r\n/** @type {function(new:?)} */ var foo = function() {};\r\n                        ^\r\n\r\nfoo.js:2: ERROR - Bad type annotation. type not recognized due to syntax error\r\n/** @type {function(new:*)} */ var bar = function() {};\r\n                        ^\r\n\r\nThis is an issue for a code generator that I'm working on.",
    "desc_source": "google"
  },
  "Closure_110": {
    "description": "Allow @private top-level functions in goog.scope\n<b>What steps will reproduce the problem?</b>\n\r\n<b>1.</b>\ngoog.scope(function() {\r\n    /* @private */\r\n    function test() {}\r\n});\r\n\r\n<b>2.</b>\nThe code above gives an error &quot;The local variable test is in a goog.scope and is not an alias.&quot;\r\n\r\nWhat is the expected output?\r\n\r\nThe code above should compile, and function test() be referenceable only from inside the file in question. If I replace &quot;function test&quot; with &quot;var test = function&quot;, the code compiles.",
    "desc_source": "google"
  },
  "Closure_111": {
    "description": "goog.isArray doesn't hint compiler\n<b>What steps will reproduce the problem?</b>\n<b>1.</b>\n\r\n/**\r\n * @param {*} object\r\n * @return {*}\r\n */\r\nvar test = function(object) {\r\n  if (goog.isArray(object)) {\r\n    /** @type {Array} */ var x = object;\r\n    return x;\r\n  }\r\n};\r\n\r\n2. ADVANCED_OPTIMIZATIONS\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nERROR - initializing variable\r\nfound   : *\r\nrequired: (Array|null)\r\n    /** @type {Array} */ var x = object;\r\n                                 ^\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nClosure Compiler (http://code.google.com/closure/compiler)\r\nVersion: v20130411-90-g4e19b4e\r\nBuilt on: 2013/06/03 12:07\r\n\r\n<b>Please provide any additional information below.</b>\n\r\ngoog.is* is supposed to help the compiler to check which type we're dealing with.",
    "desc_source": "google"
  },
  "Closure_112": {
    "description": "Template types on methods incorrectly trigger inference of a template on the class if that template type is unknown\nSee i.e.\r\n\r\n\r\n\r\n/**\r\n  * @constructor\r\n  * @template CLASS\r\n  */\r\nvar Class = function() {};\r\n\r\n/**\r\n  * @param {function(CLASS):CLASS} a\r\n  * @template T\r\n  */\r\nClass.prototype.foo = function(a) {\r\n  return 'string';\r\n};\r\n\r\n/** @param {number} a\r\n  * @return {string} */\r\nvar a = function(a) { return '' };\r\n\r\nnew Class().foo(a);\r\n\r\n\r\nThe CLASS type is never specified. If the @template T line is removed from the foo method, the block compiles with but with the @annotation on the method, the compiler seems to try to infer CLASS from the usage and fails compilation.",
    "desc_source": "google"
  },
  "Closure_113": {
    "description": "Bug in require calls processing\nThe Problem\r\n\r\nProcessClosurePrimitives pass has a bug in processRequireCall method.\r\nThe method processes goog.require calls. If a require symbol is invalid i.e is not provided anywhere, the method collects it for further error reporting. If the require symbol is valid, the method removes it from the ast.\r\n\r\nAll invalid require calls must be left for further using/checking of the code! The related comment in the code confirms this.\r\n\r\nNevertheless, the second condition (requiresLevel.isOn() -&gt; see source code) is invalid and always causes removing of the requires when we want to check these requires.\r\n\r\nIn any case, the method should not use the requiresLevel to decide if we need removing. The requiresLevel should be used to check if we need error reporting. \r\n\r\nThe Solution\r\n\r\nRemove the condition.\r\nPlease see the attached patch.",
    "desc_source": "google"
  },
  "Closure_114": {
    "description": "Crash on the web closure compiler\nWith the web application (http://closure-compiler.appspot.com/home)\r\n\r\nConfig:\r\n\r\n// ==ClosureCompiler==\r\n// @output_file_name default.js\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// ==/ClosureCompiler==\r\n\r\n\r\nCode:\r\n\r\nvar g=function(m){return m*Math.random()|0},d=document,h=d.getElementById('h'),c=d.getElementById('c'),l;\r\n(l=function(){requestAnimationFrame(l);h.style.textShadow=&quot;0 0 1px #000,&quot;+(g(10)-5)+&quot;px &quot;+(g(10)-5)+&quot;px 0 #888,0 0 180px rgb(&quot;+g(255)+&quot;,&quot;+g(255)+&quot;,&quot;+g(255)+&quot;)&quot;})();\r\nd.addEventListener('mousemove',function(v){c.style.marginTop=(v.pageY/10+15|0)+'px'})\r\n\r\n\r\nCause:\r\n\r\nvar l; // D\u00e9clare l variable\r\n\r\n// Store function in l var and call\r\n(l = function(){ ... })       ();\r\n\r\n\r\nCrash repport: (long)\r\n\r\n23: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nUnexpected variable l\r\n  Node(NAME l): Input_0:2:36\r\n(l=function(){requestAnimationFrame(l);h.style.textShadow=&quot;0 0 1px #000,&quot;+(g(10)-5)+&quot;px &quot;+(g(10)-5)+&quot;px 0 #888,0 0 180px rgb(&quot;+g(255)+&quot;,&quot;+g(255)+&quot;,&quot;+g(255)+&quot;)&quot;})();\r\n  Parent(CALL): Input_0:2:14\r\n(l=function(){requestAnimationFrame(l);h.style.textShadow=&quot;0 0 1px #000,&quot;+(g(10)-5)+&quot;px &quot;+(g(10)-5)+&quot;px 0 #888,0 0 180px rgb(&quot;+g(255)+&quot;,&quot;+g(255)+&quot;,&quot;+g(255)+&quot;)&quot;})();\r\n\r\n\tat com.google.javascript.jscomp.VarCheck.visit(VarCheck.java:159)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:544)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:538)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:538)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:538)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:538)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseRoots(NodeTraversal.java:318)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseRoots(NodeTraversal.java:507)\r\n\tat com.google.javascript.jscomp.VarCheck.process(VarCheck.java:102)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(PhaseOptimizer.java:271)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(PhaseOptimizer.java:215)\r\n\tat com.google.javascript.jscomp.Compiler.optimize(Compiler.java:1918)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Compiler.java:751)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Compiler.java:85)\r\n\tat com.google.javascript.jscomp.Compiler$2.call(Compiler.java:652)\r\n\tat com.google.javascript.jscomp.Compiler$2.call(Compiler.java:649)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:709)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:649)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:605)\r\n\tat com.google.javascript.jscomp.webservice.backend.CompilerInvokerImpl.compile(CompilerInvokerImpl.java:47)\r\n\tat com.google.javascript.jscomp.webservice.backend.ServerController.executeRequest(ServerController.java:174)\r\n\tat com.google.javascript.jscomp.webservice.backend.CompilationRequestHandler.serviceParsedRequest(CompilationRequestHandler.java:180)\r\n\tat com.google.javascript.jscomp.webservice.backend.CompilationRequestHandler.service(CompilationRequestHandler.java:162)\r\n\tat com.google.javascript.jscomp.webservice.frontend.CompilationServlet.doPost(CompilationServlet.java:83)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:637)\r\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:717)\r\n\tat org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1166)\r\n\tat com.google.apphosting.utils.servlet.ParseBlobUploadFilter.doFilter(ParseBlobUploadFilter.java:125)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.apphosting.runtime.jetty.SaveSessionFilter.doFilter(SaveSessionFilter.java:35)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.apphosting.utils.servlet.JdbcMySqlConnectionCleanupFilter.doFilter(JdbcMySqlConnectionCleanupFilter.java:60)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat com.google.apphosting.utils.servlet.TransactionCleanupFilter.doFilter(TransactionCleanupFilter.java:43)\r\n\tat org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1157)\r\n\tat org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:388)\r\n\tat org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)\r\n\tat org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)\r\n\tat org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:765)\r\n\tat org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:418)\r\n\tat com.google.apphosting.runtime.jetty.AppVersionHandlerMap.handle(AppVersionHandlerMap.java:266)\r\n\tat org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)\r\n\tat org.mortbay.jetty.Server.handle(Server.java:326)\r\n\tat org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)\r\n\tat org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:923)\r\n\tat com.google.apphosting.runtime.jetty.RpcRequestParser.parseAvailable(RpcRequestParser.java:76)\r\n\tat org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)\r\n\tat com.google.apphosting.runtime.jetty.JettyServletEngineAdapter.serviceRequest(JettyServletEngineAdapter.java:146)\r\n\tat com.google.apphosting.runtime.JavaRuntime$RequestRunnable.run(JavaRuntime.java:439)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable.runInContext(TraceContext.java:435)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable$1.run(TraceContext.java:442)\r\n\tat com.google.tracing.CurrentContext.runInContext(CurrentContext.java:186)\r\n\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContextNoUnref(TraceContext.java:306)\r\n\tat com.google.tracing.TraceContext$AbstractTraceContextCallback.runInInheritedContext(TraceContext.java:298)\r\n\tat com.google.tracing.TraceContext$TraceContextRunnable.run(TraceContext.java:439)\r\n\tat com.google.apphosting.runtime.ThreadGroupPool$PoolEntry.run(ThreadGroupPool.java:251)\r\n\tat java.lang.Thread.run(Thread.java:722)\r\nCaused by: java.lang.IllegalStateException: Unexpected variable l\r\n\t... 58 more\r\n\r\nOriginal Post Data: \r\noutput_format=json&amp;output_info=compiled_code&amp;output_info=warnings&amp;output_info=errors&amp;output_info=statistics&amp;compilation_level=ADVANCED_OPTIMIZATIONS&amp;warning_level=verbose&amp;output_file_name=default.js&amp;js_code=var%20g%3Dfunction(m)%7Breturn%20m*Math.random()%7C0%7D%2Cd%3Ddocument%2Ch%3Dd.getElementById('h')%2Cc%3Dd.getElementById('c')%2Cl%3B%0A(l%3Dfunction()%7BrequestAnimationFrame(l)%3Bh.style.textShadow%3D%220%200%201px%20%23000%2C%22%2B(g(10)-5)%2B%22px%20%22%2B(g(10)-5)%2B%22px%200%20%23888%2C0%200%20180px%20rgb(%22%2Bg(255)%2B%22%2C%22%2Bg(255)%2B%22%2C%22%2Bg(255)%2B%22)%22%7D)()%3B%0Ad.addEventListener('mousemove'%2Cfunction(v)%7Bc.style.marginTop%3D(v.pageY%2F10%2B15%7C0)%2B'px'%7D)",
    "desc_source": "google"
  },
  "Closure_115": {
    "description": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode\n<b>What steps will reproduce the problem?</b>\n\r\n1. Create a file input.js with the following &quot;minimal&quot; test case:\r\n\r\n    window[&quot;anchor&quot;] = function (obj, modifiesProp) {\r\n        return (function (saved) {\r\n            return modifiesProp(obj) + saved;\r\n        })(obj[&quot;prop&quot;]);\r\n    }\r\n\r\n2. Compile it with:\r\n\r\n    java -jar .../build/compiler.jar                    \\\r\n        --compilation_level ADVANCED_OPTIMIZATIONS      \\\r\n        --warning_level VERBOSE                         \\\r\n        --externs window.js                             \\\r\n        --js input.js                                   \\\r\n        --js_output_file output.js\r\n\r\n3. That's all!\r\n\r\nWhat is the expected output?\r\n\r\n    window.foo=function(a,b){var HOLD=a.prop;return b(a)+HOLD};\r\n\r\nWhat do you see instead?\r\n\r\n    window.foo=function(a,b){return b(a)+a.prop};\r\n\r\nNote how this is semantically very different if modifiesProp/b (whose\r\nsemantics are unknown to the compiler) side-effects a.prop.\r\n\r\nThe evaluation order of + is well-defined in EcmaScript 5, but even\r\nthen, this happens even if one substitutes the , (comma) operator.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nGit HEAD\r\n\r\n    commit 4a62ee4bca02169dd77a6f26ed64a624b3f05f95\r\n    Author: Chad Killingsworth &lt;chadkillingsworth@missouristate.edu&gt;\r\n    Date:   Wed Sep 25 14:52:28 2013 -0500\r\n    \r\n        Add history.state to html5 externs\r\n\r\non Linux.",
    "desc_source": "google"
  },
  "Closure_116": {
    "description": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode\n<b>What steps will reproduce the problem?</b>\n\r\n1. Create a file input.js with the following &quot;minimal&quot; test case:\r\n\r\n    window[&quot;anchor&quot;] = function (obj, modifiesProp) {\r\n        return (function (saved) {\r\n            return modifiesProp(obj) + saved;\r\n        })(obj[&quot;prop&quot;]);\r\n    }\r\n\r\n2. Compile it with:\r\n\r\n    java -jar .../build/compiler.jar                    \\\r\n        --compilation_level ADVANCED_OPTIMIZATIONS      \\\r\n        --warning_level VERBOSE                         \\\r\n        --externs window.js                             \\\r\n        --js input.js                                   \\\r\n        --js_output_file output.js\r\n\r\n3. That's all!\r\n\r\nWhat is the expected output?\r\n\r\n    window.foo=function(a,b){var HOLD=a.prop;return b(a)+HOLD};\r\n\r\nWhat do you see instead?\r\n\r\n    window.foo=function(a,b){return b(a)+a.prop};\r\n\r\nNote how this is semantically very different if modifiesProp/b (whose\r\nsemantics are unknown to the compiler) side-effects a.prop.\r\n\r\nThe evaluation order of + is well-defined in EcmaScript 5, but even\r\nthen, this happens even if one substitutes the , (comma) operator.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nGit HEAD\r\n\r\n    commit 4a62ee4bca02169dd77a6f26ed64a624b3f05f95\r\n    Author: Chad Killingsworth &lt;chadkillingsworth@missouristate.edu&gt;\r\n    Date:   Wed Sep 25 14:52:28 2013 -0500\r\n    \r\n        Add history.state to html5 externs\r\n\r\non Linux.",
    "desc_source": "google"
  },
  "Closure_117": {
    "description": "Wrong type name reported on missing property error.\n/**\r\n * @constructor\r\n */\r\nfunction C2() {}\r\n\r\n/**\r\n * @constructor\r\n */\r\nfunction C3(c2) {\r\n  /**\r\n   * @type {C2} \r\n   * @private\r\n   */\r\n  this.c2_;\r\n\r\n  use(this.c2_.prop);\r\n}\r\n\r\nProduces:\r\n\r\nProperty prop never defined on C3.c2_\r\n\r\nBut should be:\r\n\r\nProperty prop never defined on C2",
    "desc_source": "google"
  },
  "Closure_118": {
    "description": "Prototype method incorrectly removed\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// @formatting pretty_print\r\n// ==/ClosureCompiler==\r\n\r\n/** @const */\r\nvar foo = {};\r\nfoo.bar = {\r\n  'bar1': function() { console.log('bar1'); }\r\n}\r\n\r\n/** @constructor */\r\nfunction foobar() {}\r\nfoobar.prototype = foo.bar;\r\n\r\nfoo.foobar = new foobar;\r\n\r\nconsole.log(foo.foobar['bar1']);",
    "desc_source": "google"
  },
  "Closure_119": {
    "description": "catch(e) yields JSC_UNDEFINED_NAME warning when e is used in catch in advanced mode\n<b>What steps will reproduce the problem?</b>\n1. set closure for advanced compilation\r\n2. compile this:\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\ntry {\r\nvar x = 5;\r\n}\r\ncatch(e) {\r\nvar s = &quot;FAIL&quot; + e.name + &quot;: &quot;+ e.message;\r\n}\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nI expect no warning or error for this.  Instead I see this:\r\n\r\nJSC_UNREACHABLE_CODE: unreachable code at line 4 character 0\r\ncatch(e) {\r\n^\r\nJSC_UNDEFINED_NAME: e is never defined at line 5 character 17\r\nvar s = &quot;FAIL&quot; + e.name + &quot;: &quot;+ e.message;\r\n                 ^\r\nJSC_UNDEFINED_NAME: e is never defined at line 5 character 32\r\nvar s = &quot;FAIL&quot; + e.name + &quot;: &quot;+ e.message;\r\n                                ^\r\nIn my case I'm especially complaining about the JSC_UNDEFINED_NAME warning...  Also it seems the unreachable complaint isn't right, but i'm not sure.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nI'm using this url: http://closure-compiler.appspot.com/home\r\nusing chrome browser on windows: Version 28.0.1500.95 m \r\n... but this is a server side error from what I see...\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_120": {
    "description": "Overzealous optimization confuses variables\nThe following code:\r\n\r\n\t// ==ClosureCompiler==\r\n\t// @compilation_level ADVANCED_OPTIMIZATIONS\r\n\t// ==/ClosureCompiler==\r\n\tvar uid;\r\n\tfunction reset() {\r\n\t\tuid = Math.random();\r\n\t}\r\n\tfunction doStuff() {\r\n\t\treset();\r\n\t\tvar _uid = uid;\r\n\r\n\t\tif (uid &lt; 0.5) {\r\n\t\t\tdoStuff();\r\n\t\t}\r\n\r\n\t\tif (_uid !== uid) {\r\n\t\t\tthrow 'reset() was called';\r\n\t\t}\r\n\t}\r\n\tdoStuff();\r\n\r\n...gets optimized to:\r\n\r\n\tvar a;function b(){a=Math.random();0.5&gt;a&amp;&amp;b();if(a!==a)throw&quot;reset() was called&quot;;}b();\r\n\r\nNotice how _uid gets optimized away and (uid!==_uid) becomes (a!==a) even though doStuff() might have been called and uid's value may have changed and become different from _uid.\r\n\r\nAs an aside, replacing the declaration with &quot;var _uid = +uid;&quot; fixes it, as does adding an extra &quot;uid = _uid&quot; after &quot;var _uid = uid&quot;.",
    "desc_source": "google"
  },
  "Closure_121": {
    "description": "Overzealous optimization confuses variables\nThe following code:\r\n\r\n\t// ==ClosureCompiler==\r\n\t// @compilation_level ADVANCED_OPTIMIZATIONS\r\n\t// ==/ClosureCompiler==\r\n\tvar uid;\r\n\tfunction reset() {\r\n\t\tuid = Math.random();\r\n\t}\r\n\tfunction doStuff() {\r\n\t\treset();\r\n\t\tvar _uid = uid;\r\n\r\n\t\tif (uid &lt; 0.5) {\r\n\t\t\tdoStuff();\r\n\t\t}\r\n\r\n\t\tif (_uid !== uid) {\r\n\t\t\tthrow 'reset() was called';\r\n\t\t}\r\n\t}\r\n\tdoStuff();\r\n\r\n...gets optimized to:\r\n\r\n\tvar a;function b(){a=Math.random();0.5&gt;a&amp;&amp;b();if(a!==a)throw&quot;reset() was called&quot;;}b();\r\n\r\nNotice how _uid gets optimized away and (uid!==_uid) becomes (a!==a) even though doStuff() might have been called and uid's value may have changed and become different from _uid.\r\n\r\nAs an aside, replacing the declaration with &quot;var _uid = +uid;&quot; fixes it, as does adding an extra &quot;uid = _uid&quot; after &quot;var _uid = uid&quot;.",
    "desc_source": "google"
  },
  "Closure_122": {
    "description": "Inconsistent handling of non-JSDoc comments\n<b>What steps will reproduce the problem?</b>\n<b>1.</b>\n<b>2.</b>\n<b>3.</b>\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nWhen given:\r\n\r\n    /* @preserve Foo License */\r\n    alert(&quot;foo&quot;);\r\n\r\nIt spits out:\r\n\r\n    stdin:1: WARNING - Parse error. Non-JSDoc comment has annotations. Did you mean to start it with '/**'?\r\n    /* @license Foo License */\r\n    ^\r\n    \r\n    0 error(s), 1 warning(s)\r\n    alert(&quot;foo&quot;);\r\n\r\nIf I take the suggestion and change the opening of the comment to '/**', everything is great.  However, if I change it to '/*!', the warning goes away, but it doesn't preserve the comment either.\r\n\r\nI expect it to print the above warning, or preserve the comment.  That it does neither when starting with &quot;/*!&quot; (and every other character I tried) is confusing.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nTested with my compilation of the &quot;v20130603&quot; tag:\r\n\r\n    Closure Compiler (http://code.google.com/closure/compiler)\r\n    Version: v20130603\r\n    Built on: 2013/07/07 15:04\r\n\r\nAnd with the provided binary:\r\n\r\n    Closure Compiler (http://code.google.com/closure/compiler)\r\n    Version: v20130411-90-g4e19b4e\r\n    Built on: 2013/06/03 12:07\r\n\r\nI'm on Parabola GNU/Linux-libre with Java:\r\n\r\n    java version &quot;1.7.0_40&quot;\r\n    OpenJDK Runtime Environment (IcedTea 2.4.0) (ArchLinux build 7.u40_2.4.0-1-i686)\r\n    OpenJDK Server VM (build 24.0-b40, mixed mode)\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_123": {
    "description": "Generates code with invalid for/in left-hand assignment\n<b>What steps will reproduce the problem?</b>\n1. Compile this:\r\n\r\nwindow.Foo = function(A, B, C, D) {\r\n  if ( A ) {                        \r\n    if ( B ) {\r\n      C = 0;\r\n    } else {\r\n      C = 0 in D;\r\n    }\r\n    while ( C-- ) {}\r\n  }\r\n}\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nExpected: Something that doesn't have a syntax error, maybe\r\n\r\nwindow.Foo=function(b,c,a,d){if(b)for(a=c?0:(0 in d);a--;);};\r\n\r\nActual:\r\n\r\nwindow.Foo=function(b,c,a,d){if(b)for(a=c?0:0 in d;a--;);};\r\n\r\nSyntaxError: Unexpected token ; (Chrome)\r\ninvalid for/in left-hand side (Firefox)\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nhttp://closure-compiler.appspot.com/home\r\n\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nI noticed this while attempting to minify jquery",
    "desc_source": "google"
  },
  "Closure_124": {
    "description": "Different output from RestAPI and command line jar\nWhen I compile using the jar file from the command line I get a result that is not correct. However, when I test it via the REST API or the Web UI I get a correct output. I've attached a file with the code that we are compiling.\r\n\r\n<b>What steps will reproduce the problem?</b>\n1. Compile the attached file with &quot;java -jar compiler.jar --js test.js&quot;\r\n2. Compile the content of the attached file on http://closure-compiler.appspot.com/home\r\n3. Compare the output, note how the following part is converted in the two cases:\r\n\r\n&quot;var foreignObject = gfx.parentNode.parentNode;\r\nvar parentContainer = foreignObject.parentNode.parentNode;&quot;\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThe Web UI converts the lines into: if(b){if(a=b.parentNode.parentNode,b=a.parentNode.parentNode,null!==b)\r\nThe command line converts it into: var b=a=a.parentNode.parentNode;\r\nThe Web UI results in correct code, the other results in code that tries to do &quot;c.appendChild(b)&quot; with c = b (c=a=a.parentNode.parentNode)\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\ncompiler.jar: v20130411-90-g4e19b4e\r\nMac OSX 10.8.3\r\nJava: java 1.6.0_45\r\n\r\n<b>Please provide any additional information below.</b>\nWe are also using the compiler form within our java code, with the same result.\r\nWeb UI was called with:\r\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==",
    "desc_source": "google"
  },
  "Closure_125": {
    "description": "IllegalStateException at com.google.javascript.rhino.jstype.FunctionType.getInstanceType\n&gt; What steps will reproduce the problem?\r\n1. Unpack attached test case.\r\n2. Ensure make, wget, unzip, and java are on your PATH\r\n3. make prep (or just set up the build manually, it's not complicated)\r\n4. make crash\r\n\r\n&gt; What is the expected output? What do you see instead?\r\nExpected output: either successful compilation, or a compilation error.\r\nActual output: \r\n$ java \\\r\n\t  -jar ./compiler.jar \\\r\n\t  --js crash.js \\\r\n\t  --warning_level=VERBOSE \\\r\n\t  --compilation_level=SIMPLE_OPTIMIZATIONS\r\njava.lang.RuntimeException: java.lang.IllegalStateException\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:715)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:647)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Compiler.java:603)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(AbstractCommandLineRunner.java:783)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(AbstractCommandLineRunner.java:379)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(CommandLineRunner.java:972)\r\nCaused by: java.lang.IllegalStateException\r\n\tat com.google.common.base.Preconditions.checkState(Preconditions.java:133)\r\n\tat com.google.javascript.rhino.jstype.FunctionType.getInstanceType(FunctionType.java:1071)\r\n\tat com.google.javascript.jscomp.TypeCheck.visitNew(TypeCheck.java:1567)\r\n\tat com.google.javascript.jscomp.TypeCheck.visit(TypeCheck.java:569)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:534)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseFunction(NodeTraversal.java:569)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:522)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:528)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseWithScope(NodeTraversal.java:353)\r\n\tat com.google.javascript.jscomp.TypeCheck.check(TypeCheck.java:400)\r\n\tat com.google.javascript.jscomp.TypeCheck.process(TypeCheck.java:371)\r\n\tat com.google.javascript.jscomp.DefaultPassConfig$30$1.process(DefaultPassConfig.java:1237)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(PhaseOptimizer.java:293)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(PhaseOptimizer.java:237)\r\n\tat com.google.javascript.jscomp.Compiler.check(Compiler.java:830)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Compiler.java:742)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Compiler.java:83)\r\n\tat com.google.javascript.jscomp.Compiler$2.call(Compiler.java:650)\r\n\tat com.google.javascript.jscomp.Compiler$2.call(Compiler.java:647)\r\n\tat com.google.javascript.jscomp.Compiler$3.call(Compiler.java:677)\r\n\tat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:138)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)\r\n\tat java.lang.Thread.run(Thread.java:680)\r\nmake: *** [crash] Error 254\r\n\r\n&gt; What version of the product are you using? On what operating system?\r\nclosure-compiler release 20130411.  I have also encountered this error on earlier versions of closure-compiler, but the above repro recipe uses 20130411.  I'm currently testing on OS X but this probably happens on other platforms too.\r\n\r\n&gt; Please provide any additional information below.\r\n\r\nHere's the contents of crash.js (included in the attached archive):\r\n\r\n-----begin snip-----\r\nvar test = {};\r\n\r\n/**\r\n * @interface\r\n */\r\ntest.T = function() {};\r\n\r\n/**\r\n * @constructor\r\n * @implements {test.T}\r\n */\r\ntest.A = function() {};\r\n\r\n/**\r\n * @constructor\r\n * @implements {test.T}\r\n */\r\ntest.B = function() {};\r\n\r\n/**\r\n * @constructor\r\n */\r\ntest.X = function() {\r\n    this.type = test.A;\r\n    this.t = this.f();\r\n};\r\n\r\n/**\r\n * @return {test.T}\r\n */\r\ntest.X.prototype.f = function() {\r\n    if (this.type === test.A) {\r\n        return new test.A();\r\n    } else if (this.type === test.B) {\r\n        return new test.B();\r\n    }\r\n};\r\n-----end snip-----",
    "desc_source": "google"
  },
  "Closure_126": {
    "description": "Break in finally block isn't optimized properly\nb: try { throw(&quot;throw me&quot;) } finally { /* fake catcher */ ; break b }; console.log(&quot;ok then...&quot;)\r\n\r\n... gets optimized into ...\r\n\r\n  throw&quot;throw me&quot;;\r\n\r\n... which is not the same.\r\n\r\nThe break in the finally block should prevent the exception from being passed on. The expected result is:\r\n\r\n   console.log(&quot;ok then...&quot;)\r\n\r\nECMA-262 says:\r\n\r\nThe production TryStatement : try Block Finally is evaluated as follows:\r\n\r\nLet B be the result of evaluating Block.\r\nLet F be the result of evaluating Finally.\r\nIf F.type is normal, return B.\r\nReturn F.\r\n\r\nF.type in this case would be 'break' and not 'normal', so 'break' overrides the 'throw' of B\r\n\r\nThis is with the build available for download on Feb 28 2013.",
    "desc_source": "google"
  },
  "Closure_127": {
    "description": "Break in finally block isn't optimized properly\nb: try { throw(&quot;throw me&quot;) } finally { /* fake catcher */ ; break b }; console.log(&quot;ok then...&quot;)\r\n\r\n... gets optimized into ...\r\n\r\n  throw&quot;throw me&quot;;\r\n\r\n... which is not the same.\r\n\r\nThe break in the finally block should prevent the exception from being passed on. The expected result is:\r\n\r\n   console.log(&quot;ok then...&quot;)\r\n\r\nECMA-262 says:\r\n\r\nThe production TryStatement : try Block Finally is evaluated as follows:\r\n\r\nLet B be the result of evaluating Block.\r\nLet F be the result of evaluating Finally.\r\nIf F.type is normal, return B.\r\nReturn F.\r\n\r\nF.type in this case would be 'break' and not 'normal', so 'break' overrides the 'throw' of B\r\n\r\nThis is with the build available for download on Feb 28 2013.",
    "desc_source": "google"
  },
  "Closure_128": {
    "description": "The compiler quotes the \"0\" keys in object literals\n<b>What steps will reproduce the problem?</b>\n1. Compile alert({0:0, 1:1});\r\n\r\nWhat is the expected output?\r\nalert({0:0, 1:1});\r\n\r\nWhat do you see instead?\r\nalert({&quot;0&quot;:0, 1:1});\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nLatest version on Goobuntu.",
    "desc_source": "google"
  },
  "Closure_129": {
    "description": "Casting a function before calling it produces bad code and breaks plugin code\n1. Compile this code with ADVANCED_OPTIMIZATIONS:\r\nconsole.log( /** @type {function(!string):!string} */ ((new window.ActiveXObject( 'ShockwaveFlash.ShockwaveFlash' ))['GetVariable'])( '$version' ) );\r\n\r\nproduces:\r\n\r\n'use strict';console.log((0,(new window.ActiveXObject(&quot;ShockwaveFlash.ShockwaveFlash&quot;)).GetVariable)(&quot;$version&quot;));\r\n\r\n2. Compare with this code:\r\nconsole.log( /** @type {!string} */ ((new window.ActiveXObject( 'ShockwaveFlash.ShockwaveFlash' ))['GetVariable']( '$version' )) )\r\n\r\nproduces:\r\n\r\n'use strict';console.log((new window.ActiveXObject(&quot;ShockwaveFlash.ShockwaveFlash&quot;)).GetVariable(&quot;$version&quot;));\r\n\r\n\r\nNotice the (0,...) wrapping around the GetVariable function in the first example. This causes the call to fail in every browser (this code is IE-only but it's just for a minimal example). The second version produces a warning that the type of GetVariable could not be determined (I enabled type warnings), and it wouldn't be possible to define these in an externs file without making a horrible mess.\r\n\r\nThis applies to all cases where functions are cast, but only causes problems (other than bloat) with plugins like this. It seems to serve no purpose whatsoever, so I assume it is a bug.\r\n\r\nRunning on a mac, not sure what version but it reports Built on: 2013/02/12 17:00, so will have been downloaded about that time.",
    "desc_source": "google"
  },
  "Closure_130": {
    "description": "arguments is moved to another scope\nUsing ADVANCED_OPTIMIZATIONS with CompilerOptions.collapsePropertiesOnExternTypes = true a script I used broke, it was something like:\r\n\r\nfunction () {\r\n  return function () {\r\n    var arg = arguments;\r\n    setTimeout(function() { alert(args); }, 0);\r\n  }\r\n}\r\n\r\nUnfortunately it was rewritten to:\r\n\r\nfunction () {\r\n  return function () {\r\n    setTimeout(function() { alert(arguments); }, 0);\r\n  }\r\n}\r\n\r\narguments should not be collapsed.",
    "desc_source": "google"
  },
  "Closure_131": {
    "description": "unicode characters in property names result in invalid output\n<b>What steps will reproduce the problem?</b>\n1. use unicode characters in a property name for an object, like this:\r\nvar test={&quot;a\\u0004b&quot;:&quot;c&quot;};\r\n\r\n2. compile\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nBecause unicode characters are not allowed in property names without quotes, the output should be the same as the input. However, the compiler converts the string \\u0004 to the respective unicode character, and the output is: \r\nvar test={a\u0004b:&quot;c&quot;}; // unicode character between a and b can not be displayed here\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nnewest current snapshot on multiple os (OSX/linux)\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_132": {
    "description": "if statement\n<b>What steps will reproduce the problem?</b>\nINPUT:\r\nif( es[--esi][ es[esi+1] ] === 1)\r\n{\r\n\tes[esi] = 0;\r\n}\r\nelse\r\n{\r\n\tes[esi] = 1;\r\n}\r\nOUTPUT:\r\n\r\nes[esi] = 1 === es[--esi][es[esi + 1]] ? 0 : 1;\r\n\r\nBUT MUST BE\r\nes[--esi] = 1 === es[esi][es[esi + 1]] ? 0 : 1;\r\n\r\nIm using latest version on windows",
    "desc_source": "google"
  },
  "Closure_133": {
    "description": "Exception when parsing erroneous jsdoc: /**@return {@code foo} bar   *    baz. */\nThe following causes an exception in JSDocInfoParser.\r\n\r\n/** \r\n * @return {@code foo} bar \r\n *    baz. */\r\nvar x;\r\n\r\n\r\n\r\nFix to follow.",
    "desc_source": "google"
  },
  "Closure_134": {
    "description": "@inheritDoc doesn't play well with interfaces\nIf I use interface inheritance with @inheritDoc, the compiler doesn't \r\nknow about the types used in the method signature.\r\n\r\nSample code:\r\n\r\n/**\r\n * Interface\r\n * @interface\r\n */\r\nA = function() {};\r\n\r\n/**\r\n * @param {string} a\r\n */\r\nA.prototype.foo = function(a) {};\r\n\r\n/**\r\n * @constructor\r\n * @implements {A}\r\n */\r\nB = function() {};\r\n\r\n/**\r\n * @inheritDoc\r\n */\r\nB.prototype.foo = function(a) {\r\n  alert(a.substring(0));   //  ERROR - could not determine the type of \r\nthis expression\r\n};",
    "desc_source": "google"
  },
  "Closure_135": {
    "description": "Inheritance not detected when prototype directly assigned\nGiven the following input JS:\r\n//--------------------------\r\n/**\r\n* @constructor\r\n*/\r\nfunction SuperClass () {\r\n}\r\n\r\nSuperClass.prototype.CustomMethod = function() {\r\n}\r\n\r\n/**\r\n* @constructor\r\n* @extends {SuperClass}\r\n*/\r\nfunction SubClass () {\r\n}\r\nSubClass.prototype = new SuperClass();\r\n\r\n/**\r\n* @override\r\n*/\r\nSubClass.prototype.CustomMethod = function() {\r\n\tthis.myProperty = &quot;value&quot;;\r\n}\r\n\r\nwindow['SubClassInstance'] = new SubClass();\r\n//---------------------------------\r\n\r\nWhen compiled with ADVANCED_OPTIMIZATIONS produces the warning:\r\nJSC_UNKNOWN_OVERRIDE: property CustomMethod not defined on any superclass\r\nof SubClass\r\n\r\nThis error has been reproduced in both the downloaded compiler and the\r\nCompiler Service UI.\r\n\r\nWhen the prototype assignment is wrapped in a function, it is correctly\r\ndetected. See below:\r\n//---------------------------------\r\nfunction inherit(Child, Parent) {\r\n    Child.prototype = new Parent();\r\n} \r\ninherit(SubClass, SuperClass);\r\n//---------------------------------",
    "desc_source": "google"
  },
  "Closure_136": {
    "description": "$super is replaced when it should not be replaced\n<b>What steps will reproduce the problem?</b>\n1. Have javascript using prototype's $super\r\n2. Compile with advanced_optimizations\r\n3. See that $super is replaced by for example $super$$4\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n$super should not be renamed as it is used by prototype.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nLatest from svn.\r\n\r\n<b>Please provide any additional information below.</b>\nPersonally I made a quick fix in MakeDeclaredNamesUnique.java line 79:\r\nif (t.getCompiler().getCodingConvention().isExported(name)) { continue; }\r\nThis fixed it for me, but not sure if that's the right place or method to\r\nsolve this, as I am unfamiliar with the project.",
    "desc_source": "google"
  },
  "Closure_137": {
    "description": "Invalid JSC_DETERMINISTIC_TEST\n<b>What steps will reproduce the problem?</b>\n\r\n1. Compile following code:\r\n\r\n// ==ClosureCompiler==\r\n// @output_file_name default.js\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// ==/ClosureCompiler==\r\n\r\nvar t = null;\r\n\r\nwindow.test = function()\r\n{\r\n    if (t != null)\r\n    {\r\n       t = null;\r\n    }\r\n\r\n    t = 1;\r\n};\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nCode should be compiled without warnings, but I see \r\n&quot;JSC_DETERMINISTIC_TEST: condition always evaluates to false&quot;.",
    "desc_source": "google"
  },
  "Closure_138": {
    "description": "Invalid JSC_DETERMINISTIC_TEST\n<b>What steps will reproduce the problem?</b>\n\r\n1. Compile following code:\r\n\r\n// ==ClosureCompiler==\r\n// @output_file_name default.js\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// ==/ClosureCompiler==\r\n\r\nvar t = null;\r\n\r\nwindow.test = function()\r\n{\r\n    if (t != null)\r\n    {\r\n       t = null;\r\n    }\r\n\r\n    t = 1;\r\n};\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nCode should be compiled without warnings, but I see \r\n&quot;JSC_DETERMINISTIC_TEST: condition always evaluates to false&quot;.",
    "desc_source": "google"
  },
  "Closure_139": {
    "description": "Redefinition of a function in third party code can be miscompiled\n<b>What steps will reproduce the problem?</b>\n1. Run this code snippet and observe that it doesn't raise an error:\r\n\r\nfunction assert(b) {if (!b) throw &quot;error&quot;}\r\n\r\nassert(f() === 1)\r\nvar f = function() {return 2;}\r\nassert(f() === 2)\r\n\r\nfunction f() {return 1;}\r\n\r\n2. Compile it as third_party:\r\n3. Observe that the first definition of f has been changed from an assignment to a declaration, and that the code now raises an error.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nr8\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nThis bug is originally from a blog comment[1], I don't know if it has hit anyone in the wild yet.\r\n\r\n1) http://webreflection.blogspot.com/2009/11/google-closure-im-not-impressed.html#1604178721861066706",
    "desc_source": "google"
  },
  "Closure_140": {
    "description": "Google Common Loader Extern\nI needed this for one of my projects.\r\n\r\nChad Killingsworth",
    "desc_source": "google"
  },
  "Closure_141": {
    "description": "The side effects of function1||function2 are not calculated\n<b>What steps will reproduce the problem?</b>\n1. Compile (Math.sin||Math.cos)(0)\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nEmpty output.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nThe closure-compiler web service at r114.\r\n\r\n<b>Please provide any additional information below.</b>\nAs a result of this issue goog.now() is considered to have side effects.",
    "desc_source": "google"
  },
  "Closure_142": {
    "description": "Internet Explorer runtime error after compilation.\n<b>What steps will reproduce the problem?</b>\nSee attached HTML file in IE6+ (does not work in IE8 unless Compatibility View is turned *on* for \r\nsome reason).\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nExpected output is on the left-hand side of the page (it is generated by the raw source). Google \r\nClosure's output is on the right-hand side of the page.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nI downloaded compiler-latest.zip today (Nov. 24, 2009, ~ 12:00 PM EST)\r\n\r\n<b>Please provide any additional information below.</b>\nThere is a variable called &quot;threshold&quot; which is used to generate an array of arrays in the attached \r\nHTML file. If it is a small number, IE seems to pass arrays into the sort method (sorting an array \r\nof arrays) by value like all other browsers do. But when threshold is large enough (on my \r\nmachine that happens around 250) IE starts passing the arrays in by value. Google Closure \r\ncompiler has changed my original source from making local copies to modifying the arguments \r\nbeing passed into the sort comparator ... but as a result of this IE behavior the Closure compiled \r\ncode breaks.",
    "desc_source": "google"
  },
  "Closure_143": {
    "description": "@define does not support strings\n$ java -jar compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS --define='test.VERSION=1.0.0' --js_output_file \r\ntest-min.js --js test.js\r\njava.lang.RuntimeException: --define flag syntax invalid: test.VERSION=1.0.0\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.createDefineReplacements(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.initOptionsFromFlags(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.createOptions(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(Unknown Source)\r\n\r\ntest.js:\r\n/** @define {string} */\r\ntest.VERSION = &quot;&quot;;\r\n\r\n\r\nI have tried both of these:\r\n--define='test.VERSION=1.0.0'\r\n--define='test.VERSION=&quot;1.0.0&quot;'\r\n\r\nBoth generate the same error.",
    "desc_source": "google"
  },
  "Closure_144": {
    "description": "Auto-identify void functions\nfunction f() {\r\n}\r\n\r\nalert(f());\r\n\r\nshould emit a warning",
    "desc_source": "google"
  },
  "Closure_145": {
    "description": "Bug with labeled loops and breaks\n<b>What steps will reproduce the problem?</b>\nTry to compile this code with the closure compiler : \r\nvar i = 0; \r\nlab1: do{ \r\n    lab2: do{ \r\n        i++; \r\n        if (1) { \r\n            break lab2; \r\n        } else { \r\n            break lab1; \r\n        } \r\n    } while(false); \r\n} while(false); \r\n\r\nconsole.log(i); \r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThe generated code produced is :\r\nvar a=0;do b:do{a++;break b}while(0);while(0);console.log(a); \r\n\r\nWhich works on all browsers except IE (Looks like IE doesn't like \r\nthe missing brackets just after the first do instruction).\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nI am using the version of Jun 16 (latest) on ubuntu 10\r\n\r\n<b>Please provide any additional information below.</b>\nStrangely, this bug doesn't happen when I use PRETTY_PRINT formatting option.",
    "desc_source": "google"
  },
  "Closure_146": {
    "description": "bad type inference for != undefined\n<b>What steps will reproduce the problem?</b>\n\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\n/** @param {string} x */\r\nfunction g(x) {}\r\n\r\n/** @param {undefined} x */\r\nfunction f(x) {\r\n  if (x != undefined) { g(x); }\r\n}\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nJSC_DETERMINISTIC_TEST: condition always evaluates to false\r\nleft : undefined\r\nright: undefined at line 6 character 6\r\nif (x != undefined) { g(x); }\r\n      ^\r\nJSC_TYPE_MISMATCH: actual parameter 1 of g does not match formal parameter\r\nfound   : undefined\r\nrequired: string at line 6 character 24\r\nif (x != undefined) { g(x); }\r\n                        ^\r\n\r\nthe second warning is bogus.",
    "desc_source": "google"
  },
  "Closure_147": {
    "description": "Lost a JSC_USED_GLOBAL_THIS warning in 0616 release vs 0514\n<b>What steps will reproduce the problem?</b>\n//------------------\r\n// should warn &quot;JSC_USED_GLOBAL_THIS: dangerous use of the global this object&quot; in both methods\r\n// none of these warns in 0616 release\r\nvar NS = {\r\n\tread: function()\r\n\t{\r\n\t\treturn this.foo; // does not warn in 0514 release\r\n\t},\r\n\r\n\twrite: function()\r\n\t{\r\n\t\tthis.foo = 123; // warns in 0514 release\r\n\t}\r\n};\r\n\r\n// only the non-inline notation warns in 0616 release\r\nNS.write2 = function()\r\n{\r\n\tthis.foo = 123;\r\n};\r\n\r\n//-----------------------\r\n<b>What is the expected output? What do you see instead?</b>\nSince the 0514 release warned in in the &quot;write&quot; case above I would expect the 0616 to also report this. \r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nAs said above, 20100514 and 20100616 releases.\r\n\r\n<b>Please provide any additional information below.</b>\nI understand that the status is that inline-notation isn't preferred, though I wouldn't expect a previous, correct, warning to disappear. (Since I reported issue #144 I'm also aware of the previous limitation in global this).",
    "desc_source": "google"
  },
  "Closure_148": {
    "description": "CSS3 'writingMode' not recognised in advanced mode\nelement.style.writingMode was defined in CSS3 but later dropped. However it is supported by IE7 (possibly earlier). It's a useful way to achieve vertical text in IE.\r\n\r\nClosure Compiler will change references of element.style.writingMode to element.style.a, breaking implementation.\r\n\r\nI've attached a patch adding this to the IE css properties.\r\n\r\nCheers,\r\nJake.",
    "desc_source": "google"
  },
  "Closure_149": {
    "description": "Add option to turn off string escaping\n<b>What steps will reproduce the problem?</b>\n\r\n1. I'm having large files with strings (patterns for hyphenation, see http://code.google.com/p/hyphenator/) and no-ASCII-characters.\r\n2. Minifying with closure compiler makes them bigger\r\n    ru.js (orig): 41'216 Bytes\r\n    ru.js (orig, gzip): 17'124 Bytes\r\n    ru.js (mini): 110'770 Bytes\r\n    ru.js (mini, gzip): 18'860 Bytes\r\n\r\nWhat is the expected output?\r\nI'd like to be able to turn OFF the string escaping mechanism.\r\n\r\nThanks",
    "desc_source": "google"
  },
  "Closure_150": {
    "description": "Type checker misses annotations on functions defined within functions\n<b>What steps will reproduce the problem?</b>\n1. Compile the following code under --warning_level VERBOSE\r\n\r\nvar ns = {};\r\n\r\n/** @param {string=} b */\r\nns.a = function(b) {}\r\n\r\nfunction d() {\r\n    ns.a();\r\n    ns.a(123);\r\n}\r\n\r\n2. Observe that the type checker correctly emits one warning, as 123 \r\ndoesn't match the type {string}\r\n\r\n3. Now compile the code with ns.a defined within an anonymous function, \r\nlike so:\r\n\r\nvar ns = {};\r\n\r\n(function() {\r\n    /** @param {string=} b */\r\n    ns.a = function(b) {}\r\n})();\r\n\r\nfunction d() {\r\n    ns.a();\r\n    ns.a(123);\r\n}\r\n\r\n4. Observe that a warning is emitted for calling ns.a with 0 parameters, and \r\nnot for the type error, as though the @param declaration were ignored. \r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nr15\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nThis sort of module pattern is common enough that it strikes me as worth \r\nsupporting.\r\n\r\nOne last note to make matters stranger: if the calling code isn't itself within \r\na function, no warnings are emitted at all:\r\n\r\nvar ns = {};\r\n\r\n(function() {\r\n    /** @param {string=} b */\r\n    ns.a = function(b) {}\r\n})();\r\n\r\nns.a();\r\nns.a(123);",
    "desc_source": "google"
  },
  "Closure_151": {
    "description": "Add a --version option for the compiler.\n<b>What steps will reproduce the problem?</b>\n1. Run java -jar compiler.jar --version\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nExpected: A version statement.\r\nActual: An error that --version is not supported.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nSee above. This is a compiler.jar I downloaded from this project (didn't \r\nbuild it myself), file is dated 04/12/2009.\r\nOn Windows XP.\r\n\r\n<b>Please provide any additional information below.</b>\nThis information doesn't seem to be given anywhere, don't see it on --help \r\neither.\r\n\r\nThis is an enhancement request, not a bug report.",
    "desc_source": "google"
  },
  "Closure_152": {
    "description": "resolveTypes: jstype.UnionType cannot be cast to jstype.ObjectType\n<b>What steps will reproduce the problem?</b>\n\r\n1. Compile a bunch of JavaScript files that I can't release with these options: ['--create_name_map_files', 'true', '--jscomp_warning', 'missingProperties', '--jscomp_warning', 'undefinedVars', '--jscomp_warning', 'checkTypes', '--warning_level', 'VERBOSE', '--summary_detail_level', '3', '--process_closure_primitives', 'true', '--jscomp_error', 'strictModuleDepCheck', '--jscomp_error', 'invalidCasts', '--logging_level', 'ALL', '--compilation_level', 'ADVANCED_OPTIMIZATIONS']\r\n\r\n2. During this pass:\r\n\r\n        Oct 26, 2010 12:09:38 AM com.google.javascript.jscomp.PhaseOptimizer$NamedPass process\r\n        INFO: resolveTypes\r\n\r\n, compilation terminates with:\r\n\r\n        java.lang.RuntimeException: java.lang.ClassCastException: com.google.javascript.rhino.jstype.UnionType cannot be cast to com.google.javascript.rhino.jstype.ObjectType\r\n                at com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n                at com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(Unknown Source)\r\n                at com.google.javascript.jscomp.AbstractCommandLineRunner.run(Unknown Source)\r\n                at com.google.javascript.jscomp.CommandLineRunner.main(Unknown Source)\r\n        Caused by: java.lang.ClassCastException: com.google.javascript.rhino.jstype.UnionType cannot be cast to com.google.javascript.rhino.jstype.ObjectType\r\n                at com.google.javascript.rhino.jstype.FunctionType.resolveInternal(Unknown Source)\r\n                at com.google.javascript.rhino.jstype.JSType.resolve(Unknown Source)\r\n                at com.google.javascript.jscomp.TypedScopeCreator$DeferredSetType.resolve(Unknown Source)\r\n                at com.google.javascript.jscomp.TypedScopeCreator$AbstractScopeBuilder.resolveTypes(Unknown Source)\r\n                at com.google.javascript.jscomp.TypedScopeCreator.createScope(Unknown Source)\r\n                at com.google.javascript.jscomp.MemoizedScopeCreator.createScope(Unknown Source)\r\n                at com.google.javascript.jscomp.DefaultPassConfig$GlobalTypeResolver.process(Unknown Source)\r\n                at com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(Unknown Source)\r\n                at com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(Unknown Source)\r\n                at com.google.javascript.jscomp.PhaseOptimizer.process(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler.check(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler.compileInternal(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler.access$000(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n                at com.google.javascript.jscomp.Compiler$2.run(Unknown Source)\r\n                at java.lang.Thread.run(Thread.java:662)\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nI'm using Closure Compiler r506.  The problem first appeared in r482.",
    "desc_source": "google"
  },
  "Closure_153": {
    "description": "Namespace definition in Prototype is broken\n<b>What steps will reproduce the problem?</b>\n1. Namespace definition in prototype.js (Prototype library) looks like:\r\nif (!Node) var Node = { };\r\n2. Compile with latest command line compiler (Version: 20100917 (revision 440) Built on: 2010/09/17 17:55), with default options\r\n3. Open html which uses this script in IE8 - IE will show error message (something like &quot;Node - definition is missing&quot;, I use localized version and cannot write exact english message).\r\n\r\nWhat is the expected output?\r\nSomething like:\r\nif(!Node)var Node={};\r\n\r\nWhat do you see instead?\r\nNode||(Node={});\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nCommand line compiler (Version: 20100917 (revision 440) Built on: 2010/09/17 17:55), with default options, OS Linux Mint 7.",
    "desc_source": "google"
  },
  "Closure_154": {
    "description": "Add support for data members on interfaces\n/**\r\n * @interface\r\n */\r\nfunction I() {};\r\n\r\n/** @type {string} */\r\nI.prototype.foobar;\r\n\r\n/**\r\n * @constructor\r\n * @implements {I}\r\n */\r\nfunction C() {\r\n  // No warning generated here.\r\n  this.foobar = 2;\r\n};\r\n\r\n/** @type {I} */\r\nvar test = new C(); \r\nalert(test.foobar);",
    "desc_source": "google"
  },
  "Closure_155": {
    "description": "Overzealous arguments optimisation\nConsider the following JavaScript code:\r\n\r\nfunction d3_call(callback) {\r\n  var f = callback;\r\n  arguments[0] = this;\r\n  f.apply(this, arguments);\r\n  return this;\r\n}\r\n\r\nThis is optimised to:\r\n\r\nfunction d3_call(a){arguments[0]=this;a.apply(this,arguments);return this};\r\n\r\nHowever, the use of a temporary variable `f` is necessary to avoid `arguments[0] = this` from overwriting the first argument.\r\n\r\nIn the above optimised code, `arguments[0] = this` causes `this` to be assigned to `a`.\r\n\r\nVerified on latest SVN r878.\r\n\r\nSee also: https://github.com/mbostock/d3/issues/closed#issue/68",
    "desc_source": "google"
  },
  "Closure_156": {
    "description": "Compiler crashes on assign statement\nIt is a large app (containing the entire Dojo Toolkit library). Code fragment that fails:\r\n\r\n/** @constructor\r\n *  @param {...Object} params\r\n */\r\ndojox.gfx.shape.Shape = function(params) {};\r\ndojox.gfx.shape.Shape = dojo.declare(&quot;dojox.gfx.shape.Shape&quot;, null, /** @lends dojox.gfx.shape.Shape.prototype */ { .......\r\n\r\n\r\nError message:\r\n\r\njava.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nUnexpected variable dojox$gfx$shape$Shape\r\n  Node(NAME dojox$gfx$shape$Shape): release\\src\\dijit.js.uncompressed.js:15135:0\r\ndojox.gfx.shape.Shape = dojo.declare(&quot;dojox.gfx.shape.Shape&quot;, null, /** @lends dojox.gfx.shape.Shape.prototype */ {\r\n  Parent(ASSIGN): release\\src\\dijit.js.uncompressed.js:15135:22\r\ndojox.gfx.shape.Shape = dojo.declare(&quot;dojox.gfx.shape.Shape&quot;, null, /** @lends dojox.gfx.shape.Shape.prototype */ {\r\n\r\n\tat com.google.javascript.jscomp.Compiler.runCallable(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(Unknown Source)\r\nCaused by: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nUnexpected variable dojox$gfx$shape$Shape\r\n  Node(NAME dojox$gfx$shape$Shape): release\\src\\dijit.js.uncompressed.js:15135:0\r\ndojox.gfx.shape.Shape = dojo.declare(&quot;dojox.gfx.shape.Shape&quot;, null, /** @lends dojox.gfx.shape.Shape.prototype */ {\r\n  Parent(ASSIGN): release\\src\\dijit.js.uncompressed.js:15135:22\r\ndojox.gfx.shape.Shape = dojo.declare(&quot;dojox.gfx.shape.Shape&quot;, null, /** @lends dojox.gfx.shape.Shape.prototype */ {\r\n\r\n\tat com.google.javascript.jscomp.VarCheck.visit(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseRoots(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseRoots(Unknown Source)\r\n\tat com.google.javascript.jscomp.VarCheck.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.optimize(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compileInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.access$000(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$1.call(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler$2.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Unexpected variable dojox$gfx$shape$Shape\r\n\t... 47 more",
    "desc_source": "google"
  },
  "Closure_157": {
    "description": "Numbers and quoted property names reject for get and set properties.\n- Use --language_in=ECMASCRIPT5.\r\n- Note that these definitions cause parse errors:\r\n\r\nvar x = { get 'x'() { return 1 } };\r\nvar x = { get 1() { return 1 } };\r\n\r\nES5 allow these.  The Rhino parser needs to be updated.",
    "desc_source": "google"
  },
  "Closure_158": {
    "description": "Order of jscomp_error, jscomp_warning, jscomp_off flags are not preserved\n&quot;off&quot; always takes precedence over &quot;warning&quot;, and &quot;warning&quot; always takes precedence over &quot;error&quot;\r\n\r\nThis should be changed so that the last arguments always has highest precedence.",
    "desc_source": "google"
  },
  "Closure_159": {
    "description": "Closure Compiler failed to translate all instances of a function name\n<b>What steps will reproduce the problem?</b>\n1. Compile the attached jQuery Multicheck plugin using SIMPLE optimization.\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nYou expect that the function preload_check_all() gets its name translated appropriately. In fact, the Closure Compiler breaks the code by changing the function declaration but NOT changing the call to the function on line 76.",
    "desc_source": "google"
  },
  "Closure_160": {
    "description": "checkVars / undefinedVars diagnostics not working from command line\nIt seems that setting neither checkVars nor undefinedVars via the jscomp_warning command line argument does anything. The check(s) do work when &quot;warning_level VERBOSE&quot; is set though. Other diagnostic groups, such as globalThis, do work however.\r\n\r\nHere's what I'm seeing on the console:\r\n\r\n---------------------\r\n\r\n&gt;java -jar compiler.jar --js test.js\r\nfoo={bar:function(){alert(this.baz)}};\r\n\r\n&gt;java -jar compiler.jar --js test.js --warning_level VERBOSE\r\ntest.js:2: WARNING - dangerous use of the global this object\r\n\r\ntest.js:1: ERROR - variable foo is undefined\r\nfoo = {};\r\n^\r\n\r\n1 error(s), 1 warning(s)\r\n\r\n&gt;java -jar compiler.jar --js test.js --jscomp_warning globalThis\r\ntest.js:2: WARNING - dangerous use of the global this object\r\n\r\n0 error(s), 1 warning(s)\r\nfoo={bar:function(){alert(this.baz)}};\r\n\r\n&gt;java -jar compiler.jar --js test.js --jscomp_warning checkVars\r\nfoo={bar:function(){alert(this.baz)}};\r\n\r\n&gt;java -jar compiler.jar --js test.js --jscomp_warning undefinedVars\r\nfoo={bar:function(){alert(this.baz)}};\r\n\r\n---------------------\r\n\r\nMy test.js file looks like this:\r\n\r\n---------------------\r\n\r\nfoo = {};\r\nfoo.bar = function() { alert(this.baz); };\r\n\r\n---------------------\r\n\r\nTested against r1123 which was committed 5/20/11.",
    "desc_source": "google"
  },
  "Closure_161": {
    "description": "peephole constants folding pass is trying to fold [][11] as if it were a property lookup instead of a property assignment\n<b>What steps will reproduce the problem?</b>\n1.Try on line CC with Advance\r\n2.On the following 2-line code\r\n<b>3.</b>\n\r\n<b>What is the expected output? What do you see instead?</b>\n// ==ClosureCompiler==\r\n// @output_file_name default.js\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// ==/ClosureCompiler==\r\n\r\n\r\nvar Mdt=[];\r\nMdt[11] = ['22','19','19','16','21','18','16','20','17','17','21','17'];\r\n\r\nThe error:\r\nJSC_INDEX_OUT_OF_BOUNDS_ERROR: Array index out of bounds: NUMBER 11.0\r\n2 [sourcename: Input_0] : number at line 2 character 4\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nThe online version on 201.07.27",
    "desc_source": "google"
  },
  "Closure_162": {
    "description": "Type aliases cannot be used in type annotations before their definitions\n<b>What steps will reproduce the problem?</b>\n1. Compile the following with full warnings:\r\n\r\ngoog.provide('foo.Foo');\r\ngoog.provide('foo.Foo.Bar');\r\n\r\ngoog.scope(function() {\r\n  /**\r\n   * @param {Foo.Bar} bar\r\n   * @constructor\r\n   */\r\n  foo.Foo = function(bar) {\r\n    this.bar = bar;\r\n  };\r\n  var Foo = foo.Foo;\r\n\r\n  /** @type {Foo.Bar} */\r\n  Foo.prototype.bar = null;\r\n\r\n  /** @constructor */\r\n  Foo.Bar = function() {};\r\n});\r\n\r\n\r\n<b>What is the expected output? What do you see instead?</b>\nThis should work, but instead I get an error:\r\n\r\nERROR - Bad type annotation. Unknown type Foo.Bar\r\n   * @param {Foo.Bar} bar\r\n                    ^\r\n\r\nThis can be worked around by writing explicitly foo.Foo.Bar, but this leads to strange inconsistencies in the code before vs. after the alias definition.\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nr1346 in Linux\r\n\r\n<b>Please provide any additional information below.</b>",
    "desc_source": "google"
  },
  "Closure_163": {
    "description": "VarCheck Crash When Using Modules\njava -jar \\users\\chad\\workspace\\closure-compiler\\build\\compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS --formatting PRETTY_PRINT --debug --module jquery:1 --module core:1:jquery --module_output_path_prefix mod_ --js ..\\..\\dist\\jquery.js --js core.js --externs ..\\qunit_externs.js\r\n\r\njava.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nUnexpected variable jQuery$$2\r\n  Node(NAME jQuery$$2): core.js:100:12\r\n        equal( jQuery(&quot; &lt;div/&gt; &quot;).length, 1, &quot;Make sure whitespace is trimmed.&quot; );\r\n  Parent(GETPROP): core.js:100:12\r\n        equal( jQuery(&quot; &lt;div/&gt; &quot;).length, 1, &quot;Make sure whitespace is trimmed.&quot; );\r\n\r\n        at com.google.javascript.jscomp.Compiler.runCallable(Compiler.java:628)\r\n        at com.google.javascript.jscomp.Compiler.runInCompilerThread(Compiler.java:573)\r\n        at com.google.javascript.jscomp.Compiler.compile(Compiler.java:555)\r\n        at com.google.javascript.jscomp.Compiler.compileModules(Compiler.java:546)\r\n        at com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(AbstractCommandLineRunner.java:709)\r\n        at com.google.javascript.jscomp.AbstractCommandLineRunner.run(AbstractCommandLineRunner.java:329)\r\n        at com.google.javascript.jscomp.CommandLineRunner.main(CommandLineRunner.java:825)\r\nCaused by: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nUnexpected variable jQuery$$2\r\n  Node(NAME jQuery$$2): core.js:100:12\r\n        equal( jQuery(&quot; &lt;div/&gt; &quot;).length, 1, &quot;Make sure whitespace is trimmed.&quot; );\r\n  Parent(GETPROP): core.js:100:12\r\n        equal( jQuery(&quot; &lt;div/&gt; &quot;).length, 1, &quot;Make sure whitespace is trimmed.&quot; );\r\n\r\n        at com.google.javascript.jscomp.VarCheck.visit(VarCheck.java:170)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:498)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:491)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:491)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:491)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:491)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:491)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:491)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseRoots(NodeTraversal.java:304)\r\n        at com.google.javascript.jscomp.NodeTraversal.traverseRoots(NodeTraversal.java:464)\r\n        at com.google.javascript.jscomp.VarCheck.process(VarCheck.java:108)\r\n        at com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(PhaseOptimizer.java:273)\r\n        at com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(PhaseOptimizer.java:250)\r\n        at com.google.javascript.jscomp.PhaseOptimizer.process(PhaseOptimizer.java:168)\r\n        at com.google.javascript.jscomp.Compiler.optimize(Compiler.java:1636)\r\n        at com.google.javascript.jscomp.Compiler.compileInternal(Compiler.java:663)\r\n        at com.google.javascript.jscomp.Compiler.access$1(Compiler.java:634)\r\n        at com.google.javascript.jscomp.Compiler$2.call(Compiler.java:558)\r\n        at com.google.javascript.jscomp.Compiler$2.call(Compiler.java:1)\r\n        at com.google.javascript.jscomp.Compiler$3.run(Compiler.java:600)\r\n        at java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException: Unexpected variable jQuery$$2\r\n        ... 21 more",
    "desc_source": "google"
  },
  "Closure_164": {
    "description": "{function(number, string)} should not be assignable to {function(number)}\nConsider the following snippet. I don't think the &quot;second call&quot; should compile. As a side note: it would be great if none of the compiled in some pseudo-strict compile mode.\r\n\r\n/** @param {function(string,number):boolean} param */\r\nfunction func(param) {}\r\n\r\n/** @type {function(string,number,boolean):boolean} */\r\nfunction paramFunc1() {}\r\n\r\n/** @type {function(string):boolean} */\r\nfunction paramFunc2() {}\r\n\r\n// first call\r\nfunc(paramFunc1);\r\n\r\n// second call\r\nfunc(paramFunc2);",
    "desc_source": "google"
  },
  "Closure_165": {
    "description": "Properties defined on any record type applying to unrelated record types\nConsider the following code:\r\n\r\n/** @typedef {{name: string, id: number}} */\r\nvar RecordType1;\r\n\r\n/**\r\n* @param {RecordType1} rec\r\n*/\r\nvar func = function(rec) {\r\n  alert(rec.name2);\r\n};\r\nfunc({name: 'jim', id: 0});\r\n\r\nCompiled with: \r\njava -jar build/compiler.jar --compilation_level=ADVANCED_OPTIMIZATIONS --jscomp_error=accessControls --jscomp_error=checkTypes --jscomp_error=checkVars --js ~/Desktop/test.js\r\n\r\nProperly errors:\r\n/Users/dolapo/Desktop/test.js:9: ERROR - Property name2 never defined on rec\r\n  alert(rec.name2);\r\n\r\n\r\nHowever, add another recordtype with name2 defined:\r\n\r\n/** @typedef {{name: string, id: number}} */\r\nvar RecordType1;\r\n\r\n/** @typedef {{name2: string}} */\r\nvar RecordType2;\r\n\r\n/**\r\n* @param {RecordType1} rec\r\n*/\r\nvar func = function(rec) {\r\n  alert(rec.name2);\r\n};\r\nfunc({name: 'jim', id: 0});\r\n\r\n\r\n\r\nand this compiles with no errors.",
    "desc_source": "google"
  },
  "Closure_166": {
    "description": "anonymous object type inference inconsistency when used in union\nCode:\r\n/** @param {{prop: string, prop2: (string|undefined)}} record */\r\nvar func = function(record) {\r\n  window.console.log(record.prop);\r\n}\r\n\r\n/** @param {{prop: string, prop2: (string|undefined)}|string} record */\r\nvar func2 = function(record) {\r\n  if (typeof record == 'string') {\r\n    window.console.log(record);\r\n  } else {\r\n    window.console.log(record.prop);\r\n  }\r\n}\r\n\r\nfunc({prop: 'a'});\r\nfunc2({prop: 'a'});\r\n\r\n\r\n\r\n\r\nerrors with:\r\nERROR - actual parameter 1 of func2 does not match formal parameter\r\nfound   : {prop: string}\r\nrequired: (string|{prop: string, prop2: (string|undefined)})\r\nfunc2({prop: 'a'});\r\n\r\n\r\nthe type of the record input to func and func2 are identical but the parameters to func2 allow some other type.",
    "desc_source": "google"
  },
  "Closure_167": {
    "description": "invalid property not erroring in for loop in prototype function\nI think this example can be simplified to use a typedef instead of externs, but using an extern for the repro case.\r\n\r\nCompile the attached with:\r\njava -jar build/compiler.jar --formatting=PRETTY_PRINT --jscomp_error=checkTypes --jscomp_error=externsValidation --compilation_level=SIMPLE_OPTIMIZATIONS --externs=inloop-externs.js inloop.js (pasted below for completeness)\r\n\r\nI would expect an error on the line in the for loop in the doIt function, but this compiles just fine. The commented out line above it properly errors, and if the same code is outside a prototype function, it errors. It does not error within the prototype function.\r\n\r\nThanks\r\n\r\n\r\n/**\r\n * @param {ns.Thing} thing\r\n * @constructor\r\n */\r\nns.MyClass = function(thing) {\r\n  /** @type {ns.Thing} */ this.thing_ = thing;\r\n};\r\n\r\nns.MyClass.prototype.doIt = function() {\r\n  var subthing = this.thing_.subthing;\r\n  // ERRORS:\r\n  // window.console.log(subthing.noprop);\r\n\r\n  // NO ERROR:\r\n  for (var i = 0; i &lt; subthing.noprop; i++) {\r\n    window.console.log(i);\r\n  }\r\n};\r\n\r\nvar thing = /** @type {ns.Thing} */({subthing: {prop: 3}});\r\n\r\n/*\r\n  ERRORS:\r\n  var subthing = thing.subthing;\r\n  for (var i = 0; i &lt; subthing.noprop; i++) {\r\n    window.console.log(i);\r\n  } */\r\n\r\nvar c = new ns.MyClass(thing);\r\nco.doIt();",
    "desc_source": "google"
  },
  "Closure_168": {
    "description": "Wrong argument count error not reported on this aliasing (on function with @this annotation)\nThe following code (attached as test2-1.js) when compiled with:\r\njava -jar build/compiler.jar --compilation_level=ADVANCED_OPTIMIZATIONS --jscomp_error=accessControls --jscomp_error=checkTypes --jscomp_error=checkVars --jscomp_error=uselessCode --jscomp_off=globalThis --js ~/Desktop/test2.js \r\n\r\ncorrectly fails with:\r\n\r\n/Users/dolapo/Desktop/test2.js:28: ERROR - Function Person.prototype.getName: called with 1 argument(s). Function requires at least 0 argument(s) and no more than 0 argument(s).\r\n\r\nHowever, if the say function is modified such that this is aliased and the function is called within a setTimeout (test2-2.js), the error is not caught\r\n\r\n\r\n\r\n\r\n\r\ntest2-1.js:\r\nvar makeClass = function(protoMethods) {\r\n  var clazz = function() {\r\n    this.initialize.apply(this, arguments);\r\n  }\r\n  for (var i in protoMethods) {\r\n    clazz.prototype[i] = protoMethods[i];\r\n  }\r\n\r\n  return clazz;\r\n}\r\n\r\n/** @constructor */\r\nvar Person = function(name){};\r\nPerson = makeClass(/** @lends Person.prototype */ {\r\n  /** @this {Person} */\r\n  initialize: function(name) {\r\n    this.name = name;\r\n  },\r\n\r\n  /** @this {Person} */\r\n  getName: function() { return this.name; },\r\n\r\n  /**\r\n   * @param {string} message\r\n   * @this {Person}\r\n   */\r\n  say: function(message) {\r\n    window.console.log(this.getName(1) + ' says: ' + message);\r\n  }\r\n});\r\n\r\n\r\nvar joe = new Person('joe');\r\njoe.say('hi');\r\nvar jane = new Person('jane');\r\njane.say('hello');\r\n\r\n\r\n\r\ntest2-2.js:\r\n\r\nvar makeClass = function(protoMethods) {\r\n  var clazz = function() {\r\n    this.initialize.apply(this, arguments);\r\n  }\r\n  for (var i in protoMethods) {\r\n    clazz.prototype[i] = protoMethods[i];\r\n  }\r\n\r\n  return clazz;\r\n}\r\n\r\n/** @constructor */\r\nvar Person = function(name){};\r\nPerson = makeClass(/** @lends Person.prototype */ {\r\n  /** @this {Person} */\r\n  initialize: function(name) {\r\n    this.name = name;\r\n  },\r\n\r\n  /** @this {Person} */\r\n  getName: function() { return this.name; },\r\n\r\n  /**\r\n   * @param {string} message\r\n   * @this {Person}\r\n   */\r\n  say: function(message) {\r\n    // window.console.log(this.getName(1) + ' says: ' + message);\r\n    var self = this;\r\n    setTimeout(function() {\r\n      window.console.log(self.getName(1) + ' says: ' + message);\r\n    }, 500); \r\n  }\r\n});\r\n\r\n\r\nvar joe = new Person('joe');\r\njoe.say('hi');\r\nvar jane = new Person('jane');\r\njane.say('hello');",
    "desc_source": "google"
  },
  "Closure_169": {
    "description": "Strange \"wrong parameter\" warning for callback function\n<b>What steps will reproduce the problem?</b>\nCompile the followed code:\r\n   /** @param {{func: function()}} obj */\r\n   function test1(obj) {};\r\n   var fnStruc1 = {};\r\n   fnStruc1.func = function() {};\r\n   test1(fnStruc1); \r\n\r\n<b>What is the expected output? What do you see instead?</b>\nExpected: compiled OK\r\nI see:\r\nWARNING - actual parameter 1 of func does not match formal parameter\r\nfound   : {func: function (): undefined}\r\nrequired: {func: function (): ?}\r\nfunc(fnStruc);\r\n     ^\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\nr2102, Win7 x64\r\n\r\n<b>Please provide any additional information below.</b>\nThe followed code compiles OK:\r\n   /** @param {{func: function()}} obj */\r\n   function test2(obj) {};\r\n   var fnStruc2 = { func: function() {} };\r\n   test2(fnStruc2);\r\n\r\nDiscussion: https://groups.google.com/d/topic/closure-compiler-discuss/JuzERhGo48I/discussion",
    "desc_source": "google"
  },
  "Closure_170": {
    "description": "Overly aggressive comma removal\nWhen I compile the following code using simple optimizations, \r\nfunction Test(n) {\r\n  var i = 0;\r\n  return typeof n !== &quot;undefined&quot; ? (i = n.length) : (n = &quot;foo&quot;), i\r\n}\r\nvar dummy = &quot;6chars&quot;;\r\nconsole &amp;&amp; console.log( Test(dummy) );\r\n\r\nI get this:\r\nfunction Test(a) {\r\n  return 0\r\n}\r\nvar dummy = &quot;6chars&quot;;\r\nconsole &amp;&amp; console.log(Test(dummy));\r\n\r\nWhich provides a different result than the original code.",
    "desc_source": "google"
  },
  "Closure_171": {
    "description": "Assigning object literals to obj.prototype in a immediately executed function not recognized.\n/** @constructor */\r\nfunction foo() {}\r\n(function() {\r\n  foo.prototype = {\r\n    alert: function() {\r\n      alert(&quot;hello world&quot;);\r\n    }\r\n  };\r\n})()\r\nwindow.console.log(foo.prototype.alert); //undefined property warning",
    "desc_source": "google"
  },
  "Closure_172": {
    "description": "Type of prototype property incorrectly inferred to string\n<b>What steps will reproduce the problem?</b>\n1. Compile the following code:\r\n\r\n/** @param {Object} a */\r\nfunction f(a) {\r\n  a.prototype = '__proto';\r\n}\r\n\r\n/** @param {Object} a */\r\nfunction g(a) {\r\n  a.prototype = function(){};\r\n}\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nShould type check. Instead, gives error:\r\n\r\nWARNING - assignment to property prototype of Object\r\nfound   : function (): undefined\r\nrequired: string\r\n  a.prototype = function(){};\r\n  ^",
    "desc_source": "google"
  },
  "Closure_173": {
    "description": "Operator precedence breaks with certain combinations of *, / and %.\n<b>What steps will reproduce the problem?</b>\n1. Try to compile this: x = a % b / b * c * 2; using either simple or advanced optimizations\r\n\r\n<b>What is the expected output? What do you see instead?</b>\n\r\nExpected: probably x=a%b/b*c*2;\r\nActual: x=2*a%b/b*c; (2 is incorrectly bumped to the beginning)\r\n\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nHappens on latest version and online. By the looks of things the change occurred somewhere between versions 20111003 and 20111114.\r\n\r\n\r\n<b>Please provide any additional information below.</b>\n\r\nAs *, / and % all have the same operator precedence they should be left-to-right, but hoisting the 2 to the beginning means it's on the wrong side of the modulus operator.",
    "desc_source": "google"
  },
  "Closure_174": {
    "description": "compiler crash on goog.scope locals\ngoog.provide(&quot;main&quot;);\r\ngoog.scope (function (){\r\n  var a = foo, b, c = 1;\r\n});\r\n\r\nReported by Thomas Fischer\r\n\r\nThere are 2 separate issues here: that there's an error, and that the error make the compiler crash.",
    "desc_source": "google"
  },
  "Closure_175": {
    "description": "Erroneous optimization in ADVANCED_OPTIMIZATIONS mode\n<b>What steps will reproduce the problem?</b>\n\r\n1. Create a file input.js with the following &quot;minimal&quot; test case:\r\n\r\n    window[&quot;anchor&quot;] = function (obj, modifiesProp) {\r\n        return (function (saved) {\r\n            return modifiesProp(obj) + saved;\r\n        })(obj[&quot;prop&quot;]);\r\n    }\r\n\r\n2. Compile it with:\r\n\r\n    java -jar .../build/compiler.jar                    \\\r\n        --compilation_level ADVANCED_OPTIMIZATIONS      \\\r\n        --warning_level VERBOSE                         \\\r\n        --externs window.js                             \\\r\n        --js input.js                                   \\\r\n        --js_output_file output.js\r\n\r\n3. That's all!\r\n\r\nWhat is the expected output?\r\n\r\n    window.foo=function(a,b){var HOLD=a.prop;return b(a)+HOLD};\r\n\r\nWhat do you see instead?\r\n\r\n    window.foo=function(a,b){return b(a)+a.prop};\r\n\r\nNote how this is semantically very different if modifiesProp/b (whose\r\nsemantics are unknown to the compiler) side-effects a.prop.\r\n\r\nThe evaluation order of + is well-defined in EcmaScript 5, but even\r\nthen, this happens even if one substitutes the , (comma) operator.\r\n\r\n<b>What version of the product are you using? On what operating system?</b>\n\r\nGit HEAD\r\n\r\n    commit 4a62ee4bca02169dd77a6f26ed64a624b3f05f95\r\n    Author: Chad Killingsworth &lt;chadkillingsworth@missouristate.edu&gt;\r\n    Date:   Wed Sep 25 14:52:28 2013 -0500\r\n    \r\n        Add history.state to html5 externs\r\n\r\non Linux.",
    "desc_source": "google"
  },
  "Closure_176": {
    "description": "initial type of variable wrong when initialize in a \"var\" statement with type declaration.\nThe following code doesn't give any warning even though it is an obvious bug:\r\n\r\n-------------===============================---------\r\n/**\r\n * @constructor\r\n */\r\nfunction MyClass() {\r\n  this.value = 1;\r\n}\r\n\r\nMyClass.prototype.show = function() {\r\n  window.console.log(this.value)\r\n}\r\n\r\n/**\r\n * @type {MyClass}\r\n */\r\nvar x = null;\r\nx.show();\r\n-------------===============================---------\r\n\r\nHowever, if you remove the @type from the var declaration, then closure realizes the problem and warns about x being null rather than an Object.\r\n\r\nIn any case, since x &quot;can be null&quot;, closure should warn about a potential null pointer error, and suggest to guard against the null value, like it does if we try to pass x as an argument where a non-null type is expected. That could be an optional behavior protected behind a flag, but it would definitely help catch lots of errors and write safer code.\r\n\r\nI am using the latest closure version available to date, on Ubuntu 13.04, on an amd64 machine.",
    "desc_source": "google"
  },
  "Csv_1": {
    "description": "ExtendedBufferReader does not handle EOL consistently\nExtendedBufferReader checks for '\\n' (LF) in the read() methods, incrementing linecount when found.\n\nHowever, the readLine() method calls BufferedReader.readLine() which treats CR, LF and CRLF equally (and drops them).\n\nIf the code is to be flexible in what it accepts, the class should also allow for CR alone as a line terminator.\n\nIt should work if the code increments the line counter for CR, and for LF if the previous character was not CR.",
    "desc_source": "jira"
  },
  "Csv_2": {
    "description": "CSVRecord does not verify that the length of the header mapping matches the number of values\nCSVRecord does not verify that the size of the header mapping matches the number of values. The following test will produce a ArrayOutOfBoundsException:\n\n{code}\n@Test\npublic void testInvalidHeaderTooLong() throws Exception {\n   final CSVParser parser = new CSVParser(\"a,b\", CSVFormat.newBuilder().withHeader(\"A\", \"B\", \"C\").build());\n   final CSVRecord record = parser.iterator().next();\n   record.get(\"C\");\n}\n{code}",
    "desc_source": "jira"
  },
  "Csv_3": {
    "description": "Unescape handling needs rethinking\nThe current escape parsing converts <esc><char> to plain <char> if the <char> is not one of the special characters to be escaped.\n\nThis can affect unicode escapes if the <esc> character is backslash.\n\nOne way round this is to specifically check for <char> == 'u', but it seems wrong to only do this for 'u'.\n\nAnother solution would be to leave <esc><char> as is unless the <char> is one of the special characters.\n\nThere are several possible ways to treat unrecognised escapes:\n- treat it as if the escape char had not been present (current behaviour)\n- leave the escape char as is\n- throw an exception",
    "desc_source": "jira"
  },
  "Csv_4": {
    "description": "CSVParser: getHeaderMap throws NPE \ntitle nearly says it all :-) \n\nGiven a CSVParser parser, the following line throws an NPE:\n\n{code}\nMap<String, Integer> header = parser.getHeaderMap();\n{code}\n\nStacktrace: \n\n{noformat}\nCaused by: java.lang.NullPointerException\nat java.util.HashMap.<init>(HashMap.java:318)\nat java.util.LinkedHashMap.<init>(LinkedHashMap.java:212)\nat org.apache.commons.csv.CSVParser.getHeaderMap(CSVParser.java:288)\n{noformat}\n\nhappens if the format doesn't have a headerMap.\n\nto fix, check if the parser's headerMap is null before trying to create the returned map:\n\n{code}\npublic Map<String, Integer> getHeaderMap() {\n    return this.headerMap != null ?\n       new LinkedHashMap<String, Integer>(this.headerMap)\n       : null;\n}\n\n{code}\n",
    "desc_source": "jira"
  },
  "Csv_5": {
    "description": "CSVFormat.format allways append null\nWhen I now call\nCSVFormat.newFormat(';').withSkipHeaderRecord(true).withHeader(\"H1\",\"H2\").format(\"A\",\"B\")\nI get the output A;Bnull\n\nThe expected output would be \n\nA;B\n",
    "desc_source": "jira"
  },
  "Csv_6": {
    "description": "CSVRecord.toMap() fails if row length shorter than header length\nSimilar to CSV-96, if .toMap() is called on a record that has fewer fields than we have header columns we'll get an ArrayOutOfBoundsException.\n\n{code}\n@Test\npublic void testToMapWhenHeaderTooLong() throws Exception {\n   final CSVParser parser = new CSVParser(\"a,b\", CSVFormat.newBuilder().withHeader(\"A\", \"B\", \"C\").build());\n   final CSVRecord record = parser.iterator().next();\n   record.toMap();\n}\n{code}",
    "desc_source": "jira"
  },
  "Csv_7": {
    "description": "HeaderMap is inconsistent when it is parsed from an input with duplicate columns names\nGiven a parser format for csv files with a header line:\n{code}\nCSVFormat myFormat = CSVFormat.RFC4180.withDelimiter(\",\").withQuoteChar('\"').withQuotePolicy(Quote.MINIMAL)\n\t\t\t\t.withIgnoreSurroundingSpaces(true).withHeader().withSkipHeaderRecord(true);\n{code}\n\nAnd given a file with duplicate header names:\n \nCol1,Col2,Col2,Col3,Col4\n1,2,3,4,5\n4,5,6,7,8 \n\nThe HeaderMap returned by the parser misses an entry because of the Column name being used as a key, leading to wrong behavior when we rely on it.\n\nIf this is not supposed to happen in the file regarding the CSV format, at least this should raise an error. If not we should come up with a more clever way to store and access the headers.\n",
    "desc_source": "jira"
  },
  "Csv_8": {
    "description": "CSVFormat constructor should reject a header array with duplicate entries\nCSVFormat currently accepts whatever header String[] is provided.\nIt cannot be used if there are duplicate entries so these should be rejected.",
    "desc_source": "jira"
  },
  "Csv_9": {
    "description": "CSVRecord.toMap() throws NPE on formats with no headers.\nThe method toMap() on CSVRecord throws a NullPointerExcpetion when called on records derived using a format with no headers.\n\nThe method documentation states a null map should be returned instead.\n",
    "desc_source": "jira"
  },
  "Csv_10": {
    "description": "CSVFormat#withHeader doesn't work with CSVPrinter\nIn the current version [CSVFormat#withHeader|https://commons.apache.org/proper/commons-csv/apidocs/org/apache/commons/csv/CSVFormat.html#withHeader(java.lang.String...)] is only used by CSVParser. It would be nice if CSVPrinter also supported it. Ideally, the following line of code\n\n{code:java}\nCSVPrinter csvPrinter\n  = CSVFormat.TDF\n    .withHeader(\"x\")\n    .print(Files.newBufferedWriter(Paths.get(\"data.csv\")));\ncsvPrinter.printRecord(42);\ncsvPrinter.close();\n{code}\n\nshould produce\n\n{code}\nx\n42\n{code}\n\nIf you're alright with the idea of automatically inserting headers, I can attach a patch.",
    "desc_source": "jira"
  },
  "Csv_11": {
    "description": "NullPointerException when empty header string and and null string of \"\"\nWhen setting the format to have a nullString of \"\" and having an empty header value, a nullPointerException is thrown.",
    "desc_source": "jira"
  },
  "Csv_12": {
    "description": "CSVFormat.EXCEL should ignore empty header names\nI have an Excel file with a first row with N column names\nIf there are additional columns that are not labeled, Excel exports empty columns. For example:\nA,B,C,,\na,b,c,d,e\n\nThis causes an IAE like:\n\n{noformat}\njava.lang.IllegalArgumentException: The header contains a duplicate name: \"\" in [A, B, C, , ]\n\tat org.apache.commons.csv.CSVParser.initializeHeader(CSVParser.java:368)\n\tat org.apache.commons.csv.CSVParser.<init>(CSVParser.java:248)\n\tat org.apache.commons.csv.CSVParser.parse(CSVParser.java:206)\n{noformat}\t\n\nIt seems like the simplest solution is to ignore empty column names, such that they cannot be addressable and not attempt to index them.",
    "desc_source": "jira"
  },
  "Csv_13": {
    "description": "CsvFormat.nullString should not be escaped\nHello,\n\nUse case: I'm generating MySQL dump files (text format) - for more details check this - http://dev.mysql.com/doc/refman/5.7/en/select-into.html. \n\nIssue: The value null is represented as \"\\N\". Also by default the escape char is '\\N'. The CsvPrinter.printAndEscape method will convert this value into {noformat}\"\\\\N\"{noformat}\n\nI suggest to modify the CsvPrinter in order to not escape the nullString value  - it should be written as it is. I can create a pull request if you want.\n\nI consider it a minor issue because it can be mitigated by making sure that the escape character is not a part of the nullString - however in my case it means that the LOAD commands should be modified accordingly.",
    "desc_source": "jira"
  },
  "Csv_14": {
    "description": "Negative numeric values in the first column are always quoted in minimal mode\nNegative Numeric values are always quoted in minimal mode if (and only if) they are in the first column.\n\ni.e.\nlong,lat,data\n\"-92.222\",43.333,3\n\nLooking at the code, this is by design but seem to be for an unknown reason.\n\nFrom v1.2 CSVPrinter line 230:\n\n// TODO where did this rule come from?\nif (newRecord && (c < '0' || (c > '9' && c < 'A') || (c > 'Z' && c < 'a') || (c > 'z'))) {\n    quote = true;\n} else ...\n   \n\nI propose this rule to either be remove or at a minimum be changed to:\n// TODO where did this rule come from?\nif (newRecord && (c !='-' && c < '0' || (c > '9' && c < 'A') || (c > 'Z' && c < 'a') || (c > 'z'))) {\n    quote = true;\n} else ...\n   \n\n",
    "desc_source": "jira"
  },
  "Csv_15": {
    "description": "The behavior of quote char using is not similar as Excel does when the first string contains CJK char(s)\nWhen using CSVFormat.EXCEL to print a CSV file, the behavior of quote char using is not similar as Microsoft Excel does when the first string contains Chinese, Japanese or Korean (CJK) char(s).\r\n\r\ne.g.\r\nThere are 3 data members in a record, with Japanese chars: \"\u3042\", \"\u3044\", \"\u3046\":\r\n  Microsoft Excel outputs:\r\n  \u3042,\u3044,\u3046\r\n  Apache Common CSV outputs:\r\n  \"\u3042\",\u3044,\u3046\r\n",
    "desc_source": "jira"
  },
  "Csv_16": {
    "description": "Some multi-iterator parsing peek sequences incorrectly consume elements\nRepeated calls to CSVParser Iterable return new Iterators that each reference the same underlying parser lexer. Within the scope of a\u00a0single Iterator, row peeking with Iterator.hasNext() works as intended. When row peeking with Iterator.hasNext()\u00a0under circumstances that create a new Iterator, an element is consumed by the iterator which cannot be\u00a0accessed by subsequent, newly created Iterators and Iterator.next()s. Effectively, the record Iterator and the lexer get out of sequence. See snippet below.\r\n\r\nThe \"right thing\" is keeping the Iterator in sequence with the lexer, and since this is reading from a buffer, there seem to me to be only two resolutions:\r\n # One lexer, one Iterator.\r\n # New Iterators, but peeking with hasNext doesn't advance the lexer.\r\n\r\n\u00a0\r\n\r\nIf there's a consensus on one of these, I can put up a PR.\r\n\r\n\u00a0\r\n{code:java}\r\n\u00a0 @Test\r\n\r\n\u00a0 public void newIteratorSameLexer() throws Exception {\r\n\r\n\r\n\r\n\u00a0 \u00a0 String fiveRows = \"1\\n2\\n3\\n4\\n5\\n\";\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"Enhanced for loop, no peeking:\");\r\n\r\n\u00a0 \u00a0 CSVParser parser =\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 int recordNumber = 0;\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // CSVParser.iterator() returns a new iterator, but the lexer isn't reset so we can pick up\r\n\r\n\u00a0 \u00a0 // where we left off.\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Enhanced for loop, no peeking:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // 3 -> 3\r\n\r\n\u00a0 \u00a0 // 4 -> 4\r\n\r\n\u00a0 \u00a0 // 5 -> 5\r\n\r\n\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"\\nEnhanced for loop, with peek:\");\r\n\r\n\u00a0 \u00a0 parser = new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 recordNumber = 0;\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // CSVParser.iterator() returns a new iterator, but we call hasNext before next, so we queue\r\n\r\n\u00a0 \u00a0 // one element for consumption. This element is discarded by the new iterator, even though the\r\n\r\n\u00a0 \u00a0 // lexer has advanced a row, so we've consumed an element with the peek!\r\n\r\n\u00a0 \u00a0 System.out.println(\"hasNext(): \" + parser.iterator().hasNext());\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Enhanced for loop, with peek:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // hasNext(): true\r\n\r\n\u00a0 \u00a0 // 3 -> 4\r\n\r\n\u00a0 \u00a0 // 4 -> 5\r\n\r\n\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"\\nIterator while, with peek:\");\r\n\r\n\u00a0 \u00a0 parser = new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 recordNumber = 0;\r\n\r\n\u00a0 \u00a0 Iterator<CSVRecord> iter = parser.iterator();\r\n\r\n\u00a0 \u00a0 while (iter.hasNext()) {\r\n\r\n\u00a0 \u00a0 \u00a0 CSVRecord record = iter.next();\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // When we use the same iterator, iterator and lexer are in sequence.\r\n\r\n\u00a0 \u00a0 System.out.println(\"hasNext(): \" + iter.hasNext());\r\n\r\n\u00a0 \u00a0 while (iter.hasNext()) {\r\n\r\n\u00a0 \u00a0 \u00a0 CSVRecord record = iter.next();\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Iterator while, with peek:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // hasNext(): true\r\n\r\n\u00a0 \u00a0 // 3 -> 3\r\n\r\n\u00a0 \u00a0 // 4 -> 4\r\n\r\n\u00a0 \u00a0 // 5 -> 5\r\n\r\n\u00a0 }{code}",
    "desc_source": "jira"
  },
  "Codec_1": {
    "description": "Fix case-insensitive string handling\nThe language codecs are platform-depedent, please see [Common Bug #3|http://www.nabble.com/Re%3A-Common-Bugs-p14931921s177.html] for details.",
    "desc_source": "jira"
  },
  "Codec_2": {
    "description": "Base64 bug with empty input (new byte[0])\nBase64.encode(new byte[0]) doesn't return an empty byte array back!  It returns CRLF.",
    "desc_source": "jira"
  },
  "Codec_3": {
    "description": "Double Metaphone bugs in alternative encoding\nThe new test case (CODEC-83) has highlighted a number of issues with the \"alternative\" encoding in the Double Metaphone implementation\n\n1) Bug in the handleG method when \"G\" is followed by \"IER\" \n *  The alternative encoding of \"Angier\" results in \"ANKR\" rather than \"ANJR\"\n *  The alternative encoding of \"rogier\" results in \"RKR\" rather than \"RJR\"\n\nThe problem is in the handleG() method and is caused by the wrong length (4 instead of 3) being used in the contains() method:\n\n{code}\n } else if (contains(value, index + 1, 4, \"IER\")) {\n{code}\n\n...this should be\n\n{code}\n } else if (contains(value, index + 1, 3, \"IER\")) {\n{code}\n\n\n2)  Bug in the handleL method\n * The alternative encoding of \"cabrillo\" results in \"KPRL \" rather than \"KPR\"\n\nThe problem is that the first thing this method does is append an \"L\" to both primary & alternative encoding. When the conditionL0() method returns true then the \"L\" should not be appended for the alternative encoding\n\n{code}\nresult.append('L');\nif (charAt(value, index + 1) == 'L') {\n    if (conditionL0(value, index)) {\n        result.appendAlternate(' ');\n    }\n    index += 2;\n} else {\n    index++;\n}\nreturn index;\n{code}\n\nSuggest refeactoring this to\n\n{code}\nif (charAt(value, index + 1) == 'L') {\n    if (conditionL0(value, index)) {\n        result.appendPrimary('L');\n    } else {\n        result.append('L');\n    }\n    index += 2;\n} else {\n    result.append('L');\n    index++;\n}\nreturn index;\n{code}\n\n3) Bug in the conditionL0() method for words ending in \"AS\" and \"OS\"\n * The alternative encoding of \"gallegos\" results in \"KLKS\" rather than \"KKS\"\n\nThe problem is caused by the wrong start position being used in the contains() method, which means its not checking the last two characters of the word but checks the previous & current position instead:\n\n{code}\n        } else if ((contains(value, index - 1, 2, \"AS\", \"OS\") || \n{code}\n\n...this should be\n\n{code}\n        } else if ((contains(value, value.length() - 2, 2, \"AS\", \"OS\") || \n{code}\n\nI'll attach a patch for review",
    "desc_source": "jira"
  },
  "Codec_4": {
    "description": "new Base64().encode() appends a CRLF, and chunks results into 76 character lines\nThe instance encode() method (e.g. new Base64().encode()) appends a CRLF.  Actually it's fully chunking the output into 76 character lines.  Commons-Codec-1.3 did not do this.  The static Base64.encodeBase64() method behaves the same in both 1.3 and 1.4, so this problem only affects the instance encode() method.\n\n\n{code}\nimport org.apache.commons.codec.binary.*;\n\npublic class B64 {\n\n  public static void main(String[] args) throws Exception {\n    Base64 b64 = new Base64();\n\n    String s1 = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\";\n    String s2 = \"aaaaaaaaaa\";\n    String s3 = \"a\";\n    \n    byte[] b1 = s1.getBytes(\"UTF-8\");\n    byte[] b2 = s2.getBytes(\"UTF-8\");\n    byte[] b3 = s3.getBytes(\"UTF-8\");\n\n    byte[] result;\n    result = Base64.encodeBase64(b1);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n    result = b64.encode(b1);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n\n    result = Base64.encodeBase64(b2);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n    result = b64.encode(b2);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n\n    result = Base64.encodeBase64(b3);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n    result = b64.encode(b3);\n    System.out.println(\"[\" + new String(result, \"UTF-8\") + \"]\");\n\n  }\n}\n{code}\n\n\nHere's my output:\n\n{noformat}\n$ java -cp commons-codec-1.3.jar:. B64\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYQ==]\n[YQ==]\n[YQ==]\n\n\n$ java -cp commons-codec-1.4.jar:. B64\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFh\nYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYQ==\n]\n[YWFhYWFhYWFhYQ==]\n[YWFhYWFhYWFhYQ==\n]\n[YQ==]\n[YQ==\n]\n{noformat}\n",
    "desc_source": "jira"
  },
  "Codec_5": {
    "description": "Base64InputStream causes NullPointerException on some input\nCertain (malformed?) input to {{Base64InputStream}} causes a {{NullPointerException}} in {{Base64.decode}}.\n\nThe exception occurs when {{Base64.decode}} is entered with the following conditions:\n\n* {{buffer}} is {{null}}\n* {{modulus}} is {{3}} from a previous entry.\n* {{inAvail}} is {{-1}} because {{Base64InputStream.read}} reached EOF on line 150.\n\nUnder these conditions, {{Base64.decode}} reaches line 581 with {{buffer}} still {{null}} and throws a {{NullPointerException}}.\n\nHere is some input data that will trigger it:\n\n{noformat}\nH4sIAAAAAAAAAFvzloG1uIhBKiuxLFGvODW5tCizpFIvODM9LzXFPykrNbmE8//eDC2bq/+ZGJij\nGdiT8/NKUvNKShiYop2iGTiLgQoTS0qLUgsZ6hgYfRh4SjJSE3PS84GmZOSWMAj5gMzVz0nMS9cP\nLinKzEu3rigoLQJpXvNZ/AcbR8gDJgaGigIGBqbLayAuMUxNKdVLTyxJTc7QS07WSyzKLC7JL8lJ\n1StJLErMKynNSdTLyUxOzStO1fOB0AwQwMjEwOrJwJMbn+mSWFkclpiTmeID4joml2SWpYZk5qaW\nMEj45Bel62flpyTqlwAF9F2A9oBkrMEqnYtSoXyob1hy4z1dShgEIL4oLcnM0Q8N9XQBqubKjYfa\nDjTV1AfoZn2Im/WTk/XhbtaHu1kf6mZ9T5g2YED8BwKgj8WAbtIDuUkP5CY9mJt22FSkZEXf/QkK\noCIGeVRFSYlA/zsBCZjq//9/PvSP1VvMxMDkxcCe6ZuZk5NZ7MPAnemcUZSfl5+Tn15ZwiCF5n2E\nnDUoDhjVfhrpNABdpI5qWTJYmZ5nsD9Cg0pwSWnSyhOCaYXmAerMoDgsxnAkzG1R+XmpYPXL9Bln\n1RhJPQarL+dgYNM1MLUyMKioKAYFOCvIBb8vl8qCOFxA4/jAiRIU7HqgYN8zk/n7jNxWfbAXeXJS\nE4tLgOnUKbOk2IuBOzcfzqso6M1QmrzKkedPzcYO3QZu129As4xITlZI6QqYFNhz44v9EkFpCGua\nLmEQdkktS83JL8gF5g4FqBGlIJ+wAI1gKJtZEvTws/j3FluPu4lcr7ra9OfHKXIZNTa4FPd8n33J\nQXPFLte9AZe5uBaJvGrKVl+rbrTaXDZO6NwU7gnHOVgzzsmnGX2Y5GDqrst8wcTear0Ab1yj6PrD\nF977vL/5iUMg773My5qLLK8OVAu6Tz7Xcyjy9Uym02Z/+xY7m85nYo/t4E93FXFKOf9/a3X78neS\njE5Tu066K3Mdf17m66mbpXN9y34ZZ3ErRobfn+RfzVBIWj0vc82vY7YPvM5eLHHOulV77M6CoB4h\nxb/FjHWHRR+ldb6QmSP1ROGwGs+nx2quwitN7+mIpsRFhU37JPRoZe2ZjiX/70j7CS1tz51YP/3W\n/xfnV2i/4rAoYeAN9nA0NTQqBxYMQcGOAG5\n{noformat}\n\nSay this is read from file with a {{byte[]}} of size {{1024}} using {{Base64InputStream.read(byte[])}}.  In the first iteration, all {{1190}} bytes get read into {{buf}}, then it enters {{Base64.setInitialBuffer}} and assigns the {{byte[1024]}} to {{buffer}} and does a round of decoding.  When it then enters {{Base64.readResults}} on line {{162}} in {{Base64InputStream}}, it sets {{buffer}} to {{null}}, {{modulus}} has the left-over value {{3}}, and the NPE occurs the next iteration.\n\n{{Base64InputStream}} could avoid this by returning right away on EOF ({{-1}}), but I think the real fix needs to happen in {{Base64}} since it this same situation could be created by direct use.  My guess is either more needs to happen in the body of the {{if}} on line {{542}} (set {{modulus}} to {{0}}?) or the condition on line {{573}} is flawed and needs adjusting.\n",
    "desc_source": "jira"
  },
  "Codec_6": {
    "description": "Base64InputStream#read(byte[]) incorrectly returns 0 at end of any stream which is multiple of 3 bytes long\nUsing new InputStreamReader(new Base64InputStream(in, true)) sometimes fails with \"java.io.IOException: Underlying input stream returned zero bytes\".\n\nThis is been tracked down that Base64InputStream#read(byte[]) incorrectly returns 0 at end of any stream which is multiple of 3 bytes long.",
    "desc_source": "jira"
  },
  "Codec_7": {
    "description": "Base64.encodeBase64String() shouldn't chunk\nBase64.encodeBase64String() shouldn't chunk.\n\nChange this:\n\n{code}\npublic static String encodeBase64String(byte[] binaryData) {\n    return StringUtils.newStringUtf8(encodeBase64(binaryData, true));\n}\n{code}\n\nTo this:\n\n{code}\npublic static String encodeBase64String(byte[] binaryData) {\n    return StringUtils.newStringUtf8(encodeBase64(binaryData, false));\n}\n{code}\n\n\n\nThis will fix the following tests ggregory added a few minutes ago:\n\n        //assertEquals(\"Zg==\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"f\")));\n        //assertEquals(\"Zm8=\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"fo\")));\n        //assertEquals(\"Zm9v\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"foo\")));\n        //assertEquals(\"Zm9vYg==\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"foob\")));\n        //assertEquals(\"Zm9vYmE=\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"fooba\")));\n        //assertEquals(\"Zm9vYmFy\", Base64.encodeBase64String(StringUtils.getBytesUtf8(\"foobar\")));\n\n",
    "desc_source": "jira"
  },
  "Codec_8": {
    "description": "ArrayIndexOutOfBoundsException when doing multiple reads() on encoding Base64InputStream\nWhen encoding a sizable stream byte by byte (so, just calling Base64InputStream.read()), after 10920 successful read()s, this happens: \n\njava.lang.ArrayIndexOutOfBoundsException: 2\n        at org.apache.commons.codec.binary.Base64.encode(Base64.java:502)\n        at org.apache.commons.codec.binary.Base64InputStream.read(Base64InputStream.java:157)\n        at org.apache.commons.codec.binary.Base64InputStream.read(Base64InputStream.java:109)\n\nBased on this, the necessary conditions seem to be that buffer = null and modulus = 2. Then, if a read() is done, a single-byte buffer is used, whose length is doubled by resizeBuffer(), but that still doesn't make it big enough to hold the 4 bytes written to it because modulus was just incremented to 0. \n\nHere's some sample code:\n\nimport org.apache.commons.codec.binary.Base64InputStream;\n\npublic class TestReads {\n    public static void main(String[] args) {\n        Base64InputStream b64stream = new Base64InputStream(System.in, true, 0, null);\n        int n = 0;\n        try {\n            while (b64stream.read() != -1) n++;\n        } catch (Exception x) {\n            System.out.println(n);\n            x.printStackTrace();\n        }\n    }\n}\n",
    "desc_source": "jira"
  },
  "Codec_9": {
    "description": "Base64.encodeBase64(byte[] binaryData, boolean isChunked, boolean urlSafe, int maxResultSize) throws IAE for valid maxResultSize if isChunked is false\nIf isChunked is false, Base64.encodeBase64(byte[] binaryData, boolean isChunked, boolean urlSafe, int maxResultSize) throws IAE for valid maxResultSize.\n\nTest case and fix will be applied shortly.",
    "desc_source": "jira"
  },
  "Codec_10": {
    "description": "Caverphone encodes names starting and ending with \"mb\" incorrectly.\nCaverphone encode names starting and ending with \"mb\" incorrectly.\n\nAccording to the spec:\n\"If the name ends with mb make it m2\".\n\nThis has been coded as:\n\"If the name _starts_ with mb make it m2\".",
    "desc_source": "jira"
  },
  "Codec_11": {
    "description": "QuotedPrintableCodec does not support soft line break per the 'quoted-printable' example on Wikipedia\nWriting a unit test I discovered that the example Wikipedia uses for quoted-printable data does not decode but instead throws an exception.  \nTheir example is here:  http://en.wikipedia.org/wiki/Quoted-printable#Example\n\ntest:\n\n  String qpdata   = \"If you believe that truth=3Dbeauty, then surely=20=\\r\\n\" +\n\t\t    \"mathematics is the most beautiful branch of philosophy.\";\n\n  String expected = \"If you believe that truth=beauty, then surely \" +\n\t\t    \"mathematics is the most beautiful branch of philosophy.\";\n\n  assertEquals( expected,  new QuotedPrintableCodec().decode(qpdata) );\n\nI suppose I could fix if you like but currently I'm not a registered developer.  \n\n\n",
    "desc_source": "jira"
  },
  "Codec_12": {
    "description": "Base64InputStream.skip skips underlying stream, not output\nBase64InputStream.skip() skips within underlying stream, leading to unexpected behaviour.\n\nThe following code will reproduce the issue:\n\n@Test\npublic void testSkip() throws Throwable {\n    InputStream ins =\n            new ByteArrayInputStream(\"AAAA////\".getBytes(\"ISO-8859-1\"));//should decode to {0, 0, 0, 255, 255, 255}\n    Base64InputStream instance = new Base64InputStream(ins);\n    assertEquals(3L, instance.skip(3L)); //should skip 3 decoded characters, or 4 encoded characters\n    assertEquals(255, instance.read()); //Currently returns 3, as it is decoding \"A/\", not \"//\" \n}\n\nThe following code, if added to Base64InputStream, or (BaseNCodecInputStream in the dev build) would resolve the issue:\n\n@Override\npublic long skip(long n) throws IOException {\n    //delegate to read()\n    long bytesRead = 0;\n    while ((bytesRead < n) && (read() != -1)) {\n        bytesRead++;\n    }\n    return bytesRead;\n}\n\nMore efficient code may be possible.",
    "desc_source": "jira"
  },
  "Codec_13": {
    "description": "NullPointerException in DoubleMetaPhone.isDoubleMetaphoneEqual when using empty strings\n{{isDoubleMetaphoneEqual}} does not work with empty strings: The following test throws a {{NullPointerException}}:\n\n{code:java}\n  public void test1() throws Throwable {\n    org.apache.commons.codec.language.DoubleMetaphone var0 = new org.apache.commons.codec.language.DoubleMetaphone();\n    boolean var3 = var0.isDoubleMetaphoneEqual(\"\", \"\", false);\n  }\n{code}",
    "desc_source": "jira"
  },
  "Codec_14": {
    "description": "Beider Morse Phonetic Matching producing incorrect tokens\nI believe the Beider Morse Phonetic Matching algorithm was added in Commons Codec 1.6\n\nThe BMPM algorithm is an EVOLVING algorithm that is currently on version 3.02 though it had been static since version 3.01 dated 19 Dec 2011 (it was first available as opensource as version 1.00 on 6 May 2009).\n\nI can see nothing in the Commons Codec Docs to say which version of BMPM was implemented so I am not sure if the problem with the algorithm as coded in the Codec is simply an old version or whether there are more basic problems with the implementation.\n\nHow do I determine the version of the algorithm that was implemented in the Commons Codec?\n\nHow do we ensure that the algorithm is updated if/when the BMPM algorithm changes?\n\nHow do we ensure that the algorithm as coded in the Commons Codec is accurate and working as expected?",
    "desc_source": "jira"
  },
  "Codec_15": {
    "description": "Bug in HW rule in Soundex\nThe Soundex algorithm says that if two characters that map to the same code are separated by H or W, the second one is not encoded.\nHowever, in the implementation (in Soundex.getMappingCode() line 191), a character that is preceded by two characters that are either H or W, is not encoded, regardless of what the last consonant was.\nSource: http://en.wikipedia.org/wiki/Soundex#American_Soundex\n",
    "desc_source": "jira"
  },
  "Codec_16": {
    "description": "Base32.HEX_DECODE_TABLE contains the wrong value 32\nAt line 99:\n\n            25, 26, 27, 28, 29, 30, 31, 32,                                 // 50-57 O-V\n\nthe value 32 should not be included. That disallows to use 'W' as padding with hex table.",
    "desc_source": "jira"
  },
  "Codec_17": {
    "description": "StringUtils.newStringxxx(null) should return null, not NPE\nMethod calls such as StringUtils.newStringIso8859_1(null) should return null, not NPE.\n\nIt looks like this capability was lost with the fix for CODEC-136, i.e.\nhttp://svn.apache.org/viewvc?rev=1306366&view=rev\n\nSeveral methods were changed from\n\n{code}\nreturn StringUtils.newString(bytes, CharEncoding.xxx);\nto\nreturn new String(bytes, Charsets.xxx);\n{code}\n\nThe new code should have been:\n\n{code}\nreturn newString(bytes, Charsets.xxx);\n{code}\n\nThe newString method handles null input.\n\nThere were no tests for null input so the change in behaviour was missed.\n",
    "desc_source": "jira"
  },
  "Codec_18": {
    "description": "StringUtils.equals(CharSequence cs1, CharSequence cs2) can fail with String Index OBE\nStringUtils.equals(CharSequence cs1, CharSequence cs2) fails with String Index OBE if the two sequences are different lengths.",
    "desc_source": "jira"
  },
  "JacksonXml_1": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonXml_2": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonXml_3": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonXml_4": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonXml_5": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "JacksonXml_6": {
    "description": "",
    "desc_source": "commit_msg"
  }
}