{
  "Csv_1": {
    "description": "ExtendedBufferReader does not handle EOL consistently\nExtendedBufferReader checks for '\\n' (LF) in the read() methods, incrementing linecount when found.\n\nHowever, the readLine() method calls BufferedReader.readLine() which treats CR, LF and CRLF equally (and drops them).\n\nIf the code is to be flexible in what it accepts, the class should also allow for CR alone as a line terminator.\n\nIt should work if the code increments the line counter for CR, and for LF if the previous character was not CR.",
    "desc_source": "jira"
  },
  "Csv_2": {
    "description": "CSVRecord does not verify that the length of the header mapping matches the number of values\nCSVRecord does not verify that the size of the header mapping matches the number of values. The following test will produce a ArrayOutOfBoundsException:\n\n{code}\n@Test\npublic void testInvalidHeaderTooLong() throws Exception {\n   final CSVParser parser = new CSVParser(\"a,b\", CSVFormat.newBuilder().withHeader(\"A\", \"B\", \"C\").build());\n   final CSVRecord record = parser.iterator().next();\n   record.get(\"C\");\n}\n{code}",
    "desc_source": "jira"
  },
  "Csv_3": {
    "description": "Unescape handling needs rethinking\nThe current escape parsing converts <esc><char> to plain <char> if the <char> is not one of the special characters to be escaped.\n\nThis can affect unicode escapes if the <esc> character is backslash.\n\nOne way round this is to specifically check for <char> == 'u', but it seems wrong to only do this for 'u'.\n\nAnother solution would be to leave <esc><char> as is unless the <char> is one of the special characters.\n\nThere are several possible ways to treat unrecognised escapes:\n- treat it as if the escape char had not been present (current behaviour)\n- leave the escape char as is\n- throw an exception",
    "desc_source": "jira"
  },
  "Csv_4": {
    "description": "CSVParser: getHeaderMap throws NPE \ntitle nearly says it all :-) \n\nGiven a CSVParser parser, the following line throws an NPE:\n\n{code}\nMap<String, Integer> header = parser.getHeaderMap();\n{code}\n\nStacktrace: \n\n{noformat}\nCaused by: java.lang.NullPointerException\nat java.util.HashMap.<init>(HashMap.java:318)\nat java.util.LinkedHashMap.<init>(LinkedHashMap.java:212)\nat org.apache.commons.csv.CSVParser.getHeaderMap(CSVParser.java:288)\n{noformat}\n\nhappens if the format doesn't have a headerMap.\n\nto fix, check if the parser's headerMap is null before trying to create the returned map:\n\n{code}\npublic Map<String, Integer> getHeaderMap() {\n    return this.headerMap != null ?\n       new LinkedHashMap<String, Integer>(this.headerMap)\n       : null;\n}\n\n{code}\n",
    "desc_source": "jira"
  },
  "Csv_5": {
    "description": "CSVFormat.format allways append null\nWhen I now call\nCSVFormat.newFormat(';').withSkipHeaderRecord(true).withHeader(\"H1\",\"H2\").format(\"A\",\"B\")\nI get the output A;Bnull\n\nThe expected output would be \n\nA;B\n",
    "desc_source": "jira"
  },
  "Csv_6": {
    "description": "CSVRecord.toMap() fails if row length shorter than header length\nSimilar to CSV-96, if .toMap() is called on a record that has fewer fields than we have header columns we'll get an ArrayOutOfBoundsException.\n\n{code}\n@Test\npublic void testToMapWhenHeaderTooLong() throws Exception {\n   final CSVParser parser = new CSVParser(\"a,b\", CSVFormat.newBuilder().withHeader(\"A\", \"B\", \"C\").build());\n   final CSVRecord record = parser.iterator().next();\n   record.toMap();\n}\n{code}",
    "desc_source": "jira"
  },
  "Csv_7": {
    "description": "HeaderMap is inconsistent when it is parsed from an input with duplicate columns names\nGiven a parser format for csv files with a header line:\n{code}\nCSVFormat myFormat = CSVFormat.RFC4180.withDelimiter(\",\").withQuoteChar('\"').withQuotePolicy(Quote.MINIMAL)\n\t\t\t\t.withIgnoreSurroundingSpaces(true).withHeader().withSkipHeaderRecord(true);\n{code}\n\nAnd given a file with duplicate header names:\n \nCol1,Col2,Col2,Col3,Col4\n1,2,3,4,5\n4,5,6,7,8 \n\nThe HeaderMap returned by the parser misses an entry because of the Column name being used as a key, leading to wrong behavior when we rely on it.\n\nIf this is not supposed to happen in the file regarding the CSV format, at least this should raise an error. If not we should come up with a more clever way to store and access the headers.\n",
    "desc_source": "jira"
  },
  "Csv_8": {
    "description": "CSVFormat constructor should reject a header array with duplicate entries\nCSVFormat currently accepts whatever header String[] is provided.\nIt cannot be used if there are duplicate entries so these should be rejected.",
    "desc_source": "jira"
  },
  "Csv_9": {
    "description": "CSVRecord.toMap() throws NPE on formats with no headers.\nThe method toMap() on CSVRecord throws a NullPointerExcpetion when called on records derived using a format with no headers.\n\nThe method documentation states a null map should be returned instead.\n",
    "desc_source": "jira"
  },
  "Csv_10": {
    "description": "CSVFormat#withHeader doesn't work with CSVPrinter\nIn the current version [CSVFormat#withHeader|https://commons.apache.org/proper/commons-csv/apidocs/org/apache/commons/csv/CSVFormat.html#withHeader(java.lang.String...)] is only used by CSVParser. It would be nice if CSVPrinter also supported it. Ideally, the following line of code\n\n{code:java}\nCSVPrinter csvPrinter\n  = CSVFormat.TDF\n    .withHeader(\"x\")\n    .print(Files.newBufferedWriter(Paths.get(\"data.csv\")));\ncsvPrinter.printRecord(42);\ncsvPrinter.close();\n{code}\n\nshould produce\n\n{code}\nx\n42\n{code}\n\nIf you're alright with the idea of automatically inserting headers, I can attach a patch.",
    "desc_source": "jira"
  },
  "Csv_11": {
    "description": "NullPointerException when empty header string and and null string of \"\"\nWhen setting the format to have a nullString of \"\" and having an empty header value, a nullPointerException is thrown.",
    "desc_source": "jira"
  },
  "Csv_12": {
    "description": "CSVFormat.EXCEL should ignore empty header names\nI have an Excel file with a first row with N column names\nIf there are additional columns that are not labeled, Excel exports empty columns. For example:\nA,B,C,,\na,b,c,d,e\n\nThis causes an IAE like:\n\n{noformat}\njava.lang.IllegalArgumentException: The header contains a duplicate name: \"\" in [A, B, C, , ]\n\tat org.apache.commons.csv.CSVParser.initializeHeader(CSVParser.java:368)\n\tat org.apache.commons.csv.CSVParser.<init>(CSVParser.java:248)\n\tat org.apache.commons.csv.CSVParser.parse(CSVParser.java:206)\n{noformat}\t\n\nIt seems like the simplest solution is to ignore empty column names, such that they cannot be addressable and not attempt to index them.",
    "desc_source": "jira"
  },
  "Csv_13": {
    "description": "CsvFormat.nullString should not be escaped\nHello,\n\nUse case: I'm generating MySQL dump files (text format) - for more details check this - http://dev.mysql.com/doc/refman/5.7/en/select-into.html. \n\nIssue: The value null is represented as \"\\N\". Also by default the escape char is '\\N'. The CsvPrinter.printAndEscape method will convert this value into {noformat}\"\\\\N\"{noformat}\n\nI suggest to modify the CsvPrinter in order to not escape the nullString value  - it should be written as it is. I can create a pull request if you want.\n\nI consider it a minor issue because it can be mitigated by making sure that the escape character is not a part of the nullString - however in my case it means that the LOAD commands should be modified accordingly.",
    "desc_source": "jira"
  },
  "Csv_14": {
    "description": "Negative numeric values in the first column are always quoted in minimal mode\nNegative Numeric values are always quoted in minimal mode if (and only if) they are in the first column.\n\ni.e.\nlong,lat,data\n\"-92.222\",43.333,3\n\nLooking at the code, this is by design but seem to be for an unknown reason.\n\nFrom v1.2 CSVPrinter line 230:\n\n// TODO where did this rule come from?\nif (newRecord && (c < '0' || (c > '9' && c < 'A') || (c > 'Z' && c < 'a') || (c > 'z'))) {\n    quote = true;\n} else ...\n   \n\nI propose this rule to either be remove or at a minimum be changed to:\n// TODO where did this rule come from?\nif (newRecord && (c !='-' && c < '0' || (c > '9' && c < 'A') || (c > 'Z' && c < 'a') || (c > 'z'))) {\n    quote = true;\n} else ...\n   \n\n",
    "desc_source": "jira"
  },
  "Csv_15": {
    "description": "The behavior of quote char using is not similar as Excel does when the first string contains CJK char(s)\nWhen using CSVFormat.EXCEL to print a CSV file, the behavior of quote char using is not similar as Microsoft Excel does when the first string contains Chinese, Japanese or Korean (CJK) char(s).\r\n\r\ne.g.\r\nThere are 3 data members in a record, with Japanese chars: \"\u3042\", \"\u3044\", \"\u3046\":\r\n  Microsoft Excel outputs:\r\n  \u3042,\u3044,\u3046\r\n  Apache Common CSV outputs:\r\n  \"\u3042\",\u3044,\u3046\r\n",
    "desc_source": "jira"
  },
  "Csv_16": {
    "description": "Some multi-iterator parsing peek sequences incorrectly consume elements\nRepeated calls to CSVParser Iterable return new Iterators that each reference the same underlying parser lexer. Within the scope of a\u00a0single Iterator, row peeking with Iterator.hasNext() works as intended. When row peeking with Iterator.hasNext()\u00a0under circumstances that create a new Iterator, an element is consumed by the iterator which cannot be\u00a0accessed by subsequent, newly created Iterators and Iterator.next()s. Effectively, the record Iterator and the lexer get out of sequence. See snippet below.\r\n\r\nThe \"right thing\" is keeping the Iterator in sequence with the lexer, and since this is reading from a buffer, there seem to me to be only two resolutions:\r\n # One lexer, one Iterator.\r\n # New Iterators, but peeking with hasNext doesn't advance the lexer.\r\n\r\n\u00a0\r\n\r\nIf there's a consensus on one of these, I can put up a PR.\r\n\r\n\u00a0\r\n{code:java}\r\n\u00a0 @Test\r\n\r\n\u00a0 public void newIteratorSameLexer() throws Exception {\r\n\r\n\r\n\r\n\u00a0 \u00a0 String fiveRows = \"1\\n2\\n3\\n4\\n5\\n\";\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"Enhanced for loop, no peeking:\");\r\n\r\n\u00a0 \u00a0 CSVParser parser =\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 int recordNumber = 0;\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // CSVParser.iterator() returns a new iterator, but the lexer isn't reset so we can pick up\r\n\r\n\u00a0 \u00a0 // where we left off.\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Enhanced for loop, no peeking:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // 3 -> 3\r\n\r\n\u00a0 \u00a0 // 4 -> 4\r\n\r\n\u00a0 \u00a0 // 5 -> 5\r\n\r\n\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"\\nEnhanced for loop, with peek:\");\r\n\r\n\u00a0 \u00a0 parser = new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 recordNumber = 0;\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // CSVParser.iterator() returns a new iterator, but we call hasNext before next, so we queue\r\n\r\n\u00a0 \u00a0 // one element for consumption. This element is discarded by the new iterator, even though the\r\n\r\n\u00a0 \u00a0 // lexer has advanced a row, so we've consumed an element with the peek!\r\n\r\n\u00a0 \u00a0 System.out.println(\"hasNext(): \" + parser.iterator().hasNext());\r\n\r\n\u00a0 \u00a0 for (CSVRecord record : parser) {\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Enhanced for loop, with peek:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // hasNext(): true\r\n\r\n\u00a0 \u00a0 // 3 -> 4\r\n\r\n\u00a0 \u00a0 // 4 -> 5\r\n\r\n\r\n\r\n\r\n\r\n\u00a0 \u00a0 System.out.println(\"\\nIterator while, with peek:\");\r\n\r\n\u00a0 \u00a0 parser = new CSVParser(new BufferedReader(new StringReader(fiveRows)), CSVFormat.DEFAULT);\r\n\r\n\u00a0 \u00a0 recordNumber = 0;\r\n\r\n\u00a0 \u00a0 Iterator<CSVRecord> iter = parser.iterator();\r\n\r\n\u00a0 \u00a0 while (iter.hasNext()) {\r\n\r\n\u00a0 \u00a0 \u00a0 CSVRecord record = iter.next();\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 \u00a0 if (recordNumber >= 2) {\r\n\r\n\u00a0 \u00a0 \u00a0 \u00a0 break;\r\n\r\n\u00a0 \u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // When we use the same iterator, iterator and lexer are in sequence.\r\n\r\n\u00a0 \u00a0 System.out.println(\"hasNext(): \" + iter.hasNext());\r\n\r\n\u00a0 \u00a0 while (iter.hasNext()) {\r\n\r\n\u00a0 \u00a0 \u00a0 CSVRecord record = iter.next();\r\n\r\n\u00a0 \u00a0 \u00a0 recordNumber++;\r\n\r\n\u00a0 \u00a0 \u00a0 System.out.println(recordNumber + \" -> \" + record.get(0));\r\n\r\n\u00a0 \u00a0 }\r\n\r\n\u00a0 \u00a0 // Iterator while, with peek:\r\n\r\n\u00a0 \u00a0 // 1 -> 1\r\n\r\n\u00a0 \u00a0 // 2 -> 2\r\n\r\n\u00a0 \u00a0 // hasNext(): true\r\n\r\n\u00a0 \u00a0 // 3 -> 3\r\n\r\n\u00a0 \u00a0 // 4 -> 4\r\n\r\n\u00a0 \u00a0 // 5 -> 5\r\n\r\n\u00a0 }{code}",
    "desc_source": "jira"
  }
}