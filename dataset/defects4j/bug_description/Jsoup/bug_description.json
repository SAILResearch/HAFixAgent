{
  "Jsoup_1": {
    "description": "Parsing a HTML snippet causes the leading text to be moved to back\nCode:\n\n```\nString html = \"foo <b>bar</b> baz\";\nString text = Jsoup.parse(html).text();\nSystem.out.println(text);\n```\n\nResult: \n\n```\nbar baz foo\n```\n\nExpected:\n\n```\nfoo bar baz\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_2": {
    "description": "Unadorned text following data-only tags doesn't parse properly\nThis HTML, parsed and immediately printed out, results in:\n\n&lt;html&gt;\n&lt;body&gt;\n&lt;script type=&quot;text/javascript&quot;&gt;\n  var inside = true;\n&lt;/script&gt;\nthis should be outside.\n&lt;/body&gt;\n&lt;/html&gt;\n\nResults:\n\n&lt;html&gt; \n&lt;head&gt; \n&lt;/head&gt; \n&lt;body&gt; \n &lt;script type=&quot;text/javascript&quot;&gt; \n  var inside = true;\n\nthis should be outside.\n\n&lt;/script&gt; \n&lt;/body&gt; \n&lt;/html&gt;\n\nNote how \"this should be outside\" ends up inside the &lt;script&gt; tag, instead of following it.  From what I can tell, this only happens to data-only tags.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_3": {
    "description": "Issue with <tr>\nWhen calling append to add a table row the resulting tr gets wrapped in a table even though I appended to an existing table.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_4": {
    "description": "uppercase umlauts get replaced by lowercase umlaut entities\nThe line\n\n```\nSystem.out.println(Jsoup.clean(\"<h1>\u00dcberschrift</h1>\", Whitelist.none()));\n```\n\nshould print\n\n```\n&Uuml;berschrift\n```\n\nbut prints\n\n```\n&uuml;berschrift\n```\n\nThis used to work correctly in v0.3.1, but fails in v1.2.3.\n\nWhile _baseArray_ in _Entities.java_ distinguishes between lowercase and uppercase umlauts, the above call yields the wrong result.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_5": {
    "description": "StringIndexOutOfBoundsException when testing whether String content is valid HTML \nIf I try to parse a tag with an equals sign (an empty attribute) but without any single or double quotes around an attribute value, then I get a StringIndexOutOfBoundsException.  The stack trace is pasted below.\n\nAn example String would be \"<a =a\"\n\nThe following JUnit test case should not throw a StringIndexOutOfBoundsException:\n\nimport static org.junit.Assert.assertTrue;\nimport org.jsoup.Jsoup;\nimport org.jsoup.safety.Whitelist;\nimport org.junit.Test;\npublic class BadAttributeTest {\n    @Test\n    public void aTagWithABadAttributeIsValid() throws Exception {\n        assertTrue(Jsoup.isValid(\"<a =a\", Whitelist.relaxed()));\n    }\n}\n\njava.lang.StringIndexOutOfBoundsException: String index out of range: 13\n    at java.lang.String.charAt(String.java:686)\n    at org.jsoup.parser.TokenQueue.consume(TokenQueue.java:130)\n    at org.jsoup.parser.Parser.parseAttribute(Parser.java:207)\n    at org.jsoup.parser.Parser.parseStartTag(Parser.java:142)\n    at org.jsoup.parser.Parser.parse(Parser.java:91)\n    at org.jsoup.parser.Parser.parseBodyFragment(Parser.java:64)\n    at org.jsoup.Jsoup.parseBodyFragment(Jsoup.java:99)\n    at org.jsoup.Jsoup.isValid(Jsoup.java:155)\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_6": {
    "description": "StringIndexOutOfBoundsException when parsing link http://news.yahoo.com/s/nm/20100831/bs_nm/us_gm_china\njava.lang.StringIndexOutOfBoundsException: String index out of range: 1\n    at java.lang.String.charAt(String.java:686)\n    at java.util.regex.Matcher.appendReplacement(Matcher.java:711)\n    at org.jsoup.nodes.Entities.unescape(Entities.java:69)\n    at org.jsoup.nodes.TextNode.createFromEncoded(TextNode.java:95)\n    at org.jsoup.parser.Parser.parseTextNode(Parser.java:222)\n    at org.jsoup.parser.Parser.parse(Parser.java:94)\n    at org.jsoup.parser.Parser.parse(Parser.java:54)\n    at org.jsoup.Jsoup.parse(Jsoup.java:30)\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_7": {
    "description": "Page results in malformed tree\nThe page I will attach results in a Jsoup tree with two body elements, neither if which is a direct child of the html element.\n\nYou will find the page in \"git@github.com:bimargulies/Misc.git\" under the jsoup-tc directory.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_8": {
    "description": "toString NPE for orphans\nI'm working on code that frequently calls 'remove' and then re-adds an element. While the element is in a detached string, toString throws something, so Eclipse prints only an 'invocation target exception.' It would be nice if this were not so.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_9": {
    "description": "Html entities containing digits are not unescaped correctly\nSome html entities (such as sup1, sup2) are not unescaped correctly by Entities.unescape because they contain digits.\n\nThe problem is the pattern Entities.unescapePattern. I changed it to '&(#(x|X)?([0-9a-fA-F]+)|[0-9a-zA-Z]+);?', and it worked fine for me. But there might be side effects ...\n\nYou can see my changes here : https://github.com/clementdenis/jsoup/commit/d65387cb6763c4e6e9896917ce02ea623e30b04e\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_10": {
    "description": "attr(\"abs:href\") , absUrl(\"href\") \nDocument doc = Jsoup.parse(new URL(\"http://www.oschina.net/bbs/thread/12975\"), 5*1000);\nElements es = doc.select(\"a[href]\");\nfor(Iterator<Element> it = es.iterator();it.hasNext();){\n    Element e = it.next();\n        System.out.println(e.absUrl(\"href\"));\n}\n\nattr(\"abs:href\")   ------  &lt;a href=\"?p=1\"&gt;1&lt;/a&gt;\nresult: -------------------   http://www.oschina.net/bbs/thread/?p=1\n\nI think it's a wrong result~.\nThe correct results should be \"http://www.oschina.net/bbs/thread/12975?p=1\"\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_11": {
    "description": "Implement :not pseudo-selector\nIn version 1.3.3, the pseudo selector :not is not implemented.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_12": {
    "description": "tag[attr~=regex] fails if preceded by a combinator\nAll following selectors fail with a SelectorParseException:\n\n<pre>\ndiv table[class~=x|y]\ndiv > table[class~=x|y]\ndiv + table[class~=x|y]\ndiv ~ table[class~=x|y]\n</pre>\n\n\nNote that <pre>div, table[class~=x|y]</pre> does not fail\n\nUsing: jsoup 1.4.1 and JDK 7 build 116\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_13": {
    "description": "abs: attribute prefix does not work on Elements.attr()\nElements.attr() iterates on its element to look for the first one with the given attrbute.\n\nIf I try to get the attribute abs:href, the test element.hasAttr(\"abs:herf\") fails, and the returned value is an empty string. \n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_14": {
    "description": "Unclosed title tag causes JSoup to \"eat up\" rest of document\nHi:\n\nWe've come across an issue with parsing a document with an unclosed title tag. JSoup\nseems to \"eat up\" the rest of the document in its parsing and thus no elements after\nthe unclosed tag are available after the parse.\n\nWhile this is obviously not a valid document Firefox seems to handle it OK by displaying\nthe document and saying \"Untitled document\" in its title bar.\n\nWe come across a lot of badly formed documents in our web crawls so having a fix\nfor this issue would be much appreciated. I've given some sample source below\nwhich demonstrates the bug (tested against JSoup 1.5.2).\n\nMany thanks,\n- Francis.\n\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Element;\nimport org.jsoup.select.Elements;\n\npublic class UnclosedTitleTest {\n\n```\npublic static void main(String args[]) throws Exception {\n    String html = \"<html><head><title>First parse</head>\"\n          + \"<body><p>Parsed HTML into a doc.</p></body></html>\";\n    Document doc = Jsoup.parse(html);\n\n    Elements elements = doc.select(\"p\");\n\n    for (Element element : elements) {\n        System.out.println(element.outerHtml());\n    }\n}\n```\n\n}\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_15": {
    "description": "<script> containing tags causes issues\nThanks for the release, using 1.6.0 now, and getting issues with http://techcrunch.com.  html has a script tag containing tags inside of javascript strings.  Seems to be treating those as real tag openers, creating tag elements and causing the close script tag to be ignored and therefore include a ton of other stuff.  I think this was working in 1.5.2.  \n\nSimplified example:\n\n<pre>\n&lt;HTML>\n&lt;body>\n &lt;div class=vsc sig=Uga>\n  &lt;div class=before>&lt;/div>\n  &lt;script type=\"text/javascript\">\n   header = jQuery('#header_features');\n   if(header.length){\n    header\n     .prepend('&lt;a class=\"prevPage browse left \" />')\n     .append('&lt;a class=\"nextPage browse right\" />');\n\n    items\n     .wrapAll('&lt;div class=\"scrollable\"/>')\n     .wrapAll('&lt;ul class=\"items\"/>')\n     .wrap('&lt;li/>');\n   }\n   &lt;/script>\n   &lt;div class=after>&lt;/div>\n &lt;/div>\n&lt;/body>\n&lt;/HTML>\n</pre>\n\n\nResult, notice the script strings become tags and the script tag now subsumes the following div:\n\n<pre>\n&lt;html>\n &lt;body> \n  &lt;div class=\"vsc\" sig=\"Uga\"> \n   &lt;div class=\"before\">&lt;/div> \n   &lt;script type=\"text/javascript\">\n   header = jQuery('#header_features');\n   if(header.length){\n    header\n     .prepend('\n    &lt;a class=\"prevPage browse left \">') .append('&lt;/a>\n    &lt;a class=\"nextPage browse right\">'); items .wrapAll('\n     &lt;div class=\"scrollable\">\n      ') .wrapAll('\n      &lt;ul class=\"items\">\n       ') .wrap('\n       &lt;li>'); }  \n        &lt;div class=\"after\">&lt;/div> &lt;/li>\n      &lt;/ul>\n     &lt;/div>  &lt;/a>\n   &lt;/script>\n  &lt;/div>\n &lt;/body>\n&lt;/html>\n</pre>\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_16": {
    "description": "DocumentType.outerHtmlHead missing quote\nThere's just a doublequote missing from the append sequence right before the systemId.\n\nFor example:\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_17": {
    "description": "Cleaning a fragment with just \"0\" returns an empty string (1.6.0)\nWhen using JSoup to sanitize some fragments that are inserted into another document, I noticed if a text node contains just the \"0\", it ends up cleaning it as just 0.\n\nThe root of this seems to come from TreeBuilderState's methods, in such places like InBody and InSelect; when it checks for type Character, it seems to cause the \"0\" token to equal the nullstring; this shouldn't be the case, as character 0 is not the same as a \"null\" character.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_18": {
    "description": "outerHtml method returns extra attribute when element definition has new line\nI think this is a bug.\n\nVersion: jsoup-1.6.0.jar\n\nSource:\n---------BEGIN\n&lt;img alt=\"\"\n\n```\n         src=\"/imagelibraries/homepagebanners/british_10k_2010.jpg\" />\n```\n\n---------END\nSteps to reproduce: element.outerHtml() ->\n\nExpected result: two attributes alt and src\nObserved result output\n----------BEGIN\n&lt;img alt=\"\" =\"\" src=\"/imagelibraries/homepagebanners/british_10k_2010.jpg\" />\n----------END\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_19": {
    "description": "Cleaning html containing the cid identifier breaks images\nOk, so in mail type HTML the following is common\n\n<img src=\"cid:SDOMSDOFMOSDOMFOSD\">\n\nThe item after CID: can be almost anything (US-ASCII I think) and of any length. It corresponds to an image linked elsewhere in MIME say like this\n\n--mimebounday\nContent-ID:<SDOMSDOFMOSDOMFOSD>\nContent-Type: image/jpeg.....\n(snip)\n\nSo, to mark a long story somewhat shorter, I use Jsoup's sanitizer extensively. However, I need these CID references to be preserved post sanitization. addProtocols does not work because the items are not valid URLs. As a result\nthe above becomes <img />. Which for my purposes is not good :)\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_20": {
    "description": "Some html file's head element will be empty\nHello, Jonathan\n\nI love Jsoup, and handling many html files. \n\nBut today, I'm under the  problem.\nWhen parse with Jsoup, some html file's head element will be empty.\n\nSample html is here -> http://dl.dropbox.com/u/972460/test.html\n\nPlease help me.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_21": {
    "description": "Selector parsing gets confused by commata in regexes\nThe selector `div, li:matches([0-9,]+)` causes a java.util.regex.PatternSyntaxException because  [QueryParser (line 63)](https://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/select/QueryParser.java#L63) thinks that the comma inside the regex is a combinator and thus extracts `, li:matches([0-9` as the second alternative.\n\nInstead of scanning ahead with `chompTo(\",\"), the parser needs to parse its way through the alternative until it reaches a comma or the end of a string. That way, commata in regular expressions will be correctly interpreted as part of the regex.\n\nNote that there may be many more variations of this bug in the parser. Wherever a construct allows embedding an arbitrary string one should expect this problem. `[attr=a,b]` for example is likely to cause the same issue. In a way, any invocation of chompTo() needs to examined.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_22": {
    "description": "siblingElements in Element throws Null Pointer Exception\nHi,\n\nI have noticed that the sibling methods (nextSibling, previousSibling, siblingElements) rely on an element (underlying node) having a parent. If the node does not have a parent it throws null pointer exception.\n\nWould it be possible to modify the code so that it checks for parent nullness around Node.java:468? \n\nIn the event of nullness return null as in the javadoc?\n\nConfirmed in 1.6.2\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_23": {
    "description": "Entity whose name is made up of letters and digits is not retained\nAt about line 136 Tokenizer.java, reader.consumeLetterSequence() is called. This is fine until it an entity such as &amp;sup1; is encountered - just the letter part of the entity name will be read causing the Entities.isNamedEntity(nameRef) call at about line 140 to fail.\n\nI have fixed this quickly locally by replacing reader.consumerLetterSequence() with a call to a new consumeLetterDigitSequence() in the CharacterReader.java - there may be a better way of doing this:\n\n```\nString consumeLetterDigitSequence() {\n    String letters = consumeLetterSequence();\n    String digits = consumeDigitSequence();\n    return letters + digits;\n}\n```\n\nThe following is a sample  unit test:\n\n```\n@Test public void letterDigitEntities() {\n    String html = \"<p>&sup1;&sup2;&sup3;&frac14;&frac12;&frac34;</p>\";\n    Whitelist whitelist = Whitelist.none();\n    whitelist\n        .addTags(\"p\");\n    String html = Jsoup.clean(html, whitelist);\n    assertEquals(\"<p>&sup1;&sup2;&sup3;&frac14;&frac12;&frac34;</p>\", html);\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_24": {
    "description": "1.6.0 dropping a ' on a particular javascript string\nLoses a single quote when the javascript contains a partial tag, exampled pared from ad section of http://scienceblogs.com/pharyngula.  Note in the result that '&lt;/scr is missing closing ' :\n\nInput:\n\n<pre>\n&lt;HTML>\n&lt;body>\n &lt;div>\n  &lt;script language=\"JavaScript1.1\"> \n    document.write('&lt;/scr' + 'ipt>');\n  &lt;/script>\n &lt;/div>\n&lt;/body>\n&lt;/HTML>\n</pre>\n\n\nResult:\n\n<pre>\n&lt;html>\n &lt;body> \n  &lt;div> \n   &lt;script language=\"JavaScript1.1\"> \n    document.write('&lt;/scr + 'ipt>');\n  \n   &lt;/script> \n  &lt;/div>  \n &lt;/body>\n&lt;/html>\n</pre>\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_25": {
    "description": "JSoup is not preserving whitespace for <textArea> tags\nThis tag may have been mistakenly left out of the array of preserveWhitespace tags in the Tag class:\n\nprivate static final String[] preserveWhitespaceTags = {\"pre\", \"plaintext\", \"title\"};\n\nThere is a comment next to the preserveWhitespace  boolean that indicates this should have been added here.\n private boolean preserveWhitespace = false; // for pre, textarea, script etc\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_26": {
    "description": "NullpointerException when applying Cleaner to a frameset\nTo reproduce:\n1. Create/find a html document of a frameset.\n2. Parse the html.\n3. Create a Cleaner instance and call the clean method with the document from step 2.\n4. NullPointerException\n\nCause:\nIn Cleaner.clean(Document) (https://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/safety/Cleaner.java#L43) the copySafeNodes is called with the document.body(). However, this is null when handling a frameset document.\n\nExpected:\nAn empty document or perhaps null returned. But not a nullpointerException.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_27": {
    "description": "Invalid HTTP-Response header leads to exception\nIn particular case a HTTP-Webpage responses with a invalid HTTP-Charset field (delivered UFT8 instead of UTF8).\nThis leads to an UnsupportedCharsetException in org.jsoup.helper.DataUtil at around Line 93(?) where :\n\n``` Java\n  Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n  docData = Charset.forName(charsetName).decode(byteData).toString();\n```\n\nI fixed it by wrapping a try catch statement around these two lines such that:\n\n``` Java\ntry{\n  Validate.notEmpty(charsetName, \"Must set charset arg to character set of file to parse. Set to null to attempt to detect from HTML\");\n  docData = Charset.forName(charsetName).decode(byteData).toString();\n} catch(UnsupportedCharsetException e){\n  return parseByteData(byteData,(String)null,baseUri,parser);\n}\n```\n\nIt now falls back to the none charset argument assigned clause, and tries to detect the character set via HTML.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_28": {
    "description": "Jsoup.parse unescapes query params in plain text URL's\nI'm trying to clean the HTML snippet below, but unfortunately the URL parameter names have been mistaken for HTML entities and unescaped to HTML.\n\n``` html\n    <a href=\"http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\">\n        http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n    </a>\n```\n\nCleaned HTML:    http://www.foo.com?a=1#_rooms=1\u03c7ldren=0\u222b=VA&amp;b=2\nExpected HTML: http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n\nUnit tests...\n\n``` java\n    private static final String URL = \"http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\";\n\n    /**\n     * Passes\n     */\n    @Test\n    public void testStringEscapeUtilsUnescapeHtml() throws Exception {\n        // org.apache.commons.lang.StringEscapeUtils;\n        assertEquals(URL, StringEscapeUtils.unescapeHtml(URL));\n    }\n\n    /**\n     * Fails: unescapes &num, &chi, and &int to #, \u03c7, and \u222b respectively\n     * Expected :http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n     * Actual   :http://www.foo.com?a=1#_rooms=1\u03c7ldren=0\u222b=VA&amp;b=2\n     */\n    @Test\n    public void testJsoupClean() throws Exception {\n        String html = \"<a href=\\\"\" + URL + \"\\\">\" + URL + \"</a>\";\n        assertEquals(URL, Jsoup.clean(html, Whitelist.none()));\n    }\n\n    /**\n     * Fails: unescapes &num, &chi, and &int to #, \u03c7, and \u222b respectively\n     * Expected :http://www.foo.com?a=1&num_rooms=1&children=0&int=VA&b=2\n     * Actual   :http://www.foo.com?a=1#_rooms=1&children=0\u222b=VA&b=2\n     */\n    @Test\n    public void testJsoupTextNodeCreateFromEncoded() throws Exception {\n        assertEquals(URL, TextNode.createFromEncoded(URL, null).text());\n    }\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_29": {
    "description": "'\\n' and redundant space char is not needed from title\nWe assume that we just need 1 line title string from below uri.\nhttp://docs.oracle.com/javase/tutorial/uiswing/lookandfeel/nimbus.html\n\nwe can see title like as below by viewing page source code in that page (of course, It is real situation.)\n\n<pre>\n<title>Nimbus Look and Feel (The Java&trade; Tutorials &gt;        \n            Creating a GUI With JFC/Swing &gt; Modifying the Look and Feel)\n</title>\n</pre>\n\n\nmaybe some another page has multiline title, but browser will shows ordinarily.\nin the other words, Browser shows one line title without CR/LF and redundant space character\nwhether string has newline character or many redundant space or tab, or not.\n\nBut,\nWhen we execute Jsoup.connect(uri).get().title(); after we assign \n\"http://docs.oracle.com/javase/tutorial/uiswing/lookandfeel/nimbus.html\" into uri variable as String,\nit gives two lines like below,\n\n\"Nimbus Look and Feel (The Java\u2122 Tutorials > &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"\n\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Creating a GUI With JFC/Swing > Modifying the Look and Feel)\"\n\n\"Nimbus Look and Feel (The Java\u2122 Tutorials > Creating a GUI With JFC/Swing > Modifying the Look and Feel)\"\nis better, I think.\n\nHumm ... do you have another idea?\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_30": {
    "description": "Jsoup.clean sometimes will throw execution exception:java.lang.StackOverflowError\n [ ERROR ]  throw execution exception:java.lang.StackOverflowError\njava.util.concurrent.ExecutionException: java.lang.StackOverflowError\nCaused by: java.lang.StackOverflowError\n    at org.jsoup.safety.Whitelist.isSafeTag(Whitelist.java:323)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:115)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n    at org.jsoup.safety.Cleaner.copySafeNodes(Cleaner.java:127)\n\nclean the url:http://blog.sina.com.cn/s/blog_501a5b1f0102dx6z.html\n\nIt's have to much **wbr** tags,when i search the page source ,found 24205.\n\ni look at  org.jsoup.safety.Cleaner source code and add code like this \n\n``` java\nprivate int num = 1;\n    /**\n     * Iterates the input and copies trusted nodes (tags, attributes, text) into\n     * the destination.\n     * \n     * @param source\n     *            source of HTML\n     * @param dest\n     *            destination element to copy into\n     * @return number of discarded elements (that were considered unsafe)\n     */\n    private int copySafeNodes(Element source, Element dest) {\n        List<Node> sourceChildren = source.childNodes();\n        int numDiscarded = 0;\n\n        for (Node sourceChild : sourceChildren) {\n            num++;\n            logger.info(num);\n            if (num > 2000) {\n                //break this tag.\n                break;\n            }\n            if (sourceChild instanceof Element) {\n                Element sourceEl = (Element) sourceChild;\n\n                if (whitelist.isSafeTag(sourceEl.tagName())) { // safe, clone\n                                                                // and copy safe\n                                                                // attrs\n                    ElementMeta meta = createSafeElement(sourceEl);\n                    Element destChild = meta.el;\n                    dest.appendChild(destChild);\n                    numDiscarded += meta.numAttribsDiscarded;\n                    numDiscarded += copySafeNodes(sourceEl, destChild); // recurs\n                } else { // not a safe tag, but it may have children (els or\n                            // text) that are, so recurse\n                    numDiscarded++;\n                    numDiscarded += copySafeNodes(sourceEl, dest);\n                }\n            } else if (sourceChild instanceof TextNode) {\n                TextNode sourceText = (TextNode) sourceChild;\n                TextNode destText = new TextNode(sourceText.getWholeText(),\n                        sourceChild.baseUri());\n                dest.appendChild(destText);\n            } // else, we don't care about comments, xml proc instructions, etc\n        }\n        return numDiscarded;\n    }\n```\n\nbut the clean result will be wrong and The layout will be chaos.\n\nHow can I solve this problem?\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_31": {
    "description": "Xml declaration is parsed as a comment\nUsing jsoup 1.6.3, the following snippet\n\n``` java\nSystem.out.println(\n  Jsoup.parse(\n    \"<?xml encoding='UTF-8' version='1.0'?>\" +\n    \"<html>\" +\n    \"<head><title></title></head>\" +\n    \"<body>Document content</body>\" +\n    \"</html>\").outerHtml());\n```\n\nprints :\n\n``` html\n<!--?xml encoding='UTF-8' version='1.0'?-->\n<html>\n <head>\n  <title></title>\n </head>\n <body>\n  Document content\n </body>\n</html>\n```\n\nwhile I expect :\n\n``` html\n<?xml encoding='UTF-8' version='1.0'?>\n<html>\n <head>\n  <title></title>\n </head>\n <body>\n  Document content\n </body>\n</html>\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_32": {
    "description": "Element.clone() wrongly shared a same classNames Set instance\nIn the clone() method of Node, the Object.clone() is called, if the original element's classNames Set had been initialized before clone, the original classNames Set will be set to the new cloned Element instance due to the JDK's clone mechanism. Thus, the old element and the newly cloned Element will share a same classNames Set instance.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_33": {
    "description": "Self-closing script tag causes remainder of document to be html-escaped.\nWhen a self-closing script block is encountered it appears that the state transitions do not account for the closing tag, so the rest of the document is considered to be in the body of the script tag, and so is escaped.\n\nThe unit test HtmlParserTest.handlesKnownEmptyBlocks() will fail if a self-closing script tag is included in the String h.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_34": {
    "description": "Parser error on commented CDATA\nJsoup gives the following error when trying to parse this HTML: https://gist.github.com/felipehummel/6122799\n\n```\njava.lang.ArrayIndexOutOfBoundsException: 8666\n    at org.jsoup.parser.CharacterReader.nextIndexOf(CharacterReader.java:92)\n    at org.jsoup.parser.CharacterReader.consumeTo(CharacterReader.java:112)\n    at org.jsoup.parser.TokeniserState$67.read(TokeniserState.java:1789)\n    at org.jsoup.parser.Tokeniser.read(Tokeniser.java:42)\n    at org.jsoup.parser.TreeBuilder.runParser(TreeBuilder.java:47)\n    at org.jsoup.parser.TreeBuilder.parse(TreeBuilder.java:41)\n    at org.jsoup.parser.HtmlTreeBuilder.parse(HtmlTreeBuilder.java:37)\n    at org.jsoup.parser.Parser.parse(Parser.java:90)\n    at org.jsoup.Jsoup.parse(Jsoup.java:58)\n...\n```\n\nThe HTML is from a entry in a RSS feed. If I remove the line:\n\n```\n// ]]\n```\n\nor just the \n      ]]\n\nThen it parses the HTML nicely.\n\nDoes this syntax error should really throw an exception or it should be silently ignored?\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_35": {
    "description": "JSoup parsing unclosed tags\nUsing JSoup inclusive the last release 1.7.2 there is a bug parsing HTML with unclosed tags.\n\nExample:\n\n``` java\nString tmp = \"<a href='www.google.com'>Link<p>Error link</a>\";\nJsoup.parse(tmp);\n```\n\nThe Document that generate is:\n\n``` html\n<html>\n <head></head>\n <body>\n  <a href=\"www.google.com\">Link</a>\n  <p><a>Error link</a></p>\n </body>\n</html>\n```\n\nThe browsers would generate something as:\n\n``` html\n<html>\n <head></head>\n <body>\n  <a href=\"www.google.com\">Link</a>\n  <p><a href=\"www.google.com\">Error link</a></p>\n </body>\n</html>\n```\n\nJsoup should works as browsers or as source code.\n\nAlso there is a question on stackoverflow:\nhttp://stackoverflow.com/questions/15813821/jsoup-parsing-unclosed-tags\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_36": {
    "description": "More robust charset detection code\nWith the following HTML:\n\n```\n<html lang=\"en-US\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"Content-Type\" content=\"text/html; \" />\n</head>\n```\n\njsoup fails to parse the page with a IllegalCharsetNameException. I see that http-equiv=\"Content-Type\" has an invalid content-type but it would be possible to still parse it correctly by using the html5  <meta charset=\"UTF-8\">, i.e. jsoup could be more robust on this one.\n\nother domains which are not working but could be:\n9kuhkep.net\nwww.a-bright.org\n\nI use this code to parse the sites:\n\n```\nJsoup.connect(url).execute()\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_37": {
    "description": "Whitespaces are discared in Element.html() method\nHi,\nI'm trying to make an exact copy of a document (changing just a couple of attributes and appending a few nodes) and the trim() inside the Element.html() is killing me.\nI'm using Parsers.xml() and no prettyPrint.\n\nI think this trim should be enabled for prettyPrint only.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_38": {
    "description": "Jsoup converts \"svg image\" to \"svg img\"\nHi,\nwhen I parse a html page with a svg element, which contains an image element, the \"image\" element is replaced by \"img\". But this is not correct. The \"image\" must be \"image\".\n\nExample:\nInput:\n\n``` html\n<svg width=\"560\" height=\"150\">\n<image xlink:href=\"myimage.jpg\"\n   y=\"5\" x=\"100\"  \n   height=\"140\" width=\"230\" />\n</svg>\n```\n\nOutput:\n\n``` html\n<svg width=\"560\" height=\"150\">\n<img xlink:href=\"myimage.jpg\"\n   y=\"5\" x=\"100\"  \n   height=\"140\" width=\"230\" />\n</svg>\n```\n\nThe problem seems to be in line 457 of HtmlTreeBuilderState.java.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_39": {
    "description": "JSoup incorrectly moves content from the <head> section into <body> for sample URL\nIf you load the following URL:\n\n```\nhttp://jornutzon.sydneyoperahouse.com/home.htm\n```\n\ninto:\n\n```\nhttp://try.jsoup.org/\n```\n\nthen it will move the content from the \"head\" section into the \"body\" section. The URL\nbeing parsed validates using the W3C validator:\n\nhttp://validator.w3.org/check?uri=http%3A%2F%2Fjornutzon.sydneyoperahouse.com%2Fhome.htm&charset=%28detect+automatically%29&doctype=Inline&ss=1&group=0&user-agent=W3C_Validator%2F1.3+http%3A%2F%2Fvalidator.w3.org%2Fservices\n\nWe are using JSoup 1.7.2\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_40": {
    "description": "\"<!DOCTYPE>\" IllegalArgumentException: String must not be empty\nWhile this may be a contrived example, Jsoup.parse(\"<!DOCTYPE>\") throws an exception, this was unexpected. Possibly related, a proper document with <!DOCTYPE> (no name) is generating corrupt html e.g. \"<!DOCTYPE &lt;html&gt; ...\" (missing right angle bracket on DOCTYPE.)\n\nSpec says \"When a DOCTYPE token is created, its name, public identifier, and system identifier must be marked as missing (which is a distinct state from the empty string), [...]\"\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_41": {
    "description": "Element.hashCode() ignores the content text of the element.\nFound [this question](http://stackoverflow.com/questions/28970732/jsoup-node-hash-code-collision-when-traversing-dom-tree/28971463) on SO, OP was using `Element.hashCode()` and it wasn't woring right.\r\n\r\nThe problem is that when jsoup generates the hashCode of an Element, the content text of the element will be ignored, and the hashCode is generated only based on the attributes, and the hashCode of the parent Element.\r\n\r\n---\r\n\r\nUsing the following HTML:\r\n\r\n```\r\n<html>\r\n    <head>\r\n    </head>\r\n    <body>\r\n        <div style=\"blah\">TODO: write content</div>\r\n        <div style=\"blah\">Nothing here</div>\r\n        <p style=\"test\">Empty</p>\r\n        <p style=\"nothing\">Empty</p>\r\n    </body>\r\n</html>\r\n```\r\n\r\nAnd the following code:\r\n\r\n```\r\nString html = //HTML posted above\r\n\r\nDocument doc = Jsoup.parse(html);\r\n\r\nElements elements = doc.select(\"[style]\");\r\nfor (Element e : elements) {\r\n   System.out.println(e.hashCode());\r\n}\r\n```\r\n\r\nIt gives:\r\n\r\n```\r\n-148184373\r\n-148184373\r\n-1050420242\r\n2013043377\r\n```\r\n\r\nI believe the hashCode should be different for the first two Elements, since the content is text is different. Or is this intended behaviour?\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_42": {
    "description": "FormElement's formData ignores input checkbox checked without value.\nWhen there is input:         \n\n```\n<input type=\"checkbox\" name=\"testCheckBox\" checked=\"checked\" />\n```\n\nThe \"formData()\" of FormElement's ignores that default value which should be \"on\" as submitted by browsers.\n\nHTML fragment:\n\n```\n<html>\n    <head>\n        <title>Test</title>\n    </head>\n\n    <body>\n\n    <form name=\"myForm\" method=\"POST\">\n        <input type=\"checkbox\" name=\"testCheckBox\" checked=\"checked\" /> Something<br/>\n\n        <input type=\"submit\" value=\"Submit\" />\n    </form>\n\n    </body>\n</html>\n```\n\nWhen submiting from Firefox it sends to sever: testCheckBox=on\n\nJava code:\n\n```\n    public static void main(String[] args)\n    {\n        final String html = \"<html>\\n\"\n                            + \"    <head>\\n\"\n                            + \"        <title>Test</title>\\n\"\n                            + \"    </head>\\n\"\n                            + \"    \\n\"\n                            + \"    <body>\\n\"\n                            + \"\\n\"\n                            + \"    <form name=\\\"myForm\\\" method=\\\"POST\\\">\\n\"\n                            + \"        <input type=\\\"checkbox\\\" name=\\\"testCheckBox\\\" checked=\\\"checked\\\" /> Something<br/>\\n\"\n                            + \"\\n\"\n                            + \"        <input type=\\\"submit\\\" value=\\\"Submit\\\" />\\n\"\n                            + \"    </form>\\n\"\n                            + \"\\n\"\n                            + \"    </body>\\n\"\n                            + \"</html>\";\n\n        final Document document = Jsoup.parse(html);\n\n        final FormElement formElement = (FormElement) document.select(\"form[name=myForm]\").first();\n\n        for (Connection.KeyVal keyVal : formElement.formData())\n        {\n            System.out.println(keyVal.key() + \"=\" + keyVal.value());\n        }\n\n    }\n```\n\nOutput: testCheckBox=\n\nExpected output: testCheckBox=on\n\nSeems like Jsoup doesn't add default value which is sent by browsers. The \"submit()\" method from FormElement also uses \"formData()\" method to get form's submission parameters. By sending the empty String for checkbox the server acts as it's not checked when in fact it was checked.\n\nAlso while testing noticed that it doesn't check the checkbox'es at all. If there is checkbox with value, but not checked, it will get the value no matter what, for example:\n\n```\n        <input type=\"checkbox\" name=\"textCheckBox2\" value=\"testVal\" /> \n```\n\nThis affects radio buttons as well. Not selected radion buttons should not be sent to server, but formData() add their values anyway.\n\nI'm not sure if that's done on purpose, but submit() method will get wrong parameters for submission since not checked input value is not sent to server at all.\n\nMoreover type button value and \"disabled\" inputs are not sent to server as well (by browsers). \n\nLooked at the source, one extra else if before the final else in \"formData()\" method could solve this:\n\n```\nelse if (\"input\".equals(el.tagName())) {\n                // Not disabled? Ignore disabled inputs.\n                if(!el.hasAttr(\"disabled\")) {\n\n                    // Deal with checkbox and radio (not checked should not be added to avoid sending to server)\n                    if(\"checkbox\".equals(el.attr(\"type\")) || \"radio\".equals(el.attr(\"type\"))) {\n\n                        // Checked, but no value? Default should be \"on\".\n                        if(el.hasAttr(\"checked\") && !el.hasAttr(\"value\")) {\n                            data.add(HttpConnection.KeyVal.create(name, \"on\"));\n                        } \n                        // Checked? Add it's value\n                        else if(el.hasAttr(\"checked\")) {\n                            data.add(HttpConnection.KeyVal.create(name, el.val()));\n                        }\n                    } \n                    // Buttons should be ignored.\n                    else if(!\"button\".equals(el.attr(\"type\"))){\n                        data.add(HttpConnection.KeyVal.create(name, el.val()));\n                    }\n                }\n            }\n```\n\nOne more thing. If form has multiple type submit inputs, only the clicked input's value should be sent to server, but I have no idea how this could be implemented. Sending all submit input's values can change the server's logic and be bad (result not as expected).\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_43": {
    "description": "Unexpected behavior in elementSiblingIndex\nThe documentation for elementSiblingIndex states \"Get the list index of this element in its element sibling list. I.e. if this is the first element sibling, returns 0\".\n\nThis would imply that if\n\n```\nn=myElem.elementSiblingIndex();\n```\n\nthen\n\n```\nmyElem.parent().children().get(n)==myElem.  \n```\n\nHowever, this is not how elementSiblingIndex behaves. What is guaranteed is that\n\n```\nmyElem.parent().children().get(n).equals(myElem).  \n```\n\nFor example, if both row 2 and row 5 of a table are\n\n```\n<tr><td>Cell1</td><td>Cell2</td></tr>\n```\n\nthen the Element object associated with both rows will have the same `elementSiblingIndex()`.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_44": {
    "description": "Unexpected elements inside table are moved to wrong location\nThis commit https://github.com/jhy/jsoup/commit/e99193605b688e923d20054c13db897cff751607 introduced a bug where handling of unexpected elements inside a table element changed, resulting in the unexpected elements being pushed further up the document than before.\n\nI have constructed a minimal repro. Before the commit in question, the unexpected p tag would continue to be positioned after the comment (with some elements being closed early etc. to support this). After the commit, the p tag and its contents are moved up more than one table level, and now appear after the comment tag.\n\nObviously this input HTML is very broken and bad, but it seems that the change in behaviour was unintended. \n\ncopying @jaredstehler  \n\n```\n@Test\npublic void testInvalidTableContents() throws IOException {\n    File in = getFile(\"/htmltests/table-invalid-elements.html\");\n    Document doc = Jsoup.parse(in, \"UTF-8\");\n    doc.outputSettings().prettyPrint(true);\n    String rendered = doc.toString();\n    int endOfEmail = rendered.indexOf(\"Comment\");\n    int guarantee = rendered.indexOf(\"Why am I here?\");\n    assertTrue(\"Comment not found\", endOfEmail > -1);\n    assertTrue(\"Search text not found\", guarantee > -1);\n    assertTrue(\"Search text did not come after comment\", guarantee > endOfEmail);\n}\n```\n\nUses the following fixture:\n\n```\n<html>\n    <body>\n        <table>\n            <tr>\n                <td>\n                    <table>\n                        <tr>\n                            <!--Comment-->\n                            <table>\n                                <p>Why am I here?</p>\n                        </tr>\n                    </table>\n                </td>\n            </tr>\n        </table>\n    </body>\n</html>\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_45": {
    "description": "",
    "desc_source": "commit_msg"
  },
  "Jsoup_46": {
    "description": "EscapeMode.xhtml no longer falls back to numeric escapes - Can cause '?' replacement in output\nI've been using EscapeMode.xhtml with JSoup to avoid encoding things which don't (from my perspective) need to be encoded, like egrave in a UTF-8 document for example.\n\nWhile upgrading from JSoup 1.7.2 to 1.8.1 however, I've noticed a problem with a shift-jis related test I have. Here's a simplified/reduced version.\n\n```\npackage test;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.InputStream;\nimport java.nio.charset.Charset;\n\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.Document;\nimport org.jsoup.nodes.Entities.EscapeMode;\nimport org.junit.Assert;\nimport org.junit.Test;\n\npublic class ShiftJisTest {\n\n    @Test\n    public void testShiftJisRoundtrip() throws Exception {\n        String input = \n            \"<html>\"\n          +   \"<head>\"\n          +     \"<meta http-equiv=\\\"content-type\\\" content=\\\"text/html; charset=Shift_JIS\\\" />\"\n          +   \"</head>\"\n          +   \"<body>\"\n          +     \"before&nbsp;after\"\n          +   \"</body>\"\n          + \"</html>\";\n        InputStream is = new ByteArrayInputStream(input.getBytes(Charset.forName(\"ASCII\")));\n\n        Document doc = Jsoup.parse(is, null, \"http://example.com\");\n        doc.outputSettings().escapeMode(EscapeMode.xhtml);\n\n        String output = new String(doc.html().getBytes(doc.outputSettings().charset()), doc.outputSettings().charset());\n\n        System.out.println(output);\n\n        Assert.assertFalse(\"Should not have contained a '?'.\", output.contains(\"?\"));\n        Assert.assertTrue(\"Should have contained a '&#xa0;' or a '&nbsp;'.\", \n            output.contains(\"&#xa0;\") || output.contains(\"&nbsp;\"));\n    }\n\n}\n```\n\nUnder JSoup 1.7.2, the body of the output in this test is \"before&#xa0;after\" (which looks as expected when rendered in Firefox), where as under 1.8.1 it is \"before?after\".\n\nI assume the issue here is that I've asked JSoup to escape only XHTML characters (i.e. not nbsp), and it's producing a charset where (I assume) there's no character to represent 'non-breaking space'.\n\nThe upshot of this is that, as a result of upgrading JSoup, I end up with '?' replaced in for what used to be shown as a non breaking space.\n\nIt seems like the old behaviour was to fall back to providing an escaped numeric character (odd if there's no valid character for that in Shift_JIS, but it still rendered correctly). From my perspective, the old behaviour was better - Is there any way it can be reinstated (or an escape mode provided for it)?\n\nObviously using EscapeMode.base instead of EscapeMode.xhtml is a possible workaround, however I would really prefer not to have characters unnecessarily escaped if possible.\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_47": {
    "description": "Jsoup not retaining &lt in data attributes\nJsoup not retaining &lt in data attributes value if there is &lt;\n\nIn the example below &amp;lt; is converted to < in the output after parsing. \nPlease let me know how to retain it. \nExample:\nhttp://notes.io/Gww\n@uggedal \n@krystiangor \n@tc \n@bbeck \n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_48": {
    "description": "A small bug for duplicate tuple in response header\nfor response headers have duplicate tuple\uff0c\nin this case\nX-Powered-By:PHP/5.2.8\nX-Powered-By:ASP.NET\n\nJsoup can only get the second one\nif I run header\uff08\u201cX-powered-by\u201d\uff09 \nI got Asp.NET\n\nURL\uff1ahttp://01pt.com/\n\nCache-Control:no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nContent-Encoding:gzip\nContent-Length:16224\nContent-Type:text/html;charset=gb2312\nDate:Thu, 27 Aug 2015 09:22:40 GMT\nExpires:Thu, 19 Nov 1981 08:52:00 GMT\nPragma:no-cache\nServer:Microsoft-IIS/7.5\nVary:Accept-Encoding\nX-Powered-By:PHP/5.2.8\nX-Powered-By:ASP.NET\n\nThe bug is because \nif (!values.isEmpty()) header(name, values.get(0));\n\nI change it to\n                 if (!values.isEmpty()) {\n                        String val = \"\";\n                        for(String str: values) {\n                          val = val.concat(str).concat(\" \");\n\n```\n                    }\n                    header(name, val);\n              }\n```\n\nthen I am able to get \u201cPHP/5.2.8 ASP.NET\u201d when I run header\uff08\u201cX-powered-by\u201d\uff09\n\n void processResponseHeaders(Map<String, List<String>> resHeaders) {\n            for (Map.Entry<String, List<String>> entry : resHeaders.entrySet()) {\n                String name = entry.getKey();\n                if (name == null)\n                    continue; // http/1.1 line\n\n```\n            List<String> values = entry.getValue();\n            if (name.equalsIgnoreCase(\"Set-Cookie\")) {\n                for (String value : values) {\n                    if (value == null)\n                        continue;\n                    TokenQueue cd = new TokenQueue(value);\n                    String cookieName = cd.chompTo(\"=\").trim();\n                    String cookieVal = cd.consumeTo(\";\").trim();\n                    // ignores path, date, domain, validateTLSCertificates et al. req'd?\n                    // name not blank, value not null\n                    if (cookieName.length() > 0)\n                        cookie(cookieName, cookieVal);\n                }\n            } else { // only take the first instance of each header\n                if (!values.isEmpty())\n                    header(name, values.get(0));\n            }\n        }\n    }\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_49": {
    "description": "Bug in Element.insertChildren()\nWhen using org.jsoup.nodes.Element.insertChildren(int, Collection<? extends Node>) to move (more than one!) child-elements from one parent-element to the same parent, but different index then it produces wrong results.\n\nThe problem is that the first Element's 'move' leaves the siblingIndex unchanged and then the second 'move' removes a wrong element and produces some crap. Maybe calling reindexChildren() inside the loop in addChildren() fixes this.\nVersion 1.8.3.\nWorkaround: call remove() on the elements before passing them to insertChildren()\n\nEasy Test Case:\n\n```\n    @Test\n    public void mustCorrectlyMoveChildrenInsideOneParentElement() {\n\n        Document doc = new Document( \"\" );\n        Element body = doc.appendElement( \"body\" );\n        body.appendElement( \"div1\" );\n        body.appendElement( \"div2\" );\n        Element div3 = body.appendElement( \"div3\" );\n        Element div4 = body.appendElement( \"div4\" );\n\n        ArrayList<Element> toMove = new ArrayList<Element>() {\n            {\n                add( div3 );\n                add( div4 );\n            }\n        };\n\n        body.insertChildren( 0, toMove );\n\n        String result = doc.toString().replaceAll( \"\\\\s+\", \"\" );\n        assertEquals( \"<body><div3></div3><div4></div4><div1></div1><div2></div2></body>\", result );\n\n    }\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_50": {
    "description": "UTF16 streams with BOM are processed as UTF-8\nThe handling of the character encoding in org.jsoup.helper.DataUtil.parseByteData(...) is bugged when the input is an UTF16 stream with unicode BOM. This method does a check for presence of a BOM and, if it finds one, incorrectly assumes that this was a UTF-8 BOM. To fix this, the code would have to check the raw BOM bytes as the distinction between the various BOMs is lost after conversion to characters. See also: http://unicode.org/faq/utf_bom.html#bom4\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_51": {
    "description": "Problem in reading XML file containing Japanese tag names\nHello,\nI have XML file containing Japanese tag names and values.\nJSOUP is not parsing this Japanese tags.\nI am using JSOUP library (version: 1.8.3).\nPlease help me to solve this issue.\n\n---\n\ne.g. ( XML File to reproduce problem )\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<\u9032\u6357\u63a8\u79fb\u30b0\u30e9\u30d5>\n    <\u958b\u59cb\u4e88\u5b9a\u51e1\u4f8b\u540d \u8868\u793a\u72b6\u614b=\"0\" \u7dda\u8272=\"00CED1\">&amp;#9312;&amp;#35373;&amp;#35336; &amp;#38283;&amp;#22987;&amp;#20104;&amp;#23450;</\u958b\u59cb\u4e88\u5b9a\u51e1\u4f8b\u540d>\n## </\u9032\u6357\u63a8\u79fb\u30b0\u30e9\u30d5>\n\n//// ***\\*  Source Code  ******\nDocument doc = Jsoup.parse(XMLString.toString(),\"UTF-8\",Parser.xmlParser());\nElements objElementCollection = doc.getAllElements();\n\nint iElementsSize=objElementCollection.size();\n\nfor(Element objCurrent : objElementCollection)\n{\n        String szTag=objCurrent.tagName();\n\n```\n    for (TextNode tnTextNode : objCurrent.textNodes()) \n    {\n        String szVal=tnTextNode.text();\n    }\n```\n\n}\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_52": {
    "description": "Should detect ?xml encoding charset\nHi,\n\nFor example this is target URL: http://www.elacontecer.com.uy/rss/hoy.xml, its charset is `ISO-8859-1`.\n\nI use Jsoup like this:\n\n``` java\nfinal Document doc = Jsoup.connect(\"http://...\").parser(Parser.xmlParser()).get();\nSystem.out.println(\"charset=\" + doc.charset());\n```\n\nThe result is: `java.nio.charset.CharsetICU[UTF-8]`\n\nWould you please check to see if it's a bug?\n\nThanks,\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_53": {
    "description": "Parse failed with org.jsoup.select.Selector$SelectorParseException when selector has unbalanced '(' or '[' or ')' or ']' \nSelector I am having as following div.card-content2:has(a.subtitle[title= MySubTitle:)]) OR a.title[title=MyTitle :] ]\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_54": {
    "description": "INVALID_CHARACTER_ERR when converting Document to W3C\nA recent ClearQuest version has an HTML generation bug, which is ignored by both Chrome and Internet Explorer. Jsoup.parse is also successful:\n\n`org.jsoup.nodes.Document doc = Jsoup.parse(\"<html><head></head><body style=\\\"color: red\\\" \\\"></body></html>\");`\n\n(Please note the single quotation mark at the end of the body start tag.)\n\nBut trying to convert this to a W3C document fails:\n\n`new W3CDom().fromJsoup(doc);`\n\n```\nException in thread \"main\" org.w3c.dom.DOMException: INVALID_CHARACTER_ERR: An invalid or illegal XML character is specified. \n    at org.apache.xerces.dom.CoreDocumentImpl.createAttribute(Unknown Source)\n    at org.apache.xerces.dom.ElementImpl.setAttribute(Unknown Source)\n    at org.jsoup.helper.W3CDom$W3CBuilder.copyAttributes(W3CDom.java:124)\n    at org.jsoup.helper.W3CDom$W3CBuilder.head(W3CDom.java:92)\n    at org.jsoup.select.NodeTraversor.traverse(NodeTraversor.java:31)\n    at org.jsoup.helper.W3CDom.convert(W3CDom.java:66)\n    at org.jsoup.helper.W3CDom.fromJsoup(W3CDom.java:46)\n```\n\nPerhaps copyAttributes() should ignore invalid attributes, or catch exactly this error, and ignore it, or W3CDom could have flags to ignore such errors...\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_55": {
    "description": "Parse slash in attibutes\nHello,\nI don't know if it is a bug or not, but when I'm parsing:\n`<img /onerror=\"a()\"/>`\n\nThe result of the parsers is: \n`<img nerror=\"a()\"/>`\nIs it OK? can I change the parser behavior for those types of tags? \n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_56": {
    "description": "Jsoup.parse seems to remove system identifier in DOCTYPE\nSpecifically when I call:\r\n```\r\nDocument doc = Jsoup.parse(xhtml, \"\", Parser.xmlParser());\r\n```\r\non a xhtml document that has the following doctype:\r\n\r\n```\r\n<!DOCTYPE html SYSTEM \"exampledtdfile.dtd\">\r\n```\r\nI end up with the following result in the document (SYSTEM is now missing):\r\n\r\n```\r\n<!DOCTYPE html \"exampledtdfile.dtd\"> \r\n```\r\n\r\nBut this works fine on a document with:\r\n\r\n```\r\n <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"> \r\n```\r\n\r\nSince SYSTEM is a proper way of declaring a DTD, I believe this is an issue with Jsoup.\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_57": {
    "description": "removeIgnoreCase ConcurrentModificationException\nWhen testing out the removeIgnoreCase method, I'm now seeing a ConcurrentModificationException with code like: element.select(\"abc\").first().removeAttr(\"attr1\").removeAttr(\"attr2\");\n\nIt appears to be due to using a foreach loop over the LinkedHashMap to do the removal. Changing to do the removal directly with an iterator fixes this issue.\nLike so:\n\n```\nfor (Iterator<Map.Entry<String, Attribute>> iter = attributes.entrySet().iterator(); iter.hasNext();) {\n            Map.Entry<String, Attribute> entry = iter.next();\n            if (entry.getKey().equalsIgnoreCase(\"key1\")) {\n                iter.remove();\n            }\n        }\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_58": {
    "description": "Jsoup.isValid returns true even when htmlFragment includes tags not on whitelist\nCaused by Jsoup.isValid performing a destructive parse before testing for validity.  The html returned from parseBodyFragment is not what was passed in.\n\nAccording to documentation, html, head tags etc. should be specifically added to whitelist if they should be allowed.\n\nTest cases below.\n\n```\npackage jsoup;\n\nimport junit.framework.Assert;\nimport org.jsoup.Jsoup;\nimport org.jsoup.nodes.Document;\nimport org.jsoup.parser.Parser;\nimport org.jsoup.safety.Cleaner;\nimport org.jsoup.safety.Whitelist;\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\nimport org.junit.runners.Parameterized;\n\nimport java.util.Arrays;\nimport java.util.Collection;\n\n@RunWith(Parameterized.class)\npublic class JsoupTest\n{\n    private String htmlFragment;\n\n    public JsoupTest(String htmlFragment)\n    {\n        this.htmlFragment = htmlFragment;\n    }\n\n    @Parameterized.Parameters\n    public static Collection<String[]> dirtyHtml()\n    {\n        String[][] htmlFragments = new String[][] { {\"<html></html>\"},\n                                                    {\"<head></head>\"},\n                                                    {\"<body></body>\"}\n        };\n\n        return Arrays.asList(htmlFragments);\n    }\n\n    @Test\n    public void emptyWhitelistReturnsFalseForAllTags()\n    {\n        Assert.assertEquals(false, Jsoup.isValid(htmlFragment, new Whitelist()));\n    }\n\n    @Test\n    public void whitelistNoneReturnsFalseForAllTags()\n    {\n        Assert.assertEquals(false, Jsoup.isValid(htmlFragment, Whitelist.none()));\n    }\n\n    @Test\n    public void typicalWhitelistReturnsFalseForNonIncludedTags()\n    {\n        Whitelist whitelist = new Whitelist();\n        whitelist.addTags(\"p\");\n\n        Assert.assertEquals(false, Jsoup.isValid(htmlFragment, whitelist));\n    }\n\n    @Test\n    public void codeFromSource()\n    {\n        Document dirty = Parser.parseBodyFragment(htmlFragment, \"\");\n        Cleaner cleaner = new Cleaner(Whitelist.none());\n\n        Assert.assertEquals(false, cleaner.isValid(dirty));\n    }\n\n}\n```\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_59": {
    "description": "Jsoup.clean control characters throws: IllegalArgumentException: String must not be empty\nI found that when running Jsoup.clean() on a string that contains the format below, Jsoup throws: `IllegalArgumentException: String must not be empty`.\r\nThe problematic string format:\r\n`'<a/*>'`, (where * is a control char).\r\ni.e. `<` char followed by a letter (a-z), then any chars, `/` and any control char (ASCII 0-31) except 0, 9-10, 12-13, any chars, and a `>` char.\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_60": {
    "description": "1.10.1 failed a test while 1.8.3 passed for a contains query\nToday I tried to upgrade jsoup from 1.8.3 to 1.10.1, however, one of my unit test failed like this:\r\n\r\n\"div.a-row.a-spacing-medium span.a-size-base:contains(I'll Ship & Pay)\"\r\n\"div.a-row.a-spacing-medium span.a-size-base:contains(I'll Send & Pay)\"\r\n\"div.a-row.a-spacing-medium span.a-color-price:contains(Varies)\"\r\n\r\nAbove are 3 css selectors and in a webpage that no such element exists, Jsoup selector find 9 elements, which broke my unit test. It seems like that the **contains** logic broke. I'm not sure whether **'** or **&** processing changed in newer version.\r\n\r\nCan you have a look at this? For your reference I've attached the html page as a zip file.\r\n\r\n[AmazonReturn.zip](https://github.com/jhy/jsoup/files/676839/AmazonReturn.zip)\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_61": {
    "description": "Unexpected case sensitivity for CSS class selector\nHi,\r\ni use JSoup version 1.10.2 and noticed an unexpected case sensitivity for a CSS class selector. I tried to parse the following HTML document with capitalized class attributes:\r\n\r\n```html\r\n<!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN' 'http://www.w3.org/TR/html4/loose.dtd'>\r\n<HTML>\r\n  <HEAD>\r\n    <FORM Method='POST' name='Form' Action='Action'>\r\n      <TABLE Class='Lst'>\r\n        <TR Class='Lst'>\r\n          <TH Class='Lst'>Header 1</TH>\r\n          <TH Class='Lst'>Header 2</TH>\r\n          <TH Class='Lst'>Header 3</TH>\r\n        </TR>\r\n        <TR Class='Lst1'>\r\n          <TD Class='Lst'>Cell 1</TD>\r\n          <TD Class='Lst'>Cell 2</TD>\r\n          <TD Class='Lst'>Cell 3</TD>\r\n        </TR>\r\n      </TABLE>\r\n    </FORM>\r\n  </BODY>\r\n</HTML>\r\n```\r\n\r\nI wanted to select the table using the selector _\"html > body > form table.Lst\"_ because I expected it to choose the table with the class attribute \"Lst\", but that did not work. The selector _\"html > body > form table[class=Lst]\"_ works. Is this a bug?\r\n\r\nHere is the parser code:\r\n\r\n```java\r\ntry {\r\n  final String htmlStr = \"<!DOCTYPE HTML PUBLIC '-//W3C//DTD HTML 4.01 Transitional//EN' 'http://www.w3.org/TR/html4/loose.dtd'>\\n\"\r\n      + \"<HTML>\\n\"\r\n      + \"  <HEAD>\\n\"\r\n      + \"    <FORM Method='POST' name='Form' Action='Action'>\\n\"\r\n      + \"      <TABLE Class='Lst'>\\n\"\r\n      + \"        <TR Class='Lst'>\\n\"\r\n      + \"          <TH Class='Lst'>Header 1</TH>\\n\"\r\n      + \"          <TH Class='Lst'>Header 2</TH>\\n\"\r\n      + \"          <TH Class='Lst'>Header 3</TH>\\n\"\r\n      + \"        </TR>\\n\"\r\n      + \"        <TR Class='Lst1'>\\n\"\r\n      + \"          <TD Class='Lst'>Cell 1</TD>\\n\"\r\n      + \"          <TD Class='Lst'>Cell 2</TD>\\n\"\r\n      + \"          <TD Class='Lst'>Cell 3</TD>\\n\"\r\n      + \"        </TR>\\n\"\r\n      + \"      </TABLE>\\n\"\r\n      + \"    </FORM>\\n\"\r\n      + \"  </BODY>\\n\"\r\n      + \"</HTML>\";\r\n  final Document htmlDoc = Jsoup.parse(htmlStr,\r\n      \"\");\r\n\r\n  final Element tableNotOk = htmlDoc.select(\"html > body > form table.Lst\")\r\n      .first();\r\n  final Element tableOk = htmlDoc.select(\"html > body > form table[class=Lst]\")\r\n      .first();\r\n\r\n  Logger.getLogger(this.getClass().getName())\r\n      .log(Level.INFO,\r\n          \"tableNotOk found: ''{0}'', tableOk found: ''{1}''\",\r\n          new Object[]{(tableNotOk != null), (tableOk != null)});\r\n\r\n} catch (UnsupportedCharsetException | ParseException | Selector.SelectorParseException ex) {\r\n  Logger.getLogger(this.getClass().getName())\r\n      .log(Level.SEVERE,\r\n          null,\r\n          ex);\r\n}\r\n```\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_62": {
    "description": "Wrong parsing of case sensitive HTML \nExecuting : \r\n\r\n            String xml=\"<r><X>A</X><y>B</y></r>\";\r\n\t\tParser parser = Parser.htmlParser();\r\n\t\tparser.settings(ParseSettings.preserveCase);\r\n\t\torg.jsoup.nodes.Document _doc = parser.parseInput(xml, \"/\");\r\n\r\n\r\nResults in : \r\n&lt;html&gt;\r\n &lt;head&gt;&lt;/head&gt;\r\n &lt;body&gt;\r\n  &lt;r&gt;\r\n   &lt;X&gt;\r\n    A\r\n    &lt;y&gt;\r\n     B\r\n    &lt;/y&gt;\r\n   &lt;/X&gt;\r\n  &lt;/r&gt;\r\n &lt;/body&gt;\r\n&lt;/html&gt;\r\n\r\nManual hacking : remove all .toLowerCase() invocations from Token.java (normalName=...)\r\n\r\n\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_63": {
    "description": "Error: \"Self closing flag not acknowledged\" for self closing break\nThis code snippet returns invalid html with the message: \"Self closing flag not acknowledged\"\r\n```java\r\nJsoup.isValid(\"<p>test<br/>test</p>\")\r\n```\r\nWhy breaks could not be self closing?\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_64": {
    "description": "Incorrect handling of self-closing tags noframes, style and title cause remainder of document to be html-escaped\nGiven the input:\r\n\r\n```html\r\n<html>\r\n<head>\r\n\t<style />   <!-- < - - this is the culprit -->\r\n</head>\r\n<body>\r\n\t<p>Whatever</p>\r\n</body>\r\n</html>\r\n```\r\n\r\nJSoup 1.8.2 and also http://try.jsoup.org/~lJwWpjXYUSTBeBZhdEnS3Mt56g4 will produce:\r\n```html\r\n    <html>\r\n     <head> \r\n      <style></style>\r\n     </head>\r\n     <body>\r\n       &lt;/head&gt; &lt;body&gt; &lt;p&gt;Whatever&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;\r\n     </body>\r\n    </html>\r\n```\r\n\r\nWith `<title/>` instead of `<style/>`, the result is different but still wrong (http://try.jsoup.org/~BZ3uoMki-r904fZxUOWJgLJO7r8 ):\r\n```html\r\n<html>\r\n <head> \r\n  <title></title>\r\n </head>\r\n <body>\r\n   &lt;/head&gt;  \r\n  <p>Whatever</p>  \r\n </body>\r\n</html>\r\n```\r\n\r\nThat weirdness was fixed for `<script>` with Issue #305: http://try.jsoup.org/~3Ms6TQCrrdaA_uPgxgURYYvwFAg\r\n```html\r\n<html>\r\n <head> \r\n  <script></script> \r\n </head> \r\n <body> \r\n  <p>Whatever</p>  \r\n </body>\r\n</html>\r\n```\r\n\r\nLooking [at the source](https://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/parser/HtmlTreeBuilderState.java#L106), it seems only the HtmlTreeBuilderState handling for `<noframes>`, `<style>` and `<title>` in the methods `handleRawText` and `handleRcData` doesn't get along with the self-closing tags.\r\nAny other tagname I've checked (and I tried to cover all branches of that `case StartTag` switch) results in a good parse similar to the `<script>` case, which is what I'd expect.\r\n\r\nThanks for looking into this!\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_65": {
    "description": "Parser error on <template> inside <tr>\nI've been experimenting with jsoup as a validator for TensorBoard code and I encountered a bug.\r\n\r\nIf I have code like this:\r\n\r\n```html\r\n          <tr>\r\n            <th></th>\r\n            <th>Name</th>\r\n            <template is=\"dom-if\" if=\"{{smoothingEnabled}}\">\r\n              <th>Smoothed</th>\r\n            </template>   \r\n            <th>Value</th>\r\n            <th>Step</th>\r\n            <th>Time</th>\r\n            <th>Relative</th>\r\n          </tr>\r\n```\r\n\r\nI get errors like this:\r\n\r\nERROR: tensorflow/tensorboard/components/vz_line_chart/vz-line-chart.html (offset 1282): Unexpected token [StartTag] when in state [InTable]\r\nERROR: tensorflow/tensorboard/components/vz_line_chart/vz-line-chart.html (offset 1338): Unexpected token [EndTag] when in state [InTable]\r\nERROR: tensorflow/tensorboard/components/vz_line_chart/vz-line-chart.html (offset 1338): Unexpected token [EndTag] when in state [InBody]\r\n\r\nPlease note that those offset numbers point to the `<template>` tags.\r\n\r\nTemplate tag is legal here because https://www.w3.org/TR/html5/tabular-data.html#the-tr-element says content model for `tr` is \"Zero or more td, th, and script-supporting elements\" and `template` is a script supporting element.\n",
    "desc_source": "github_issue"
  },
  "Jsoup_66": {
    "description": "Method nextElementSibling() returns null after adding an element to a document that was cloned\nIf I clone a document, and add an element by the method `after()`, and try to get the new element by the method `nextElementSibling()` I get null. In the same time the method `nextSibling()` successfully returns this element.\r\nIf I do the same with the original document everything is fine.\r\n\r\nCode:\r\n\r\n    String html = \"<!DOCTYPE html><html lang=\\\"en\\\"><head></head><body><div>Initial element</div></body></html>\";\r\n    Document original = Jsoup.parse(html);\r\n    Document clone = original.clone();\r\n\r\n    Element originalElement = original.body().child(0);\r\n    originalElement.after(\"<div>New element</div>\");\r\n    Element originalNextElementSibling = originalElement.nextElementSibling();\r\n    Element originalNextSibling = (Element) originalElement.nextSibling();\r\n    System.out.println(\"originalNextElementSibling:\\n\" + originalNextElementSibling);\r\n    System.out.println(\"originalNextSibling:\\n\" + originalNextSibling);\r\n    System.out.println();\r\n\r\n    Element cloneElement = clone.body().child(0);\r\n    cloneElement.after(\"<div>New element</div>\");\r\n    Element cloneNextElementSibling = cloneElement.nextElementSibling();\r\n    Element cloneNextSibling = (Element) cloneElement.nextSibling();\r\n    System.out.println(\"cloneNextElementSibling:\\n\" + cloneNextElementSibling);\r\n    System.out.println(\"cloneNextSibling:\\n\" + cloneNextSibling);\r\n\r\nOutput:\r\n\r\n    originalNextElementSibling:\r\n    <div>\r\n     New element\r\n    </div>\r\n    originalNextSibling:\r\n    <div>\r\n     New element\r\n    </div>\r\n\r\n    cloneNextElementSibling:\r\n    null\r\n    cloneNextSibling:\r\n    <div>\r\n    New element\r\n    </div>\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_67": {
    "description": "Quadratic behaviour on deeply nested pages\nOn pages with very deep sequence of elements (like this one sv.stargate.wikia.com/wiki/M2J), Jsoup gets very slow and spends too much time in this function:\r\nhttps://github.com/jhy/jsoup/blob/master/src/main/java/org/jsoup/parser/HtmlTreeBuilder.java#L462\r\n\r\nIs there any way to remove this quadratic behaviour? Either by using better data structures or by having option to limit stack size (and throw exception when it is too deep).\n",
    "desc_source": "github_issue"
  },
  "Jsoup_68": {
    "description": "version 1.11.1 java.lang.StackOverflowError\nversion 1.10.3 no problem\r\nversion 1.11.1 java.lang.StackOverflowError\r\nExample URL\uff1a\r\nhttp://szshb.nxszs.gov.cn/\r\nhttp://www.lnfsfda.gov.cn/\r\nhttp://www.beihai.gov.cn/\r\nhttp://www.fsepb.gov.cn/\r\nhttp://www.bhem.gov.cn\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_69": {
    "description": "Removing nodes from forms using jsoup\nI'm having a problem removing nodes from forms using jsoup v1.7.3. The following code works as expected:\n\n```\nConnection.Response response = Jsoup.connect(\"myURL\").execute();\n\nDocument doc = response.parse();\n\n//prints HTML including \"input[name=alpha]\"\nSystem.out.println(doc.toString());\n\ndoc.select(\"input[name=alpha]\").first().remove();\n\n//prints HTML excluding \"input[name=alpha]\"\nSystem.out.println(doc.toString());\n\nFormElement form = (FormElement)doc.select(\"form\").first();\n\n//prints HTML excluding \"input[name=alpha]\"\nSystem.out.println(form.toString());\n```\n\nHowever, the following code appears to highlight a bug:\n\n```\nList<Connection.KeyVal> data = form.formData();\n\n//prints a list including \"alpha\"\nSystem.out.println(data.toString());\n```\n\nI would expect \"alpha\" to have been removed from the form data, but it hasn't. Is this a bug? Or am I doing something wrong?\n\n[Previously reported on [Stack Overflow](http://stackoverflow.com/questions/24104910/removing-nodes-from-forms-using-jsoup/24110967)]\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_70": {
    "description": "Whitespaces not properly handled in <pre> tag\nIf a \"pre\" tag contains deep nested tags, whitespaces in nested tags are not preserved.\n## Example:\n\n```\nString s = \"<pre><code>\\n\"\n        + \"  message <span style=\\\"color:red\\\"> other   \\n    message  with \\n\"\n        + \"   whitespaces      </span>\\n\"\n        + \"</code></pre>\";\n    Document doc = Jsoup.parse(s);\n    System.out.println(doc.select(\"pre\").first().outerHtml());\n```\n\nWill output:\n&lt;pre&gt;&lt;code&gt;\n  &nbsp;&nbsp;message &lt;span style=\"color:red\"&gt; other message with whiptespaces &lt;/span&gt;\n&lt;/pre&gt;&lt;/code&gt;\n\n---\n\nOutput is OK if we omit the \"code\" tag\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_71": {
    "description": "Please support text node selector\nPlease support some kind of text node selectors. Currently it's not possible to select a sibling text node of an element without coding Java. A possible expression would be:\nELEM + :text\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_72": {
    "description": "StringIndexOutOfBoundsException as of jsoup 1.11.1\nExample:\r\n\r\n    Jsoup.parse(new URL(\"https://gist.githubusercontent.com/valodzka/91ed27043628e9023009e503d41f1aad/raw/a15f68671e6f0517e48fdac812983b85fea27c16/test.html\"), 10_000);\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_73": {
    "description": "In w3c dom, siblings are incorrectly inheriting namespaces\nI am not sure if this is a bug or I am missing something that is defined in specification.\r\n\r\nWhen I am parsing (W3C DOM)  html file without namespace that have some element(s) with defined namespace, elements that are following will inherit that namespace.\r\n\r\nSmall test case and test html are included.\r\n\r\n[test.zip](https://github.com/jhy/jsoup/files/1478508/test.zip)\r\n\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_74": {
    "description": "&shy; renders as '-' when Node.text() is called\nConsider the following JUnit4 test \r\n```java\r\n@Test\r\npublic void testIfShyIsStripped(){\r\n        String htmlwithSHY = \"<html><body>quite&shy;a&shy;long&shy;word</body></html>\";\r\n        Document parse = Jsoup.parse(htmlwithSHY);\r\n        String text = parse.body().text();\r\n        assertEquals(\"quitealongword\", text);\r\n}\r\n```\r\nThis test fails as text is parsed as `quite-a-long-word` rather then it's actual textual representation that would have been `quitealongword` in any browser.\r\n\r\nPerhaps this is working as intended, but it would be interesting to understand the reasoning behind it.\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_75": {
    "description": "Regression - Boolean attributes not collapsed when using HTML syntax\nHello,\r\n\r\nFirst off, thanks for a really useful library.\r\n\r\nSo, upgrading from 1.10.2 to 1.11.2 we see that boolean attributes are no longer collapsed when using html syntax. Example test case:\r\n\r\n```\r\n    @Test\r\n    public void test() {\r\n        Document document = Jsoup.parse(\r\n                \"<html><head></head><body><hr size=\\\"1\\\" noshade=\\\"\\\"></body></html>\");\r\n        assertEquals(\"<html>\\n\" +\r\n                     \" <head></head>\\n\" +\r\n                     \" <body>\\n\" +\r\n                     \"  <hr size=\\\"1\\\" noshade>\\n\" +\r\n                     \" </body>\\n\" +\r\n                     \"</html>\",\r\n                     document.outerHtml());\r\n    }\r\n```\r\n\r\nTracked it down to commit \"Refactored Attributes to be an array pair vs LinkedHashSet \" ea1fb65. The `Attibutes.html(final Appendable accum, final Document.OutputSettings out)` method no longer uses `Attribute` and **fails** to check the value of the attribute for an _empty string_(line 320). \r\n\r\nIf I may also suggest to use `Attribute.shouldCollapseAttribute(String key, String val, Document.OutputSettings out)` instead as a single source of truth as the boolean expression is complex enough and easy to make a mistake. Not sure if this would have an impact in performance though but I am guessing that optimizer will inline the call at some point anyways? \n",
    "desc_source": "github_issue"
  },
  "Jsoup_76": {
    "description": "Newline after pre and textarea not handled properly\nThe WHATWG spec for HTML syntax indicates that if there is a newline directly after an opening `<pre>` or `<textarea>`, it should be removed.\r\n\r\nhttps://html.spec.whatwg.org/multipage/syntax.html#element-restrictions\r\n\r\njsoup currently does not do this:\r\n\r\n```\r\nJsoup.parse(\"<pre>\\nabc  def</pre>\").select(\"pre\").get(0).childNodes().get(0).text();\r\n// Outputs  \" abc def\"\r\n// Expected \"abc def\"\r\n```\r\n\r\nArguably, jsoup is also wrong for the value of `getWholeText()`, although I guess this depends on one's interpretation of what `getWholeText()` is supposed to do. I am hoping that it intends to correspond to the value of [Node.nodeValue](https://developer.mozilla.org/en-US/docs/Web/API/Node/nodeValue), in which case:\r\n\r\n```\r\nJsoup.parse(\"<pre>\\nabc  def</pre>\").select(\"pre\").get(0).childNodes().get(0).getWholeText();\r\n// Outputs  \"\\nabc  def\"\r\n// Expected \"abc  def\" \r\n\r\nJsoup.parse(\"<pre>\\n\\nabc  def</pre>\").select(\"pre\").get(0).childNodes().get(0).getWholeText();\r\n// Outputs  \"\\n\\nabc  def\"\r\n// Expected \"\\nabc  def\"\r\n```\n",
    "desc_source": "github_issue"
  },
  "Jsoup_77": {
    "description": "xmlParser() with ParseSettings.htmlDefault does not put end tag to lower case\n```java\r\n@Test public void test() {\r\n    Parser parser = Parser.xmlParser().settings(ParseSettings.htmlDefault);\r\n    Document document = Jsoup.parse(\"<div>test</DIV><p></p>\", \"\", parser);\r\n    assertEquals(\"<div>\\n test\\n</div>\\n<p></p>\", document.toString()); // fail -> toString() = \"<div>\\n test\\n <p></p>\\n</div>\"\r\n}\r\n\r\n@Test public void test1() {\r\n    Parser parser = Parser.xmlParser().settings(ParseSettings.htmlDefault);\r\n    Document document = Jsoup.parse(\"<DIV>test</div><p></p>\", \"\", parser);\r\n    assertEquals(\"<div>\\n test\\n</div>\\n<p></p>\", document.toString()); // pass\r\n}\r\n```\n",
    "desc_source": "github_issue"
  },
  "Jsoup_78": {
    "description": "Underlying input stream returned zero bytes\n```\r\nCaused by org.jsoup.c: java.io.IOException: Underlying input stream returned zero bytes\r\n       at org.jsoup.parser.CharacterReader.bufferUp(CharacterReader.java:60)\r\n       at org.jsoup.parser.CharacterReader.(CharacterReader.java)\r\n       at org.jsoup.parser.CharacterReader.(CharacterReader.java)\r\n       at org.jsoup.parser.TreeBuilder.defaultSettings(TreeBuilder.java:35)\r\n       at org.jsoup.parser.HtmlTreeBuilder.initialiseParse(HtmlTreeBuilder.java:66)\r\n       at org.jsoup.parser.TreeBuilder.parse(TreeBuilder.java:44)\r\n       at org.jsoup.parser.Parser.parseInput(Parser.java:39)\r\n       at org.jsoup.helper.DataUtil.parseInputStream(DataUtil.java:151)\r\n       at org.jsoup.helper.HttpConnection$Response.parse(HttpConnection.java:832)\r\n       at org.jsoup.helper.HttpConnection.get(HttpConnection.java:289)\r\n```\r\n\r\nThere isn't much information I can offer here.\r\nThis is with JSoup 1.11.1, with an attempt of parsing for a user's name.\r\n\r\nMy assumption is that the call is executing the following:\r\n\r\n```kotlin\r\nvar result = \"\"\r\ntry {\r\n\tresult = frostJsoup(cookie, FbItem.PROFILE.url).title()\r\n\tL.d(\"Fetch username found\", result)\r\n} catch (e: Exception) {\r\n\tif (e !is UnknownHostException)\r\n\t\te.logFrostAnswers(\"Fetch username failed\")\r\n} finally {\r\n\tif (result.isBlank() && (name?.isNotBlank() == true)) {\r\n\t\tcallback(name!!)\r\n\t\treturn@subscribe\r\n\t}\r\n\tif (name != result) {\r\n\t\tname = result\r\n\t\tsaveFbCookie(this@fetchUsername)\r\n\t}\r\n\tcallback(result)\r\n}\r\n```\r\n\r\nwhere cookie is the user's cooke, and the url is touch.facebook.com/me\r\n\r\nI'm not sure why this is a seemlingly fatal error though.\r\n\r\nAs usual, the full log and thread info can be found [here](http://crashes.to/s/92e0e5d0b69)\n",
    "desc_source": "github_issue"
  },
  "Jsoup_79": {
    "description": "LeafNode.childNodes() throws UnsupportedOperationException.\n`LeafNode.childNodes()` throws `UnsupportedOperationException` since this commit:\r\nhttps://github.com/jhy/jsoup/commit/f71712ba5d28df09c9a5b6e3c8a37f05f5e3372d#diff-605d28890f72a0f43298f842d0a3414f\r\n\r\nThe javadoc of `Node.childNodes()` says this:\r\n  `@return list of children. If no children, returns an empty list.`\r\n\r\nBut in the case of a LeafNode, which has no children, it throws `UnsupportedOperationException`. This is because `childNodes()` calls `ensureChildNodes()`, which throws an exception when called on a `LeafNode`.\r\n\r\nThe result is that the calling application needs to guard against this case. But the application should not need to know if the `Node` it has is a `LeafNode` or not.\r\n\r\n`LeafNode.childNodes()` should simply return an empty list as it used to do, and as per the javadoc.\r\n\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_80": {
    "description": "Faulty Xml Causes IndexOutOfBoundsException\n\r\n```java\r\n@Test\r\npublic void parseFaultyXml() {\r\n    String xml = \"<?xml version='1.0'><val>One</val>\";\r\n    Document doc = Jsoup.parse(xml, \"\", Parser.xmlParser());\r\n}\r\n```\r\n\r\nResults in:\r\n\r\n```\r\njava.lang.IndexOutOfBoundsException: Index: 0, Size: 0\r\n\r\n\tat java.util.ArrayList.rangeCheck(ArrayList.java:657)\r\n\tat java.util.ArrayList.get(ArrayList.java:433)\r\n\tat org.jsoup.nodes.Element.child(Element.java:254)\r\n\tat org.jsoup.parser.XmlTreeBuilder.insert(XmlTreeBuilder.java:91)\r\n\tat org.jsoup.parser.XmlTreeBuilder.process(XmlTreeBuilder.java:49)\r\n\tat org.jsoup.parser.TreeBuilder.runParser(TreeBuilder.java:52)\r\n\tat org.jsoup.parser.TreeBuilder.parse(TreeBuilder.java:45)\r\n\tat org.jsoup.parser.Parser.parseInput(Parser.java:34)\r\n\tat org.jsoup.Jsoup.parse(Jsoup.java:45)\r\n```\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_81": {
    "description": "Failure to guess correct XHTML encoding even when explicitly declared\n```\r\nString encoding = \"iso-8859-1\";\r\nInputStream soup = new ByteArrayInputStream((\r\n    \"<?xml version=\\\"1.0\\\" encoding=\\\"\" + encoding + \"\\\"?>\" +\r\n    \"<!DOCTYPE html PUBLIC \\\"-//W3C//DTD XHTML 1.0 Strict//EN\\\" \\\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\\\">\" +\r\n    \"<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\" lang=\\\"en\\\" xml:lang=\\\"en\\\">Hell\u00f6 W\u00f6rld!</html>\"\r\n    ).getBytes(encoding));\r\n\r\nSystem.out.println(Jsoup.parse(soup, null, \"\"));\r\n```\r\nprints:\r\n\r\n```\r\n<!--?xml version=\"1.0\" encoding=\"iso-8859-1\"?--><!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\r\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\">\r\n <head></head>\r\n <body>\r\n  Hell\ufffd W\ufffdrld!\r\n </body>\r\n</html>\r\n```\r\n\r\ninstead of expected output:\r\n\r\n```\r\n<!--?xml version=\"1.0\" encoding=\"iso-8859-1\"?--><!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\r\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\">\r\n <head></head>\r\n <body>\r\n  Hell\u00f6 W\u00f6rld!\r\n </body>\r\n</html>\r\n```\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_82": {
    "description": "UnsupportedOperationException thrown for charsets that don't support encoding\n```\r\npublic static void main(String[] args) throws IOException {\r\n\r\n    String html = \"<html><meta charset=\\\"ISO-2022-CN\\\"/></html>\";\r\n\r\n    System.out.println(\r\n        Jsoup.parse(new ByteArrayInputStream(html.getBytes()), null, \"\")\r\n    );  \r\n\r\n}\r\n```\r\n\r\nthrows\r\n\r\n<pre>\r\nException in thread \"main\" java.lang.UnsupportedOperationException\r\n\tat sun.nio.cs.ext.ISO2022_CN.newEncoder(ISO2022_CN.java:76)\r\n\tat org.jsoup.nodes.Document$OutputSettings.prepareEncoder(Document.java:443)\r\n\tat org.jsoup.nodes.Node$OuterHtmlVisitor.<init>(Node.java:704)\r\n\tat org.jsoup.nodes.Node.outerHtml(Node.java:573)\r\n\tat org.jsoup.nodes.Element.html(Element.java:1395)\r\n\tat org.jsoup.nodes.Element.html(Element.java:1389)\r\n\tat org.jsoup.nodes.Document.outerHtml(Document.java:195)\r\n\tat org.jsoup.nodes.Element.toString(Element.java:1422)\r\n\tat java.lang.String.valueOf(String.java:2982)\r\n\tat java.io.PrintStream.println(PrintStream.java:821)\r\n</pre>\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_83": {
    "description": "Could handle missing tag ends (>) better\nWe are using Jsoup to parse HTML documents from some external websites, which are not under our control. A few days ago, one of these sites updated their website, and introduced a bug, causing our crawling to fail spectacularly. The HTML which was broken looked a bit like this:\r\n\r\n```\r\n<td class=\"my-cell\"\r\n   <div class=\"great-formatting\">100</div>\r\n</td>\r\n```\r\n\r\nAs you can see, the TD is missing a closing `>`, while we did a `document.select(\"div.great-formatting\")`. This failed, because Jsoup couldn't parse the document correctly anymore. \r\n\r\nI understand it's a very edge case, and maybe very hard to fix. However, for us it was a production issue, and caused us quite a few headaches. Right now, we have a sort of preprocessor running over the HTML to close all elements which should be closed, but it would be much nicer if Jsoup would handle this out of the box. \r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_84": {
    "description": "W3CDom Helper fails to convert whenever some namespace declarations are missing\nHello\r\n\r\nI've been running into an issue where if I convert my Jsoup parsed document into a org.w3c.dom.Document with the W3CDom helper and that document happens to be missing namespace declarations we get the following exception:\r\n\r\n```\r\nNAMESPACE_ERR: An attempt is made to create or change an object in a way which is incorrect with regard to namespaces.\r\n```\r\n\r\nI've looked into this a bit and first thing I tried was using a locally forked version of the W3CDom helper that simply turned this flag off:\r\n\r\n```\r\nfactory.setNamespaceAware(false);\r\n```\r\n\r\nHowever the issue continued, so instead I simply hacked the code to completely ignore namespaces\r\n\r\n```\r\n// (csueiras): We purposely remove any namespace because we get malformed HTML that might not be\r\n// declaring all of it's namespaces!\r\nElement el = doc.createElementNS(\"\", sourceEl.tagName());\r\n```\r\n\r\nI am not completely sure if this will have any side effects, but it resolved the issues with the document I'm interacting with. I would be glad to provide a pull request if I have some guidance regarding how to properly handle this issue if it can be handled by Jsoup.\r\n\r\nThe document I'm having issues is simply making use of the Facebook like buttons using tags like this:\r\n\r\n```\r\n<fb:like ...\r\n```\r\n\r\nBut there's no namespace declaration for \"fb\".\n",
    "desc_source": "github_issue"
  },
  "Jsoup_85": {
    "description": "Attribute.java line 45 variable key scope error, it seems should be \"this.key\"\n![image](https://user-images.githubusercontent.com/41705526/49982508-ca65db80-ff11-11e8-9833-1775ddcc8871.png)\r\n\r\nAttribute.java Line 45, it should be:\r\n```java\r\nValidate.notEmpty(this.key);\r\n```\r\nrather than\r\n```java\r\nValidate.notEmpty(key);\r\n```\r\n\r\nThis issue only happens when **key** is blank or empty, in reality this would rarely happen, but in the syntax context it is still an issue, so better fix this.\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_86": {
    "description": "Jsoup 1.11.3: IndexOutOfBoundsException\nHi, I am using Jsoup 1.11.3. While trying to parse HTML content, I'm getting IndexOutOfBoundsException.\r\n\r\nI am using such Jsoup call as this is the only way to parse iframe content.\r\n\r\nJsoup call:\r\n\r\n`Jsoup.parse(html, \"\", Parser.xmlParser())`\r\n\r\nHTML is here:  https://files.fm/u/v43yemgb. I can't add it to the body as it's huge.\n",
    "desc_source": "github_issue"
  },
  "Jsoup_87": {
    "description": "wrong parsing with ParseSettings.preserveCase\njsoup version:1.11.3\r\nwhen using case sensitive settings,  parse wrong \r\n```java \r\npublic class TestJsoupParser {\r\n\r\n    public static void main(String[] args) {\r\n        Parser parser = Parser.htmlParser();\r\n        parser.settings(ParseSettings.preserveCase); // this line\r\n        String html = \"<div class=\\\"bdsharebuttonbox\\\">\"\r\n                + \"<A class=bds_more href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"more\\\">\u5206\u4eab\u5230\uff1a</A>\"\r\n                + \"<A title=\u5206\u4eab\u5230QQ\u7a7a\u95f4 class=bds_qzone href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"qzone\\\">\"\r\n                + \"</A><A title=\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a class=bds_tsina href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"tsina\\\"></A>\"\r\n                + \"<A title=\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a class=bds_tqq href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"tqq\\\"></A>\"\r\n                + \"<A title=\u5206\u4eab\u5230\u4eba\u4eba\u7f51 class=bds_renren href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"renren\\\"></A>\"\r\n                + \"<A title=\u5206\u4eab\u5230\u5fae\u4fe1 class=bds_weixin href=\\\"http://share.baidu.com/code#\\\" data-cmd=\\\"weixin\\\"></A>\"\r\n                + \"</div>\\r\\n\";\r\n        Document doc = Jsoup.parse(html, \"\", parser);\r\n        System.out.println(doc.html());\r\n    }\r\n    \r\n\r\n}\r\n```\r\n\r\nthe result is:\r\n\r\n```\r\n<html>\r\n <head></head>\r\n <body>\r\n  <div class=\"bdsharebuttonbox\">\r\n   <A class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\r\n    \u5206\u4eab\u5230\uff1a\r\n   </A>\r\n   <A class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\r\n    <A title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\"></A>\r\n    <A title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\">\r\n     <A title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\"></A>\r\n     <A title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\">\r\n      <A title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\"></A>\r\n      <A title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\">\r\n       <A title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\"></A>\r\n       <A title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\">\r\n        <A title=\"\u5206\u4eab\u5230\u5fae\u4fe1\" class=\"bds_weixin\" href=\"http://share.baidu.com/code#\" data-cmd=\"weixin\"></A>\r\n       </A>\r\n      </A>\r\n     </A>\r\n    </A>\r\n   </A>\r\n  </div>\r\n  <A class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\r\n   <A title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\">\r\n    <A title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\">\r\n     <A title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\">\r\n      <A title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\">\r\n       <A title=\"\u5206\u4eab\u5230\u5fae\u4fe1\" class=\"bds_weixin\" href=\"http://share.baidu.com/code#\" data-cmd=\"weixin\"> \r\n       </A>\r\n      </A>\r\n     </A>\r\n    </A>\r\n   </A>\r\n  </A>\r\n </body>\r\n</html>\r\n```\r\n\r\nhowever, when not use preserveCase , result is right\r\n```\r\n<html>\r\n <head></head>\r\n <body>\r\n  <div class=\"bdsharebuttonbox\">\r\n   <a class=\"bds_more\" href=\"http://share.baidu.com/code#\" data-cmd=\"more\">\u5206\u4eab\u5230\uff1a</a>\r\n   <a title=\"\u5206\u4eab\u5230QQ\u7a7a\u95f4\" class=\"bds_qzone\" href=\"http://share.baidu.com/code#\" data-cmd=\"qzone\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u65b0\u6d6a\u5fae\u535a\" class=\"bds_tsina\" href=\"http://share.baidu.com/code#\" data-cmd=\"tsina\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u817e\u8baf\u5fae\u535a\" class=\"bds_tqq\" href=\"http://share.baidu.com/code#\" data-cmd=\"tqq\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u4eba\u4eba\u7f51\" class=\"bds_renren\" href=\"http://share.baidu.com/code#\" data-cmd=\"renren\"></a>\r\n   <a title=\"\u5206\u4eab\u5230\u5fae\u4fe1\" class=\"bds_weixin\" href=\"http://share.baidu.com/code#\" data-cmd=\"weixin\"></a>\r\n  </div> \r\n </body>\r\n</html>\r\n```\n",
    "desc_source": "github_issue"
  },
  "Jsoup_88": {
    "description": "Attribute.getValue() broken for empty attributes since 1.11.1\n```\r\n        Document doc = Jsoup.parse(\"<div hidden>\");\r\n        Attributes attributes = doc.body().child(0).attributes();\r\n        System.out.println(String.format(\"Attr: '%s', value: '%s'\", \"hidden\",\r\n                attributes.get(\"hidden\")));\r\n\r\n        Attribute first = attributes.iterator().next();\r\n        System.out.println(String.format(\"Attr: '%s', value: '%s'\",\r\n                first.getKey(), first.getValue()));\r\n```\r\n\r\nExpected output, as in 1.10.x\r\n```\r\nAttr: 'hidden', value: ''\r\nAttr: 'hidden', value: ''\r\n```\r\n\r\nOutput in 1.11.1-1.11.3:\r\n```\r\nAttr: 'hidden', value: ''\r\nAttr: 'hidden', value: 'null'\r\n```\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_89": {
    "description": "NPE in Attribute.setValue() for attribute without parent\n```\r\n    public String setValue(String val) {\r\n        String oldVal = parent.get(this.key);\r\n        if (parent != null) {\r\n            int i = parent.indexOfKey(this.key);\r\n            if (i != Attributes.NotFound)\r\n                parent.vals[i] = val;\r\n        }\r\n        this.val = val;\r\n        return oldVal;\r\n    }\r\n```\r\nIts useless to check `parent` for `null` after it has been dereferenced. I guess this is a copy-paste-bug:\r\n```\r\n    public void setKey(String key) {\r\n        Validate.notNull(key);\r\n        key = key.trim();\r\n        Validate.notEmpty(key); // trimming could potentially make empty, so validate here\r\n        if (parent != null) {\r\n            int i = parent.indexOfKey(this.key);\r\n            if (i != Attributes.NotFound)\r\n                parent.keys[i] = key;\r\n        }\r\n        this.key = key;\r\n    }\r\n```\n",
    "desc_source": "github_issue"
  },
  "Jsoup_90": {
    "description": "ArrayIndexOutOfBoundsException when parsing with some URL\n### error\r\n```\r\nCaused by: java.lang.ArrayIndexOutOfBoundsException: 11\r\n\tat org.jsoup.helper.HttpConnection$Base.looksLikeUtf8(HttpConnection.java:437)\r\n\tat org.jsoup.helper.HttpConnection$Base.fixHeaderEncoding(HttpConnection.java:400)\r\n\tat org.jsoup.helper.HttpConnection$Base.addHeader(HttpConnection.java:386)\r\n\tat org.jsoup.helper.HttpConnection$Response.processResponseHeaders(HttpConnection.java:1075)\r\n\tat org.jsoup.helper.HttpConnection$Response.setupFromConnection(HttpConnection.java:1019)\r\n\tat org.jsoup.helper.HttpConnection$Response.execute(HttpConnection.java:752)\r\n\tat org.jsoup.helper.HttpConnection$Response.execute(HttpConnection.java:722)\r\n\tat org.jsoup.helper.HttpConnection.execute(HttpConnection.java:306)\r\n```\r\n\r\n### code\r\n```\r\ntry {\r\n            String url = \"https://www.colisprive.com/moncolis/pages/detailColis.aspx?numColis=P4000000037777930\";\r\n            Connection connection = Jsoup.connect(url).referrer(url).\r\n                    userAgent(\"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36\")\r\n                    .ignoreContentType(true).timeout(20000);\r\n           \r\n            connection.method(Method.GET);\r\n            return connection.execute().parse();\r\n        } catch (Exception e) {\r\n            throw new RuntimeException(e);\r\n        }\r\n```\n",
    "desc_source": "github_issue"
  },
  "Jsoup_91": {
    "description": "Jsoup.parse method hangs for certain bogus input text\nWe are indexing the [ClueWeb12](https://lemurproject.org/clueweb12/) dataset using [lucene-clueweb-retrieval](https://github.com/iorixxx/lucene-clueweb-retrieval) library. We are using JSoup to parse Web pages. After a (drop-in) upgrade to JSoup version 1.11.3, our indexing processes hanged. Note than this was not the issue for earlier version of JSoup. Using jstack we spot document(s) that cause this problem crated a failing test case using it. We understand that the input is bogus (not a html code, but a binary file), but we expect JSoup to throw an exception or return an empty string. But the program hangs and never ends. We would like to report this to the community in the hope for obtaining a fix for the issue.\n",
    "desc_source": "github_issue"
  },
  "Jsoup_92": {
    "description": "Duplicated attribute parsing problem \nIn case there is duplicated tag attribute Jsoup parses the last one, but Chrome browser takes the first one.\r\n\r\n\n",
    "desc_source": "github_issue"
  },
  "Jsoup_93": {
    "description": "<input type=\"image\"> is not special cased in formData method\nThe following code:\r\n\r\n```java\r\nimport org.jsoup.Jsoup;\r\nimport org.jsoup.nodes.FormElement;\r\n\r\nclass Scratch {\r\n    public static void main(String[] args) {\r\n        System.out.println(((FormElement) Jsoup.parse(\"<form id=f><input type=image name=x></form>\").getElementById(\"f\")).formData());\r\n    }\r\n}\r\n```\r\n\r\nReturns the following output:\r\n\r\n```\r\n[x=]\r\n```\r\n\r\nWhen either `[]` or `[x.x=0, x.y=0]` is expected (not sure which, but `[x=]` is definitely wrong).\n",
    "desc_source": "github_issue"
  }
}